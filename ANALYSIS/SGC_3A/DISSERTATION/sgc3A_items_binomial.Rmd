---
title: "SGC3_A Items"
output: 
  # rmdformats::robobook:
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
---

*The purpose of this notebook is to analyze item-level data collected for study SGC-3: The Insight Hypothesis *

```{r SETUP, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#IMPORT LIBRARIES
library(rmdformats)
library(dplyr) #tidyverse data handling
library(tidyr) #pivot
library(knitr) #printing tables
library(forcats)#for factor re-ordering
library(ggpubr) #joining plots (alt to gridExtra)
# library(tables) # pretty tables
library(pastecs) #stat.desc
library(mosaic) #simple descriptives [favstats]

library(ggplot2) #graphs
library(car) #ANOVA, qqplot
library(effectsize) #effect size
# library(pwr) #power analysis

library(lme4) #linear mixed effects model


#Set custom colors 
lgrey = "#cacec8"
lgreen = "#c6edbb"
lyellow = "#FBEEBB"
lblue = "#BCD9EE"

```
  
```{r IMPORT-DATA, message= FALSE}  

#IMPORT DATA from fall and spring files
fall_items <- "data/fall17_sgc3a_blocks.csv"
spring_items <- "data/spring18_sgc3a_blocks.csv"
online_items <- "data/fall21_sgc3a_blocks.csv"

df_fall <- read.csv(fall_items)
df_spring <- read.csv(spring_items)
df_online <- read.csv(online_items)

#Create combined data frames
df_items <- rbind(df_fall, df_spring, df_online)

#Create extra fields 
df_items$time_sec <- df_items$rt / 1000 #item time in seconds

#Create answer-consistency column (desired values in column : TRI, ORTH, BOTH, NONE)
df_items$consistency = 0 #set initial dummy values
df_items <- df_items %>% mutate(consistency = replace(consistency, correct==1 & orth_correct==1, "Both"), #both
                                consistency = replace(consistency, correct==0 & orth_correct==1, "Ortho"), #orthogonal
                                consistency = replace(consistency, correct==1 & orth_correct==0, "Tri"), #triangular
                                consistency = replace(consistency, correct==0 & orth_correct==0, "Neither"), #neither
                                consistency = replace(consistency, answer=="", "BLANK")) #neither and BLANK
                   
#Create TOTAL column for future sorting
df_totals <- df_items %>% filter(!q ==16) %>% group_by(subject)  %>% summarise(TOTAL = sum(correct))
df_items <- left_join(df_items, df_totals)

# #Code incorrect responses (not triangular or otho correct)
# df_items$response <- df_items$orth_correct + df_items$correct #items not correct in tri or orth interpretation
# df_items$response <- dplyr::recode( df_items$response, `1`= "right", `2`="both", `0`="wrong" )
# df_items$incorrect <- dplyr::recode( df_items$response, "right"=0, "both"=0, "wrong"=1 )

#Create factors 
df_items <- df_items %>% mutate(
  subject = as.factor(subject),
  session = as.factor(session),
  term = as.factor(term),
  condition = as.factor(condition),
  consistency = as.factor(consistency),
  explicit = as.factor(explicit),
  impasse = as.factor(impasse),
  axis = as.factor(axis),
  q = as.factor(q),
  correct = as.factor(correct),
  orth_correct = as.factor(orth_correct),
  question = as.factor(question),
  error = 0 #temporary holder for error codes
)

#Change values of column names for later reshaping
# df_items <- rename(df_items, rs_incorrect = incorrect)
df_items <- rename(df_items, rs_tri = correct)
df_items <- rename(df_items, rs_ortho = orth_correct)

#Separate free response from (main) multiple choice blocks
df_freeResponse <- df_items %>% filter(q==16)
df_items <- df_items %>% filter (q!=16)

#Differentiate in-person and online
df_inperson <- df_items %>% filter (term %in% c("fall17", "spring18"))
df_online <- df_items %>% filter (term == "fall21")

#Cleanup temporary dataframes
rm(df_fall, df_spring, df_totals)


```
```{r}

# cnt_items <- table(df_items$condition, df_items$rs_tri)
cnt_items

chisq <- chisq.test(cnt_items)
chisq

prop.table(cnt_items,1)#proportion of entire row

```


```{r}
#build a contingency table
df_items %>% select(condition,rs_tri) %>% group_by(condition, rs_tri) %>% summarize(n=n())


my_table_0 <- table(df_tbl$x1, fk_data$x2)
print.table(my_table_0)


```
```{r}
chisq <- chisq.test(df_tbl)
chisq

```

```{r}
#PLOT response accuracy by condition
# data = df_items %>% filter(!q %in% c(1,2,3,4,5,6)) %>% filter(term == "fall21")
#plot accuracy by condition
gf_jitter(rs_tri ~ condition, color=~term, data = df_items) %>% 
  gf_labs(title = "(triangular) Response Accuracy by Condition")

```

```{r}

#binomial model 
# outcome: rs_tri [0,1]
# fixed: condition
# random: q, subject

df_data <- df_items %>% select(condition,rs_tri, subject,q)
df_data$condition <- dplyr::recode( df_data$condition, `111`= 0, `121`=1)



m1 <- glmer(rs_tri ~ condition + (1 | subject), data = df_data, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

# print the mod results without correlations among fixed effects
print(m1, corr = FALSE)

```


```{r}
se <- sqrt(diag(vcov(m1)))
# table of estimates with 95% CI
(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *
    se))

```




//TODO BINOMIAL REGRESSION  [BINARY]
//fixed | condition
//random | subject, item
// ?modelling interpretation ;) as 



# TIMECOURSE OF ACCURACY

I have the intuition that (for an individual participant) accurate — inaccurate responses are not randomly distributed across the timecourse of the study. There should be a substantial learning effect, such that response are incorrect — until the individual has LEARNS how the coordinate system works - and then responses will be correct. 

```{r}

#FILTER question-response data 
l_timecourse <- df_items %>% filter(!q %in% c(6,9,16)) %>% #remove questions 6,9 where tri == ortho correct
  select(subject,impasse,q,consistency,TOTAL)

#ORDER dataframe by subject total amount
l_timecourse <- l_timecourse %>% mutate(subject = fct_reorder(l_timecourse$subject, l_timecourse$TOTAL, min))

#WIDE dataframe (for manual inspection)
w_timecourse <- l_timecourse %>% spread(q,consistency)

#VISUALIZE
facetlabels <- c("1"="control", "2"="impasse")
p1 <- ggplot(l_timecourse %>% filter(impasse ==1), aes(x = q, y = subject, fill = consistency, palette = "jco")) +
  facet_grid(~ impasse, labeller = labeller(impasse=facetlabels)) +
  geom_raster() + scale_fill_manual(values = c("#cacec8", "#FBEEBB", "#BCD9EE","#c6edbb")) +
  labs(x="Question Sequence", fill = "Response Type")

p2 <- ggplot((l_timecourse %>% filter(impasse==2)), aes(x = q, y = subject, fill = consistency)) +
  facet_grid(~ impasse, labeller = labeller(impasse=facetlabels)) +
  geom_raster() + scale_fill_manual(values = c("#cacec8", "#FBEEBB", "#BCD9EE","#c6edbb")) +
  labs(x="Question Sequence", fill = "Response Type", facet="control")

figure <- ggarrange(p1, p2, ncol=1) 
annotate_figure(figure,
        top = text_grob("Timecourse of Response Type by Participant and Condition", color = "black", face = "bold", size = 14))

```
<br>
<span style="color: red;">TODO: This plot of Response Type by Question (in sequence) for each participant demonstrates that ... </span>.

```{r message=FALSE}

#SUMMARIZE items response-type by question (which relation is being asked)
df_items$dummy <- 1 #add a temporary dummy column for counting
df_questions <- df_items %>% 
  filter(!q %in% c(6,9)) %>% 
  group_by(q,condition) %>% 
  select(q,question,rs_tri, rs_ortho, consistency, dummy) %>% 
  summarize(n=n(), 
            rs_tri = sum(rs_tri), 
            rs_ortho = sum(rs_ortho),
            rs_blank = sum(dummy[consistency == "BLANK"]),
            rs_neither = sum(dummy[consistency == "Neither"]),
            question = question[1])

#convert to LONG dataframe
l_questions <- df_questions %>%
  pivot_longer(cols = starts_with("rs_"), names_to = "answer_type", values_to = "count")

#update factor level order in order to maximize comparison in plot
l_questions$answer_type = factor(l_questions$answer_type)
l_questions$answer_type <- relevel(l_questions$answer_type, 'rs_neither')

#TOTAL ACROSS CONDITIONS
ggplot(data = l_questions, aes (x = q, y=count, fill=answer_type))+
  geom_bar(position="stack", stat="identity") + 
  facet_grid(~condition) +
  scale_fill_manual(values = c(lyellow, lgrey,lblue,lgreen)) +
  labs(title = "Answer Type by Question and Condition", x="Question Sequence", y="Count(n)", fill = "Response Type")
```

<br>
<span style="color: red;">TODO: This plot of Response Type by Question (in sequence) and Condition demonstrates that... </span>.

<br>
<span style="color: red;">TODO: Test this with a linear mixed effects model. </span>.

# WIP ALTERNATIVE ANSWERS

## Q1: Starts

What are the alternative answers subjects give for the *first* question?

```{r}
#Create a contingency table with marginal sums for all answers across both conditions on Q1
df_q1 <- df_items %>% filter(q==1)
t <- table(df_q1$answer, df_q1$condition)
t <- t[order(-rowSums(t)),] #reorder by marginal freqency
addmargins(t)

```
### A:: Orthogonal or Satisficing?

```{r}
img_path <- "images/q1_A.png"
include_graphics(img_path)
```
<br> **(control: `r t[1,1]`, impasse: `r t[1,2]`)** The most common erroneous response is the "A". In the control condition, this is the orthogonal distractor. However, in the impasse condition, the 'A' is *not* orthogonal to the directed start time, but the closest nearly orthogonal response. **Potentially revealing a satisficing strategy? Or visual error in seeing it as an orthogonal intersect?**

```{r}

#A 
subjects <- df_items %>% filter(q==1 & answer == "A") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$condition ==111) & (df_items$answer == "A"),]$error = "orthogonal"
df_items[(df_items$q==1) & (df_items$condition ==121) & (df_items$answer == "A"),]$error = "visualerror-right-30"

```

### F :: Triangular

```{r}
img_path <- "images/q1_F.png"
include_graphics(img_path)
```
<br> **(control: `r t[2,1]`, impasse: `r t[2,2]`)** The second most common response was the correct (triangular) response "F". In the impasse condition, there are no orthogonal-distractors. In the control condition, the A datapoint acts as an orthogonal distractor. 

```{r}
#F 
subjects <- df_items %>% filter(q==1 & answer == "F") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$condition ==111) & (df_items$answer == "F"),]$error = ""
df_items[(df_items$q==1) & (df_items$condition ==121) & (df_items$answer == "F"),]$error = ""

```

### No Response 

```{r}
img_path <- "images/q1_blank.png"
include_graphics(img_path)
```
<br> **(control: `r t[3,1]`, impasse: `r t[3,2]`)** The third most common response was (blank) no response, though this only occurred in the impasse condition; likely when subjects could not locate an orthogonal distractor, and **chose not to revert to an alternative strategy**. 

```{r}
#BLANK 
subjects <- df_items %>% filter(q==1 & answer == "") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)


#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AF"),]$error = "fixed-no-response" #graphical fixedness, no response

```

### O :: Visual Error or Satisficing?

```{r}
img_path <- "images/q1_O.png"
include_graphics(img_path)
```
<br> **(control: `r t[4,1]`, impasse: `r t[4,2]`)** The fourth most common response was an O though this only occurred in the impasse condition.Similar to the 1 person who entered an 'A', the 'O' response indicates **either a visual-alignment error (thinking the O is an orthogonal intersector) OR a satisficing strategy to select the closes non-orthogonal data point.**  However, A is both closer (in y-distance height) as well as (x-distance). A has an orthogonal intersection of +0:30m, while O has an orthogonal intersection of -0:30m. However, because O has a greater duration (higher in the graph) the visual angle between 11am and 0 is less than that of A, making it more likely to be confused as true orthogonal intersection. In this sense, it sensical that event O has `t[4,2]` responses and A only `t[1,2]` responses. 

<span style="color: red;">TODO: Can mousepath be used to differentiate between a visual error (thinking O was orthogonal) and a satisficing decicion (closes point to orthogonal line)? </span>. If the subject traces up from the start time, A is the first data point [impasse condition] they would come across. My inutuition is that folks that trace the orthogonal would select A, and folks that don't (i.e. are just inspecting the graph and not using the mouse) would be more likely to select 0. 


```{r}
#O 
subjects <- df_items %>% filter(q==1 & answer == "O") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AF"),]$error = "visualerror-left-30" 
```


### CF :: Lines Connect 

```{r}
img_path <- "images/q1_CF.png"
include_graphics(img_path)
```
<br> **(control: `r t[5,1]`, impasse: `r t[5,2]`)** The fifth most common response was the two-item entry C and F, both of which are diagonal intersects with the start time. However, this response violates the encoding convention that a given referent (i.e start time) has a single spatial encoding in the representation. **This suggests a partial understanding of something diagonal about the coordinate system; the reader is attending to the gridlines and using them to intersect data and the x-axis. However, they've not decoded the spatial referent of start time vs. end time.** 

<span style="color: red;">TODO: I would suspect this acts as a transition strategy, or an indication of partial undertanding that may eventually lead to full understanding, and unlikely to revert to orthogonal. MODEL THIS. </span>.

```{r}
#CF 
subjects <- df_items %>% filter(q==1 & answer == "CF") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AF"),]$error = "lines-connect" 
```

### AI :: Satisficing or Visual Error 

```{r}
img_path <- "images/q1_AI.png"
include_graphics(img_path)
```
<br> **(control: `r t[6,1]`, impasse: `r t[6,2]`)** The sixth most common response was the two item: A,I, with only having responses in the impasse condition. Both A and I are near-orthogonal distracts of 11AM, with +0:30m offset, **suggesting this is either a satisficing or visual error case.**  We do not see this response in the control condition, most likely because there is a true orthogonal intersect. 

```{r}
#AI
subjects <- df_items %>% filter(q==1 & answer == "AI") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AI"),]$error = "visualerror-right-2" 
```

### AF :: Clerical Error

```{r}
img_path <- "images/q1_AF.png"
include_graphics(img_path)
```
<br> **(control: `r t[7,1]`, impasse: `r t[7,2]`)** One subject in the control condition selected *both* the triangular and orthogonal-consistent responses. Considering this was only a single subject, and the multiple choice checkboxes were directly underneath each other in the response list, it is plausible that this was a clerical error, whereby the subject selected one response, and then the other, without unchecking the other box. 

**TODO: Can we verify this from the mouseclick stream data? **

```{r}
#AF
subjects <- df_items %>% filter(q==1 & answer == "AF") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lyellow,lgreen,lblue,lgrey)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AF"),]$error = "clerical" 
```


### AO :: Special Case? Visual Error? 

```{r}
img_path <- "images/q1_AO.png"
include_graphics(img_path)
```
<br> **(control: `r t[8,1]`, impasse: `r t[8,2]`)** One subject in the impasse condition selected both events A and O, each near-orthogonal distractors, but in opposite directions. This sits as a hybrid between 'lines connect' in that they are both off the orthogonal intersection, and visual error. However, since the options are both off the orthogonal line, it seems unlikely the individual saw them both as accurate orthogonal intersects.  

**TODO: What is happening here? Can we recreate from the mouseclick data? Another clerical error? or something more interesting?** 

```{r}
#AO
subjects <- df_items %>% filter(q==1 & answer == "AO") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lyellow,lblue,lgreen,lgrey)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AO"),]$error = "visualerror-right-left" 
```

**How did this subject have an accidental? triangular answer on Q5?  


### C :: Backwards

```{r}
img_path <- "images/q1_C.png"
include_graphics(img_path)
```
<br> **(control: `r t[9,1]`, impasse: `r t[9,2]`)** One subject in the impasse condition selected event C, which is a diagonal intersect with the given start time, but ends, rather than starts, at 11. 

**I'm surprised to not see more of these type of responses, actually!**

```{r}
#C
subjects <- df_items %>% filter(q==1 & answer == "C") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "AO"),]$error = "backwards" 
```
**How did this subject have an accidental? triangular answers on Q4 Q10 Q14?  


### I :: Visual Error?

```{r}
img_path <- "images/q1_I.png"
include_graphics(img_path)
```
<br> **(control: `r t[10,1]`, impasse: `r t[10,2]`)** One subject in the impasse condition selected event I, which is a near-orthogonal distractor. What is interesting about this answer, is that the individual does NOT also select A, which falls along the same orthogonal intersect. **This might suggest that a visual error judging I as orthogonal to 11 (but not A) because the it is so much higher in the graph**. 

**I'm surprised to not see more of these type of responses, actually!**

```{r}
#O
subjects <- df_items %>% filter(q==1 & answer == "O") %>%  select(subject)
ggplot(l_timecourse %>% filter(subject %in% subjects$subject), aes(x = q, y = subject, fill = consistency)) + 
  geom_raster() + scale_fill_manual(values = c(lgrey,lyellow,lblue,lgreen)) + facet_grid(~ impasse)

#CODE ERROR TYPES from manual inference  
df_items[(df_items$q==1) & (df_items$answer == "O"),]$error = "visualerror-right" 
```

## RESPONSE LATENCY

### 1.1 Distribution of Response Latency

What is the distribution of response times per question?

```{r}
#SUMMARIZE response time 
time.stats <- favstats(~time_sec, data = df_items)
time.stats
```
Response time per question (n=1890) ranged from 1.2s to 336s (5.5 minutes), with a M=35.5s, SD = 33.12s. 

```{r message=FALSE, results=FALSE}

#VISUALIZE distribution of response times per question
gf_dhistogram(~time_sec, binwidth = 5, data = df_items) %>%
gf_vline(xintercept = ~time.stats$mean, color = "blue") %>%
gf_fitdistr(color="blue") %>% 
gf_labs(title ="Distribution of response latency (per item)")

#VERIFY normality of resulting data with qqPlot
qqPlot(~time_sec, data = df_items)
```
However, the distribution is clearly not normal, so it is appropriate to transform the response latency variable. 

### 1.2 TRANSFORM Response Latency
```{r message=FALSE, results=FALSE}

#APPLY a log transform
df_items$log_time <- log(df_items$time_sec)
log_time.stats <- favstats(~log_time, data = df_items)
log_time.stats

gf_dhistogram(~log_time, data = df_items) %>%
gf_vline(xintercept = ~log_time.stats$mean, color = "blue") %>%
gf_fitdistr(color="blue") %>% 
gf_labs(title ="Distribution of response latency (LOGT) on first question", x="Log-transform (seconds)")

#VERIFY normality of resulting data with qqPlot
qqPlot(~log_time, data = df_items)

```
<br>
<span style="color: red;">TODO: Is this an appropriate outcome? What about the hump at the start of the plot?</span>.



## FIRST QUESTION
### 1.1 Response Latency (First Question)

What is the distribution of response times on the very first question?

```{r}
df_q1 <- df_items %>% filter (q==1)
q1.stats <- favstats(~time_sec, data = df_q1)
q1.stats
```
<br> <br> 
Response time (in seconds) on the first question (n=126) ranged from 7.2 to 161 seconds, with a M = 44.5, SD = 26.2. The distribution is clearly not-normal. 

```{r message=FALSE, results=FALSE}
gf_dhistogram(~ time_sec, data = df_q1) %>%
gf_vline(xintercept = ~q1.stats$mean, color = "blue") %>%
gf_fitdistr(color="blue") %>% # gf_dist("norm", color="blue", params=list(q1.stats$mean, q1.stats$sd), xlim(0,50)) %>% 
gf_labs(title ="Distribution of response latency on first question")

#VERIFY normality of resulting data with qqPlot
qqPlot(~time_sec, data = df_q1)

```




### 1.2 Response Latency by Condition (First Question)

Do response times differ by condition? 
TODO: EXPLORE how to model reaction time. https://lindeloev.github.io/shiny-rt/ 

```{r messages = FALSE}

time.stats <- favstats(time_sec ~ condition, data = df_q1)
time.stats

gf_dhistogram(~time_sec, fill = ~condition, data = df_q1) %>% 
  gf_facet_grid(condition~.) %>% 
  gf_vline(xintercept = ~mean, color = "red", data = time.stats)
```
The average total response latency (entire 15 question block) for the control condition was slightly higher (M = 9.54s, SD = 3.09) than the impasse-scaffold condition (M = 8.9, 2.69s)

```{r messages = FALSE}

time.stats <- favstats(log_time ~ condition, data = df_q1)
time.stats

gf_dhistogram(~log_time, fill = ~condition, data = df_q1) %>% 
  gf_facet_grid(condition~.) %>% 
  gf_vline(xintercept = ~mean, color = "red", data = time.stats)
```

```{r}
qqPlot(~log_time, data = df_q1)
```


```{r}
#LINEAR MODEL with dependent variable
m1 <- lm(time_sec ~ condition, data = df_q1)
summary(m1)

#LINEAR MODEL with log-transformed dependent variable
mT <- lm(log_time ~ condition, data = df_q1)
summary(mT)
```
The difference in average response time (for the first question) IS  statistically significant F(1,124) = 10.61 , p < 0.05, with a linear model predicting response time from condition explaining around 8% of variance. (The log-transform model reduces residual standard error from 25 to 0.5.)


## Question Types
TODO consider item type [what relation is being tested]








# VALIDATION


## Verify item totals
First, verify (sanity check!) that the flatten.js data wrangling scripts were correct by generating participant totals directly from item-level data, and compare with participant level file. Comparison of summarized data from item_level files and participant level file show that the question accuracy totals for each participant are the same. 

```{r}
# 
# #SUMMARIZE FROM ITEMS FILES
# df_item_sanity <- df_items %>% filter(!q == 16) %>% group_by(subject) %>% summarise(
#   tri_correct = sum(rs_tri),
#   orth_correct = sum(rs_ortho),
#   total = tri_correct + orth_correct) %>% 
#   mutate( subject = factor(subject)) %>% 
#   arrange(desc(subject))
# 
# #SUMMARIZE FROM PARTICIPANT FILES
# fall_participants <- "data/fall_sgc3a_participants.csv"
# spring_participants <- "data/spring_sgc3a_participants.csv"
# df_fall_p <- read.csv(fall_participants)
# df_spring_p <- read.csv(spring_participants)
# df_participants_sanity <- rbind(df_fall_p, df_spring_p) %>% 
#   mutate(subject = factor(subject), 
#          tri_correct = triangular_score, 
#          orth_correct = orthogonal_score,
#          total = tri_correct + orth_correct
#          ) %>% 
#   select(subject, tri_correct, orth_correct, total) %>% 
#   arrange(desc(subject))
# 
# #CHECK EQUALITY
# all_equal(df_participants_sanity,df_item_sanity)
# 
# #REMOVE TEMPORARY DFS
# rm(fall_participants, spring_participants, df_participants_sanity, df_fall_p,df_spring_p)
# 
# df_items_by_participant <- df_item_sanity
# rm(df_item_sanity, df_fall, df_spring)

```

## Verify session totals
How many subjects were run in each data collection session?

```{r}
#MANUALLY INSPECT SESSIONS
df_items %>% group_by(session) %>% 
  summarize(n=length(unique(subject)))
```

```{r}
sessionInfo()
```