{
  "hash": "85b922393af0a6a066d46af4fc8b1e05",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC2 | Hypothesis Testing'\n---\n\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC2-hypotesting}\n\n**TODO ADD INTERACTIONS**\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC2 study.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc) # %nin% operator\nlibrary(mosaic) #favstats\nlibrary(jtools) #prettier model summ(m)\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggeasy) #easy edits to ggplots \n\n#plot model estimates with uncertainty\nlibrary(ggdist)\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\n\n#models and performance\nlibrary(lmerTest) #for CIs in glmer \nlibrary(ggstatsplot) #plots w/ embedded stats\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\n# library(equatiomatic) #extract model equation\n# library(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models \nlibrary(ggeffects) #visualization log regr models\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\ntheme_set(theme_minimal()) \n```\n:::\n\n\n**Research Questions**\n\nIn SGC2 we compare learner performance on the linear and triangular model graphs by testing the effectiveness of 4 scaffolds and by seeking to replicate the Qiang et.al (2014) finding that after 20 minutes of video training, students perform faster and more accurately with the unconventional TM than the conventional Linear Model (LM). Will our participants show similar performance on the TM with scaffolds rather than formal instruction? Further, will engagement with the TM in a reading task be sufficient for students to reproduce the graph in a subsequent drawing task?\n\n**Hypotheses**\n\n1.  Learners without scaffolding (control) will perform better with the LM than TM\n2.  Learners with (any form of) scaffolding will perform better with the TM than LM (replication of \\[12\\]).\n3.  Based on observations in Study One we expect that graph-order will act as a scaffold. Learners who solve problems with the LM graph first will perform better on the TM (relative to TM-first learners) as their attention will be drawn to the salient differences between the graphs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nmbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(mbp)\n\n#IMPORT DATA \ndf_items <- read_rds('analysis/SGC2/data/2-scored-data/sgc2_items.rds')\ndf_subjects <- read_rds('analysis/SGC2/data/2-scored-data/sgc2_participants.rds') \n```\n:::\n\n\n## H1 \\| The Need for Scaffolding\n\n**Hypothesis** The TM graph is not *discoverable* and requires scaffolding for correct interpretation. We predict that learners without scaffolding (the control condition) will perform better with the LM than TM\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Do Ss in the CONTROL condition perform better on the LINEAR graph than the TRIANGULAR graph?                            |\n+=======================+=========================================================================================================================+\n| **Hypothesis**        | Ss in the CONTROL condition will have higher scores on the LINEAR graph than the TRIANGULAR graph                       |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | data: `df_subjects` where `condition == 1`                                                                              |\n|                       |                                                                                                                         |\n|                       | outcome:                                                                                                                |\n|                       |                                                                                                                         |\n|                       | -   *linear graph accuracy* `linear_score` \\[absolute score\\]                                                           |\n|                       | -   *triangular graph accuracy* `triangular_score`                                                                      |\n|                       |                                                                                                                         |\n|                       | predictor: `graph` (block) \\[within-subjects factor\\]                                                                   |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Paired Samples T-Test                                                                                               |\n|                       |     -   compare average accuracy score in linear vs triangular block                                                    |\n|                       |     -   either T-Test or Wilcoxon Rank Sum (paired sample) alternative if difference scores are is non normal           |\n|                       |                                                                                                                         |\n|                       | *Alternative*                                                                                                           |\n|                       |                                                                                                                         |\n|                       | 1.  Linear Mixed Effects Model \\[violates normality of residuals\\]                                                      |\n|                       |     -   predict subject `score` \\[0-15\\] by `graph` with random intercept for `subject`                                 |\n|                       |     -   demonstrate that `score` is independent of `order` \\[nested\\] and `scenario` \\[nested\\]                         |\n|                       | 2.  Logistic Mixed Effects Model                                                                                        |\n|                       |     -   predict item `score` \\[0,1\\] by `graph` with random intercept for `subject` and random intercept for `question` |\n|                       |                                                                                                                         |\n|                       |     -   demonstrate than `score` is independent of `order` and `scenario`                                               |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             |                                                                                                                         |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#FILTER THE DATASET\ndf <- df_subjects %>% filter(condition == 1)\n\ndf_long <- df %>% dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios,linear_score, triangular_score) %>% pivot_longer(\n  cols = ends_with(\"score\"),\n  names_to = \"graph\",\n  values_to = \"score\"\n)\n  \n\ntitle = \"Descriptive Statistics of Response Accuracy by Block (CONTROL Condition)\"\nabs.stats <- rbind(\n  \"linear.block\"= df %>% dplyr::select(linear_score) %>% unlist() %>% favstats(),\n  \"triangular.block\" = df %>% dplyr::select(triangular_score) %>% unlist() %>% favstats(),\n  \"block.differences\" = df %>% dplyr::select(score_diff) %>% unlist() %>% favstats()\n)\n\nabs.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"block # questions correct [0,15]; DIFF = triangular - linear\",\n           general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;border-bottom: 0;'>\n<caption>Descriptive Statistics of Response Accuracy by Block (CONTROL Condition)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> linear.block </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 9.0 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 13.0 </td>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:right;\"> 11.07 </td>\n   <td style=\"text-align:right;\"> 2.19 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> triangular.block </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 6.5 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 12.5 </td>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:right;\"> 8.81 </td>\n   <td style=\"text-align:right;\"> 4.28 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> block.differences </td>\n   <td style=\"text-align:right;\"> -12 </td>\n   <td style=\"text-align:right;\"> -4.0 </td>\n   <td style=\"text-align:right;\"> -2 </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> -2.25 </td>\n   <td style=\"text-align:right;\"> 3.93 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<span style=\"font-style: italic;\">Note: </span> <sup></sup> block # questions correct [0,15]; DIFF = triangular - linear</td></tr></tfoot>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF SCORE\ngf_dhistogram(~score, fill = ~graph, data = df_long) %>% gf_facet_wrap(~graph)+\n  labs(title = \"Distribution of scores in CONTROL condition\") + \n  easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/SETUP-H1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_long, aes(x = graph, y = score,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of scores in CONTROL condition\", \n    x = \"Condition\", y = \"Score (# correct)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/SETUP-H1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF SCORE\ngf_dhistogram(~score_diff, data = df) %>% \n  gf_fitdistr(~score_diff) + \n  labs(title = \"Distribution of paired score differences in CONTROL condition\") + \n  easy_remove_legend() \n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/SETUP-H1-3.png){width=672}\n:::\n:::\n\n\nFor participants in the CONTROL condition, total absolute scores for the LINEAR graph (n = 59) range from 5 to 15 with a mean score of (M = 11.07, SD = 2.19).\n\nFor participants in the CONTROL condition, total absolute scores for the TRIANGULAR graph (n = 59) range from 0 to 14 with a mean score of (M = 8.81, SD = 4.28).\n\nVisual inspection of the distribution of scores for each block reveal that scores in on the triangular task were more variant than those in the linear graph. On average, scores on the triangular block were lower than those on the linear block.\n\n### PAIRED SAMPLES T-TEST\n\n#### Check Assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#PAIRED T TEST ASSUMPTIONS\n\n# 1| PAIRED?\npaste(\"1| Data are paired? \", \"YES, block is crossed within subjects\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1| Data are paired?  YES, block is crossed within subjects\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"2| Sample size? \", \"YES, sample size \",nrow(df), \"> 30\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2| Sample size?  YES, sample size  59 > 30\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"3| Paired differences are normally distributed? accept null [normal] at p > 0.05\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3| Paired differences are normally distributed? accept null [normal] at p > 0.05\"\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(df$score_diff) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df$score_diff\nW = 0.9, p-value = 0.007\n```\n:::\n:::\n\n\n\\_Because the difference scores are not normally distributed, we don't meet the assumptions of a standard paired t-test. Instead, we should use the alternative test Wilcoxon Rank Sum \\[paired\\] designed for non-normal distributions.\n\n#### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#PLOT PAIRED DATA\n#subset linear\nlinear <- subset(df_long,  graph == \"linear_score\", score,\n                 drop = TRUE)\n# subset triangular\ntriangular <- subset(df_long,  graph == \"triangular_score\", score,\n                 drop = TRUE)\n# Plot paired data\nlibrary(PairedData)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: MASS\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'MASS' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: gld\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: mvtnorm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'PairedData'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:Matrix':\n\n    summary\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:base':\n\n    summary\n```\n:::\n\n```{.r .cell-code}\npd <- paired(linear, triangular)\nplot(pd, type = \"profile\") + theme_bw() + labs(title = \"Paired Data | Control Condition scores by block\")\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SANITY CHECK\nggwithinstats(\n  data = df_long,\n  x    = graph,\n  y    = score, \n  type  = \"nonparametric\" #parametric, robust, bayes\n)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n#### Run Test (Wilcoxon Paired Rank Sum)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#WILCOXON RANK SUM PAIRED T-TEST\nw <- wilcox.test(df$linear_score, df$triangular_score, \n            paired = TRUE, alternative = \"greater\", conf.int = TRUE)\nw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  df$linear_score and df$triangular_score\nV = 1134, p-value = 0.0001\nalternative hypothesis: true location shift is greater than 0\n95 percent confidence interval:\n 1.5 Inf\nsample estimates:\n(pseudo)median \n           2.5 \n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ranktransform.numeric(x, verbose = verbose, ...): Zeros detected.\nThese cannot be sign-rank transformed.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon signed rank test with continuity correction testing the difference in ranks between df$linear_score and df$triangular_score suggests that the effect is positive, statistically significant, and very large (W = 1134.50, p < .001; r (rank biserial) = 0.59, 95% CI [0.40, 1.00])\n```\n:::\n:::\n\n\n#### Inference\n\nThe Wilcoxon signed rank test confirms that (for subjects in the control condition) scores on the **triangle graph** were significantly lower than those in the **linear graph** block. This provides evidence in support of our hypothesis that the Triangular model graph (though computationally efficient) is in fact unconventional and lacking in discoverablility. It needs to be augmented with scaffolding in order to be correctly interpreted by novice readers.\n\n## H2 \\| The Effectiveness of Scaffolding **TODO reconsider accuracy vs latency??**\n\n**Hypothesis** All of the designs offered by participants in Study 1 are promising. We expect that only a small amount of scaffolding (a little nudge) will be required to help readers correctly interpret the graph. We predict that learners with (any form of) scaffolding will perform better with the TM than readers in the CONTROL condition.\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does SCAFFOLDING result in superior performance on the Triangular graph?                                                      |\n+=======================+===============================================================================================================================+\n| **Hypothesis**        | Ss in any of the SCAFFOLD conditions will have higher scores on the TRIANGULAR graph compared with CONTROL condition readers. |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | data: `df_subjects`                                                                                                           |\n|                       |                                                                                                                               |\n|                       | outcome:                                                                                                                      |\n|                       |                                                                                                                               |\n|                       | -   *triangular block score* `triangular_score` \\[triangular absolute score\\]                                                 |\n|                       |                                                                                                                               |\n|                       | predictor: `condition` \\[between-subjects factor\\]                                                                            |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  (non parametric) One Way ANOVA (Kruskal Wallis)                                                                           |\n|                       |     -   compare `triangular_score` between conditions                                                                         |\n|                       | 2.  Linear Regression                                                                                                         |\n|                       |     -   predict `triangular_score` by `condition`                                                                             |\n|                       |     -   confirm each condition yields significantly higher score than control                                                 |\n|                       | 3.  Logistic Mixed Effects Regression                                                                                         |\n|                       |     -   predict item `score` by `condition` with random intercepts for `subject` and `item`                                   |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             |                                                                                                                               |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------+\n\n### ONE WAY ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PREPARE DATA \ndf <- df_subjects\n```\n:::\n\n\n#### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Box plots\n# ++++++++++++++++++++\n# Plot weight by group and color by group\nlibrary(\"ggpubr\")\nggboxplot(df, x = \"pretty_condition\", y = \"triangular_score\", \n          color = \"pretty_condition\", \n          # palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n          # order = c(\"ctrl\", \"trt1\", \"trt2\"),\n          title = \"Difference in Triangular Block Scores by Condition\",\n          ylab = \"Triangular Score [0,15]\", xlab = \"Condition\") +\n  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +\n  easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n#### Run Test (One Way ANOVA)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ONE WAY ANOVA\naov <- aov(triangular_score ~ pretty_condition, data = df)\naov\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\n   aov(formula = triangular_score ~ pretty_condition, data = df)\n\nTerms:\n                pretty_condition Residuals\nSum of Squares               463      5776\nDeg. of Freedom                4       311\n\nResidual standard error: 4.31\nEstimated effects may be unbalanced\n```\n:::\n\n```{.r .cell-code}\nreport(aov)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFor one-way between subjects designs, partial eta squared is equivalent to eta squared.\nReturning eta squared.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe ANOVA (formula: triangular_score ~ pretty_condition) suggests that:\n\n  - The main effect of pretty_condition is statistically significant and medium (F(4, 311) = 6.23, p < .001; Eta2 = 0.07, 95% CI [0.03, 1.00])\n```\n:::\n\n```{.r .cell-code}\n#POSTHOC TUKEY COMPARISONS\nTukeyHSD(aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = triangular_score ~ pretty_condition, data = df)\n\n$pretty_condition\n                       diff     lwr  upr p adj\ntext:what-control     1.912 -0.2474 4.07 0.110\ntext:how-control      1.795 -0.3049 3.90 0.134\nimg:static-control    1.663 -0.4697 3.80 0.206\nimg:ixv-control       3.775  1.6895 5.86 0.000\ntext:how-text:what   -0.117 -2.2353 2.00 1.000\nimg:static-text:what -0.249 -2.3997 1.90 0.998\nimg:ixv-text:what     1.863 -0.2410 3.97 0.110\nimg:static-text:how  -0.132 -2.2239 1.96 1.000\nimg:ixv-text:how      1.980 -0.0638 4.02 0.063\nimg:ixv-img:static    2.112  0.0355 4.19 0.044\n```\n:::\n\n```{.r .cell-code}\nplot(TukeyHSD(aov))\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n#### Check Assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ONE WAY ANOVA ASSUMPTIONS\n\npaste(\"1| Homogoneity of variance? \", \"YES, block is crossed within subjects\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1| Homogoneity of variance?  YES, block is crossed within subjects\"\n```\n:::\n\n```{.r .cell-code}\nplot(aov, 1)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nl <- car::leveneTest(triangular_score ~ pretty_condition, data = df)\npaste (\"reject null hypothesis of homogeneity of variance? \", l$`Pr(>F)`[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"reject null hypothesis of homogeneity of variance?  0.00401958517198785\"\n```\n:::\n\n```{.r .cell-code}\noneway.test(triangular_score ~ pretty_condition, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne-way analysis of means (not assuming equal variances)\n\ndata:  triangular_score and pretty_condition\nF = 8, num df = 4, denom df = 153, p-value = 1e-05\n```\n:::\n\n```{.r .cell-code}\npairwise.t.test(df$triangular_score, df$pretty_condition,\n                 p.adjust.method = \"BH\", pool.sd = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with non-pooled SD \n\ndata:  df$triangular_score and df$pretty_condition \n\n           control text:what text:how img:static\ntext:what  0.04    -         -        -         \ntext:how   0.05    0.88      -        -         \nimg:static 0.06    0.88      0.88     -         \nimg:ixv    5e-06   0.02      0.02     0.02      \n\nP value adjustment method: BH \n```\n:::\n\n```{.r .cell-code}\npaste(\"2| Residuals of ANOVA are normally distributed?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2| Residuals of ANOVA are normally distributed?\"\n```\n:::\n\n```{.r .cell-code}\n# Extract the residuals\nresid <- residuals(object = aov )\n# Run Shapiro-Wilk test\ns <- shapiro.test(x = resid )\npaste (\"reject null hypothesis of normally distributed residuals?\", s$p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"reject null hypothesis of normally distributed residuals? 6.69360335751768e-10\"\n```\n:::\n:::\n\n\n*Because the residuals of the ANOVA are not normally distributed, (and variance is not homogenous) we need to use a non-parametric alternative test : The Kruskal-Wallis rank sum test.*\n\n#### Non Parametric Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#KRUSKAL WALLIS RANK SUM TEST \nkruskal.test(triangular_score ~ pretty_condition, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  triangular_score by pretty_condition\nKruskal-Wallis chi-squared = 21, df = 4, p-value = 0.0003\n```\n:::\n\n```{.r .cell-code}\n#POSTHOC \npairwise.wilcox.test(df$triangular_score, df$pretty_condition,\n  p.adjust.method = \"holm\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  df$triangular_score and df$pretty_condition \n\n           control text:what text:how img:static\ntext:what  0.2     -         -        -         \ntext:how   0.2     1.0       -        -         \nimg:static 0.2     1.0       1.0      -         \nimg:ixv    4e-05   0.1       0.2      0.1       \n\nP value adjustment method: holm \n```\n:::\n:::\n\n\n*Because the residuals of the ANOVA are not normally distributed, (and variance is not homogenous) we need to use a non-parametric alternative test : The Kruskal-Wallis rank sum test.*\n\n#### Inference\n\nA Kruskal-Wallis test reveals that **triangle graph** scores are significantly different by condition, though posthoc (holm-adjusted) Wilcoxon rank sum tests show than *only* the interactive image condition yielded significantly higher score than those in the control condition. Visual inspection of the distribution of triangular scores reveals substantial variance across all conditions. It is likely that the scaffolds function not by helping most subjects a little bit, but only some subjects a great deal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ++++++++++++++++++++\n# BETWEEN SUBJECTS PLOT\nggbetweenstats(y = triangular_score, x = condition, data = df,\n    type = \"nonparametric\",\n    pairwise.display = \"significant\",\n)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### LINEAR REGRESSION\n\n*Fit a linear model (at the subject level), predicting triangular block accuracy (absolute score) by condition*\n\n#### Fit Model\n\n*First, we fit a linear regression with graph as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING:::::::::::::::::::::::::::::::::::::\n\n#: 1 EMPTY MODEL [grand mean as intercept]\nm0 = lm(triangular_score ~ 1, data = df)\nprint(\"EMPTY MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"EMPTY MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = triangular_score ~ 1, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -8.77  -3.77   1.23   3.23   6.23 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     8.77       0.25      35   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.45 on 315 degrees of freedom\n```\n:::\n\n```{.r .cell-code}\n#: 2 CONDITION as predictor\nm1 = lm(triangular_score ~ pretty_condition, data = df)\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = triangular_score ~ pretty_condition, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -9.68  -2.90   1.19   3.32   7.10 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   6.902      0.552   12.51  < 2e-16 ***\npretty_conditiontext:what     1.912      0.787    2.43    0.016 *  \npretty_conditiontext:how      1.795      0.765    2.35    0.020 *  \npretty_conditionimg:static    1.663      0.777    2.14    0.033 *  \npretty_conditionimg:ixv       3.775      0.760    4.97  1.1e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.31 on 311 degrees of freedom\nMultiple R-squared:  0.0742,\tAdjusted R-squared:  0.0623 \nF-statistic: 6.23 on 4 and 311 DF,  p-value: 0.0000775\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           2.5 % 97.5 %\n(Intercept)                5.816   7.99\npretty_conditiontext:what  0.363   3.46\npretty_conditiontext:how   0.289   3.30\npretty_conditionimg:static 0.134   3.19\npretty_conditionimg:ixv    2.279   5.27\n```\n:::\n\n```{.r .cell-code}\n#: 3 TEST SUPERIOR FIT\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName | Model | df | df_diff |  Chi2 |      p\n--------------------------------------------\nm0   |    lm |  2 |         |       |       \nm1   |    lm |  6 |       4 | 24.37 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000672264236399889\"\n```\n:::\n:::\n\n\n*The CONDITION predictor significantly improves model fit.*\n\n#### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\n#: 4 ASSESS PERFORMANCE\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-------------------------------------------------------\n1827.001 | 1849.536 | 0.074 |     0.062 | 4.275 | 4.310\n```\n:::\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict triangular_score with pretty_condition (formula: triangular_score ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.07, F(4, 311) = 6.23, p < .001, adj. R2 = 0.06). The model's intercept, corresponding to pretty_condition = control, is at 6.90 (95% CI [5.82, 7.99], t(311) = 12.51, p < .001). Within this model:\n\n  - The interaction effect of what on pretty conditiontext is statistically significant and positive (beta = 1.91, 95% CI [0.36, 3.46], t(311) = 2.43, p = 0.016; Std. beta = 0.43, 95% CI [0.08, 0.78])\n  - The interaction effect of how on pretty conditiontext is statistically significant and positive (beta = 1.80, 95% CI [0.29, 3.30], t(311) = 2.35, p = 0.020; Std. beta = 0.40, 95% CI [0.06, 0.74])\n  - The interaction effect of static on pretty conditionimg is statistically significant and positive (beta = 1.66, 95% CI [0.13, 3.19], t(311) = 2.14, p = 0.033; Std. beta = 0.37, 95% CI [0.03, 0.72])\n  - The interaction effect of ixv on pretty conditionimg is statistically significant and positive (beta = 3.77, 95% CI [2.28, 5.27], t(311) = 4.97, p < .001; Std. beta = 0.85, 95% CI [0.51, 1.18])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\nlibrary(jtools) # pretty printing \nsumm(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 316 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> triangular_score </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> OLS linear regression </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> F(4,311) </td>\n   <td style=\"text-align:right;\"> 6.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> RÂ² </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Adj. RÂ² </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> S.E. </th>\n   <th style=\"text-align:right;\"> t val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 6.90 </td>\n   <td style=\"text-align:right;\"> 0.55 </td>\n   <td style=\"text-align:right;\"> 12.51 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditiontext:what </td>\n   <td style=\"text-align:right;\"> 1.91 </td>\n   <td style=\"text-align:right;\"> 0.79 </td>\n   <td style=\"text-align:right;\"> 2.43 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditiontext:how </td>\n   <td style=\"text-align:right;\"> 1.80 </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 2.35 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditionimg:static </td>\n   <td style=\"text-align:right;\"> 1.66 </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 2.14 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditionimg:ixv </td>\n   <td style=\"text-align:right;\"> 3.77 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 4.97 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors: OLS</td></tr></tfoot>\n</table>\n`````\n:::\n\n```{.r .cell-code}\n#: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \n# library(ggstatsplot)\nggcoefstats(m1, output = \"plot\") \n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/VIS-CONTROLSCORE-LM-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"pred\",\n           title = \"Model Predicted Score\",\n           axis.title = c(\"Graph Block\",\"Score [0,15]\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/VIS-CONTROLSCORE-LM-2.png){width=672}\n:::\n:::\n\n\n#### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: About 89% of the residuals are inside the error bounds (~95% or higher would be good).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n\n\n#### Inference\n\nWe fit a linear regression model to analyze the effect of experimental condition triangular block score. In this model, the effect of condition is statistically significant (F(4,311) = 6.23, p \\< 0.001) and explains approximately 7% of variance in triangular block scores. All conditions yield score significantly higher than control at the 0.05 alpha level, with the interactive image yielding the highest difference, with an average of 4 points higher \\[95% CI 2.3, 5.3\\] than the control condition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#PRETTY TABLE SJPLOT\ntab_model(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">triangular score</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">6.90</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.82&nbsp;&ndash;&nbsp;7.99</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditiontext *<br>what</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.91</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.36&nbsp;&ndash;&nbsp;3.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.016</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditiontext *<br>how</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.80</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.29&nbsp;&ndash;&nbsp;3.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.020</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditionimg *<br>static</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.66</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13&nbsp;&ndash;&nbsp;3.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.033</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditionimg * ixv</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.77</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.28&nbsp;&ndash;&nbsp;5.27</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">316</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.074 / 0.062</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n### MIXED EFFECTS LOGISTIC REGRESSION\n\n*Fit a logistic regression (at the subject level), predicting triangular item accuracy (absolute score) by condition.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(graph == \"triangular\")\n```\n:::\n\n\n\n#### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING:::::::::::::::::::::::::::::::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(score ~ 1, data = df, family = \"binomial\")\nprint(\"EMPTY MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"EMPTY MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = score ~ 1, family = \"binomial\", data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n -1.33   -1.33    1.04    1.04    1.04  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.3422     0.0295    11.6   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6432.9  on 4738  degrees of freedom\nResidual deviance: 6432.9  on 4738  degrees of freedom\nAIC: 6435\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n#: RANDOM SUBJECT INTERCEPT \nmm.0 <- glmer( score ~ (1|subject), data = df, family = \"binomial\")\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(mm.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score ~ (1 | subject)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    5401     5414    -2699     5397     4737 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.783 -0.571  0.359  0.626  2.537 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 2.26     1.5     \nNumber of obs: 4739, groups:  subject, 316\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.4336     0.0923     4.7  2.6e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#: TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > AIC(mm.0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.0) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName |    Model | df | df_diff |    Chi2 |      p\n-------------------------------------------------\nm0   |      glm |  1 |         |         |       \nmm.0 | glmerMod |  2 |       1 | 1035.52 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.0))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  3.41580110983183e-227\"\n```\n:::\n\n```{.r .cell-code}\n#: CONDITION MODEL\nmm1 <- glmer(score ~ pretty_condition + (1|subject), data = df, family = \"binomial\")\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(mm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score ~ pretty_condition + (1 | subject)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    5386     5424    -2687     5374     4733 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.987 -0.576  0.366  0.613  2.675 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 2.06     1.43    \nNumber of obs: 4739, groups:  subject, 316\n\nFixed effects:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  -0.241      0.201   -1.20    0.230    \npretty_conditiontext:what     0.660      0.287    2.30    0.021 *  \npretty_conditiontext:how      0.656      0.280    2.34    0.019 *  \npretty_conditionimg:static    0.606      0.284    2.13    0.033 *  \npretty_conditionimg:ixv       1.378      0.279    4.94  7.8e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n                 (Intr) prtty_cndtntxt:w prtty_cndtntxt:h prtty_cndtnmg:s\nprtty_cndtntxt:w -0.701                                                  \nprtty_cndtntxt:h -0.719  0.504                                           \nprtty_cndtnmg:s  -0.709  0.497            0.510                          \nprtty_cndtnmg:x  -0.722  0.507            0.520            0.512         \n```\n:::\n\n```{.r .cell-code}\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(mm.0) > AIC(mm1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.0,mm1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName |    Model | df | df_diff |  Chi2 |      p\n-----------------------------------------------\nmm.0 | glmerMod |  2 |         |       |       \nmm1  | glmerMod |  6 |       4 | 23.78 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.0,mm1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000883541191174091\"\n```\n:::\n:::\n\n\n*The Condition predictor significantly improves model fit.*\n\n#### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsumm(mm1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 4739 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> score </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> Mixed effects generalized linear model </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Family </td>\n   <td style=\"text-align:right;\"> binomial </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Link </td>\n   <td style=\"text-align:right;\"> logit </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> AIC </td>\n   <td style=\"text-align:right;\"> 5385.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> BIC </td>\n   <td style=\"text-align:right;\"> 5424.41 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-RÂ² (fixed effects) </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-RÂ² (total) </td>\n   <td style=\"text-align:right;\"> 0.41 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"5\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Fixed Effects</div></th></tr>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> S.E. </th>\n   <th style=\"text-align:right;\"> z val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -0.24 </td>\n   <td style=\"text-align:right;\"> 0.20 </td>\n   <td style=\"text-align:right;\"> -1.20 </td>\n   <td style=\"text-align:right;\"> 0.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditiontext:what </td>\n   <td style=\"text-align:right;\"> 0.66 </td>\n   <td style=\"text-align:right;\"> 0.29 </td>\n   <td style=\"text-align:right;\"> 2.30 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditiontext:how </td>\n   <td style=\"text-align:right;\"> 0.66 </td>\n   <td style=\"text-align:right;\"> 0.28 </td>\n   <td style=\"text-align:right;\"> 2.34 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditionimg:static </td>\n   <td style=\"text-align:right;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 0.28 </td>\n   <td style=\"text-align:right;\"> 2.13 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditionimg:ixv </td>\n   <td style=\"text-align:right;\"> 1.38 </td>\n   <td style=\"text-align:right;\"> 0.28 </td>\n   <td style=\"text-align:right;\"> 4.94 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Random Effects</div></th></tr>\n  <tr>\n   <th> Group </th>\n   <th> Parameter </th>\n   <th> Std. Dev. </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td> subject </td>\n   <td> (Intercept) </td>\n   <td> 1.43 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Grouping Variables</div></th></tr>\n  <tr>\n   <th> Group </th>\n   <th> # groups </th>\n   <th> ICC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td> subject </td>\n   <td> 316 </td>\n   <td> 0.38 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n\n```{.r .cell-code}\n#: INTERPRET COEFFICIENTS\n\n# print(\"Coefficients â€”- LOG ODDS\")\n# summ(confint(mm1))\n# print(\"Coefficients â€”- ODDS RATIOS\")\n# e <- cbind( exp(coef(mm1)), exp(confint(mm1))) #exponentiate\n# e\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(mm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n--------------------------------------------------------------------------------------------------------------\n5385.624 | 5424.405 |      0.406 |      0.035 | 0.385 | 0.396 | 1.000 |    0.482 |      -Inf |           0.001\n```\n:::\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(mm1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict score with pretty_condition (formula: score ~ pretty_condition). The model included subject as random effect (formula: ~1 | subject). The model's total explanatory power is substantial (conditional R2 = 0.41) and the part related to the fixed effects alone (marginal R2) is of 0.04. The model's intercept, corresponding to pretty_condition = control, is at -0.24 (95% CI [-0.64, 0.15], p = 0.230). Within this model:\n\n  - The interaction effect of what on pretty conditiontext is statistically significant and positive (beta = 0.66, 95% CI [0.10, 1.22], p = 0.021; Std. beta = 0.66, 95% CI [0.10, 1.22])\n  - The interaction effect of how on pretty conditiontext is statistically significant and positive (beta = 0.66, 95% CI [0.11, 1.20], p = 0.019; Std. beta = 0.66, 95% CI [0.11, 1.20])\n  - The interaction effect of static on pretty conditionimg is statistically significant and positive (beta = 0.61, 95% CI [0.05, 1.16], p = 0.033; Std. beta = 0.61, 95% CI [0.05, 1.16])\n  - The interaction effect of ixv on pretty conditionimg is statistically significant and positive (beta = 1.38, 95% CI [0.83, 1.92], p < .001; Std. beta = 1.38, 95% CI [0.83, 1.92])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n# print(\"MODEL PREDICTIONS\")\n# # Retrieve predictions as probabilities \n# # (for each level of the predictor)\n# p.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n# paste(\"Probability of success in control,\", p.control)\n# p.textwhat <- predict(m1,data.frame(pretty_condition=\"text:what\"),type=\"response\")\n# paste(\"Probability of success in text:what,\", p.textwhat)\n# p.textwhat <- predict(m1,data.frame(pretty_condition=\"text:what\"),type=\"response\")\n# paste(\"Probability of success in text:what,\", p.textwhat)\n\n#: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \n# library(ggstatsplot)\nggcoefstats(mm1, output = \"plot\") + labs(x = \"Log Odds Estimate\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/MODEL-TRIANGLEITEM-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | RANDOM EFFECTS\nplot_model(mm1, type=\"re\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkMatrixPackageVersion(): Package version inconsistency detected.\nTMB was built with Matrix version 1.4.1\nCurrent Matrix version is 1.4.0\nPlease re-install 'TMB' from source using install.packages('TMB', type = 'source') or ask CRAN for a binary version of 'TMB' matching CRAN's 'Matrix' package\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/MODEL-TRIANGLEITEM-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(mm1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE) +  \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/MODEL-TRIANGLEITEM-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(mm1, type=\"pred\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/MODEL-TRIANGLEITEM-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGEFFECTS | MODEL | PROBABILITIES\n# library(ggeffects)\n# ggeffect(model = m1) %>% plot()\n```\n:::\n\n\n#### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(mm1)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(mm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: About 82% of the residuals are inside the error bounds (~95% or higher would be good).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n:::\n\n\n#### Inference\n\nWe fit a mixed logistic regression model to analyze the effect of experimental condition on probability of a correct answer on the triangular graph block, including subject as a random intercept. The model explains a small proportion of variance (Pseudo R2 = 0.04). In this model, the fixed effect of condition is statistically accounts for 4% of variance, while the random effects component (conditional r2) accounts for 41%. \n\nTODO EXPONENTIATE \n- The model predicts that the odds of a correct response on a triangular graph question question in either of the text or static image conditions increases by a factor of about 1.6 relative to control, while participants in the interactive image condition experience an increase in odds of around 2.8 relative to control (($e^{beta_1}$ = 2.98, 95% CI \\[2.4, 3.5\\]) over the *control condition*.\n\n*Equivalent statements:*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#PRETTY TABLE SJPLOT\ntab_model(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">triangular score</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">6.90</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.82&nbsp;&ndash;&nbsp;7.99</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditiontext *<br>what</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.91</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.36&nbsp;&ndash;&nbsp;3.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.016</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditiontext *<br>how</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.80</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.29&nbsp;&ndash;&nbsp;3.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.020</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditionimg *<br>static</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.66</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13&nbsp;&ndash;&nbsp;3.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.033</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty conditionimg * ixv</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.77</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.28&nbsp;&ndash;&nbsp;5.27</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">316</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.074 / 0.062</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n#### TODO\n\n-   Are these residuals OK? I didn't think normally distributed residuals were an assumption for logistic regression.\n-   Interpretation/reporting of model fit?\n-   sanity check correct interpretation of coefficients & reporting\n\n## H3 \\| Computational Efficiency\n\n**Hypothesis** Qiang et. al found that the TM graph was more computationally efficient than the LM graph. We expect that for learners that *do* correctly interpret the graph, they will have lower response times for the TM vs. LM graph.\\*\\*\n\n**Hypothesis** All of the designs offered by participants in Study 1 are promising. We expect that only a small amount of scaffolding (a little nudge) will be required to help readers correctly interpret the graph. We predict that learners with (any form of) scaffolding will perform better with the TM than LM (a replication of Qiang et. al's finding on the computational efficiency of the TM graph).\n\n\n**TODO RE-EVALUATE THIS**\nA difference score of 0 represents the case where the particpant performs *equally well* on the linear and triangular blocks. Positive scores indicate better performance on the triangular block, and negative scores indicate better performance on the linear block.\n\n**To determine that a scaffold is *effective*, we expect to see a difference score greater than or equal to 0** such that the participant performs *at least* as well on the triangular block as the linear block.\n+-----------------------+-----------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does SCAFFOLDING result in superior performance on the Triangular graph?                                        |\n+=======================+=================================================================================================================+\n| **Hypothesis**        | Ss in any of the SCAFFOLD conditions will have higher scores on the TRIANGULAR graph than the LINEAR graph      |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------+\n| **Data**              | data: `df_subjects`                                                                                             |\n|                       |                                                                                                                 |\n|                       | outcome:                                                                                                        |\n|                       |                                                                                                                 |\n|                       | -   *difference score* `diff_score` \\[linear - triangular absolute score\\]                                      |\n|                       |                                                                                                                 |\n|                       | predictor: `condition` \\[between-subjects factor\\]                                                              |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Independent Samples ANOVA                                                                                   |\n|                       |     -   compare `diff_score` between conditions                                                                 |\n|                       |     -   check assumptions re: variance and normality                                                            |\n|                       | 2.  Linear Regression                                                                                           |\n|                       |     -   predict `diff_score` by `condition`                                                                     |\n|                       |     -   confirm each condition yields significantly higher score than control                                   |\n|                       | 3.  Mixed Effects Linear Regression                                                                             |\n|                       |     -   predict block `score` \\[0-15\\] by `graph` and `condition` with random intercept for `subject`           |\n|                       |     -   expect significant interaction between fixed effects `graph` and `condition` for non-control conditions |\n|                       | 4.  Logistic Mixed Effects Regression                                                                           |\n|                       |     -   predict item `score` by `graph` and `condition` with random intercepts for `subject` and `item`         |\n|                       |                                                                                                                 |\n|                       |     -   expect significant interaction between `graph` and `condition` for non-control conditions               |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------+\n| **Notes**             |                                                                                                                 |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------+\n\n\n\n\n\n### ONE WAY ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PREPARE DATA \ndf <- df_subjects\n```\n:::\n\n\n#### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Box plots\n# ++++++++++++++++++++\n# Plot weight by group and color by group\nlibrary(\"ggpubr\")\nggboxplot(df, x = \"pretty_condition\", y = \"score_diff\", \n          color = \"pretty_condition\", \n          # palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n          # order = c(\"ctrl\", \"trt1\", \"trt2\"),\n          title = \"Difference in Block Scores by Condition\",\n          ylab = \"Triangular (minus) Linear Score\", xlab = \"Condition\") +\n  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +\n  easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ++++++++++++++++++++\n# BETWEEN SUBJECTS PLOT\nggbetweenstats(y = score_diff, x = condition, data = df,\n    type = \"nonparametric\",\n    pairwise.display = \"significant\",\n)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-23-2.png){width=672}\n:::\n:::\n\n\n#### Run Test (One Way ANOVA)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ONE WAY ANOVA\naov <- aov(score_diff ~ condition, data = df)\naov\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\n   aov(formula = score_diff ~ condition, data = df)\n\nTerms:\n                condition Residuals\nSum of Squares        484      4840\nDeg. of Freedom         4       311\n\nResidual standard error: 3.94\nEstimated effects may be unbalanced\n```\n:::\n\n```{.r .cell-code}\nreport(aov)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFor one-way between subjects designs, partial eta squared is equivalent to eta squared.\nReturning eta squared.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe ANOVA (formula: score_diff ~ condition) suggests that:\n\n  - The main effect of condition is statistically significant and medium (F(4, 311) = 7.77, p < .001; Eta2 = 0.09, 95% CI [0.04, 1.00])\n```\n:::\n\n```{.r .cell-code}\n#POSTHOC TUKEY COMPARISONS\nTukeyHSD(aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score_diff ~ condition, data = df)\n\n$condition\n       diff     lwr  upr p adj\n1-0  1.8277 -0.1488 3.80 0.085\n2-0  1.8850 -0.0375 3.81 0.058\n3-0  1.7271 -0.2250 3.68 0.111\n4-0  3.8614  1.9525 5.77 0.000\n2-1  0.0573 -1.8821 2.00 1.000\n3-1 -0.1006 -2.0693 1.87 1.000\n4-1  2.0336  0.1078 3.96 0.033\n3-2 -0.1579 -2.0723 1.76 0.999\n4-2  1.9764  0.1060 3.85 0.032\n4-3  2.1343  0.2335 4.04 0.019\n```\n:::\n\n```{.r .cell-code}\nplot(TukeyHSD(aov))\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# library(multcomp)\n# glht(res.aov, alternative = \"less\", # linfct = mcp(pretty_condition = \"Tukey\"))\n#      \n```\n:::\n\n\n#### Check Assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ONE WAY ANOVA ASSUMPTIONS\n\npaste(\"1| Homogoneity of variance? \", \"YES, block is crossed within subjects\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1| Homogoneity of variance?  YES, block is crossed within subjects\"\n```\n:::\n\n```{.r .cell-code}\nplot(aov, 1)\n```\n\n::: {.cell-output-display}\n![](4_sgc2_hypotesting_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\npaste(\"2| Sample size? \", \"YES, sample size \",nrow(df), \"> 30\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2| Sample size?  YES, sample size  316 > 30\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"3| Paired differences are normally distributed? accept null [normal] at p > 0.05\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"3| Paired differences are normally distributed? accept null [normal] at p > 0.05\"\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(df$score_diff) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df$score_diff\nW = 1, p-value = 1e-08\n```\n:::\n:::\n\n\n\\_Because the difference scores are not normally distributed, we don't meet the assumptions of a standard paired t-test. Instead, we should use the alternative test Wilcoxon Rank Sum \\[paired\\] designed for non-normal distributions.\n\n#### Inference\n\nThe Wilcoxon signed rank test confirms that (for subjects in the control condition) scores on the **triangle graph** were significantly lower than those in the **linear graph** block. This provides evidence in support of our hypothesis that the Triangular model graph (though computationally efficient) is in fact unconventional and lacking in discoverablility. It needs to be augmented with scaffolding in order to be correctly interpreted by novice readers.\n\n\n\n\n## H4 \\| Graph Order as Scaffold\n\n**Hypothesis** Based on observations in Study One we expect that graph-order will act as a scaffold. Learners who solve problems with the LM graph first will perform better on the TM (relative to TM-first learners) as their attention will be drawn to the salient differences between the graphs.\n\n## MODELLING\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# df_items <- df_items %>% filter(graph != \"none\") %>% \n#   mutate(graph = as.factor(graph)) #only include linear and triangular items\n# \n# ##FIT LINEAR MODEL\n# library(lme4)\n# m <- lm(triangular_score ~ pretty_condition + order + tm_scenarios+ linear_score, data = df_subjects)\n# summary(m)\n# check_model(m)\n# \n# #+ linear_score\n# m <- lm(score ~  pretty_condition*graph, data = long_scores)\n# summary(m)\n# check_model(m)\n# \n# \n# ##FI MIXED MODEL\n# library(lmerTest)\n# #on subject, score total per block\n# m0 <- lm( score ~ 1, data = long_scores)\n# summary(m0)\n# \n# m.rS <- lmer(score ~ (1|subject), data = long_scores)\n# summary(m.rS)\n# \n# #compare fit\n# compare_performance(m0,m.rS)\n# test_lrt(m0, m.rS)\n# #validates that mixed mod is justified \n# \n# mC.rS <- lmer(score ~ pretty_condition + (1|subject), data = long_scores)\n# summary(mC.rS)\n# \n# #compare fit\n# compare_performance(m.rS,mC.rS)\n# test_lrt(m.rS, mC.rS)\n# #validates that fixed effect significantly improves fit \n# \n# \n# ##ITEM LEVEL MIXED MODEL\n# \n# #empty model\n# m <- glm(correct ~ 1, data = df_items, family = \"binomial\")\n# summary(m)\n# \n# #condition model\n# m1 <- glm(correct ~ condition, data = df_items, family = \"binomial\")\n# summary(m1)\n# \n# compare_performance(m,m1)\n# test_lrt(m,m1)\n# #condition model is better fit than null\n# \n# #graph model\n# m2 <- glm(correct ~ condition + graph + graph*condition, data = df_items, family = \"binomial\" )\n# summary(m2)\n# \n# library(effects)\n# plot(allEffects(m2))\n# \n# compare_performance(m1,m2)\n# test_lrt(m1,m2)\n# #condition model is better fit than null\n# \n# \n# #scenario model\n# m3 <- glm(correct ~ condition + graph + graph*condition + order + scenario, data = df_items, family = \"binomial\" )\n# summary(m3)\n# \n# library(effects)\n# plot(allEffects(m2))\n# \n# compare_performance(m1,m2)\n# test_lrt(m1,m2)\n# #condition model is better fit than null\n# \n# \n# \n# #IGNORE THE ONES ABOVE \n# \n# #full model\n# m <- glm(correct ~ condition + order + scenario + condition*order + condition*scenario + order*scenario + condition*order*scenario, data = df_items %>% filter(graph==\"triangular\"), family = \"binomial\" )\n# summary(m)\n# \n# library(effects)\n# plot(allEffects(m2))\n# \n# compare_performance(m1,m2)\n# test_lrt(m1,m2)\n# #condition model is better fit than null\n```\n:::\n\n\n\n\n## DIAGRAMS 2018 PUBLICATION ANALYSIS\n\n## RESOURCES\n\nreset plot margins par(mar=c(1,1,1,1))\n\n### Logistic Regression Notes\n\n*The logistic regression intercept gives the log odds of the outcome for the reference level of the predictor variable*\n\n*The logistic regression coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable.*\n",
    "supporting": [
      "4_sgc2_hypotesting_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}