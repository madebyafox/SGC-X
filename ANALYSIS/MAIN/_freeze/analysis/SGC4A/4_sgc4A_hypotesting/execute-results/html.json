{
  "hash": "83b70b13ba985067def9e14de3043c3e",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC4A | Hypothesis Testing'\n---\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC4A-hypotesting}\n\n**TODO**\n\n*The purpose of this notebook is test the hypotheses that determined the designs of the SGC4A studies.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#UTILITIES\nlibrary(Hmisc) # %nin% operator\nlibrary(broom) #tidy model output\nlibrary(mosaic) #favstats\n# library(modelr)\nlibrary(distributional)\n# library(jtools)\n# library(pwr) #power analysis\n\n#VISUALIZATION\n# library(ggpubr) #arrange plots\n# library(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\n# # library(vcd) #mosaic plots\n# # library(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables\nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz\nlibrary(gghalves) # plots. in half\nlibrary(ggbeeswarm) # violin plot stuffs\nlibrary(statsExpressions)\nlibrary(ggstatsplot) #plots with stats\nlibrary(modelsummary) #latex tables for models!\n\n#MODELLING\nlibrary(ARTool) #nonparametric anova\n# library(rstatix) #helpful testing functions incl wilcoxon, etc\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(parameters) #easystats model summary and vis\n# library(qqplotr) #confint on qq plot\n# library(gmodels) #contingency table and CHISQR\n# library(equatiomatic) #extract model equation\n# library(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models\nlibrary(lmerTest) #for CIs in glmer\n# library(ggeffects) #visualization log regr models\n#MULTINOMIAL \nlibrary(nnet) #multinomial logistic regression [not mixed] #no p values\nlibrary(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values\n#BAYESIAN\nlibrary(cmdstanr) #executing stan\nlibrary(brms) #bayesian mixed multinomials [+ other bayesian reg models]\nlibrary(bayestestR) \n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\n# theme_set(theme_minimal()) \n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"BarlowSemiCondensed-Bold\"),\n          axis.title = element_text(family = \"BarlowSemiCondensed-Medium\"),\n          strip.text = element_text(family = \"BarlowSemiCondensed-Bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA))\n}\n\nset_theme(base = theme_clean())\n```\n:::\n\n**Research Questions**\n\n**Experimental Hypothesis**\\\n\n**Null Hypothesis**\\\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#IMPORT DATA \ndf_subjects <- read_rds('analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.rds') %>% \n  mutate(\n    task_percent = DV_percent_NABS\n  ) %>% droplevels()\n\n\ndf_items <- read_rds('analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.rds') %>% \n   mutate (\n    q = as.factor(q), \n    subject = as.factor(subject),\n    accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n    # CODES TVERSKY AS TRI-LIKE\n    # state = recode_factor(score_SCALED, #for ordinal\n    #                      \"-1\" = \"orth-like\",\n    #                      \"-0.5\" = \"unknown\",\n    #                      \"0\" = \"unknown\",\n    #                      \"0.5\" = \"tri-like\",\n    #                      \"1\" = \"tri-like\"),\n    # CODES TVERSKY AS OTHER\n    state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orthogonal\",\n                         \"-0.5\" = \"other\",\n                         \"0\" = \"other\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"triangular\"),\n    state = as.ordered(state)) \n\n#SEPARATE INTO PARTS 1 AND 2\n# sgc4a <- df_subjects %>% filter(condition %in% c(111,113)) %>% droplevels()\n# sgc4b <- df_subjects %>% filter(condition %in% c(111,114,115)) %>% filter(mode==\"asynch\") %>% droplevels()\n# \n# sgc4a_items <- df_items %>% filter( subject %in% sgc4a$subject) %>% droplevels()\n# sgc4b_items <- df_items %>% filter( subject %in% sgc4b$subject) %>% droplevels()\n```\n:::\n\n\n## \n\n## H1A \\| OVERALL TASK  ACCURACY\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q)\n\ndf_s <- df_subjects %>% \n   dplyr::select(pretty_condition, task_percent)\n```\n:::\n\n\n#### Describe\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(title = \"Overall Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/DESC-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs(title = \"Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/DESC-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  # gf_facet_grid(pretty_condition ~ pretty_mode) %>%\n  gf_facet_grid(~pretty_condition) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Overall Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/DESC-ACC-3.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.184 </td>\n   <td style=\"text-align:right;\"> 0.324 </td>\n   <td style=\"text-align:right;\"> 480 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> pretty_condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Full </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.169 </td>\n   <td style=\"text-align:right;\"> 0.319 </td>\n   <td style=\"text-align:right;\"> 150 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Sparse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.202 </td>\n   <td style=\"text-align:right;\"> 0.350 </td>\n   <td style=\"text-align:right;\"> 88 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Grid </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.101 </td>\n   <td style=\"text-align:right;\"> 0.233 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Tri-Sparse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.538 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.245 </td>\n   <td style=\"text-align:right;\"> 0.355 </td>\n   <td style=\"text-align:right;\"> 144 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n#### TESTS\n\n##### Aligned Ranks Transformation\n<!-- https://rcompanion.org/handbook/F_16.html -->\n::: {.cell}\n\n```{.r .cell-code}\nm.art = art(task_percent ~ pretty_condition, data = df_s)\nanova(m.art)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance of Aligned Rank Transformed Data\n\nTable Type: Anova Table (Type III tests) \nModel: No Repeated Measures (lm)\nResponse: art(task_percent)\n\n                   Df Df.res F value Pr(>F)  \n1 pretty_condition  3    476  2.9176   0.03 *\n---\nSignif. codes:   0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n```\n:::\n:::\n\n##### Kruskal Wallis Test\n::: {.cell}\n\n```{.r .cell-code}\n(k <- kruskal.test(df_s$task_percent ~ df_s$pretty_condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  df_s$task_percent by df_s$pretty_condition\nKruskal-Wallis chi-squared = 9, df = 3, p-value = 0.03\n```\n:::\n:::\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n(results <- statsExpressions::oneway_anova(data = df_s, \n          x = pretty_condition, y = task_percent,\n          type = \"nonparametric\", alternative = \"less\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 15\n  parameter1   parameter2  statistic df.error p.value method effectsize estimate\n  <chr>        <chr>           <dbl>    <int>   <dbl> <chr>  <chr>         <dbl>\n1 task_percent pretty_con…      8.65        3  0.0343 Krusk… Epsilon2 …   0.0181\n# … with 7 more variables: conf.level <dbl>, conf.low <dbl>, conf.high <dbl>,\n#   conf.method <chr>, conf.iterations <int>, n.obs <int>, expression <list>\n```\n:::\n\n```{.r .cell-code}\n#:::::::: STATSPLOT | VIOLIN\nggbetweenstats(y = task_percent, x = pretty_condition, \n               data = df_s, type = \"nonparametric\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/TEST-VIZ-ACC-1.png){width=672}\n:::\n:::\n\n\n\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\nTODO model with item as random doesn't converge unless use bobyqa optimizer. \n::: {.cell}\n\n```{.r .cell-code}\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |    Chi2 |      p\n--------------------------------------------------\nm0    |      glm |  1 |         |         |       \nmm.rS | glmerMod |  2 |       1 | 3019.81 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0\"\n```\n:::\n\n```{.r .cell-code}\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject Intercept + Item intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\",\n                control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |   Chi2 |      p\n--------------------------------------------------\nmm.rS  | glmerMod |  2 |         |        |       \nmm.rSQ | glmerMod |  3 |       1 | 282.10 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  2.61584550644328e-63\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = binomial,\n                control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n# summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |      |      \nmm.CrSQ | glmerMod |  6 |       3 | 2.55 | 0.466\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.466121170373078\"\n```\n:::\n:::\n\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\nControl: glmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 200000))\n\n     AIC      BIC   logLik deviance df.resid \n    2662     2702    -1325     2650     6234 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-10.213  -0.032  -0.010  -0.004   8.369 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 88.403   9.402   \n q       (Intercept)  0.658   0.811   \nNumber of obs: 6240, groups:  subject, 480; q, 13\n\nFixed effects:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  -10.212      0.671  -15.22   <2e-16 ***\npretty_conditionOrth-Sparse    0.440      0.814    0.54     0.59    \npretty_conditionTri-Sparse     0.914      0.749    1.22     0.22    \npretty_conditionOrth-Grid     -0.311      0.780   -0.40     0.69    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) pr_O-S pr_T-S\nprtty_cnO-S -0.400              \nprtty_cnT-S -0.375  0.391       \nprtty_cnO-G -0.466  0.367  0.395\n```\n:::\n\n```{.r .cell-code}\nprint(\"SIGNIFICANCE TEST [non directional]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGNIFICANCE TEST [non directional]\"\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m, type = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)\npretty_condition  2.51  3       0.47\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n\n\n#TODO POSTHOCS\n#:::::::: INTERPRET COEFFICIENTS\n\n# se <- sqrt(diag(stats::vcov(m)))\n# table of estimates with 95% CI\n# paste(\"LOG ODDS\")\n# (tab <- cbind(Est = fixef(m), \n#               LL = fixef(m) - 1.96 * se, \n#               UL = fixef(m) + 1.96 * se))\n# paste(\"ODDS RATIOS\")\n# (e <- exp(tab))\n```\n:::\n\n\n##### TODO Inference\n\n**TODO REDO UPDATE THIS**\n\nWe fit a mixed-effect binomial logistic regression model with random intercepts for subjects and items; to investigate the effect of condition on test phase item accuracy. The model including a fixed effect of condition performed significantly better than an intercept-only baseline model (χ2(4): 11.02, p \\< 0.001); and the total explanatory power is substantial (conditional R2 = 0.82) and the part related to the fixed effects (marginal R2) is 0.02. Consistent with the pattern of results for the first question only, across all test-phase items, being in the impasse condition increases the odds of a correct response by a factor of 2.8 over the control condition $e^{\\beta_1}$ = 2.80, 95% CI \\[1.54, 5.09\\], p \\< 0.001.\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\") #why no error bars? problem with model?\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-ACC-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")[[1]] +\n  ylim(0,1) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-ACC-5.png){width=672}\n:::\n\n```{.r .cell-code}\n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n```\n:::\n\n\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\n# report(m)\n\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n##### TODO\nModel with random intercept of Question doesn't want to converge unless I use the optimizer, which also throws warnings. Maybe jsut use random subject?\n(hint... yes...) Otherwise, try the bayesian version\n##### BAYESIAN \nFor some reason there are convergence difficulties. Try again with the brms version\n\n::: {.cell}\n\n```{.r .cell-code}\n#BAYESIAN MIXED VERSION\n\ndf <- df_i %>% mutate(\n  accuracy = as.integer(accuracy)\n)\n\n#TODO bernoulli or binomial?\nB.mm.acc.CrSQ <- brm( accuracy ~ pretty_condition + (1|subject) + (1|q),\n                 data = df_i,\n                 # family = \"binomial\",\n                 family = bernoulli(link = \"logit\"),\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC4A/models/sgc4a_brms_B.mm.acc.CrSQ.rds\")\n\n\nsummary(B.mm.acc.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: binomial \n  Links: mu = logit \nFormula: as.integer(accuracy) ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 6240) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.11      0.04     0.05     0.19 1.00     1659     1997\n\n~subject (Number of levels: 480) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.70      0.04     0.63     0.77 1.00     1561     2218\n\nPopulation-Level Effects: \n                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                       0.40      0.07     0.26     0.54 1.00     1192\npretty_conditionOrthMSparse     0.09      0.10    -0.11     0.29 1.00     1097\npretty_conditionTriMSparse      0.18      0.09     0.00     0.37 1.00     1070\npretty_conditionOrthMGrid      -0.17      0.10    -0.36     0.02 1.00     1246\n                            Tail_ESS\nIntercept                       1824\npretty_conditionOrthMSparse     2165\npretty_conditionTriMSparse      1844\npretty_conditionOrthMGrid       1992\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nplot_model(B.mm.acc.CrSQ, show.values = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(pd(B.mm.acc.CrSQ))\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# plot(equivalence_test(B.mm.acc.CrSQ))\nplot_model(B.mm.acc.CrSQ, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing the maximum response value as the number of trials.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using 'binomial' families without specifying 'trials' on the left-hand\nside of the model formula is deprecated.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in max(out$Y, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n:::\n\n## H1A \\| OVERALL INTERPRETATION STATE\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions?                                          |\n+=======================+=================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q nin 6,9` (13 discriminant test phase items)                                                              |\n|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                          |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |\n|                       |                                                                                                                                                 |\n|                       | Alternative:                                                                                                                                    |\n|                       |                                                                                                                                                 |\n|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |\n|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(title = \"Interpretation across all Questions\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             Orth-Full Orth-Sparse Tri-Sparse Orth-Grid    Sum\n  orthogonal    0.6728      0.6442     0.5743    0.7017 0.6439\n  other         0.1215      0.1241     0.1357    0.1664 0.1354\n  tri-like      0.0210      0.0210     0.0342    0.0235 0.0255\n  triangular    0.1846      0.2107     0.2559    0.1083 0.1952\n  Sum           1.0000      1.0000     1.0000    1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             Orth-Full Orth-Sparse Tri-Sparse Orth-Grid  Sum\n  orthogonal      1312         737       1075       894 4018\n  other            237         142        254       212  845\n  tri-like          41          24         64        30  159\n  triangular       360         241        479       138 1218\n  Sum             1950        1144       1872      1274 6240\n```\n:::\n:::\n\n#### MIXED MULTINOMIAL REGRESSION\n\n\n*Does condition affect the response state of of items across the task?*\n\n\n##### TODO Fit Model \\[mblogit\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n# TRY AGAIN... MAYBE HUNG? \n\n# #https://www.elff.eu/software/mclogit/manual/mblogit/\n# #\"baseline category logit\" model matches multinom()\n# \n# #check reference level \n# print(\"Categories (first is reference)\")\n# levels(df_i$state)\n# \n# #FIT EMPTY MODEL\n# # print(\"EMPTY MODEL\")\n# m.mbl0 <- mblogit(state ~ pretty_condition ,  #no random intercepts; fixed only model \n#                   data = df_i)\n# #summary(m.mbl0)\n# \n# #FIT PREDICTOR MODEL\n# # print(\"PREDICTOR MODEL\")\n# m.mbl1 <- mblogit(state ~ pretty_condition , \n#                   random = list( ~ 1|subject, ~1|q), \n#                   data = df_i)\n# # summary(m.mbl1)\n# \n# #COMPARE MODEL FIT\n# paste(\"AIC wth predictor is lower than empty model?\", AIC(m.mbl0) > AIC(m.mbl1))\n# test_lrt(m.mbl0, m.mbl1)\n# \n# #DESCRIBE MODEL\n# summary(m.mbl1)\n# \n# #INTERPRET COEFFICIENTS\n# cint <- confint(m.mbl1, level = 0.95)\n# print(\"ODDS RATIO\")\n# (e <- cbind( exp(coef(m.mbl1)), exp(cint))) #exponentiated, adjusted\n# \n# #PERFORMANCE\n# performance(m.mbl1)\n# \n# #TABLE\n# tab_model(m.mbl1, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n```\n:::\n\n\n##### TODO Inference\n\n\n##### Fit Model \\[brms\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#BAYESIAN MIXED VERSION\nmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC4A/models/sgc4a_brms_mixedcat_state.rds\")\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model \nm <- mm.cat.CrSQ\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muother = logit; mutrilike = logit; mutriangular = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 6994) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.65      0.36     1.10     2.51 1.00      936\nsd(mutrilike_Intercept)        2.41      0.70     1.40     4.15 1.00     1257\nsd(mutriangular_Intercept)     1.64      0.41     1.07     2.58 1.01     1172\n                           Tail_ESS\nsd(muother_Intercept)          1638\nsd(mutrilike_Intercept)        2219\nsd(mutriangular_Intercept)     1716\n\n~subject (Number of levels: 538) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.83      0.10     1.63     2.03 1.00     1373\nsd(mutrilike_Intercept)        2.99      0.29     2.46     3.61 1.00     1085\nsd(mutriangular_Intercept)     5.27      0.32     4.65     5.92 1.00      928\n                           Tail_ESS\nsd(muother_Intercept)          2313\nsd(mutrilike_Intercept)        2028\nsd(mutriangular_Intercept)     1829\n\nPopulation-Level Effects: \n                                         Estimate Est.Error l-95% CI u-95% CI\nmuother_Intercept                           -2.70      0.51    -3.72    -1.66\nmutrilike_Intercept                         -6.71      0.91    -8.58    -4.97\nmutriangular_Intercept                      -4.46      0.69    -5.85    -3.12\nmuother_pretty_conditionOrthMSparse          0.12      0.28    -0.44     0.67\nmuother_pretty_conditionOrthMGrid            0.48      0.26    -0.03     0.99\nmuother_pretty_conditionTriMSparse           0.69      0.27     0.17     1.22\nmutrilike_pretty_conditionOrthMSparse        0.19      0.59    -0.97     1.32\nmutrilike_pretty_conditionOrthMGrid          0.12      0.57    -1.04     1.22\nmutrilike_pretty_conditionTriMSparse         1.49      0.53     0.48     2.53\nmutriangular_pretty_conditionOrthMSparse     0.21      0.74    -1.20     1.67\nmutriangular_pretty_conditionOrthMGrid      -1.43      0.77    -2.98     0.04\nmutriangular_pretty_conditionTriMSparse      1.54      0.69     0.26     2.97\n                                         Rhat Bulk_ESS Tail_ESS\nmuother_Intercept                        1.00      571     1157\nmutrilike_Intercept                      1.01      735     1277\nmutriangular_Intercept                   1.00      470     1017\nmuother_pretty_conditionOrthMSparse      1.00     1214     2044\nmuother_pretty_conditionOrthMGrid        1.00     1189     2075\nmuother_pretty_conditionTriMSparse       1.00     1237     1993\nmutrilike_pretty_conditionOrthMSparse    1.00     1606     2707\nmutrilike_pretty_conditionOrthMGrid      1.00     1531     2119\nmutrilike_pretty_conditionTriMSparse     1.00     1426     2399\nmutriangular_pretty_conditionOrthMSparse 1.01      440      764\nmutriangular_pretty_conditionOrthMGrid   1.01      497      729\nmutriangular_pretty_conditionTriMSparse  1.01      394      617\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\", \n#            show.intercept = TRUE, \n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test   \n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# result <- simulate_parameters(m)\n# plot(result, stack = FALSE)\n\n#check posterior\npp_check(m, ndraws=1000)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.0783\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 4800 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-3.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- rope(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-4.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- pd(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-5.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-BRMS-STATE-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n```\n:::\n\n##### TODO Inference\n\n\n##### COMPARE\n\n::: {.cell}\n\n```{.r .cell-code}\n# compare_models(m.mbl1, mm.cat.CrSQ)\n```\n:::\n\n\n\n## H1B \\| Q1 ACCURACY\n\n\nThe graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                   |\n+=======================+========================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the TRI condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                    |\n|                       | -   outcome: *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                            |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                 |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |\n|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |\n|                       |                                                                                                                                                                                                                                        |\n|                       | Alternatives:                                                                                                                                                                                                                          |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   Chi-Square test of independence on outcome `accuracy` by `condition`                                                                                                                                                               |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \\~ continuous; though with regression we can quantify the size of the effect and overall model fit |\n|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |\n|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1)  %>% dplyr::select(accuracy, pretty_condition)\n```\n:::\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-Q1ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: BARSTATS\nggbarstats( data = df, y = pretty_condition, x = accuracy)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-Q1ACC-2.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Proportions of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            Orth-Full Orth-Sparse Tri-Sparse Orth-Grid    Sum\n  incorrect    0.9000      0.8864     0.8542    0.9592 0.8958\n  correct      0.1000      0.1136     0.1458    0.0408 0.1042\n  Sum          1.0000      1.0000     1.0000    1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\npaste(\"Number of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Number of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            Orth-Full Orth-Sparse Tri-Sparse Orth-Grid Sum\n  incorrect       135          78        123        94 430\n  correct          15          10         21         4  50\n  Sum             150          88        144        98 480\n```\n:::\n:::\n\n#### LOGISTIC REGRESSION\n\nFit a logistic regression predicting accuracy (absolute score) (n = 480) by condition (k = 2).\\\n\n-   Parameter estimate: $\\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition\n-   $e^{\\beta_{0}}$ = ODDS of correct response in CONTROL condition\n-   Parameter estimate: $\\beta_{1}$ = $\\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])\n-   $e^{\\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\n-   **Null hypothesis**:$\\beta_{impasse} \\le 0$ the odds for a correct response does not change, or decreases\n-   **Alternative hypothesis:** $\\beta_{impasse} \\gt 0$ the odds of a correct response increases\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.561  -0.561  -0.459  -0.289   2.529  \n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   -2.197      0.272   -8.07  6.9e-16 ***\npretty_conditionOrth-Sparse    0.143      0.432    0.33    0.741    \npretty_conditionTri-Sparse     0.430      0.360    1.19    0.233    \npretty_conditionOrth-Grid     -0.960      0.578   -1.66    0.097 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 320.78  on 479  degrees of freedom\nResidual deviance: 312.90  on 476  degrees of freedom\nAIC: 320.9\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     7.88  3      0.049 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  4 |       3 | 7.88 | 0.049\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0486364443240912\"\n```\n:::\n:::\n\n*The Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .*\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.561  -0.561  -0.459  -0.289   2.529  \n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   -2.197      0.272   -8.07  6.9e-16 ***\npretty_conditionOrth-Sparse    0.143      0.432    0.33    0.741    \npretty_conditionTri-Sparse     0.430      0.360    1.19    0.233    \npretty_conditionOrth-Grid     -0.960      0.578   -1.66    0.097 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 320.78  on 479  degrees of freedom\nResidual deviance: 312.90  on 476  degrees of freedom\nAIC: 320.9\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     7.88  3      0.049 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.741\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.37\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"adjusted confint for directional hypothesis\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"adjusted confint for directional hypothesis\"\n```\n:::\n\n```{.r .cell-code}\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                               5 %    95 %\n(Intercept)                 -2.674 -1.7741\npretty_conditionOrth-Sparse -0.587  0.8464\npretty_conditionTri-Sparse  -0.158  1.0329\npretty_conditionOrth-Grid   -2.009 -0.0704\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients —- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                    5 %  95 %\n(Intercept)                 0.111 0.069 0.170\npretty_conditionOrth-Sparse 1.154 0.556 2.331\npretty_conditionTri-Sparse  1.537 0.853 2.809\npretty_conditionOrth-Grid   0.383 0.134 0.932\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\n# pred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n# #this should match : plogis(intercept coefficient)\n# paste(\"Probability of success in control,\", pred.control)\n# pred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n# #this should match : plogis(intercept coefficient + predictor coeff)\n# paste(\"Probability of success in impasse,\", pred.impasse)\n```\n:::\n##### TODO Inference\n\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#SET MODEL\nm <- m1\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"pred\")[[1]] +\n  ylim(0,1) + #scale y axis to actual range\n  labs(title = \"MODEL PREDICTION  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases probability of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.06&nbsp;&ndash;&nbsp;0.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.48&nbsp;&ndash;&nbsp;2.67</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.741</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Tri-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.54</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.76&nbsp;&ndash;&nbsp;3.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.233</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Grid]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.38</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11&nbsp;&ndash;&nbsp;1.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.097</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">480</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.015</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# print(\"SANITY CHECK REPORTING\")\n# report::report(m)\n\n#print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-DIAG-Q1ACC-1.png){width=672}\n:::\n:::\n\n\n## H1B \\| Q1 INTERPRETATION STATE\n\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |\n+=======================+===========================================================================================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |\n|                       | -   outcome: `state` ( 4 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                                                                                                    |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |\n|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) %>% dplyr::select(pretty_condition, state)\n```\n:::\n\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-Q1STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: BARSTATS\nggbarstats( data = df, y = pretty_condition, x = state)\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/VIS-Q1STATE-2.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             Orth-Full Orth-Sparse Tri-Sparse Orth-Grid     Sum\n  orthogonal   0.86000     0.81818    0.72917   0.91837 0.82500\n  other        0.02667     0.03409    0.03472   0.02041 0.02917\n  tri-like     0.00667     0.03409    0.09028   0.02041 0.03958\n  triangular   0.10667     0.11364    0.14583   0.04082 0.10625\n  Sum          1.00000     1.00000    1.00000   1.00000 1.00000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             Orth-Full Orth-Sparse Tri-Sparse Orth-Grid Sum\n  orthogonal       129          72        105        90 396\n  other              4           3          5         2  14\n  tri-like           1           3         13         2  19\n  triangular        16          10         21         4  51\n  Sum              150          88        144        98 480\n```\n:::\n:::\n\n#### MULTINOMIAL REGRESSION\n\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orthogonal\" \"other\"      \"tri-like\"   \"triangular\"\n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 665.421293 \niter  10 value 301.363054\niter  10 value 301.363052\niter  10 value 301.363052\nfinal  value 301.363052 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  20 (12 variable)\ninitial  value 665.421293 \niter  10 value 289.824282\niter  20 value 288.928010\nfinal  value 288.928004 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |     p\n------------------------------------------------\ncatm.0 | multinom |  3 |         |       |      \ncatm   | multinom | 12 |       9 | 24.87 | 0.003\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model\nm <- catm\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionOrth-Sparse pretty_conditionTri-Sparse\nother            -3.47                       0.295                      0.429\ntri-like         -4.86                       1.682                      2.771\ntriangular       -2.09                       0.113                      0.478\n           pretty_conditionOrth-Grid\nother                         -0.333\ntri-like                       1.053\ntriangular                    -1.026\n\nStd. Errors:\n           (Intercept) pretty_conditionOrth-Sparse pretty_conditionTri-Sparse\nother            0.508                       0.778                      0.684\ntri-like         1.004                       1.164                      1.046\ntriangular       0.265                       0.429                      0.357\n           pretty_conditionOrth-Grid\nother                          0.877\ntri-like                       1.232\ntriangular                     0.576\n\nResidual Deviance: 578 \nAIC: 602 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 665.421293 \niter  10 value 301.363054\niter  10 value 301.363052\niter  10 value 301.363052\nfinal  value 301.363052 \nconverged\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)   \npretty_condition     24.9  9     0.0031 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           p..Intercept. p.pretty_conditionOrth.Sparse\nother           7.82e-12                         0.704\ntri-like        1.29e-06                         0.149\ntriangular      3.33e-15                         0.792\n           p.pretty_conditionTri.Sparse p.pretty_conditionOrth.Grid\nother                           0.53022                      0.7039\ntri-like                        0.00808                      0.3928\ntriangular                      0.18066                      0.0746\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           OR..Intercept. OR.pretty_conditionOrth.Sparse\nother             0.03101                           1.34\ntri-like          0.00775                           5.37\ntriangular        0.12403                           1.12\n           OR.pretty_conditionTri.Sparse OR.pretty_conditionOrth.Grid\nother                               1.54                        0.717\ntri-like                           15.97                        2.867\ntriangular                          1.61                        0.358\n           p..Intercept. p.pretty_conditionOrth.Sparse\nother           7.82e-12                         0.704\ntri-like        1.29e-06                         0.149\ntriangular      3.33e-15                         0.792\n           p.pretty_conditionTri.Sparse p.pretty_conditionOrth.Grid\nother                           0.53022                      0.7039\ntri-like                        0.00808                      0.3928\ntriangular                      0.18066                      0.0746\n```\n:::\n:::\n\n##### TODO Inference\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-Q1STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"eff\", ci.lvl = 0.95)[[1]] +\n  ylim(0,1) +\n  labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n       subtitle = \"Impasse increases probability of more accurate response states Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc4A_hypotesting_files/figure-html/MODEL-VIS-Q1STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# #MANUALLY BUILD PREDICTION PLOT FACET BY CONDITION RATHER THAN STATE\n# p <-plot_model(m, type=\"eff\")[[1]]\n# d <- ggplot_build(p)[[1]]  \n# points <- d[[2]]\n# points <- points %>% mutate(\n#   state = recode(PANEL, \"1\" =\"orth\", \"2\"=\"other\", \"3\" = \"trilike\", \"4\"=\"tri\"),\n#   condition = recode(x, \"1\"=\"control\",\"2\"=\"impasse\"),\n#   prob = y\n# )\n# gf_point( prob ~ state, group = ~x, data = points) + \n#   geom_errorbar(aes( x = state, ymin = ymin, ymax = ymax)) + facet_grid(~condition) +ylim(0,1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Response</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.01&nbsp;&ndash;&nbsp;0.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.34</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.29&nbsp;&ndash;&nbsp;6.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.704</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Tri-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.54</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.40&nbsp;&ndash;&nbsp;5.88</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.531</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Grid]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.72</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13&nbsp;&ndash;&nbsp;4.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.704</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.06</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">tri-like</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.55&nbsp;&ndash;&nbsp;52.94</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.149</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">tri-like</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Tri-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">15.97</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.04&nbsp;&ndash;&nbsp;124.76</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.008</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">tri-like</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Grid]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.87</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.25&nbsp;&ndash;&nbsp;32.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.393</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">tri-like</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07&nbsp;&ndash;&nbsp;0.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.48&nbsp;&ndash;&nbsp;2.60</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.792</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Tri-Sparse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.61</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.80&nbsp;&ndash;&nbsp;3.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.181</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[Orth-Grid]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12&nbsp;&ndash;&nbsp;1.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.075</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">480</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.041 / 0.038</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(catm, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n601.856 | 651.941 | 0.041 |     0.038 | 0.273 | 1.111\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n    0.0413     0.0505     0.0706 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\n# chisq.test(df$state, predict(catm)) #actual states VS predicted states\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations\n```\n:::",
    "supporting": [
      "4_sgc4A_hypotesting_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}