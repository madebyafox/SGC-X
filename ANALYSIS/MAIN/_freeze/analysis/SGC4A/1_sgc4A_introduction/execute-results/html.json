{
  "hash": "84c722b35a667d833d28c1f260945184",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC4A | 1 Introduction'\n---\n\n\\newpage\n\n# Introduction {#sec-SGC4A-introduction}\n\n**In Study 4A we explore the extent to which the design of the axes and gridlines of the graph influence how a reader interprets its underlying coordinate system.**\n\n+----------------------------------+--------------------------------------------------------------------------------------------------------+\n| ![](/analysis/utils/img/111.png) | **Orthogonal-Full**\\                                                                                   |\n|                                  | Demo: [111](https://limitless-plains-85018.herokuapp.com/?study=SGC4A&condition=111&session=WEB-DEMO)  |\n+----------------------------------+--------------------------------------------------------------------------------------------------------+\n| ![](/analysis/utils/img/114.png) | **Orthogonal-Sparse**\\                                                                                 |\n|                                  | Demo: [114](https://limitless-plains-85018.herokuapp.com/?study=SGC4A&condition=114&session=WEB-DEMO)  |\n+----------------------------------+--------------------------------------------------------------------------------------------------------+\n| ![](/analysis/utils/img/115.png) | **Orthogonal-Grid**\\                                                                                   |\n|                                  | Demo: [115](https://limitless-plains-85018.herokuapp.com/?study=SGC4A&condition=115&session=WEB-DEMO)  |\n+----------------------------------+--------------------------------------------------------------------------------------------------------+\n| ![](/analysis/utils/img/113.png) | **Triangular-Sparse**\\                                                                                 |\n|                                  | Demo: [113](https://limitless-plains-85018.herokuapp.com/?study=SGC4A&condition=113&session=WEB-DEMO)\\ |\n+----------------------------------+--------------------------------------------------------------------------------------------------------+\n\n: **SGC4A Study Conditions** {tbl-colwidths=\"\\[40,60\\]\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(codebook) #data dictionary\nlibrary(tidyverse) #ALL THE THINGS\nlibrary(kableExtra) #tables\n\n#set some output options\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#IMPORT DATA \ndf_subjects <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_participants.rds')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Participants by Condition\"\ncols = c(\"Condition\",\"n\")\ncont <- table(df_subjects$pretty_condition)\ncont %>%  addmargins() %>% kbl(caption = title, col.names = cols) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Participants by Condition</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Condition </th>\n   <th style=\"text-align:right;\"> n </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Full </td>\n   <td style=\"text-align:right;\"> 88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Sparse </td>\n   <td style=\"text-align:right;\"> 88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Orth-Grid </td>\n   <td style=\"text-align:right;\"> 98 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Tri-Sparse </td>\n   <td style=\"text-align:right;\"> 86 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 360 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Experimental Hypothesis:**\\\n*We hypothesize that the design of the major axes (specifically orthogonal) axes establish for the learner the basis of the coordinate system. Differently oriented axes should lead the reader to be more open to alternative coordinate systems.*\n\n-   H1 The Triangular axes condition should yield significantly better performance\n    -   H1A \\| Triangular axis condition should yield higher total absolute score\n    -   H1B \\| Triangular axis condition should yield higher first question score\n    -   H1C \\| Triangular axis condition should yield lower response times on the first question (both overall, and specifically among participants who answer correctly)\n-   H2 \\| Addition of gridlines inside the orthogonal axes does not change performance\n    -   H2A \\| No difference in overall performance between Orth-Full, Orth-Sparse and Orth-Grid\n    -   H2B \\| No difference in first question score between Orth-Full, Orth-Sparse and Orth-Grid\n    -   H2C \\| No difference in response latency between Orth-Full, Orth-Sparse and Orth-Grid\n\n**Exploratory Questions**\n\n-   mouse path traversal: Does axes design yield different exploration pattern with the mouse?\n\n## METHODS\n\n### Design\n\nWe employed a mixed design with 1 between-subjects factor with 4 levels (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE) and 15 items (within-subjects factor).\n\nIndependent Variables:\n\n-   B-S (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE)\n-   W-S (Item x 15)\n\nDependent Variables:\n\n-   Response Accuracy : Is the response triangular-correct?\n-   Response Interpretation : (derived) With which interpretation of the graph is the subject's response on an individual question consistent?\n-   Response Latency : Time from stimulus onset to clicking 'Submit' button: time in (s)\n\n### Materials\n\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. @fig-sample. The list of questions can be found [here](utils/stimuli/sgcx_questions.csv).\n\n![Sample Question (Q=1) for Graph Comprehension Task](/analysis/utils/img/sample_graphComprehensionTask.png){#fig-sample fig-alt=\"picture of multiple select question on the left, accompanied by a triangular model graph on the right\" fig-align=\"center\"}\n\n### Procedure\n\nParticipants completed the study via a web-browser.\n\n\\(1\\) Upon starting, they submitted informed consent, before reading task instructions.\n\n\\(2\\) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n\n\\(3\\) Then participants completed an experimental block of 15 items : the Graph Comprehension Task\n\n\\(4\\) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n### Sample\n\nData were collected by convenience sample of a university subject pool during the winter of 2022. Participants accessed the study via a web browser (asynchronously). The stimulus application required the participant stay in full-screen mode for the entirety of the study.\n\n## ANALYSIS\n\n### Data Preparation {#sec-SGC4A-harmonize}\n\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\n-   completion status : \"success\" ; subject must have finished all parts of the study, including demographic questionnaire\n-   session ID: \\[in list\\] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\n-   browser interaction violations \\< 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\n-   self-rated effort \\> 2; subjects who reported, \"not trying hard/rushing through questions\" or \"started out trying hard but giving up at some point\" were excluded from analysis.\n-   attention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\n| Pre-Requisite              | Followed By         |\n|----------------------------|---------------------|\n| winter2022_clean_sgc4a.Rmd | 2_sgc4A_scoring.qmd |\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single *harmonized* data file for analysis (one for participants, one for items).\n\n#### Participants\n\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame `df_subjects` containing one row for each subject (across all periods). Note that we *are not* discarding any *response* data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\n\n*Note that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC4A/data/0-session-level/fall17_sgc4a_participants.csv\"\nspring18 <- \"analysis/SGC4A/data/0-session-level/spring18_sgc4a_participants.csv\"\nwinter22 <- \"analysis/SGC4A/data/0-session-level/winter22_sgc4a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,pretty_condition, term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    condition = as.factor(condition),\n    pretty_condition = \"NULL\",\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, pretty_condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  dplyr::select(subject, condition, pretty_condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#compare dataframe columns\njanitor::compare_df_cols(df_subjects, df_subjects_winter22, df_subjects_before)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        column_name df_subjects df_subjects_winter22 df_subjects_before\n1               age     integer              integer            numeric\n2           browser      factor               factor          character\n3         condition      factor               factor             factor\n4        confidence     integer              integer          character\n5           country   character            character          character\n6        difficulty     integer              integer          character\n7        disability        <NA>            character          character\n8            effort   character            character          character\n9         enjoyment     integer              integer          character\n10           gender      factor               factor          character\n11           height     integer              integer          character\n12         language   character            character          character\n13             mode      factor               factor          character\n14            other   character            character          character\n15 pretty_condition      factor               factor          character\n16       schoolyear   character            character          character\n17          subject      factor               factor          character\n18             term      factor               factor          character\n19      totaltime_m     numeric              numeric            numeric\n20       violations     numeric              numeric          character\n21            width     integer              integer          character\n```\n:::\n\n```{.r .cell-code}\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#REFACTOR CONDITIONS\ndf_subjects <- df_subjects %>% mutate(\n    condition = recode_factor(condition, \"11111\" = \"111\", \"112\" = \"112\", \"111\" = \"111\", \"113\" = \"113\", \"114\" = \"114\", \"115\"=\"115\"),\n    pretty_condition = recode_factor(condition, \"111\" = \"Orth-Full\", \"114\" =  \"Orth-Sparse\", \"113\"=\"Tri-Sparse\", \n                                     \"115\"=\"Orth-Grid\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_subjects_fall17, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,spring18,winter22)\n\n#FINALLY DROP CONDITION 112 (partial orthog with y axis lines extending only to right end of triangle)\n#this was an incomplete [pilot only] condition collected in FA17 SP18 for pilot purposes\ndf_subjects <- df_subjects %>% filter(condition != \"112\") %>% \n  mutate(\n    condition = droplevels(condition),\n    pretty_condition = droplevels(pretty_condition)\n  )\n\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#import file\n# df_subjects <- read_rds(\"analysis/SGC4A/data/0-session-level/sgc4a_participants.rds\") #use RDS file as it contains metadata\n# \n# #save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\n# df_q16 <- df_subjects %>% \n#   select(subject, condition, term , mode, explanation) %>% \n#   mutate(\n#     q = 16,\n#     response = explanation\n#   ) %>% select(-explanation)\n# \n# #reduce data collected using NEW webapp to useful columns\n# df_subjects <- df_subjects %>% \n#   mutate(score = absolute_score) %>% \n#   #select only columns we'll be analyzing, discard others\n#   dplyr::select( subject, condition, pretty_condition, term, mode, \n#                  #demographics\n#                  gender, age, language, schoolyear, country,\n#                  #effort survey\n#                  effort, difficulty, confidence, enjoyment, \n#                  #explanations\n#                  other,disability,\n#                  #response characteristics\n#                  totaltime_m,\n#                  #exploratory factors\n#                  violations, browser, width, height\n#                  )\n# \n# \n# effort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n# \n# #set factors\n# df_subjects <- df_subjects %>% \n#   #refactor factors\n#   mutate (\n#     subject = factor(subject),\n#     condition = factor(condition),\n#     term = factor(term),\n#     mode = factor(mode),\n#     gender = factor(gender),\n#     schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n#   )\n```\n:::\n\n#### Items\n\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame `df_items` containing one row for each *graph comprehension task question* (qs=15) (across all periods). A second data frame `df_freeresponse` contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we *do not* discard any *response* data. Rather, we *do* discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC4A/data/0-session-level/fall17_sgc4a_blocks.csv\"\nspring18 <- \"analysis/SGC4A/data/0-session-level/spring18_sgc4a_blocks.csv\"\nwinter22 <- \"analysis/SGC4A/data/0-session-level/winter22_sgc4a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% select(q,relation) %>% unique()\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n\n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_winter22_q16 <- df_winter22_q16 %>% dplyr::select(-pretty_condition)\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#REFACTOR CONDITIONS\ndf_items <- df_items %>% mutate(\n    condition = recode_factor(condition, \"11111\" = \"111\", \"112\" = \"112\", \"111\" = \"111\", \"113\" = \"113\", \"114\" = \"114\", \"115\"=\"115\"),\n    pretty_condition = recode_factor(condition, \"111\" = \"Orth-Full\", \"114\" =  \"Orth-Sparse\", \"113\"=\"Tri-Sparse\", \n                                     \"115\"=\"Orth-Grid\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,spring18,winter22, map_relations)\n\n#FINALLY DROP CONDITION 112 (partial orthog with y axis lines extending only to right end of triangle)\n#this was an incomplete [pilot only] condition collected in FA17 SP18 for pilot purposes\ndf_items <- df_items %>% filter(condition != \"112\") %>% \n  mutate(\n    condition = droplevels(condition),\n    pretty_condition = droplevels(pretty_condition)\n  )\n\n##OLD WITH ONLY WI22\n\n# # HACK WD FOR LOCAL RUNNING?\n# # imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #setwd(mbp)\n# \n# #read datafiles\n# df_items <- read_rds(\"analysis/SGC4A/data/0-session-level/sgc4a_items.rds\") #use RDS file as it contains metadata\n# \n# #reduce data collected using new webapp\n# df_items <- df_items %>% \n#   select(subject, condition, pretty_condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n#   mutate(\n#     subject = as.character(subject),\n#     condition = as.character(condition),\n#     term = as.character(term),\n#     mode = as.character(mode),\n#     q = as.integer(q),\n#     correct = as.logical(correct)\n#   ) %>% \n#   mutate(\n#     response = str_remove_all(as.character(answer), \",\"),\n#     num_o = str_length(response)\n#   ) %>% \n#   # handle NA values (why are some empty responses blank and others NA?) \n#   mutate(\n#     response = replace_na(response, \"\"),\n#     num_o = replace_na(num_o, 0)\n#   )\n```\n:::\n\n#### Validation\n\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n::: {.cell}\n\n```{.r .cell-code}\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n#### Export\n\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4A/data/1-study-level/sgc4a_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4A/data/1-study-level/sgc4a_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC4A/data/1-study-level/sgc4a_freeresponse.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4A/data/1-study-level/sgc4a_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4A/data/1-study-level/sgc4a_items.rds\") # to R data structure file\n```\n:::\n\n## RESOURCES\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9     \n [5] purrr_0.3.4      readr_2.1.2      tidyr_1.2.0      tibble_3.1.7    \n [9] ggplot2_3.3.6    tidyverse_1.3.1  codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3        bit64_4.0.5       vroom_1.5.7       jsonlite_1.8.0   \n [5] viridisLite_0.4.0 modelr_0.1.8      assertthat_0.2.1  highr_0.9        \n [9] cellranger_1.1.0  yaml_2.3.5        pillar_1.7.0      backports_1.4.1  \n[13] glue_1.6.2        digest_0.6.29     rvest_1.0.2       snakecase_0.11.0 \n[17] colorspace_2.0-3  htmltools_0.5.2   pkgconfig_2.0.3   broom_0.8.0      \n[21] labelled_2.9.1    haven_2.5.0       scales_1.2.0      webshot_0.5.3    \n[25] svglite_2.1.0     openxlsx_4.2.5    rio_0.5.29        tzdb_0.3.0       \n[29] generics_0.1.2    ellipsis_0.3.2    withr_2.5.0       janitor_2.1.0    \n[33] cli_3.3.0         magrittr_2.0.3    crayon_1.5.1      readxl_1.4.0     \n[37] evaluate_0.15     fs_1.5.2          fansi_1.0.3       xml2_1.3.3       \n[41] foreign_0.8-82    tools_4.2.1       data.table_1.14.2 hms_1.1.1        \n[45] lifecycle_1.0.1   munsell_0.5.0     reprex_2.0.1      zip_2.2.0        \n[49] compiler_4.2.1    systemfonts_1.0.4 rlang_1.0.3       grid_4.2.1       \n[53] rstudioapi_0.13   htmlwidgets_1.5.4 rmarkdown_2.14    gtable_0.3.0     \n[57] DBI_1.1.3         curl_4.3.2        R6_2.5.1          lubridate_1.8.0  \n[61] knitr_1.39        fastmap_1.1.0     bit_4.0.4         utf8_1.2.2       \n[65] stringi_1.7.6     parallel_4.2.1    Rcpp_1.0.8.3      vctrs_0.4.1      \n[69] dbplyr_2.2.1      tidyselect_1.1.2  xfun_0.31        \n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}