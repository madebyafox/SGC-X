{
  "hash": "ff8a06637e51fb1193df069096bccc96",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | (Relication) Hypothesis Testing'\n# YAML FOR generating modelsummary tables\n# uncomment to run those  cells only \n# \\usepackage{booktabs}\n# \\usepackage{siunitx}\n# \\newcolumntype{d}{S[input-symbols = ()]}\n---\n\n\\newpage\n\n# (Lab) Hypothesis Testing {#sec-SGC3A-replication-hypotesting}\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study (online replication, without OSPAN).*\n\n::: {.cell}\n\n```{.r .cell-code}\n#UTILITIES\nlibrary(Hmisc) # %nin% operator\nlibrary(broom) #tidy model output\nlibrary(broom.mixed) #tidy mixed models\nlibrary(mosaic) #favstats\nlibrary(svglite) #saving plots as svg\nlibrary(distributional)\n\n#VISUALIZATION\n# library(ggpubr) #arrange plots\n# library(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\n# # library(vcd) #mosaic plots\n# # library(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables\nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz\nlibrary(gghalves) # plots. in half\nlibrary(ggbeeswarm) # violin plot stuffs\nlibrary(statsExpressions)\nlibrary(ggstatsplot) #plots with stats\nlibrary(modelsummary) #latex tables for models!\n\n#MODELLING\n# library(rstatix) #helpful testing functions incl wilcoxon, etc\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(parameters) #easystats model summary and vis\n# library(qqplotr) #confint on qq plot\n# library(gmodels) #contingency table and CHISQR\n# library(equatiomatic) #extract model equation\n# library(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models\nlibrary(lmerTest) #for CIs in glmer\nlibrary(merTools) #prediction intervalus for glmers \n# library(ggeffects) #visualization log regr models\n#MULTINOMIAL \nlibrary(nnet) #multinomial logistic regression [not mixed] #no p values\nlibrary(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values\n#BAYESIAN\nlibrary(cmdstanr) #executing stan\nlibrary(brms) #bayesian mixed multinomials [+ other bayesian reg models]\nlibrary(bayestestR) \nlibrary(modelr) #helping with tidybayes\nlibrary(tidybayes)\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\n# theme_set(theme_minimal()) \n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"BarlowSemiCondensed-Bold\"),\n          axis.title = element_text(family = \"BarlowSemiCondensed-Medium\"),\n          strip.text = element_text(family = \"BarlowSemiCondensed-Bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA))\n}\n\nset_theme(base = theme_clean())\n```\n:::\n\n**Research Questions**\n\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task?\n\n**Experimental Hypothesis**\\\n*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the IMPASSE condition will score higher overall than learners in CONTROL.\n-   H1B \\| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.\n\n**Null Hypothesis**\\\n*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT DATA \ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds') %>% \n  filter(mode == \"asynch\") %>% #only get lab-run participants\n  mutate(\n    task_percent = DV_percent_NABS\n  ) %>% droplevels()\n\n#IMPORT OSPAN SUBJECTS\ndf_ospan <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_ospan.rds') \n\n#KEEP ONLY SUBJECTS WHO DIDNT COMPLETE OPSAN [ie the replication study]\ndf_subjects <- df_subjects %>% filter( subject %nin% df_ospan$subject)\n\ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds') %>% \n  filter(subject %in% df_subjects$subject) %>% #only get lab-run participants\n  mutate (\n    q = as.factor(q), \n    subject = as.factor(subject),\n    accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n    # CODES TVERSKY AS TRI-LIKE\n    # state = recode_factor(score_SCALED, #for ordinal\n    #                      \"-1\" = \"orth-like\",\n    #                      \"-0.5\" = \"unknown\",\n    #                      \"0\" = \"unknown\",\n    #                      \"0.5\" = \"tri-like\",\n    #                      \"1\" = \"tri-like\"),\n    # CODES TVERSKY AS OTHER\n    state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orthogonal\",\n                         \"-0.5\" = \"other\",\n                         \"0\" = \"other\",\n                         \"0.5\" = \"angular\",\n                         \"1\" = \"triangular\"),\n    state = as.ordered(state)) \n```\n:::\n\n## SAMPLE\n\n### Data Collection\n\nData was collected (online, via SONA) in Fall 2021 and Winter 2022, for the purpose of verifying the use of the graph comprehension task for online, asynchronous data collection. \n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Participants by Condition and Data Collection Period</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Control Condition </th>\n   <th style=\"text-align:right;\"> Impasse Condition </th>\n   <th style=\"text-align:right;\"> Total for Period </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> fall21 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> winter22 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 37 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 31 </td>\n   <td style=\"text-align:right;\"> 40 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n### Participants\n\n::: {.cell}\n\n```{.r .cell-code}\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;border-bottom: 0;'>\n<caption>Descriptive Statistics of Participant Age and Gender</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n   <th style=\"text-align:right;\"> percent.male </th>\n   <th style=\"text-align:right;\"> percent.female </th>\n   <th style=\"text-align:right;\"> percent.other </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 20.6 </td>\n   <td style=\"text-align:right;\"> 1.61 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.282 </td>\n   <td style=\"text-align:right;\"> 0.676 </td>\n   <td style=\"text-align:right;\"> 0.042 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<span style=\"font-style: italic;\">Note: </span> <sup></sup> Age in Years</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n**Overall** 71 participants (28 % male, 68 % female, 4 % other)  undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 27 years).\n\n\n## H1A \\| OVERALL ACCURACY\n\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Do Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?                                                                                                                                                                                |\n+=======================+====================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | (H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.                                                                                                                                               |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | **data**: `df_items` where `q nin 6,9` (the 13 discriminating Qs ), `df_subjects`                                                                                                                                                                                                  |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **outcome**:                                                                                                                                                                                                                                                                       |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   \\[at item level\\] : *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                                                             |\n|                       | -   \\[subject level\\]: accuracy (number of test phase qs correct from total `s_NABS`)                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **predictor**: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                             |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Wilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (`s_NABS`)                                                                                                                                                                                 |\n|                       | 2.  Mixed Logistic Regression\\                                                                                                                                                                                                                                                     |\n|                       |     `accuracy` \\~ `condition` + (1 \\| `subject` ) + (1 \\| `question`)\\                                                                                                                                                                                                             |\n|                       |     model effect of condition on probability of correct response \\[during test phase\\] while accounting for subject (and item-level?) effects                                                                                                                                      |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Alternatives**      | -   Ordinal Mixed Logistic Regression on `scaled_score`                                                                                                                                                                                                                            |\n|                       | -   OLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | **Also exploring:**                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   Hurdle model (mixture model w/ binomial + \\[poisson or negbinom count; 0s from 1 DGP)                                                                                                                                                                                          |\n|                       | -   Zero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)                                                                                                                                                                                    |\n|                       | -   Beta regression hurdle model? (mixture with location and scale parameters \\[mean, variance\\] and hurdles for floor and ceiling effects)                                                                                                                                        |\n|                       | -   Other way to account for the severe bimodality?                                                                                                                                                                                                                                |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q)\n\ndf_s <- df_subjects %>% \n   dplyr::select(pretty_condition, task_percent)\n```\n:::\n\n#### Visualize\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 2))+\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n  # coord_flip() +\n  theme(legend.position=\"bottom\")+\n   labs(title = \"DISTRIBUTION | Question Accuracy\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/DESC-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs(title = \"DISTRIBUTION | Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/DESC-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  # gf_facet_grid(pretty_condition ~ pretty_mode) %>%\n  gf_facet_grid(~pretty_condition) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"DISTRIBUTION | Total Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/DESC-ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: RAINCLOUD WITH STATS\n  \ndf <- df_s %>% mutate(task_percent = task_percent*100)\n\np <-   ggbetweenstats(data = df, x = pretty_condition, y = task_percent,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               # package = \"RColorBrewer\",\n               # palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  # aes(color = pretty_condition, fill = pretty_condition),\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  theme(axis.text.x = element_text(angle = 90)))\n               ) +\n  ggdist::stat_halfeye(\n    alpha = 0.7, \n    point_colour = NA,\n    adjust = .5, \n    width = .5, .width = 0, \n    justification = -.5) +\n  geom_boxplot(\n    alpha = 0.1,\n    width = .2, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 2,\n    alpha = .5,\n    position = position_jitter(\n      seed = 1, width = .08, height = 1.5\n    )\n  )  +\ncoord_flip() + theme_clean() + theme(legend.position = \"blank\")\np$layers[[3]]=NULL #remove default boxplot\ne <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE)\n#labels are layer 4\np + labs(title = \"DISTRIBUTION of Total Score\",\n         y = \"Percentage of correct responses across task\", x = \"\",\n         # caption=e$expression[[1]],\n         subtitle = \"Impasse condition yields greater variance and more high scores\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/DESC-ACC-4.png){width=672}\n:::\n:::\n\n\n### Describe\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.769 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.315 </td>\n   <td style=\"text-align:right;\"> 0.39 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> pretty_condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.231 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.233 </td>\n   <td style=\"text-align:right;\"> 0.372 </td>\n   <td style=\"text-align:right;\"> 31 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> impasse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.115 </td>\n   <td style=\"text-align:right;\"> 0.788 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.379 </td>\n   <td style=\"text-align:right;\"> 0.397 </td>\n   <td style=\"text-align:right;\"> 40 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n#### WILCOXON RANK SUM (Mann-Whitney Test) \n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n##### Test\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$task_percent ~ df_s$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$task_percent by df_s$pretty_condition\nW = 468, p-value = 0.03\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_s$task_percent and df_s$pretty_condition suggests that the effect is negative, statistically significant, and medium (W = 467.50, p = 0.034; r (rank biserial) = -0.25, 95% CI [-1.00, -0.02])\n```\n:::\n:::\n\n\n##### Inference -- DIRECTIONAL EFFECT\n\n\n##### Visualize\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats( x = pretty_condition, y = task_percent, data = df_s,\n                type = \"nonparametric\", var.equal = FALSE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIZ-TEST-ACC-1.png){width=672}\n:::\n:::\n\n\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  2 |       1 | 542.09 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  6.62439101233609e-120\"\n```\n:::\n\n```{.r .cell-code}\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject Intercept + Item intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.rSQ | glmerMod |  3 |       1 | 13.43 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.00024829256662973\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n#summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |      |      \nmm.CrSQ | glmerMod |  4 |       1 | 3.81 | 0.051\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0510053431608199\"\n```\n:::\n\n```{.r .cell-code}\n# control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n```\n:::\n\n*A likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.*\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::: SETUP\nm <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     599      618     -296      591      919 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-6.192 -0.230 -0.091  0.195  4.828 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 15.137   3.891   \n q       (Intercept)  0.474   0.689   \nNumber of obs: 923, groups:  subject, 71; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -3.583      0.951   -3.77  0.00017 ***\npretty_conditionimpasse    2.124      1.114    1.91  0.05657 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.769\n```\n:::\n\n```{.r .cell-code}\nprint(\"SIGNIFICANCE TEST [non directional]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGNIFICANCE TEST [non directional]\"\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)  \npretty_condition  3.64  1      0.057 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"MODEL INFO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL INFO\"\n```\n:::\n\n```{.r .cell-code}\nglance(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n   nobs sigma logLik   AIC   BIC deviance df.residual\n  <int> <dbl>  <dbl> <dbl> <dbl>    <dbl>       <int>\n1   923     1  -296.  599.  619.     368.         919\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n# se <- sqrt(diag(stats::vcov(m)))\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   -3.58      0.951     -3.77  1.65e-4  -5.45       -1.72\n2 fixed    <NA>   pret…    2.12      1.11       1.91  5.66e-2  -0.0594      4.31\n3 ran_pars subje… sd__…    3.89     NA         NA    NA        NA          NA   \n4 ran_pars q      sd__…    0.689    NA         NA    NA        NA          NA   \n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- exp(tab))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   0.0278    0.0264     -3.77  1.65e-4  0.00431     0.179\n2 fixed    <NA>   pret…   8.36      9.31        1.91  5.66e-2  0.942      74.2  \n3 ran_pars subje… sd__…   3.89     NA          NA    NA       NA          NA    \n4 ran_pars q      sd__…   0.689    NA          NA    NA       NA          NA    \n```\n:::\n\n```{.r .cell-code}\npaste(\"PROBABILITIES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PROBABILITIES\"\n```\n:::\n\n```{.r .cell-code}\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\n#setup df \nnewdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(pretty_condition, fit, lwr, upr) %>% \n  group_by(pretty_condition) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  pretty_condition median   lower upper\n  <fct>             <dbl>   <dbl> <dbl>\n1 control          0.0267 0.00468 0.142\n2 impasse          0.185  0.0444  0.523\n```\n:::\n:::\n\n##### INFERENCE — DIRECTIONAL EFFECT\n\np = 0.06; but we should be performing a directional test, so actually OK.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.94&nbsp;&ndash;&nbsp;74.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.057</td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">15.14</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.47</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.83</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">71</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">923</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.055 / 0.836</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n\n#SJPLOT | MODEL | lOG ODDS\nplot_model(m, transform = NULL,\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, transform = \"exp\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | Log Odds\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result) + labs(\n#     title = \"Model ESTIMATE | ODDS RATIO\"\n#   )\n\n## | PLOT TESTS\n# result <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n# plot(result)\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"pred\")[[1]]  +\n  ylim(0,1) +\n  labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"Impasse increases probability of correct response\",\n    y = \"Probability of Correct Response\", x = \"Condition\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGDIST | MODEL | PREDICTED PROBABILITIES\npreds %>% \n  ggplot(aes( x = fit, y = pretty_condition, fill = pretty_condition)) + \n  stat_halfeye(alpha = 0.5, normalize = \"xy\") + \n  xlim(0,0.3) + theme_clean() + labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"TODO check preds to see if fixed or includes random\"\n  )\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-ACC-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# SIMULATE FIXED EFFECTS\n# simulate values of fixed effects \n# (feEx <- FEsim(m,  oddsRatio = FALSE, n.sims = 1000))\n# PLOT estimates of fixed effects\n# plotFEsim(feEx) +\n#   theme_bw() + labs(title = \"Coefficient Plot of InstEval Model\",\n#                     x = \"Median Effect Estimate\")\n\n# SIMULATE RANDOM EFFECTS\n# simulate values of random effects\n# reEx <- REsim(m)\n# PLOT estimates of random effects\n# plotREsim(reEx)\n```\n:::\n\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-DIAG-ACC-1.png){width=672}\n:::\n:::\n\n\n##### Sanity Check :: Bayesian\n\n::: {.cell}\n\n```{.r .cell-code}\n# ## 0 | SETUP\n# #confirm 13 items [all discriminating items]\n# nrow(df_i) / nrow(df_s) == 13\n# #confirm all factors \n# is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n# \n#\n# \n# print(\"FIXED Condition + Subject & Item random intercepts\")\n# Bmm.CrSQ <- brm( accuracy ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"bernoulli\",\n#                  chains = 4, iter = 2000, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_acc_Bmm.CrSQ_REP.rds\")\n# \n# #get Priors \n# # describe_priors(Bmm.CrSQ)\n# \n# #GRAPHICAL POSTERIOR PREDICTION CHECKS\n# pp_check(Bmm.CrSQ)\n# \n# #DESCRIBE MODEL\n# (d <- describe_posterior(ci=.95, Bmm.CrSQ))\n# \n# #SEE MODEL\n# plot(pd(Bmm.CrSQ))\n# #convert to a pd value\n# (pds <- pd_to_p(d$pd))\n```\n:::\n\n*A likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# #::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n# ##WORKING\n# ## VIS probability of correct response\n# #TAKES A REALLY LONG TIME\n# \n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(\"analysis/SGC3A/models/draws_BB.catCrSQ.rds\")\n# \n# #2| VISUALIZE PREDICTIONS | GGDIST\n# ##TODO figure out height normalization.\n# ##do it with much smaller number of draws \n# #TODO adjust bandwidth/smoothing? + put on same line + \n# #TAKES A REAAALY LONG TIME\n# # draws %>% sample_n(1000) %>% \n# #   ggplot(aes(x = .value,  y = 0, fill = pretty_condition)) +\n# #   stat_slab(width = c(.95), alpha = 1, normalize=\"xy\") +\n# #   #normalize = all, panels, xy, groups, none\n# #   xlim(0,1) + labs(\n# #     title = \"Model Predicted Probability of Correct Response\",\n# #     x = \"probability of correct response\",\n# #     y = \"Interpretation\"\n# #   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n```\n:::\n\n## H1A \\| OVERALL INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions?                                          |\n+=======================+=================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q nin 6,9` (13 discriminant test phase items)                                                              |\n|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                          |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |\n|                       |                                                                                                                                                 |\n|                       | Alternative:                                                                                                                                    |\n|                       |                                                                                                                                                 |\n|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |\n|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  # facet_wrap(~pretty_mode) + \n  theme(legend.position = \"bottom\")+\n   labs(title = \"DISTRIBUTION of Interpretation\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  facet_wrap(~q) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. In the impasse condition, there are also more positive transition (i.e. triangle-like) and neutral (ie. blank or uncertain response types) than in the control condition.\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse    Sum\n  orthogonal  0.5682  0.3096 0.4225\n  other       0.1489  0.2250 0.1918\n  angular     0.0323  0.0500 0.0423\n  triangular  0.2506  0.4154 0.3434\n  Sum         1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse Sum\n  orthogonal     229     161 390\n  other           60     117 177\n  angular         13      26  39\n  triangular     101     216 317\n  Sum            403     520 923\n```\n:::\n:::\n\n#### MIXED MULTINOMIAL REGRESSION\n\n\n*Does condition affect the response state of of items across the task?*\n\n*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n##### Fit Model \\[mblogit\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://www.elff.eu/software/mclogit/manual/mblogit/\n#\"baseline category logit\" model matches multinom()\n\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df_i$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nmm.cat.rSQ <- mblogit(state ~ 1 , \n                      random = list( ~ 1|subject, ~1|q), \n                      data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 1692 - criterion = 0.811\nIteration 2 - deviance = 1480 - criterion = 0.0727\nIteration 3 - deviance = 1411 - criterion = 0.0226\nIteration 4 - deviance = 1360 - criterion = 0.0156\nIteration 5 - deviance = 1352 - criterion = 0.00284\nIteration 6 - deviance = 1361 - criterion = 0.000387\nIteration 7 - deviance = 1362 - criterion = 0.000149\nIteration 8 - deviance = 1362 - criterion = 0.0000855\nIteration 9 - deviance = 1361 - criterion = 0.0000554\nIteration 10 - deviance = 1360 - criterion = 0.0000361\nIteration 11 - deviance = 1360 - criterion = 0.000023\nIteration 12 - deviance = 1360 - criterion = 0.0000143\nIteration 13 - deviance = 1359 - criterion = 8.81e-06\nIteration 14 - deviance = 1359 - criterion = 5.36e-06\nIteration 15 - deviance = 1359 - criterion = 3.25e-06\nIteration 16 - deviance = 1359 - criterion = 1.96e-06\nIteration 17 - deviance = 1359 - criterion = 1.19e-06\nIteration 18 - deviance = 1359 - criterion = 7.27e-07\nIteration 19 - deviance = 1359 - criterion = 4.45e-07\nIteration 20 - deviance = 1359 - criterion = 2.74e-07\nIteration 21 - deviance = 1359 - criterion = 1.7e-07\nIteration 22 - deviance = 1359 - criterion = 1.06e-07\nIteration 23 - deviance = 1359 - criterion = 6.62e-08\nIteration 24 - deviance = 1359 - criterion = 4.16e-08\nIteration 25 - deviance = 1359 - criterion = 2.63e-08\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Algorithm did not converge\n```\n:::\n\n```{.r .cell-code}\n#summary(mm.cat.rSQ)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nmm.cat.CrSQ <- mblogit(state ~ pretty_condition , \n                  random = list( ~ 1|subject, ~1|q), \n                  data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 1667 - criterion = 0.809\nIteration 2 - deviance = 1473 - criterion = 0.0698\nIteration 3 - deviance = 1400 - criterion = 0.0263\nIteration 4 - deviance = 1378 - criterion = 0.00458\nIteration 5 - deviance = 1365 - criterion = 0.00112\nIteration 6 - deviance = 1356 - criterion = 0.000422\nIteration 7 - deviance = 1350 - criterion = 0.000212\nIteration 8 - deviance = 1347 - criterion = 0.000121\nIteration 9 - deviance = 1346 - criterion = 0.000071\nIteration 10 - deviance = 1345 - criterion = 0.0000412\nIteration 11 - deviance = 1344 - criterion = 0.0000235\nIteration 12 - deviance = 1344 - criterion = 0.0000134\nIteration 13 - deviance = 1344 - criterion = 7.57e-06\nIteration 14 - deviance = 1343 - criterion = 4.31e-06\nIteration 15 - deviance = 1343 - criterion = 2.47e-06\nIteration 16 - deviance = 1343 - criterion = 1.43e-06\nIteration 17 - deviance = 1343 - criterion = 8.37e-07\nIteration 18 - deviance = 1343 - criterion = 4.95e-07\nIteration 19 - deviance = 1343 - criterion = 2.96e-07\nIteration 20 - deviance = 1343 - criterion = 1.79e-07\nIteration 21 - deviance = 1343 - criterion = 1.09e-07\nIteration 22 - deviance = 1343 - criterion = 6.71e-08\nIteration 23 - deviance = 1343 - criterion = 4.15e-08\nIteration 24 - deviance = 1343 - criterion = 2.59e-08\nIteration 25 - deviance = 1343 - criterion = 1.62e-08\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Algorithm did not converge\n```\n:::\n\n```{.r .cell-code}\n# summary(mm.cat.CrSQ)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(mm.cat.rSQ) > AIC(mm.cat.CrSQ))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.cat.rSQ, mm.cat.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        |    Model | df | df_diff |  Chi2 |      p\n------------------------------------------------------\nmm.cat.rSQ  | mmblogit | 15 |         |       |       \nmm.cat.CrSQ | mmblogit | 18 |       3 | 23.60 | < .001\n```\n:::\n:::\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- mm.cat.CrSQ\n\n#DESCRIBE MODEL\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in sqrt(diag(vcov.phi)): NaNs produced\n\nWarning in sqrt(diag(vcov.phi)): NaNs produced\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df_i, random = list(~1 | \n    subject, ~1 | q))\n\nEquation for other vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.587      0.571   -2.78  0.00549 ** \npretty_conditionimpasse    1.573      0.419    3.75  0.00017 ***\n\nEquation for angular vs orthogonal:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  -3.282      0.743   -4.42  9.9e-06 ***\ntri(Intercept)               -1.904      0.817   -2.33    0.020 *  \npretty_conditionimpasse       1.643      0.653    2.52    0.012 *  \ntripretty_conditionimpasse    2.296      0.919    2.50    0.012 *  \n\nEquation for triangular vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)  \n(Intercept)               -1.904      0.817   -2.33    0.020 *\npretty_conditionimpasse    2.296      0.919    2.50    0.012 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Co-)Variances:\nGrouping level: subject \n             Estimate            Std.Err.            \nother~1       1.89                0.693              \nangular~1     1.86  3.97          1.536  2.510       \ntriangular~1  3.24  5.48 12.28      NaN  5.293 10.878\n\nGrouping level: q \n             Estimate         Std.Err.         \nother~1      2.91               NaN            \nangular~1    1.79 3.62         8.31 13.14      \ntriangular~1 1.51 1.96 2.25    4.92  9.42  6.19\n\nNull Deviance:     2560 \nResidual Deviance: 1340 \nNumber of Fisher Scoring iterations:  25\nNumber of observations\n  Groups by subject: 71\n  Groups by q: 13\n  Individual observations:  923\nNote: Algorithm did not converge.\n```\n:::\n\n```{.r .cell-code}\n#INTERPRET COEFFICIENTS\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `tidy()` method for objects of class mmblogit is not maintained by\nthe broom team, and is only supported through the lm tidier method. Please be\ncautious in interpreting and reporting broom output.\n\nWarning: NaNs produced\n\nWarning: NaNs produced\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  <chr>                     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 other~(Intercept)         -1.59     0.571     -2.78 5.49e-3   -2.71     -0.466\n2 angular~(Intercept)       -3.28     0.743     -4.42 9.91e-6   -4.74     -1.83 \n3 triangular~(Intercept)    -1.90     0.817     -2.33 1.97e-2   -3.51     -0.303\n4 other~pretty_conditio…     1.57     0.419      3.75 1.74e-4    0.751     2.39 \n5 angular~pretty_condit…     1.64     0.653      2.52 1.18e-2    0.363     2.92 \n6 triangular~pretty_con…     2.30     0.919      2.50 1.25e-2    0.494     4.10 \n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `tidy()` method for objects of class mmblogit is not maintained by\nthe broom team, and is only supported through the lm tidier method. Please be\ncautious in interpreting and reporting broom output.\n\nWarning: NaNs produced\n\nWarning: NaNs produced\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  <chr>                     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 other~(Intercept)         -1.59     0.571     -2.78 5.49e-3   -2.71     -0.466\n2 angular~(Intercept)       -3.28     0.743     -4.42 9.91e-6   -4.74     -1.83 \n3 triangular~(Intercept)    -1.90     0.817     -2.33 1.97e-2   -3.51     -0.303\n4 other~pretty_conditio…     1.57     0.419      3.75 1.74e-4    0.751     2.39 \n5 angular~pretty_condit…     1.64     0.653      2.52 1.18e-2    0.363     2.92 \n6 triangular~pretty_con…     2.30     0.919      2.50 1.25e-2    0.494     4.10 \n```\n:::\n\n```{.r .cell-code}\n# paste(\"MODEL INFO\")\n# glance(m)\n\n#PERFORMANCE\nperformance(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC       |       BIC |  RMSE | Sigma\n-------------------------------------\n12552.758 | 12639.656 | 0.276 | 1.210\n```\n:::\n:::\n\n\n##### TODO Inference\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">other~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.59</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.71&nbsp;&ndash;&nbsp;-0.47</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.006</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">angular~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.28</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;4.74&nbsp;&ndash;&nbsp;-1.83</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">triangular~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.90</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.51&nbsp;&ndash;&nbsp;-0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.020</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">other~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.57</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.75&nbsp;&ndash;&nbsp;2.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">angular~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.64</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.36&nbsp;&ndash;&nbsp;2.92</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.012</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">triangular~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.49&nbsp;&ndash;&nbsp;4.10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.013</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">71</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">923</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, \n           transform = \"exp\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-MBLOGIT-STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#TODO SEPARATE THIS BY EQUATION \n# ms <- model_parameters(Bmm.cat.CrSQ, component = \"conditional\")\n# m1 <- ms %>% filter(str_detect(Parameter, \"muother\"))\n# plot(m1)\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result, show_labels = TRUE, n_columns = 3)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-MBLOGIT-STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# result <- simulate_parameters(m)\n# plot(result, stack = FALSE)\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Could not estimate a good default ROPE range. Using 'c(-0.1, 0.1)'.\n```\n:::\n\n```{.r .cell-code}\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-MBLOGIT-STATE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")[[1]] + \n#   ylim(0,1) + labs(\n#     title = \"Model Prediction | Probability of Accurate Response\",\n#     subtitle = \"Impasse increases Probability of Correct Response\"\n#   )\n\n#TODO EMMEANS for the estimated marginal means\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# check_model(m)\n```\n:::\n\n\n\n##### Fit Model \\[brms\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.rSQ_REP.rds\")\n\n\n#UNINFORMATIVE PRIOR BAYESIAN MIXED VERSION\n# flat_Bmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"categorical\",\n#                  chains = 4, iter = 2500, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  save_pars = save_pars(all = TRUE),\n#                  # backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_state_FLAT_Bmm.cat.CrSQ_REP.rds\")\n\n\n# determine default priors \n# prior_summary(flat_Bmm.cat.CrSQ)\n\n#set priors [see justification, below]\ninf_priors <- c(\n  # too strong?\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muangular\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muother\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\")\n)\n\n#INFORMATIVE PRIORS\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 prior = inf_priors,\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.CrSQ_REP.rds\"\n                 )\n\n#a bayes factor model comparison of the flat vs informative prior models suggest convicing evidence that \n#informative prior model is a better fit\n# bayesfactor(Bmm.cat.CrSQ, flat_Bmm.cat.CrSQ)\n\n# PRIORS LOGIC \n# https://www.bayesrulesbook.com/chapter-13.html#building-the-logistic-regression-model\n\n#expectation for probability of _better_ response [in control]?\n#very low probability center: 0.1% [very low]; as logodds = logit(0.001) = -6.91\n#range from 0 to 55%  logit(0.55) = 0.201\n#probability of 0.1 to 55% is equivalent to [logodds] -6.91 +/ 2* 0.201\n#therefore... prior for intercept => Normal(−6.91, 0)\n\n\n#expectation for probability of _better_ response [in impasse]?\n#increases probablity from 0 % \n# 0 [very low]; as OR  = exp(0) = 1\n#range from 0 to 90%  exp(0.9) = 2.46\n#probability of 0 to 90% is equivalent to [ODDS scale] 1 +/ 2* 2.42\n#on log odds scale ? [0, ]\n#therefore... prior for intercept => Normal(1, 2.42)\n                             # prior = normal(0.07, 0.035),\n```\n:::\n\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm <- Bmm.cat.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 923) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.54      0.40     0.92     2.50 1.00     2162\nsd(muangular_Intercept)        1.68      0.61     0.82     3.21 1.00     1992\nsd(mutriangular_Intercept)     1.12      0.31     0.66     1.88 1.00     2299\n                           Tail_ESS\nsd(muother_Intercept)          3445\nsd(muangular_Intercept)        3351\nsd(mutriangular_Intercept)     3097\n\n~subject (Number of levels: 71) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.00      0.19     0.65     1.41 1.00     2354\nsd(muangular_Intercept)        1.47      0.37     0.80     2.26 1.01     2019\nsd(mutriangular_Intercept)     4.17      0.58     3.20     5.47 1.00     1646\n                           Tail_ESS\nsd(muother_Intercept)          3083\nsd(muangular_Intercept)        2903\nsd(mutriangular_Intercept)     3070\n\nPopulation-Level Effects: \n                                     Estimate Est.Error l-95% CI u-95% CI Rhat\nmuother_Intercept                       -1.96      0.49    -2.93    -1.01 1.00\nmuangular_Intercept                     -3.94      0.70    -5.40    -2.64 1.00\nmutriangular_Intercept                  -2.42      0.81    -4.02    -0.89 1.00\nmuother_pretty_conditionimpasse          1.43      0.36     0.77     2.14 1.00\nmuangular_pretty_conditionimpasse        1.36      0.60     0.21     2.60 1.00\nmutriangular_pretty_conditionimpasse     2.21      0.96     0.33     4.11 1.00\n                                     Bulk_ESS Tail_ESS\nmuother_Intercept                        1482     3068\nmuangular_Intercept                      2553     3560\nmutriangular_Intercept                   1548     2956\nmuother_pretty_conditionimpasse          3270     3916\nmuangular_pretty_conditionimpasse        4023     4413\nmutriangular_pretty_conditionimpasse     1284     2271\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n(d <- describe_posterior(ci=.95, Bmm.cat.CrSQ))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -1.95 | [-2.93, -1.01] | 99.92% | [-0.18, 0.18] |        0% | 1.001 | 1479.00\nmuangular_Intercept                  |  -3.91 | [-5.40, -2.64] |   100% | [-0.18, 0.18] |        0% | 1.002 | 2525.00\nmutriangular_Intercept               |  -2.40 | [-4.02, -0.89] | 99.95% | [-0.18, 0.18] |        0% | 1.000 | 1547.00\nmuother_pretty_conditionimpasse      |   1.43 | [ 0.77,  2.14] | 99.97% | [-0.18, 0.18] |        0% | 1.000 | 3248.00\nmuangular_pretty_conditionimpasse    |   1.35 | [ 0.21,  2.60] | 99.08% | [-0.18, 0.18] |        0% | 1.000 | 3986.00\nmutriangular_pretty_conditionimpasse |   2.21 | [ 0.33,  4.11] | 98.80% | [-0.18, 0.18] |        0% | 1.001 | 1282.00\n```\n:::\n\n```{.r .cell-code}\nprint(\"BAYES FACTOR [comparison to null]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BAYES FACTOR [comparison to null]\"\n```\n:::\n\n```{.r .cell-code}\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(Bmm.cat.rSQ, m))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBayes Factors for Model Comparison\n\n    Model                                            BF\n[2] pretty_condition + (1 | subject) + (1 | q) 1.59e+04\n\n* Against Denominator: [1] 1 + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n```\n:::\n\n```{.r .cell-code}\nprint(\"DESCRIBE POSTERIOR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DESCRIBE POSTERIOR\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(l <- describe_posterior(m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -1.95 | [-2.93, -1.01] | 99.92% | [-0.18, 0.18] |        0% | 1.001 | 1479.00\nmuangular_Intercept                  |  -3.91 | [-5.40, -2.64] |   100% | [-0.18, 0.18] |        0% | 1.002 | 2525.00\nmutriangular_Intercept               |  -2.40 | [-4.02, -0.89] | 99.95% | [-0.18, 0.18] |        0% | 1.000 | 1547.00\nmuother_pretty_conditionimpasse      |   1.43 | [ 0.77,  2.14] | 99.97% | [-0.18, 0.18] |        0% | 1.000 | 3248.00\nmuangular_pretty_conditionimpasse    |   1.35 | [ 0.21,  2.60] | 99.08% | [-0.18, 0.18] |        0% | 1.000 | 3986.00\nmutriangular_pretty_conditionimpasse |   2.21 | [ 0.33,  4.11] | 98.80% | [-0.18, 0.18] |        0% | 1.001 | 1282.00\n```\n:::\n\n```{.r .cell-code}\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- model_parameters(m, exponentiate = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                            | Median |        95% CI |     pd | % in ROPE |  Rhat |     ESS\n----------------------------------------------------------------------------------------------------\nmuother_Intercept                    |   0.14 | [0.05,  0.36] | 99.92% |        0% | 1.001 | 1479.00\nmuangular_Intercept                  |   0.02 | [0.00,  0.07] |   100% |        0% | 1.002 | 2525.00\nmutriangular_Intercept               |   0.09 | [0.02,  0.41] | 99.95% |        0% | 1.000 | 1547.00\nmuother_pretty_conditionimpasse      |   4.16 | [2.16,  8.51] | 99.97% |        0% | 1.000 | 3248.00\nmuangular_pretty_conditionimpasse    |   3.84 | [1.23, 13.45] | 99.08% |        0% | 1.000 | 3986.00\nmutriangular_pretty_conditionimpasse |   9.07 | [1.39, 60.87] | 98.80% |        0% | 1.001 | 1282.00\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n```\n:::\n\n```{.r .cell-code}\n# tidy(m,   conf.int = TRUE, exponentiate = TRUE)\n# tm %>% mutate(\n#   OR.est = exp(estimate),\n#   exp.low = exp(conf.low),\n#   exp.high = exp(conf.high)\n# ) %>% dplyr::select(effect, component, group, term, OR.est, exp.low, exp.high)\n\n# paste(\"PROBABILITIES\")\n# \n# #PREDICT METHOD\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# #lengthen data frame to handle multinomial\n# preds <- preds %>% \n#   dplyr::select(-subject, -q) %>% #marginalize over subject and q\n#   pivot_longer(\n#   cols = !pretty_condition,\n#   values_to = \"preds\",\n#   names_to = \"state\",\n# ) \n# \n# (p <- preds %>% \n#   group_by(pretty_condition, state ) %>%\n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se))\n\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n```\n:::\n\n\n##### INFERENCE — EFFECT\n\n[REPORT POSTERIOR MEDIAN $\\exp_{beta}$, 95 \\% credible interval, \\% probability of direction]\n\nWe fit a (bayesian) multinomial logistic regression model with random intercepts for subjects and questions. A Bayes Factor model comparison (against a random intercepts-only model) indicates extreme evidence for a main effect of CONDITION (BF = 3.65e+04). \n**Consistent with our hypothesis, the impasse condition substantially increases the odds of transitional interpretations.** \n\nAcross the entire task participants in the impasse condition were 4 times more likely to offer an 'unknown' rather than orthogonal response compared with those in the control condition ( $e^{\\beta_1} = 4.16, 95 \\% CI [2.16, 8.51], pd = 99\\%$). Participants in the impasse condition were 4 times more likely to offer an 'angular' rather than orthogonal response compared with those in the control condition ( $e^{\\beta_1} = 3.84, 95 \\% CI [1.23, 13.45], pd = 99\\%$), and 9 times more likely to offer an 'triangular' rather than orthogonal response compared with those in the control condition ( $e^{\\beta_1} = 9.07, 95 \\% CI [1.39, 60.87], pd = 99\\%$). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'bayes_R2' is not defined for unordered categorical models.\n```\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: other</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: angular</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: triangular</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: other_pretty</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: angular_pretty</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: triangular_pretty</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8\">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9\">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0\">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1\">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  2\">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  3\">CI (95%)</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Intercept</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\">0.05&nbsp;&ndash;&nbsp;0.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0\">0.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1\">0.02&nbsp;&ndash;&nbsp;0.41</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3\"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.84</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.23&nbsp;&ndash;&nbsp;13.45</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8\">4.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9\">2.16&nbsp;&ndash;&nbsp;8.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1\"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2\">9.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3\">1.39&nbsp;&ndash;&nbsp;60.87</td>\n</tr>\n<tr>\n<td colspan=\"13\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"12\">0.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"12\">1.46</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"12\">0.17</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"12\">71</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"12\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"12\">923</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n# \n# \n# ## POINT ESTIMATES IN PROBABILITY\n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #2 | SUMMARIZE draws \n# k <- kable(draws %>%\n#   select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 2, col.names = \n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>% \n#   kable_styling()\n# k\n\n#COMPARISONS\n# c <- draws %>% \n#   # dplyr::select(pretty_condition, .category, .value) %>%\n#   compare_levels(variable = .value, by = pretty_condition, \n#                  comparison = list(c(\"control\",\"impasse\"))) \n#                                    # c(\"adots\",\"interval\"),\n#                                    # c(\"adots\",\"mean\"),\n#                                    # c(\"adots\",\"text\"),\n#                                    # c(\"density\",\"interval\"),\n#                                    # c(\"density\",\"mean\"),\n#                                    # c(\"density\",\"text\"),\n#                                    # c(\"interval\",\"mean\"),\n#                                    # c(\"interval\",\"text\"),\n#                                    # c(\"mean\",\"text\")\n#                                    \n# c %>%\n#   ggplot(aes(x = .value, y = reorder(x =pretty_condition, X = .value)))+\n#   stat_interval(.width = .95, color = \"black\") +\n#   geom_vline(xintercept = 0)+\n#   theme_bw()+\n#   # coord_cartesian(xlim = c(-.5,1)) +\n#   theme_tidybayes() \n# comps\n```\n:::\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test\n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(Bmm.cat.CrSQ, exponentiate = TRUE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-BRMS-STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# + theme_clean()\n\n# \n# result <- estimate_density(m,exponentiate = TRUE)\n# plot(result,  stack = FALSE, priors = TRUE)\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.0827\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3600 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-BRMS-STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- rope(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-BRMS-STATE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n(result <- pd(m,exponentiate = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProbability of Direction\n\nParameter                            |     pd\n---------------------------------------------\nmuother_Intercept                    | 99.92%\nmuangular_Intercept                  |   100%\nmutriangular_Intercept               | 99.95%\nmuother_pretty_conditionimpasse      | 99.97%\nmuangular_pretty_conditionimpasse    | 99.08%\nmutriangular_pretty_conditionimpasse | 98.80%\n```\n:::\n\n```{.r .cell-code}\nplot(result, show_intercept = TRUE, show_labels = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-BRMS-STATE-4.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-BRMS-STATE-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA) \n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\n# d <- draws %>%\n#   ggplot(aes(x = .value,  y = pretty_condition, fill = .category)) +\n#   stat_slab(width = c(.95), alpha = 1, normalize=\"xy\") +\n#   #   #normalize = all, panels, xy, groups, none\n#   xlim(0,1) + labs(\n#     title = \"Model Predicted Probability of Correct Response\",\n#     x = \"probability of correct response\",\n#     y = \"Interpretation\"\n#   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # \n# # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\n# d\n```\n:::\n\n\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#CHECK Fit of posterior predictive to data\npp_check(Bmm.cat.CrSQ, ndraws=1000)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#CHECK posterior vs. priors\nresult <- estimate_density(Bmm.cat.CrSQ)\nplot(result, stack = FALSE, priors = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-30-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#CHECK model\nplot(Bmm.cat.CrSQ)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-30-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-30-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/unnamed-chunk-30-5.png){width=672}\n:::\n:::\n\n\n\n\n##### COMPARE MBLOGIT to BRMS\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_models(mm.cat.CrSQ, Bmm.cat.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                            |          mm.cat.CrSQ |         Bmm.cat.CrSQ\n----------------------------------------------------------------------------------\nother~(Intercept)                    | -1.59 (-2.71, -0.47) |                     \nangular~(Intercept)                  | -3.28 (-4.74, -1.83) |                     \ntriangular~(Intercept)               | -1.90 (-3.51, -0.30) |                     \nother~pretty conditionimpasse        |  1.57 ( 0.75,  2.39) |                     \nangular~pretty conditionimpasse      |  1.64 ( 0.36,  2.92) |                     \ntriangular~pretty conditionimpasse   |  2.30 ( 0.49,  4.10) |                     \nmuother_Intercept                    |                      | -1.95 (-2.93, -1.01)\nmuangular_Intercept                  |                      | -3.91 (-5.40, -2.64)\nmutriangular_Intercept               |                      | -2.40 (-4.02, -0.89)\nmuother_pretty_conditionimpasse      |                      |  1.43 ( 0.77,  2.14)\nmuangular_pretty_conditionimpasse    |                      |  1.35 ( 0.21,  2.60)\nmutriangular_pretty_conditionimpasse |                      |  2.21 ( 0.33,  4.11)\n----------------------------------------------------------------------------------\nObservations                         |                  923 |                  923\n```\n:::\n:::\nThe predictions of the manual, frequentist mixed multinomial and bayesian mixed multinomial models are comparable. \n\n## H1B \\| Q1 ACCURACY\n\n**Do Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?**\n\nThe graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                   |\n+=======================+========================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                    |\n|                       | -   outcome: *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                            |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                 |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |\n|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |\n|                       |                                                                                                                                                                                                                                        |\n|                       | Alternatives:                                                                                                                                                                                                                          |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   Chi-Square test of independence on outcome `accuracy` by `condition`                                                                                                                                                               |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \\~ continuous; though with regression we can quantify the size of the effect and overall model fit |\n|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |\n|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1)  %>% dplyr::select(accuracy, pretty_condition)\n```\n:::\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-Q1ACC-1.png){width=672}\n:::\n:::\n\nA proportional bar chart visualizing the proportion of incorrect (vs) correct responses in each condition for each data collection modality (left/right facet) reveals that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition (marginal probability of incorrect). In the impasse condition, the difference in proportions is smaller than the control condition (conditional probability of success in impasse; (i.e) There are more correct responses in the impasse condition than the control condition).\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Proportions of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse   Sum\n  incorrect   0.839   0.650 0.732\n  correct     0.161   0.350 0.268\n  Sum         1.000   1.000 1.000\n```\n:::\n\n```{.r .cell-code}\npaste(\"Number of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Number of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse Sum\n  incorrect      26      26  52\n  correct         5      14  19\n  Sum            31      40  71\n```\n:::\n:::\n\n#### LOGISTIC REGRESSION\n\nFit a logistic regression predicting accuracy (absolute score) (n = 71) by condition (k = 2).\\\n\n-   Parameter estimate: $\\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition\n-   $e^{\\beta_{0}}$ = ODDS of correct response in CONTROL condition\n-   Parameter estimate: $\\beta_{1}$ = $\\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])\n-   $e^{\\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\n-   **Null hypothesis**:$\\beta_{impasse} \\le 0$ the odds for a correct response does not change, or decreases\n-   **Alternative hypothesis:** $\\beta_{impasse} \\gt 0$ the odds of a correct response increases\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.928  -0.928  -0.593   1.449   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.488   -3.38  0.00074 ***\npretty_conditionimpasse    1.030      0.590    1.74  0.08107 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 82.483  on 70  degrees of freedom\nResidual deviance: 79.188  on 69  degrees of freedom\nAIC: 83.19\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.29  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 3.29 | 0.069\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.069492127779542\"\n```\n:::\n:::\n\n*The Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .*\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.928  -0.928  -0.593   1.449   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.488   -3.38  0.00074 ***\npretty_conditionimpasse    1.030      0.590    1.74  0.08107 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 82.483  on 70  degrees of freedom\nResidual deviance: 79.188  on 69  degrees of freedom\nAIC: 83.19\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.29  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.081\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.041\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"adjusted confint for directional hypothesis\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"adjusted confint for directional hypothesis\"\n```\n:::\n\n```{.r .cell-code}\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                           5 %   95 %\n(Intercept)             -2.538 -0.907\npretty_conditionimpasse  0.094  2.058\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients —- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                5 %  95 %\n(Intercept)             0.192 0.079 0.404\npretty_conditionimpasse 2.800 1.099 7.832\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\npaste(\"Probability of success in control,\", pred.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.161290322580645\"\n```\n:::\n\n```{.r .cell-code}\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\npaste(\"Probability of success in impasse,\", pred.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.350000000000014\"\n```\n:::\n:::\n##### Inference — DIRECTIONAL EFFECT\n\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#SET MODEL\nm <- m1\n\n#GGSTATS | MODEL | LOG ODDS \n# ggcoefstats(m1, output = \"plot\", \n#               conf.level = 0.90) + \n#   labs(x = \"Log Odds Estimate\", \n#        title = \"LOGODDS | Q1 Accuracy ~ condition\",\n#        subtitle = \"(p is for two tailed test)\")\n\n\n#PARAMETERS | MODEL | SIMULATED PARAMETERS\n# similar to bayesian dist of estimate\n# result <- simulate_parameters(m1)\n# #rename params so intercept is plotted \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result) \n\n#EQUIVALENCE TEST [not sure if appropriate for log model?]\n# https://journals.sagepub.com/doi/10.1177/2515245918770963#:~:text=Consequently%2C%20when%20reporting%20an%20equivalence,values%20is%20smaller%20than%20alpha.\n# https://easystats.github.io/parameters/reference/equivalence_test.lm.html\n# (result <- equivalence_test(m1, rule = \"classic\", component = c(\"all\")))\n# plot(result,   show_intercept = TRUE) + \n#   scale_y_discrete(labels = c(\"impasse\", \"control\")) + \n#   labs( title = \"Equivalence Test for Model Parameter Estimates\")\n\n\n#PARAMETERS | MODEL | ODDS RATIO \n# result <- model_parameters(m1,exponentiate = TRUE)\n# #rename params \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result,   show_intercept = TRUE) +  labs(\n#   title = \"Model Parameter Estimates\"\n# ) + theme_clean() + theme(legend.position=\"blank\")\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  scale_y_continuous() + #remove to put on log scale x axis \n  scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"pred\")[[1]] +\n  ylim(0,1) + #scale y axis to actual range\n  labs(title = \"MODEL PREDICTION  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases probability of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07&nbsp;&ndash;&nbsp;0.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.80</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.92&nbsp;&ndash;&nbsp;9.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.081</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">71</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.045</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-DIAG-Q1ACC-1.png){width=672}\n:::\n:::\n\n\n## H1B \\| Q1 INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |\n+=======================+===========================================================================================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |\n|                       | -   outcome: `state` ( 4 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                                                                                                    |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |\n|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) %>% dplyr::select(pretty_condition, state)\n```\n:::\n\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/VIS-Q1STATE-1.png){width=672}\n:::\n:::\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. We see that around half of the 'incorrect' (i.e. not triangular) responses in the impasse condition are not orthogonal-like, but \"other/unknown\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse    Sum\n  orthogonal  0.8387  0.1750 0.4648\n  other       0.0000  0.4000 0.2254\n  angular     0.0000  0.0750 0.0423\n  triangular  0.1613  0.3500 0.2676\n  Sum         1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse Sum\n  orthogonal      26       7  33\n  other            0      16  16\n  angular          0       3   3\n  triangular       5      14  19\n  Sum             31      40  71\n```\n:::\n:::\n\n#### MULTINOMIAL REGRESSION\n\n*Does condition affect the response state of Q1?*\n\n*Fit a logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 98.426900 \niter  10 value 83.663951\nfinal  value 83.663925 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 98.426900 \niter  10 value 63.286429\niter  20 value 63.042636\niter  30 value 63.026275\nfinal  value 63.026272 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  3 |         |       |       \ncatm   | multinom |  6 |       3 | 41.28 | < .001\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model\nm <- catm\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionimpasse\nother           -12.20                   13.02\nangular         -10.88                   10.03\ntriangular       -1.65                    2.34\n\nStd. Errors:\n           (Intercept) pretty_conditionimpasse\nother           87.342                  87.343\nangular         45.215                  45.221\ntriangular       0.488                   0.673\n\nResidual Deviance: 126 \nAIC: 138 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 98.426900 \niter  10 value 83.663951\nfinal  value 83.663925 \nconverged\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     41.3  3    5.7e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           p..Intercept. p.pretty_conditionimpasse\nother           0.888933                  0.881461\nangular         0.809829                  0.824406\ntriangular      0.000735                  0.000501\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           OR..Intercept. OR.pretty_conditionimpasse p..Intercept.\nother          0.00000504                   453336.0      0.888933\nangular        0.00001881                    22779.9      0.809829\ntriangular     0.19230417                       10.4      0.000735\n           p.pretty_conditionimpasse\nother                       0.881461\nangular                     0.824406\ntriangular                  0.000501\n```\n:::\n:::\n\n##### Inference — CAN'T MODEL, SPARSE CELLS\nsample size is too low to estimate this model. There are no participants in the control condition with 'other' or 'angular' answers. \n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \n# ggcoefstats(m, output = \"plot\", \n#               # conf.level = 0.90,\n#               exclude.intercept = FALSE) + \n#   labs(x = \"Log Odds Estimate\", \n#        title = \"LOGODDS | Q1 State ~ condition\",\n#        subtitle = \"(p is for two tailed test)\")\n#:::::::: PLOT\n\n#PARAMETERS | MODEL | SIMULATED PARAMETERS\n# similar to bayesian dist of estimate\n# result <- simulate_parameters(m)\n# plot(result, show_intercept = TRUE, stack=FALSE)\n\n#PARAMETERS | MODEL | ODDS RATIO \n# result <- model_parameters(m1,exponentiate = TRUE)\n# #rename params \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result,   show_intercept = TRUE) +  labs(\n#   title = \"Model Parameter Estimates\"\n# ) + theme_clean() + theme(legend.position=\"blank\")\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'x' is already present. Adding another scale for 'x', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-Q1STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"eff\", ci.lvl = 0.95)[[1]] +\n  ylim(0,1) +\n  labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n       subtitle = \"Impasse increases probability of more accurate response states Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-Q1STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#MANUALLY BUILD PREDICTION PLOT FACET BY CONDITION RATHER THAN STATE\np <-plot_model(m, type=\"eff\")[[1]]\nd <- ggplot_build(p)[[1]]  \npoints <- d[[2]]\npoints <- points %>% mutate(\n  state = recode(PANEL, \"1\" =\"orth\", \"2\"=\"other\", \"3\" = \"trilike\", \"4\"=\"tri\"),\n  condition = recode(x, \"1\"=\"control\",\"2\"=\"impasse\"),\n  prob = y\n)\ngf_point( prob ~ state, group = ~x, data = points) + \n  geom_errorbar(aes( x = state, ymin = ymin, ymax = ymax)) + facet_grid(~condition) +ylim(0,1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_replication_hypotesting_files/figure-html/MODEL-VIS-Q1STATE-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Response</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;28722943722689885056297507068099247428705629324489501913190908976693248.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.889</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">453336.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;2588676395945885478672530837777748631114813950974385474275281551223317278062804992.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.882</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;31041424057090752611383649685733376.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.811</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">22779.87</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;37983240834656997126437600879159232069369856.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.825</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07&nbsp;&ndash;&nbsp;0.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">10.40</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.71&nbsp;&ndash;&nbsp;39.87</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">71</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.247 / 0.235</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\ntest <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\npred <- predict(catm, newdata = test, \"probs\")\npaste(\"Predicted Probability of Being in Each State\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Predicted Probability of Being in Each State\"\n```\n:::\n\n```{.r .cell-code}\n( x <- cbind(test, pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pretty_condition orthogonal      other   angular triangular\n1          control      0.839 0.00000423 0.0000158      0.161\n2          impasse      0.175 0.39999611 0.0750004      0.350\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n138.053 | 151.629 | 0.247 |     0.235 | 0.354 | 1.393\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n     0.247      0.441      0.487 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\n# chisq.test(df$state, predict(catm)) #actual states VS predicted states\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n",
    "supporting": [
      "4_sgc3A_replication_hypotesting_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}