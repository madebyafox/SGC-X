{
  "hash": "e3bdcf3eea996bfe21587b597b9d5099",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | Hypothesis Testing'\n---\n\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC3A-hypotesting}\n\n**TODO**\n\n-   ORDINAL models on interpretation scale\n-   HURDLE MODEL? (mixture model w/ 0 + count)\n-   review models already created in ARCHIVE?\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#misc utilities\nlibrary(Hmisc) # %nin% operator\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\nlibrary(jtools)\nlibrary(pwr) #power analysis\n\n#visualization\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz \nlibrary(ggstatsplot) #plots with stats\n\n#models and performance\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(equatiomatic) #extract model equation\nlibrary(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models \nlibrary(lmerTest) #for CIs in glmer \nlibrary(ggeffects) #visualization log regr models\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\ntheme_set(theme_minimal()) \n```\n:::\n\n\n**Research Questions**\n\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the graph comprehension task?\n\n**Experimental Hypothesis**\\\n*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.\n-   H1B \\| Learners in the IMPASSE condition will score higher on the TEST Phase than learners in CONTROL.\n\n**Null Hypothesis**\\\n*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#IMPORT DATA \ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds') %>% \n   mutate (\n    state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n    state = as.ordered(state))\n```\n:::\n\n\n## H1A \\| Q1 ACCURACY\n\n**Do Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?**\n\nThe graph comprehension tasks includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                   |\n+=======================+========================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | data: `df_items` where `q == 1`                                                                                                                                                                                                        |\n|                       |                                                                                                                                                                                                                                        |\n|                       | outcome:                                                                                                                                                                                                                               |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   *interpretation* (ordered factor from `interpretation`)                                                                                                                                                                            |\n|                       |                                                                                                                                                                                                                                        |\n|                       | predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                     |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |\n|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |\n|                       | 2.  Ordinal Regression on `interpretation` predicted by `condition`                                                                                                                                                                    |\n|                       |     -   account for difference in (ordered correctness of interpretation) by condition                                                                                                                                                 |\n|                       |                                                                                                                                                                                                                                        |\n|                       | Alternative:                                                                                                                                                                                                                           |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   Chi-Square test of independence on outcome `score_niceABS` by `condition`                                                                                                                                                          |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \\~ continuous; though with regression we can quantify the size of the effect and overall model fit |\n|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |\n|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\n#:::::::: GROUPED PROPORTIONAL BAR CHART\n# gf_props(~accuracy, fill = ~pretty_condition,\n#        position = position_dodge(), data = df_q1) %>%\n#   gf_facet_grid(~pretty_mode) +\n#    labs(x = \"Correct Response on Q 1\",\n#        title = \"Accuracy on First Question by Condition\",\n#        subtitle=\"Impasse Condition yields a greater proportion of correct responses\") #theme(legend.position = \"none\")\n\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-Q1ACC-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of incorrect (vs) correct responses in each condition for each data collection modality (left/right facet) reveals that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition (marginal probability of incorrect). In the impasse condition, the difference in proportions is smaller than the control condition (conditional probability of success in impasse; (i.e) There are more correct responses in the impasse condition than the control condition).\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n```\n:::\n\n\n#### LOGISTIC REGRESSION\n\n*Fit a logistic regression predicting accuracy (absolute score) by condition.*\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 3.31 | 0.069\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0687084837283363\"\n```\n:::\n:::\n\n\n*The Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal.*\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.839  -0.839  -0.593  -0.593   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.345   -4.77  1.8e-06 ***\npretty_conditionimpasse    0.786      0.441    1.79    0.074 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 135.95  on 125  degrees of freedom\nResidual deviance: 132.63  on 124  degrees of freedom\nAIC: 136.6\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.074\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.037\"\n```\n:::\n\n```{.r .cell-code}\nncint <- confint(m1, level = 0.90) # get 90% for right side)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\npaste(\"exponentiated adjusted confint\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"exponentiated adjusted confint\"\n```\n:::\n\n```{.r .cell-code}\nexp(ncint)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          5 %  95 %\n(Intercept)             0.105 0.329\npretty_conditionimpasse 1.078 4.631\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nprint(\"Confidence Interval â€”- LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval â€”- LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                          2.5 % 97.5 %\n(Intercept)             -2.3853  -1.02\npretty_conditionimpasse -0.0595   1.68\n```\n:::\n\n```{.r .cell-code}\nprint(\"Coefficients â€”- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients â€”- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiate\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                               2.5 % 97.5 %\n(Intercept)             0.192 0.0921  0.362\npretty_conditionimpasse 2.196 0.9422  5.376\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n136.632 | 142.305 |     0.026 | 0.415 | 1.034 |    0.526 |    -7.184 |           0.046 | 0.655\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\np.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\npaste(\"Probability of success in control,\", p.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.161290322580645\"\n```\n:::\n\n```{.r .cell-code}\np.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\npaste(\"Probability of success in impasse,\", p.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.296875000000275\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-LAB-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-LAB-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-LAB-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic model (estimated using ML) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model's explanatory power is weak (Tjur's R2 = 0.03). The model's intercept, corresponding to pretty_condition = control, is at -1.65 (95% CI [-2.39, -1.02], p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically non-significant and positive (beta = 0.79, 95% CI [-0.06, 1.68], p = 0.074; Std. beta = 0.79, 95% CI [-0.06, 1.68])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOk: About 100% of the residuals are inside the error bounds.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n##### Inference\n\n**We fit a logistic regression model to analyze the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 1.79, p = 0.04, *one-tailed*). The model predicts that the odds of a correct response on the first question in the *impasse condition* increase by nearly 120% (**$e^{beta_1}$ = 2.19, 95% CI \\[1.08, 4.63\\]) over the *control condition*.\n\n*Equivalent statements:*\n\n-   being in impasse condition increases log odds of correct response by 0.79 (over control)\n-   being in impasse increases odds of correct response in impasse over control increases by factor of 2.22\n-   probability of correct response in impasse predicted as 30%, vs only 16% in control condition\n\n##### TODO\n\n-   Are these residuals OK? I didn't think normally distributed residuals were an assumption for logistic regression.\n-   interpretation/reporting of model fit?\n-   sanity check correct interpretation of coefficients & reporting\n\n### (ONLINE REPLICATION)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: ONLINE ONLY\ndf <- df_items %>% filter(mode == \"asynch\") %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n```\n:::\n\n\n#### LOGISTIC REGRESSION\n\n*Fit a logistic regression predicting accuracy (absolute score) by condition.*\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 7.49 | 0.006\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.00621908608981449\"\n```\n:::\n:::\n\n\n*The Condition predictor decreases AIC, and the Likelihood Ratio Test indicates the more complex model is a better fit.*\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.807  -0.807  -0.517  -0.517   2.039  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.946      0.309   -6.31  2.9e-10 ***\npretty_conditionimpasse    0.990      0.376    2.63   0.0084 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 207.45  on 203  degrees of freedom\nResidual deviance: 199.96  on 202  degrees of freedom\nAIC: 204\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.008\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.004\"\n```\n:::\n\n```{.r .cell-code}\nncint <- confint(m1, level = 0.90) # get 90% for right side\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\npaste(\"exponentiated adjusted confint\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"exponentiated adjusted confint\"\n```\n:::\n\n```{.r .cell-code}\nexp(ncint)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          5 %  95 %\n(Intercept)             0.083 0.231\npretty_conditionimpasse 1.473 5.109\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nprint(\"Confidence Interval â€”- LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval â€”- LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                         2.5 % 97.5 %\n(Intercept)             -2.602  -1.38\npretty_conditionimpasse  0.275   1.76\n```\n:::\n\n```{.r .cell-code}\nprint(\"Coefficients â€”- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients â€”- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiate\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                               2.5 % 97.5 %\n(Intercept)             0.143 0.0741  0.251\npretty_conditionimpasse 2.692 1.3164  5.811\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n203.962 | 210.598 |     0.036 | 0.397 | 0.995 |    0.490 |    -9.361 |           0.034 | 0.685\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\np.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\npaste(\"Probability of success in control,\", p.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.125000000004466\"\n```\n:::\n\n```{.r .cell-code}\np.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\npaste(\"Probability of success in impasse,\", p.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.277777777778245\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-ONLINE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-ONLINE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/MODEL-Q1ACC-LOG-ONLINE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic model (estimated using ML) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model's explanatory power is weak (Tjur's R2 = 0.04). The model's intercept, corresponding to pretty_condition = control, is at -1.95 (95% CI [-2.60, -1.38], p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 0.99, 95% CI [0.27, 1.76], p = 0.008; Std. beta = 0.99, 95% CI [0.27, 1.76])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOk: About 100% of the residuals are inside the error bounds.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n:::\n\n\n##### Inference\n\n**We fit a logistic regression model to analyze the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 2.63, p = 0.004, *one-tailed*). The model predicts that the odds of a correct response on the first question in the *impasse condition* increase by nearly 170% (**$e^{beta_1}$ = 2.69, 95% CI \\[1.47, 5.11\\]) over the *control condition*.\n\n*Equivalent statements:*\n\n-   being in impasse condition increases log odds of correct response by 0.99 (over control)\n-   being in impasse increases odds of correct response in impasse over control increases by factor of 2.69\n-   probability of correct response in control predicted as 28%, vs only 13% in the control condition\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#PRETTY TABLE SJPLOT\ntab_model(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07&nbsp;&ndash;&nbsp;0.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.69</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.32&nbsp;&ndash;&nbsp;5.81</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.008</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">204</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.036</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n## H1B \\| TEST PHASE ACCURACY\n\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question      | Do Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group.                                                     |\n+========================+=========================================================================================================================================================+\n| **Hypothesis**         | (H1B) Participants in the IMPASSE condition will have higher test phase performance than those in the CONTROL condition.                                |\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**               | **data**: `df_items` where `q nin 6,9` (the 8 discriminating Qs ), `df_subjects`                                                                        |\n|                        |                                                                                                                                                         |\n|                        | **outcome**:                                                                                                                                            |\n|                        |                                                                                                                                                         |\n|                        | -   \\[at item level\\]                                                                                                                                   |\n|                        |     -   *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                  |\n|                        |     -   *interpretation* (ordered factor from `interpretation`)                                                                                         |\n|                        | -   \\[subject level\\]                                                                                                                                   |\n|                        |     -   accuracy (number of test phase qs correct )                                                                                                     |\n|                        |                                                                                                                                                         |\n|                        | **predictor**: `condition` \\[between-subjects factor\\]                                                                                                  |\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy**  | 1.  Wilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (`item_test_NABS`)                                              |\n|                        | 2.  Mixed Logistic Regression\\                                                                                                                          |\n|                        |     `accuracy` \\~ `condition` + (1 \\| `subject` )\\                                                                                                      |\n|                        |     model effect of condition on probability of correct response \\[during test phase\\] while accounting for subject (and item-level?) effects           |\n|                        | 3.  Ordinal Mixed Logistic Regression\\                                                                                                                  |\n|                        |     `interpretation` \\~ `condition` + (1 \\| `subject` )\\                                                                                                |\n|                        |     model effect of condition on \\[ordered correctness of interpretation\\] \\[during test phase\\] while accounting for subject (and item-level?) effects |\n|                        | 4.  Shift in Modal Mass (descriptive)\\                                                                                                                  |\n|                        |     describe & visualize shift in deciles between conditions for `` `scaled_score` `` (at subject level)                                                |\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Alternatives**       | -   OLS LINEAR REGRESSION                                                                                                                               |\n|                        |     -   bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals                        |\n|                        |     -   lm `DV_percent_test_NABS` \\~ `condition` (absolute scoring) OR lm `item_test_SCALED` \\~ `condition` (scaled scoring)                            |\n|                        |     -   both absolute and scaled scores yield non-normal residuals                                                                                      |\n|                        |     -   no transformation of the outcome variables yield normal residuals                                                                               |\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**              | **Also exploring:**                                                                                                                                     |\n|                        |                                                                                                                                                         |\n|                        | -   Hurdle model (mixture model w/ binomial + \\[poisson or negbinom count; 0s from 1 DGP)                                                               |\n|                        | -   Zero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)                                                         |\n|                        | -   Beta regression hurdle model? (mixture with location and scale parameters \\[mean, variance\\] and hurdles for floor and ceiling effects)             |\n|                        | -   Other way to account for the severe bimodality?                                                                                                     |\n+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\nn_items = 13 #number of items in test\n\n#item level\ndf = df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n  q = as.factor(q)\n)\n\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(title = \"Test Phase Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS))\ngf_props(~item_test_NABS, \n         fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_grid(pretty_condition ~ pretty_mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"# Correct\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Absolute Score (# Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-ACC-2.png){width=672}\n:::\n:::\n\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf_i <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q %in% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\ndf_s <- df_subjects %>% filter(mode == \"lab-synch\") %>% mutate(\n  test_score = item_test_NABS\n)\n```\n:::\n\n\n#### WILCOXON RANK SUM (Mann-Whitney Test)\n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$test_score ~ df_s$condition,\n                 paired = FALSE, alternative = \"two.sided\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$test_score by df_s$condition\nW = 1438, p-value = 0.003\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_s$test_score and df_s$condition suggests that the effect is negative, statistically significant, and medium (W = 1438.00, p = 0.003; r (rank biserial) = -0.28, 95% CI [-0.45, -0.08])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df_s,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName  |    Model | df | df_diff |  Chi2 |      p\n------------------------------------------------\nm0    |      glm |  1 |         |       |       \nmm.rS | glmerMod |  2 |       1 | 30.94 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  2.66463579492752e-08\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD RANDOM RANDOM INTERCEPT ITEM\n\n#:: RANDOM INTERCEPT SUBJECT + INTERCEPT Q\nprint(\"Subject & Question random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject & Question random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n# summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName   |    Model | df | df_diff |   Chi2 |      p\n--------------------------------------------------\nmm.rS  | glmerMod |  2 |         |        |       \nmm.rSQ | glmerMod |  3 |       1 | 319.76 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  1.63270079086771e-71\"\n```\n:::\n\n```{.r .cell-code}\n## 3 | ADD FIXED EFFECT\n\n# SUBJECT INTERCEPT | FIXED CONDITION \nprint(\"FIXED Condition + Subject & Question random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Question random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q), \n                data = df_i, family = \"binomial\")\n# summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |      |      \nmm.CrSQ | glmerMod |  4 |       1 | 9.81 | 0.002\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.00173559269025604\"\n```\n:::\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     868      887     -430      860      878 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.556 -0.466 -0.293  0.566  2.432 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 1.89     1.37    \n q       (Intercept) 7.06     2.66    \nNumber of obs: 882, groups:  subject, 126; q, 7\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)   \n(Intercept)               -0.146      1.036   -0.14   0.8877   \npretty_conditionimpasse    0.991      0.309    3.20   0.0014 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.151\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.00136\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.00068\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n------------------------------------------------------------------------------------------------------------\n867.803 | 886.931 |      0.736 |      0.020 | 0.731 | 0.323 | 1.000 |    0.353 |      -Inf |           0.002\n```\n:::\n\n```{.r .cell-code}\nse <- sqrt(diag(stats::vcov(m1)))\n# table of estimates with 95% CI\n(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n    se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Est     LL   UL\n(Intercept)             -0.146 -2.177 1.88\npretty_conditionimpasse  0.991  0.385 1.60\n```\n:::\n\n```{.r .cell-code}\n(e <- exp(tab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          Est    LL   UL\n(Intercept)             0.864 0.113 6.58\npretty_conditionimpasse 2.693 1.469 4.94\n```\n:::\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-18-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model included subject and q as random effects (formula: list(~1 | subject, ~1 | q)). The model's total explanatory power is substantial (conditional R2 = 0.74) and the part related to the fixed effects alone (marginal R2) is of 0.02. The model's intercept, corresponding to pretty_condition = control, is at -0.15 (95% CI [-2.18, 1.88], p = 0.888). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 0.99, 95% CI [0.38, 1.60], p = 0.001; Std. beta = 0.99, 95% CI [0.38, 1.60])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Probably bad model fit. Only about 30% of the residuals are inside the error bounds.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n:::\n\n\n##### Inference\n\nWe fit a mixed-effect binomial logistic regression model with random intercepts for subjects and items; to investigate the effect of condition on test phase item accuracy. The model including a fixed effect of condition performed significantly better than an intercept-only baseline model (Ï‡2(4): 9.81, p \\< 0.002); and the total explanatory power is substantial (conditional R2 = 0.74) and the part related to the fixed effects (marginal R2) is 0.02. Consistent with the pattern of results for the first question only, across all test-phase items, being in the impasse condition increases the odds of a correct response by a factor of 2.7 over the control condition $e^{\\beta_1}$ = 2.69, 95% CI \\[1.31, 5.811\\], p \\< 0.001.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PRETTY TABLE SJPLOT\ntab_model(mm.CrSQ)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11&nbsp;&ndash;&nbsp;6.58</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.888</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition: impasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.69</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.47&nbsp;&ndash;&nbsp;4.94</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">1.89</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">7.06</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.73</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">7</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">882</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.020 / 0.736</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### TODO\n\n-   sanity check interpretation\n-   sanity check random effects structure : ITEM appropriate as random intercept? What does it mean to have two random intercepts?\n-   DIAGNOSTICS: What in the world is happening with the normality of random effects plot? Do the fixed effects residuals need to be normally distributed?\n-   Are there other plots or recommended diagnostics for mixed log regression\n-   consider multiple regression with rt, sequence cluster, confidence, etc.\n-   What else needs to be interpreted with respect to the item and subject random effects?\n-   Double check: can't have condition by subject or item slope bc subjects are nested in conditions, not crossed\n\n### (ONLINE REPLICATION)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: ONLINE ONLY\ndf_i <- df_items %>% filter(mode == \"asynch\") %>% filter(q %in% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\ndf_s <- df_subjects %>% filter(mode == \"asynch\") %>% mutate(\n  test_score = item_test_NABS\n)\n```\n:::\n\n\n#### WILCOXON RANK SUM (Mann-Whitney Test)\n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$test_score ~ df_s$condition,\n                 paired = FALSE, alternative = \"two.sided\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$test_score by df_s$condition\nW = 3962, p-value = 0.0008\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_s$test_score and df_s$condition suggests that the effect is negative, statistically significant, and medium (W = 3962.00, p < .001; r (rank biserial) = -0.24, 95% CI [-0.38, -0.08])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df_s,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i,family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName  |    Model | df | df_diff |  Chi2 |      p\n------------------------------------------------\nm0    |      glm |  1 |         |       |       \nmm.rS | glmerMod |  2 |       1 | 60.89 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  6.02345970489899e-15\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD RANDOM RANDOM INTERCEPT ITEM\n\n#:: RANDOM INTERCEPT SUBJECT + INTERCEPT Q\nprint(\"Subject & Question random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject & Question random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i,family = \"binomial\")\n# summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName   |    Model | df | df_diff |   Chi2 |      p\n--------------------------------------------------\nmm.rS  | glmerMod |  2 |         |        |       \nmm.rSQ | glmerMod |  3 |       1 | 682.12 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  2.31540068318277e-150\"\n```\n:::\n\n```{.r .cell-code}\n## 3 | ADD FIXED EFFECT\n\n# SUBJECT INTERCEPT | FIXED CONDITION \nprint(\"FIXED Condition + Subject & Question random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Question random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q), \n                data = df_i,family = \"binomial\")\n# summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison\n\nName    |    Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |       |       \nmm.CrSQ | glmerMod |  4 |       1 | 11.02 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.000899766022705468\"\n```\n:::\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n    1217     1238     -605     1209     1424 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-6.792 -0.346 -0.240  0.415  3.198 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept)  3.3     1.82    \n q       (Intercept) 11.0     3.32    \nNumber of obs: 1428, groups:  subject, 204; q, 7\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -0.264      1.280   -0.21  0.83650    \npretty_conditionimpasse    1.031      0.305    3.39  0.00071 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.125\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.00071\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.00035\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n--------------------------------------------------------------------------------------------------------------\n1217.385 | 1238.441 |      0.816 |      0.015 | 0.813 | 0.278 | 1.000 |    0.278 |      -Inf |           0.002\n```\n:::\n\n```{.r .cell-code}\nse <- sqrt(diag(stats::vcov(m1)))\n# table of estimates with 95% CI\n(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n    se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           Est     LL   UL\n(Intercept)             -0.264 -2.772 2.24\npretty_conditionimpasse  1.031  0.434 1.63\n```\n:::\n\n```{.r .cell-code}\n(e <- exp(tab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          Est     LL   UL\n(Intercept)             0.768 0.0625 9.43\npretty_conditionimpasse 2.804 1.5439 5.09\n```\n:::\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model included subject and q as random effects (formula: list(~1 | subject, ~1 | q)). The model's total explanatory power is substantial (conditional R2 = 0.82) and the part related to the fixed effects alone (marginal R2) is of 0.01. The model's intercept, corresponding to pretty_condition = control, is at -0.26 (95% CI [-2.77, 2.24], p = 0.836). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 1.03, 95% CI [0.43, 1.63], p < .001; Std. beta = 1.03, 95% CI [0.43, 1.63])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Probably bad model fit. Only about 14% of the residuals are inside the error bounds.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-26-2.png){width=672}\n:::\n:::\n\n\n##### Inference\n\nWe fit a mixed-effect binomial logistic regression model with random intercepts for subjects and items; to investigate the effect of condition on test phase item accuracy. The model including a fixed effect of condition performed significantly better than an intercept-only baseline model (Ï‡2(4): 11.02, p \\< 0.001); and the total explanatory power is substantial (conditional R2 = 0.82) and the part related to the fixed effects (marginal R2) is 0.02. Consistent with the pattern of results for the first question only, across all test-phase items, being in the impasse condition increases the odds of a correct response by a factor of 2.8 over the control condition $e^{\\beta_1}$ = 2.80, 95% CI \\[1.54, 5.09\\], p \\< 0.001.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PRETTY TABLE SJPLOT\ntab_model(mm.CrSQ)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.77</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.06&nbsp;&ndash;&nbsp;9.43</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.836</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition: impasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.80</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.54&nbsp;&ndash;&nbsp;5.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.30</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">11.01</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.81</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">204</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">7</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1428</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.015 / 0.816</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### TODO\n\n-   sanity check interpretation\n-   sanity check random effects structure : ITEM appropriate as random intercept? What does it mean to have two random intercepts?\n-   DIAGNOSTICS: What in the world is happening with the normality of random effects plot? Do the fixed effects residuals need to be normally distributed?\n-   Are there other plots or recommended diagnostics for mixed log regression\n-   consider multiple regression with rt, sequence cluster, confidence, etc.\n-   What else needs to be interpreted with respect to the item and subject random effects?\n-   Double check: can't have condition by subject or item slope bc subjects are nested in conditions, not crossed\n\n\n### SHIFT IN MODAL MASS\n\nThe Effect of Condition on Total Scaled Score can be described as a 'shift' in mass between the low and high modes of each distribution.\n\n*First, we use the Kolmogorov-Smirnov test as a Robust alternative to the t-test to test if the two distributions likely come from different populations.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#(requires shift function files loaded)\n#LOAD MODAL SHIFT FUNCTION RESOURCES\nsource(\"analysis/utils/shift_function/Rallfun-v30.txt\")\nsource(\"analysis/utils/shift_function/wilcox_modified.txt\")\nsource(\"analysis/utils/shift_function/rgar_visualisation.txt\")\nsource(\"analysis/utils/shift_function/rgar_utils.txt\")\n#NOTE: something in these breaks the stat_ecdf in ggplot2\n\n#PREP DATA \ndf <- df_subjects %>%\n  dplyr::select(s_SCALED, pretty_condition) %>%\n  mutate(\n    data = as.numeric(s_SCALED),\n    #flip order levels to correctly orient graph\n    # gr = recode_factor(pretty_condition, \"impasse\" = \"impasse\", \"control\"=\"control\")\n    gr = as.character(pretty_condition)\n  ) %>% dplyr::select(data,gr)\n\n\ng1 <- df %>% filter(gr == \"control\") %>% dplyr::pull(data)\ng2 <- df %>% filter(gr == \"impasse\") %>% dplyr::pull(data)\n\n\n#COMPARE DISTRIBUTIONS WITH ROBUST TESTS\n\n#What do common tests say about the difference?\n\n# Kolmogorov-Smirnov test\n#If y is numeric, a two-sample (Smirnov) test of the null hypothesis that x and y \n#were drawn from the same continuous distribution is performed. Alternatively, y ...\n\n#null is X is drawn from CDF EQUAL TO Y\nks.test(g1,g2) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2): p-value will be approximate in the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD = 0.5, p-value <2e-16\nalternative hypothesis: two-sided\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that impasse and control come from different population distributions\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that impasse and control come from different population distributions\"\n```\n:::\n\n```{.r .cell-code}\n# #null is X is NOT LESS THAN Y\nks.test(g1,g2, alternative = \"greater\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2, alternative = \"greater\"): p-value will be approximate\nin the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD^+ = 0.5, p-value <2e-16\nalternative hypothesis: the CDF of x lies above that of y\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\"\n```\n:::\n\n```{.r .cell-code}\n#REGULAR T-TEST\nt.test(g1,g2) # regular Welsh t-test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  g1 and g2\nt = -7, df = 325, p-value = 7e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -8.93 -5.06\nsample estimates:\nmean of x mean of y \n   -6.427     0.567 \n```\n:::\n:::\n\n::: {.cell warnings='false' messages='false'}\n\n```{.r .cell-code}\n#IF THIS ERRORS, consider loadling plyr (older than dplyr)\n# kernel density estimate + rug plot + superimposed deciles\nkde <- plot.kde_rug_dec2(df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: plyr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    compact\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcdExtra':\n\n    summarise\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggpubr':\n\n    mutate\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:Hmisc':\n\n    is.discrete, summarize\n```\n:::\n\n```{.r .cell-code}\n# kde\n\n# compute shift function\nout <- shifthd( g1, g2, nboot=200)\n\n# plot shift function\nsf <- plot.sf(data=out) # function from rgar_visualisation.txt\n# sf\n\n# combine KDE + SF\ncowplot::plot_grid(kde, sf, labels=c(\"A\", \"B\"), ncol = 1, nrow = 2, rel_heights = c(1.5, 1),label_size = 18,hjust = -1,scale=.95)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SHIFT-FN-NABS-comb-1.png){width=672}\n:::\n:::\n\n\n## RESOURCES\n\nreset plot margins par(mar=c(1,1,1,1))\n\n\n\n",
    "supporting": [
      "4_sgc3A_hypotesting_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}