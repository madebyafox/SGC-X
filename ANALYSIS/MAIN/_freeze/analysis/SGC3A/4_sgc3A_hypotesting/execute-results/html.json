{
  "hash": "c180aba8fae2c3dafd4371c42f402141",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 4 Hypothesis Testing'\n---\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC3A-hypotesting}\n\n**TODO**\n\n-   MODEL diagnostics\n-   review models already created in ARCHIVE?\n-   explore response consistency\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study.*\n\n+------------------------+\n| Pre-Requisite          |\n+========================+\n| 1_sgc3A_harmonize.qmd\\ |\n| 2_sgc3A_scoring.qmd    |\n+------------------------+\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) #ALL THE THINGS\nlibrary(Hmisc) # %nin% operator\nlibrary(ggpubr) #arrange plots\nlibrary(ggformula) #easy graphs\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n```\n:::\n\n**Research Questions**\n\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the graph comprehension task?\n\n*Specifically, we will test the following experimental hypotheses:*\n\n**Experimental Hypothesis:** *Learners posed with impasse-inducing questions will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the impasse condition will have better cumulative accuracy (get more questions correctly overall)\n-   H1B \\| Learners in impasse condition will be more likely to correctly answer the first question\n-   H1C \\| Learners in the impasse condition will spend more time on the first question.\n\nThe Null Hypothesis asserts that *no significant differences in performance will exist between learners in the impasse and control conditions.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT DATA \ndf_items <- read_rds('data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('data/2-scored-data/sgc3a_scored_participants.rds')\n\n\n#SEPARATE ITEM DATA BY QUESTION TYPE\ndf_scaffold <- df_items %>% filter(q < 6)\ndf_test <- df_items %>% filter(q > 6) %>% filter (q %nin% c(6,9))\ndf_nondiscrim <- df_items %>% filter (q %in% c(6,9))\n```\n:::\n\n## H1A \\| CUMULATIVE PERFORMANCE\n\nOver the course of the entire graph comprehension task does the impasse condition affect performance on the graph comprehension task?\n\n### Cumulative Absolute Score\n\nCumulative absolute score gives us a measure of the exact triangular-correctness of each response given by a participant across all discriminant items (n=13) in the graph comprehension task.\n\n#### Linear Regression\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does posing a mental impasse improve performance?                                                                                                                                                                                                                                                                                                                                                                                                  |\n+=======================+====================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | (H1A) Participants in the IMPASSE condition will have significantly higher cumulative performance than those in the CONTROL condition.                                                                                                                                                                                                                                                                                                             |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | OLS Linear Regression `s_NABS` \\~ `condition`                                                                                                                                                                                                                                                                                                                                                                                                      |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Justification**     | \\(0\\) goal is to understand how much variance in absolute score is accounted for by condition                                                                                                                                                                                                                                                                                                                                                      |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(1\\) linearity assumption **TODO**                                                                                                                                                                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(2\\) homoscedasticity assumption: **TODO**                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(3\\) independence assumption : observations correspond to individual participants and are thus independent                                                                                                                                                                                                                                                                                                                                        |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(2\\) normality assumption : **TODO**                                                                                                                                                                                                                                                                                                                                                                                                              |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Steps**             | \\(1\\) Calculate regression model using `lmer`                                                                                                                                                                                                                                                                                                                                                                                                      |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(2\\) Interpret coefficients                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(3\\) Interpret ANOVA and $R^2$ value                                                                                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | \\(4\\) Model diagnostics                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | **For in-lab data collection** an OLS linear regression predicting cumulative absolute score by experimental condition explains a statistically significant though small 7.5% variance in score (F(1,124) = 10.1, p \\< 0.01). The estimated beta coefficient ($\\beta$ = 2.76, 95% CI \\[1.04, 4.48\\]) predicts that participants in the impasse condition will on average score 2.76 points (21%) higher than those in the control condition.       |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|                       | **For the online replication**, an OLS linear regression model predicting cumulative absolute score by condition explains a statistically significant though small 5.5% of variance in absolute score (F(1,202) = 11.73, p \\< 0.001). The beta coefficient for condition indicates that on average, participants in the IMPASSE group scored 2.3 points higher on the task than those in the control condition ($\\beta$ = 2.28, CI\\[0.97, 3.59\\]). |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n::: {.cell}\n\n```{.r .cell-code}\n#VISUALIZE distribution of response accuracy across SUBJECTS\n\n#HISTOGRAM\nstats = df_subjects %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(s_ABS))\ngf_density(~s_ABS, data = df_subjects) %>% \n  gf_facet_grid(condition~mode, labeller = label_both) %>% \n  gf_lims(x = c(0, 13)) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Cumulative Absolute Score\",\n       y = \"proportion of subjects\",\n       title = \"Subject Cumulative Score (Absolute)\",\n       subtitle = \"Score distributions are comparable across modalities and different across conditions\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-SUBJECT-ABS-1.png){width=672}\n:::\n:::\n\n##### In-Lab Data Collection \n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_ABS ~ condition, data = df_subjects %>% filter(mode==\"lab-synch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_ABS ~ condition, data = df_subjects %>% filter(mode == \n    \"lab-synch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -5.44  -2.68  -2.68   4.31  10.32 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     2.677      0.620    4.32 0.000031 ***\ncondition121    2.760      0.869    3.17   0.0019 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.88 on 124 degrees of freedom\nMultiple R-squared:  0.0752,\tAdjusted R-squared:  0.0677 \nF-statistic: 10.1 on 1 and 124 DF,  p-value: 0.00189\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_ABS\n           Df Sum Sq Mean Sq F value Pr(>F)   \ncondition   1    240   239.9    10.1 0.0019 **\nResiduals 124   2951    23.8                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)   1.45   3.90\ncondition121  1.04   4.48\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n```\n:::\n\n**For in-lab data collection** an OLS linear regression predicting cumulative absolute score by experimental condition explains a statistically significant though small 7.5% variance in score (F(1,124) = 10.1, p \\< 0.01). The estimated beta coefficient ($\\beta$ = 2.76, 95% CI \\[1.04, 4.48\\]) predicts that participants in the impasse condition will on average score 2.76 points (21%) higher than those in the control condition.\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_subjects %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(s_ABS))\ngf_density(~s_ABS, data = df_subjects) %>% \n  gf_facet_grid(condition~mode, labeller = label_both) %>% \n  gf_lims(x = c(0, 13)) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Cumulative Absolute Score\",\n       y = \"proportion of subjects\",\n       title = \"Subject Cumulative Score (Absolute)\",\n       subtitle = \"Score distributions are comparable across modalities and different across conditions\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n##### Online Replication\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_ABS ~ condition, data = df_subjects %>% filter(mode==\"asynch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_ABS ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.58  -3.58  -2.30   3.42  10.70 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     2.302      0.485    4.75  3.8e-06 ***\ncondition121    2.281      0.666    3.43  0.00074 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.75 on 202 degrees of freedom\nMultiple R-squared:  0.0549,\tAdjusted R-squared:  0.0502 \nF-statistic: 11.7 on 1 and 202 DF,  p-value: 0.000745\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_ABS\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1    264   264.5    11.7 0.00074 ***\nResiduals 202   4554    22.5                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  1.347   3.26\ncondition121 0.968   3.59\n```\n:::\n\n```{.r .cell-code}\n#report(m1) #sanity check\n```\n:::\n\n**For the online replication**, an OLS linear regression model predicting cumulative absolute score by condition explains a statistically significant though small 5.5% of variance in absolute score (F(1,202) = 11.73, p \\< 0.001). The beta coefficient for condition indicates that on average, participants in the IMPASSE group scored 2.3 points higher on the task than those in the control condition (CI\\[0.97, 3.59\\]).\n\n::: callout-note\n**From these models we can reasonably conclude that the impasse condition yielded a small but reliable improvement in performance across items in the graph reading task.**\n:::\n\n##### **Model Diagnostics**\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAGNOSTICS-ABSCORE-LINEAR-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(check_normality(m1), type = \"qq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Non-normality of residuals detected (p < .001).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAGNOSTICS-ABSCORE-LINEAR-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(check_heteroscedasticity(m1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.054).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAGNOSTICS-ABSCORE-LINEAR-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(result <- check_homogeneity(m1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.053).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAGNOSTICS-ABSCORE-LINEAR-4.png){width=672}\n:::\n:::\n\n**TODO**\n\n#### Poisson Regression\n\nThe outcome variable absolute score is clearly not normal. As it represents the cumulative number of items a participant has answered correctly, we can consider it a type of *count*, (ie. count of the number of questions the participant got correct) and attempt to model it using a General Linear Model with the Poisson distribution (and the default log-link function).\n\n::: {.cell}\n\n```{.r .cell-code}\n# library('fitdistrplus')\n# plot(fitdist(df_subjects$s_ABS,\"pois\"))\n# plot(fitdist(df_subjects$s_ABS,\"norm\"))\n# plot(fitdist(df_subjects$s_ABS,\"beta\"))\n# \n# \n# plotdist(df_subjects$s_ABS, histo = TRUE, demp = TRUE)\n# descdist(df_subjects$s_ABS, discrete=FALSE, boot=500)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION --> POISSON DISTRIBUTION\nmp1 <- glm(s_ABS ~ condition, data = df_subjects %>% filter(mode==\"lab-synch\"), family = \"poisson\")\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(mp1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = s_ABS ~ condition, family = \"poisson\", data = df_subjects %>% \n    filter(mode == \"lab-synch\"))\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n -3.30   -2.31   -2.31    1.75    4.52  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.9849     0.0776   12.69  < 2e-16 ***\ncondition121   0.7085     0.0943    7.51  5.9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 855.68  on 125  degrees of freedom\nResidual deviance: 795.46  on 124  degrees of freedom\nAIC: 1045\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(mp1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: s_ABS\n\nTerms added sequentially (first to last)\n\n          Df Deviance Resid. Df Resid. Dev\nNULL                        125        856\ncondition  1     60.2       124        795\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(mp1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  0.829  1.133\ncondition121 0.525  0.896\n```\n:::\n\n```{.r .cell-code}\nreport(mp1) #sanity check\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a poisson model (estimated using ML) to predict s_ABS with condition (formula: s_ABS ~ condition). The model's explanatory power is substantial (Nagelkerke's R2 = 0.38). The model's intercept, corresponding to condition = 111, is at 0.98 (95% CI [0.83, 1.13], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 0.71, 95% CI [0.53, 0.90], p < .001; Std. beta = 0.71, 95% CI [0.53, 0.90])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(mp1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAGNOSTICS-ABSCORE-POISSON-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Which is a better fit? linear or poisson?\n\ncompare_performance(m1,mp1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: When comparing models, please note that probably not all models were fit from\n  same data.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName | Model |      AIC | AIC weights |      BIC | BIC weights |  RMSE | Sigma |    R2 | R2 (adj.) | Nagelkerke's R2 | Score_log | Score_spherical\n--------------------------------------------------------------------------------------------------------------------------------------------------\nm1   |    lm | 1218.500 |     < 0.001 | 1228.454 |     < 0.001 | 4.725 | 4.748 | 0.055 |     0.050 |                 |           |                \nmp1  |   glm | 1044.751 |        1.00 | 1050.423 |        1.00 | 4.840 | 2.533 |       |           |           0.380 |    -4.130 |           0.063\n```\n:::\n:::\n\n## INITIAL PERFORMANCE\n\nThe graph comprehension tasks includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\nTODO: - does impasse yield different exploration behavior? (characterize mouse) - does impasse yield more time on task? (characterize response time ? number of answers then de-selected?)\n\nTODO: Think about characterizing how variable the interpretations are across a participant. Do they form an interpretation and hold it constant? Or do they change question to question.\n\n### Response Accuracy of First Question by Condition\n\n#### Chi Square \\| Accuracy \\~ Condition\n\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                                                                                                                                                                                                                                                                                                                              |\n+=======================+===================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| **Analysis Strategy** | Chi-Square test of independence on outcome `score_niceABS` by `condition` for `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Justification**     | \\(0\\) simplest method to examine independence of two categorical factors; logistic regression is recommended for binomial \\~ continuous                                                                                                                                                                                                                                                                                                                                                                                                           |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|                       | \\(1\\) independence assumption : as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|                       | \\(2\\) frequency size assumption : expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                                                                                                                                                                                                                                                                                                                              |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Steps**             | \\(1\\) Express raw data as contingency table & visualize                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|                       | \\(2\\) Calculate Chi-Squared Statistic and p-value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|                       | \\(3\\) Interpret Odds-Ratio as effect size                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | **Lab** For the in-lab data collection (n=126) the Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. In this particular data sample, the odds ratio (2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition. |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n|                       | **Online** For online data collection (n=204), a Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. The odds ratio (2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition.                                              |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n::: {.cell}\n\n```{.r .cell-code}\n#FITER THE DATASET\ndf = df_items %>% filter(q==1) \n\n#PROPORTIONAL BAR CHART\ngf_props(~score_niceABS, data = df, fill = ~mode) %>% \n  gf_facet_grid(mode~condition, labeller = label_both) +\n  labs(x = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition (Both Modalities)\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses than control \")+\n  theme_minimal()+ theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC.by.COND-bar-1.png){width=672}\n:::\n:::\n\nA proportional bar chart visualizing the proportion of incorrect (x =0) vs correct (x = 1) responses in each condition (right/left facet) for each data collection modality (top/bottom) reveal that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition. In the impasse condition, the difference in proportions is smaller than the control condition (i.e. There are more correct responses in the impasse condition than the control condition).\n\n::: {.cell}\n\n```{.r .cell-code}\n#MOSAIC PLOT\nvcd::mosaic(main=\"Accuracy on First Question by Condition (Both Modalities)\",\n            data = df, score_niceABS ~ condition, rot_labels=c(0,90,0,0),\n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\")))\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC.by.COND-mosaic-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#PRINT CONTINGENCY TABLE\ntitle = \"Proportion of Correct Responses On First Item (Both Modalities)\"\nitem.contingency <-  df %>% dplyr::select(condition, score_niceABS) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Proportion of Correct Responses On First Item (Both Modalities)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 0 </th>\n   <th style=\"text-align:right;\"> 1 </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 111 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> 0.067 </td>\n   <td style=\"text-align:right;\"> 0.479 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 121 </td>\n   <td style=\"text-align:right;\"> 0.373 </td>\n   <td style=\"text-align:right;\"> 0.148 </td>\n   <td style=\"text-align:right;\"> 0.521 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:right;\"> 0.215 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nA mosaic plot condition by response accuracy on the first question (across both data collection modalities) reveals the same pattern (the mosaic plot is an alternative visualization technique to the proportional bar chart). The relative size of condition boxes (111 vs 121) reflects that the sample is roughly evenly split across experimental conditions. The difference in size between 0 (incorrect) and 1 (correct) reflects that the proportion of correct responses (1) is greater in the impasse condition (121).\n\nNext, we compute a contingency table and Pearson's Chi-Squared test for each data collection modality.\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"lab-synch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        52 |        10 |        62 | \n             |    47.730 |    14.270 |           | \n             |     0.382 |     1.278 |           | \n             |     0.839 |     0.161 |     0.492 | \n             |     0.536 |     0.345 |           | \n             |     0.413 |     0.079 |           | \n-------------|-----------|-----------|-----------|\n         121 |        45 |        19 |        64 | \n             |    49.270 |    14.730 |           | \n             |     0.370 |     1.238 |           | \n             |     0.703 |     0.297 |     0.508 | \n             |     0.464 |     0.655 |           | \n             |     0.357 |     0.151 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |        97 |        29 |       126 | \n             |     0.770 |     0.230 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  3.27     d.f. =  1     p =  0.0707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  2.55     d.f. =  1     p =  0.111 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.18 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.0909 \n95% confidence interval:  0.86 5.84 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.979 \n95% confidence interval:  0 5.03 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.0547 \n95% confidence interval:  0.982 Inf \n\n\n \n```\n:::\n:::\n\n**For the in-lab data collection** (n=126) the Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. In this particular data sample, the odds ratio (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition .\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"asynch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  204 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        84 |        12 |        96 | \n             |    76.235 |    19.765 |           | \n             |     0.791 |     3.050 |           | \n             |     0.875 |     0.125 |     0.471 | \n             |     0.519 |     0.286 |           | \n             |     0.412 |     0.059 |           | \n-------------|-----------|-----------|-----------|\n         121 |        78 |        30 |       108 | \n             |    85.765 |    22.235 |           | \n             |     0.703 |     2.711 |           | \n             |     0.722 |     0.278 |     0.529 | \n             |     0.481 |     0.714 |           | \n             |     0.382 |     0.147 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       162 |        42 |       204 | \n             |     0.794 |     0.206 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  7.26     d.f. =  1     p =  0.00707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  6.35     d.f. =  1     p =  0.0117 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.68 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00894 \n95% confidence interval:  1.23 6.17 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.998 \n95% confidence interval:  0 5.42 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.00539 \n95% confidence interval:  1.37 Inf \n\n\n \n```\n:::\n:::\n\n**For online data collection** (n=204), a Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. The odds ratio (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition .\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) \nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  330 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |       136 |        22 |       158 | \n             |   124.006 |    33.994 |           | \n             |     1.160 |     4.232 |           | \n             |     0.861 |     0.139 |     0.479 | \n             |     0.525 |     0.310 |           | \n             |     0.412 |     0.067 |           | \n-------------|-----------|-----------|-----------|\n         121 |       123 |        49 |       172 | \n             |   134.994 |    37.006 |           | \n             |     1.066 |     3.887 |           | \n             |     0.715 |     0.285 |     0.521 | \n             |     0.475 |     0.690 |           | \n             |     0.373 |     0.148 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       259 |        71 |       330 | \n             |     0.785 |     0.215 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  10.3     d.f. =  1     p =  0.0013 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  9.5     d.f. =  1     p =  0.00205 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.46 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00131 \n95% confidence interval:  1.37 4.53 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  1 \n95% confidence interval:  0 4.12 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.000928 \n95% confidence interval:  1.49 Inf \n\n\n \n```\n:::\n:::\n\n**Combining data across both sessions** (n=330), a Pearson's Chi-squared test suggests a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi_2$ (1) = 10.3, p = 0.001. The sample odds ratio (2.46, p = 0.001, 95% CI \\[1.37, 4.53\\]) indicates that the odds of providing a correct response to the first question are 2.46 higher for subjects in the impasse condition than those in the control condition.\n\n## RESOURCES\n\n-   https://rpkgs.datanovia.com/ggpubr/reference/index.html",
    "supporting": [
      "4_sgc3A_hypotesting_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}