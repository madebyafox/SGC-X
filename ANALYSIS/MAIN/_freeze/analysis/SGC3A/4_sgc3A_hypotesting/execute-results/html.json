{
  "hash": "e0d85364592151a9d18865b79e531fff",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | Hypothesis Testing'\n# YAML FOR generating modelsummary tables\n# uncomment to run those  cells only \n# \\usepackage{booktabs}\n# \\usepackage{siunitx}\n# \\newcolumntype{d}{S[input-symbols = ()]}\n---\n\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC3A-hypotesting}\n\n**TODO**\n\n-   run (online replication models) for item-level data, once approach is reviewed for the lab-based data\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#misc utilities\nlibrary(Hmisc) # %nin% operator\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\nlibrary(jtools)\nlibrary(pwr) #power analysis\n\n#visualization\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz\nlibrary(gghalves) # plots. in half\nlibrary(ggbeeswarm) # violin plot stuffs\nlibrary(statsExpressions)\nlibrary(ggstatsplot) #plots with stats\nlibrary(modelsummary) #latex tables for models!\n\n\n#models and performance\nlibrary(rstatix) #helpful testing functions incl wilcoxon, etc\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(equatiomatic) #extract model equation\nlibrary(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models \nlibrary(lmerTest) #for CIs in glmer \nlibrary(ggeffects) #visualization log regr models\nlibrary(nnet) #multinomial logistic regression [not mixed]\nlibrary(mclogit) #frequentist mixed multinomial logistic regression [mblogit]\nlibrary(brms) #bayesian mixed multinomials [+ other bayesian reg models]\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\ntheme_set(theme_minimal()) \n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"BarlowSemiCondensed-Bold\"),\n          axis.title = element_text(family = \"BarlowSemiCondensed-Medium\"),\n          strip.text = element_text(family = \"BarlowSemiCondensed-Bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA))\n}\n\nset_theme(base = theme_clean())\n```\n:::\n\n\n**Research Questions**\n\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task?\n\n**Experimental Hypothesis**\\\n*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.\n-   H1B \\| Learners in the IMPASSE condition will score higher on the TEST Phase than learners in CONTROL.\n\n**Null Hypothesis**\\\n*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#IMPORT DATA \ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds') %>% \n   mutate (\n    q = as.factor(q), #QUESTION\n    state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n    state = as.ordered(state))\n```\n:::\n\n\n## H1A \\| OVERALL ACCURACY\n\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Do Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?                                                                                                                                                                                |\n+=======================+====================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | (H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.                                                                                                                                               |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | **data**: `df_items` where `q nin 6,9` (the 13 discriminating Qs ), `df_subjects`                                                                                                                                                                                                  |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **outcome**:                                                                                                                                                                                                                                                                       |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   \\[at item level\\] : *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                                                             |\n|                       | -   \\[subject level\\]: accuracy (number of test phase qs correct from total `s_NABS`)                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **predictor**: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                             |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Wilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (`s_NABS`)                                                                                                                                                                                 |\n|                       | 2.  Mixed Logistic Regression\\                                                                                                                                                                                                                                                     |\n|                       |     `accuracy` \\~ `condition` + (1 \\| `subject` ) + (1 \\| `question`)\\                                                                                                                                                                                                             |\n|                       |     model effect of condition on probability of correct response \\[during test phase\\] while accounting for subject (and item-level?) effects                                                                                                                                      |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Alternatives**      | -   Ordinal Mixed Logistic Regression on `scaled_score`                                                                                                                                                                                                                            |\n|                       | -   OLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | **Also exploring:**                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   Hurdle model (mixture model w/ binomial + \\[poisson or negbinom count; 0s from 1 DGP)                                                                                                                                                                                          |\n|                       | -   Zero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)                                                                                                                                                                                    |\n|                       | -   Beta regression hurdle model? (mixture with location and scale parameters \\[mean, variance\\] and hurdles for floor and ceiling effects)                                                                                                                                        |\n|                       | -   Other way to account for the severe bimodality?                                                                                                                                                                                                                                |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#item level\ndf = df_items %>% filter(q %nin% c(6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n  q = as.factor(q)\n)\n\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(title = \"Overall Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-OVERALL-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(DV_percent_NABS))\ngf_props(~DV_percent_NABS, \n         fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_grid(pretty_condition ~ pretty_mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Overall Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-OVERALL-ACC-2.png){width=672}\n:::\n:::\n\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf_i <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q %nin% c(6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n  subject = as.factor(subject),\n  q = as.factor(q)\n) %>% dplyr::select(pretty_condition, accuracy, subject,q)\n\ndf_s <- df_subjects %>% filter(mode == \"lab-synch\") %>% mutate(\n  task_percent = DV_percent_NABS\n) %>% dplyr::select(pretty_condition, task_percent)\n```\n:::\n\n\n**SPLIT SIDE BY SIDE**\n\n::: {.cell}\n\n```{.r .cell-code}\n# quota_halves <- ggplot(vdem_2015, aes(x = quota, y = prop_fem)) +\nboxes <- ggplot(df_s, aes(x = pretty_condition, y = task_percent)) +\n  \n  \n  geom_half_point(aes(color = pretty_condition),\n                  transformation = position_quasirandom(width = 0.1),\n                  side = \"l\", size = 1.5, alpha = 0.5) +\n  geom_half_boxplot(aes(fill = pretty_condition), side = \"r\", width = 0.5) +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.8) +\n  scale_color_viridis_d(option = \"plasma\", end = 0.8) +\n  guides(color = \"none\", fill = \"none\") +\n  labs(x = \"Condition\", y = \"Proportion of correct responses (test phase)\") +\n  theme_clean()\n\n# quota_densities <- ggplot(vdem_2015, aes(x = prop_fem, fill = quota)) +\ndensities <- ggplot(df_s, aes(x = task_percent, fill = pretty_condition)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.8) +\n  labs(x = \"proportion of correct responses (test phase)\", y = \"Density\", fill = \"Condition\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\nboxes | densities\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n**CUSTOM ONLY**\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df_s, # data we are using\n       aes(x = task_percent,\n           y = pretty_condition)) +\n  stat_slab(aes(fill = pretty_condition), # slab geometry\n            geom = \"slab\",\n            position = position_nudge(y = .20), # nudged up by .20\n            scale = .5,\n            # color = \"grey\",\n            alpha = 1.0) + # transparency\n  geom_boxplot(# boxplot geometry; grey contrast w/ points\n               width = .20,\n               size = 0.5,\n               show.legend = FALSE,\n               alpha = .25) + # transparency\n  geom_point(aes(color = pretty_condition), # point geometry\n             position = position_jitter(width = .01, height = .05), # \n             size = 1.0,\n             shape = 19, # circles\n             alpha = .5) + # transparency\n  labs(title = \"Distribution of Test Phase Accuracy\",\n       y = \"Test Phase Proportion Correct\", x = \"Condition\") +\n  theme_clean() + theme(legend.position = \"blank\") +\n  ggeasy::easy_rotate_y_labels(angle = 90)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n**WIP CUSTOM + STATSEXPRESSIONS LABELS ONLY**\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df_s, aes(x = task_percent, y = pretty_condition, fill=pretty_condition)) +\n  stat_slab(\n            geom = \"slab\",\n            position = position_nudge(y = .20), # nudged up by .20\n            scale = .5) + \n  geom_boxplot(aes(fill = NULL),\n               width = .20,\n               size = 0.5,\n               show.legend = FALSE,\n               alpha = .25) + \n  geom_point(aes(color = pretty_condition), \n             position = position_jitter(width = .01, height = .05), \n             size = 1.0,\n             shape = 19, # circles\n             alpha = .5) + \n  labs(title = \"Distribution of Test Phase Accuracy\",\n       x = \"Test Phase Proportion Correct\", y = \"Condition\") +\n  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncentrality_description(df_s, y = task_percent, x = pretty_condition) |>\n  ggplot(aes(y = task_percent, x = pretty_condition)) +\n  geom_point() +\n  geom_label(aes(label = expression), parse = TRUE, nudge_y = -0.05) + \n  coord_flip()+\n  stat_slab(\n            geom = \"slab\",\n            position = position_nudge(y = .20), # nudged up by .20\n            scale = .5) + \n  geom_boxplot(aes(fill = NULL),\n               width = .20,\n               size = 0.5,\n               show.legend = FALSE,\n               alpha = .25) + \n  geom_point(aes(color = pretty_condition), \n             position = position_jitter(width = .01, height = .05), \n             size = 1.0,\n             shape = 19, # circles\n             alpha = .5) + \n  labs(title = \"Distribution of Test Phase Accuracy\",\n       x = \"Test Phase Proportion Correct\", y = \"Condition\") +\n  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n**CUSTOM + BETWEEN, WORKING** \n\n::: {.cell}\n\n```{.r .cell-code}\np <-   ggbetweenstats(data = df_s, x = pretty_condition, y = task_percent,\n               plot.type = \"box\", type = \"nonparametric\",\n               centrality.type = \"parametric\",\n               package = \"RColorBrewer\",\n               palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  aes(color = pretty_condition, fill = pretty_condition),\n                  scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  theme(axis.text.x = element_text(angle = 90)))\n               ) +\n  ggdist::stat_halfeye(\n    alpha = 0.7, \n    point_colour = NA,\n    adjust = .5, \n    width = .5, .width = 0, \n    justification = -.5) +\n  geom_boxplot(\n    alpha = 0.1,\n    width = .2, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 2,\n    alpha = .5,\n    position = position_jitter(\n      seed = 1, width = .05, height = .02\n    )\n  )  +\ncoord_flip() + theme_clean() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\n```\n:::\n\n```{.r .cell-code}\np$layers[[3]]=NULL #remove default boxplot\ne <- statsExpressions::oneway_anova(data = df_s, x = pretty_condition, y = task_percent,\n               type = \"nonparametric\") #gen stats test\n#labels are layer 4\np + labs(title = \"Distribution of Test Phase Accuracy\",\n         y = \"Proportion of correct responses in test phase\", x = \"\",\n         subtitle = \"Impasse condition yields higher scores and greater variance\",\n         caption=e$expression[[1]])\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n#### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Test Phase % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n```\n:::\n\n```{.r .cell-code}\ntbl1 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Test Phase % Correct)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.692 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.316 </td>\n   <td style=\"text-align:right;\"> 0.392 </td>\n   <td style=\"text-align:right;\"> 126 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Test Phase % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Test Phase % Correct) BY CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> pretty_condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.210 </td>\n   <td style=\"text-align:right;\"> 0.370 </td>\n   <td style=\"text-align:right;\"> 62 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> impasse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.058 </td>\n   <td style=\"text-align:right;\"> 0.346 </td>\n   <td style=\"text-align:right;\"> 0.846 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.419 </td>\n   <td style=\"text-align:right;\"> 0.387 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAcross both conditions, overall accuracy on the task ranges from 0 to 100 with a mean of 31.624. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.\n\nA score of 100% indicates that the participant correctly interpreted the interval-coordinate system throughout the task, *starting at the first question*. A score of 0% indicates the individual *never* correctly interpreted the coordinate system. A score somewhere inbetween indicates that an individual deciphered the coordinate system *sometime over the course the task*.\n\n#### WILCOXON RANK SUM (Mann-Whitney Test) --- SCORE\n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n##### Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$task_percent ~ df_s$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$task_percent by df_s$pretty_condition\nW = 1243, p-value = 7e-05\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in\nranks between df_s$task_percent and df_s$pretty_condition suggests that the\neffect is negative, statistically significant, and large (W = 1243.00, p <\n.001; r (rank biserial) = -0.37, 95% CI [-1.00, -0.22])\n```\n:::\n:::\n\n##### Inference\n\n**Reported in dissertation**\n\nBecause the distribution of the outcome variable is not normally distributed, we evaluate the effect of CONDITION on ACCURACY via a non-parametric test. Consistent with our hypothesis, a Wilcoxon rank sum test (with continuity correction) on ACCURACY by CONDITION indicates that data in each condition likely come from different population distributions (W = 1243, p < 0.001; one-tailed), and that the distribution of the control condition is less (i.e. shifted to the left/ lower scores) than the impasse condition (\\^{r} = -0.37, 95% CI \\[-1.00, -0.22\\]), a large-sized effect.\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <-   ggbetweenstats(data = df_s, x = pretty_condition, y = task_percent,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               package = \"RColorBrewer\",\n               palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  aes(color = pretty_condition, fill = pretty_condition),\n                  scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  theme(axis.text.x = element_text(angle = 90)))\n               ) +\n  ggdist::stat_halfeye(\n    alpha = 0.7, \n    point_colour = NA,\n    adjust = .5, \n    width = .5, .width = 0, \n    justification = -.5) +\n  geom_boxplot(\n    alpha = 0.1,\n    width = .2, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 2,\n    alpha = .5,\n    position = position_jitter(\n      seed = 1, width = .05, height = .02\n    )\n  )  +\ncoord_flip() + theme_clean() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\n```\n:::\n\n```{.r .cell-code}\np$layers[[3]]=NULL #remove default boxplot\ne <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df_s,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE)\n#labels are layer 4\np + labs(title = \"Distribution of Total Accuracy\",\n         y = \"Proportion of correct responses across task\", x = \"\",\n         subtitle = \"Impasse condition yields higher scores and greater variance\",\n         caption=e$expression[[1]])\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |    Chi2 |      p\n--------------------------------------------------\nm0    |      glm |  1 |         |         |       \nmm.rS | glmerMod |  2 |       1 | 1011.83 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  4.82063151679769e-222\"\n```\n:::\n\n```{.r .cell-code}\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject Intercept + Item intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.rSQ | glmerMod |  3 |       1 | 15.82 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000697594950188617\"\n```\n:::\n:::\n\n\n*A likelihood ratio test indicates that a logistic regression model including random intercepts for SUBJECT and QUESTION explains more variance in the data than an empty \\[intercept only\\] model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n# summary(mm.CrSQ)\n\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |       |       \nmm.CrSQ | glmerMod |  4 |       1 | 18.66 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000156066263742927\"\n```\n:::\n:::\n\n\n*A likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.*\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm1 <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n    1006     1028     -499      998     1634 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.316 -0.136 -0.052  0.168  5.522 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 22.216   4.713   \n q       (Intercept)  0.308   0.555   \nNumber of obs: 1638, groups:  subject, 126; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -5.51       1.02   -5.40  6.5e-08 ***\npretty_conditionimpasse     4.32       1.12    3.87  0.00011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.802\n```\n:::\n\n```{.r .cell-code}\nprint(\"SIGNIFICANCE TEST [non directional]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGNIFICANCE TEST [non directional]\"\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)    \npretty_condition    15  1    0.00011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.00011\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one  directional, null: B <= 0:  5e-05\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nse <- sqrt(diag(stats::vcov(m1)))\n# table of estimates with 95% CI\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n    se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          Est    LL    UL\n(Intercept)             -5.51 -7.51 -3.51\npretty_conditionimpasse  4.32  2.14  6.51\n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- exp(tab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                             Est      LL       UL\n(Intercept)              0.00406 0.00055   0.0299\npretty_conditionimpasse 75.50665 8.46147 673.7900\n```\n:::\n:::\n\n\n##### Inference\n\n***(In Dissertation)***\n\nTo quantify the effect of CONDITION on ACCURACY, we fit a mixed-effect binomial logistic regression model with random intercepts for subjects and questions. The structure of this model allows us to differentiate between random variance introduced by individual subjects and questions, versus the expected systematic variance of CONDITION. A likelihood ratio test indicates that a model including a fixed effect of CONDITION is explains significantly more variance in the data than an intercepts-only baseline model ($\\chi^2 (3) = 18.66, p < 0.001$). The explanatory power of the entire model is substantial ($conditional \\ R^2 = 0.89$) and the part related to the fixed effect CONDITION ($marginal \\ R^2$) explains 15% of variance. Consistent with our hypothesis, the impasse condition substantially increased the odds of a correct response.  Across the entire task participants in the impasse condition were 75 times as likely to offer a correct response, compared with those in the control condition ( $e^{\\beta_1} = 75.51, p < 0.001$ , one-tailed $90 \\% \\  CI [8.46, 673.79]$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">75.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.46&nbsp;&ndash;&nbsp;673.76</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">22.22</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.31</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.87</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1638</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.153 / 0.892</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n# \n# \n# \n```\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGIDST\nbroom.mixed::tidy(m1) %>% \n  head(2) %>% #take only fixed effects\n  ggplot(aes(y = term)) +\n  stat_halfeye(\n    #is this legit? ok to use dist_student_t for logistic? \n    aes(xdist = dist_student_t(df = exp(df.residual(m1)), \n                               mu = exp(estimate), sigma = exp(std.error))))\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-3.png){width=672}\n:::\n\n```{.r .cell-code}\n  # stat_halfeye(\n  #   aes(xdist = dist_student_t(df = df.residual(m1), mu = estimate, sigma = std.error)))\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(parameters)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'parameters' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'parameters'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:gmodels':\n\n    ci\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:modelsummary':\n\n    supported_models\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:gnm':\n\n    parameters\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:distributional':\n\n    kurtosis, parameters, skewness\n```\n:::\n\n```{.r .cell-code}\nresult <- simulate_parameters(m1)\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in out$Effects[out$Parameter == i] <- params$Effects[params$Parameter\n== : number of items to replace is not a multiple of replacement length\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-5.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- equivalence_test(m1, rule = \"cet\")\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-6.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- equivalence_test(m1, effects = \"random\")\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT PARAMETERS\nresult <- model_parameters(m1, exponentiate = TRUE, \n                           component = \"all\")\nplot(result) + \n  labs(\n  title = \"Accuracy ~ Condition + (1 | subject) + (1 | question)\",\n  subtitle = \"Logistic Mixed Effects Model\"\n)  + theme_clean() +  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-8.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m1, type = \"pred\")[[1]] + \n  ylim(0,1) + labs(\n    title = \"Model Prediction | Probability of Accurate Response\",\n    subtitle = \"Impasse increases Probability of Correct Response\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-16-9.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n# \n# \n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list('N(subject) = 126 $\\tau_{00}$(subject) = 22.22',\n#              'N(question) = 13 $\\tau_{00}$(question) = 0.31',\n#                \"*** indicates p < 0.001\")\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term + statistic ~ model,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = c(\n#                            \"s.e. = {std.error}\"),\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              # coef_omit = \"Intercept\",\n#              gof_omit = 'AIC|RMSE|ICC|BIC',\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\n# report(m1)\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |     AICc |      BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n-------------------------------------------------------------------------------------------------------------------------\n1005.923 | 1005.947 | 1027.528 |      0.892 |      0.153 | 0.873 | 0.243 | 1.000 |    0.192 |      -Inf |           0.013\n```\n:::\n\n```{.r .cell-code}\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Probably bad model fit. Only about 42% of the residuals are inside the error bounds.\n```\n:::\n:::\n\n\n##### TODO\n\n-   DIAGNOSTICS: What in the world is happening with the normality of random effects plot? Do the fixed effects residuals need to be normally distributed?\n-   What else needs to be interpreted with respect to the item and subject random effects?\n\n\n##### BAYESIAN \n\n**Sanity Check** Compare frequentist model with bayesian alternative\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##FLAT PRIORS\n#fit matching bayesian model [flat priors]\nFLAT_B.mm.CrSQ <-  brm(\n  bf(accuracy ~ pretty_condition + (1|subject) + (1|q)),\n  data = df_i,\n  family = bernoulli(link = \"logit\"),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f33cf964a.stan', line 6, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f33cf964a.stan', line 12, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f33cf964a.stan', line 18, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f33cf964a.stan', line 36, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f33cf964a.stan', line 38, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 10.0 seconds.\nChain 3 finished in 10.0 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 10.1 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 10.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 10.0 seconds.\nTotal execution time: 10.4 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#describe model\nsummary(FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1638) \n  Draws: 4 chains, each with iter = 1000; warmup = 0; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.66      0.20     0.34     1.12 1.00     1459     2281\n\n~subject (Number of levels: 126) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.50      0.50     3.61     5.58 1.01     1118     1947\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  -4.28      0.78    -5.84    -2.80 1.00     1036\npretty_conditionimpasse     3.28      0.96     1.40     5.22 1.00      617\n                        Tail_ESS\nIntercept                   1682\npretty_conditionimpasse     1211\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n#compare to frequentist model\npaste(\"COMPARE TO FREQUENTIST\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"COMPARE TO FREQUENTIST\"\n```\n:::\n\n```{.r .cell-code}\ncompare_models(mm.CrSQ, FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                  |              mm.CrSQ |       FLAT_B.mm.CrSQ\n------------------------------------------------------------------------\n(Intercept)                | -5.51 (-7.51, -3.51) | -4.26 (-5.84, -2.80)\npretty condition (impasse) |  4.32 ( 2.14,  6.51) |                     \npretty_conditionimpasse    |                      |  3.26 ( 1.40,  5.22)\n------------------------------------------------------------------------\nObservations               |                 1638 |                 1638\n```\n:::\n:::\n\n_Here we see that the model with default priors yields estimates comparable to the frequentist mixed model, though slightly smaller for fixed effects condition, with tighter credible intervals._\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#describe priors that were used\npaste(\"DEFAULT PRIORS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DEFAULT PRIORS\"\n```\n:::\n\n```{.r .cell-code}\nprior_summary(FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class                    coef   group resp dpar nlpar\n               (flat)         b                                                \n               (flat)         b pretty_conditionimpasse                        \n student_t(3, 0, 2.5) Intercept                                                \n student_t(3, 0, 2.5)        sd                                                \n student_t(3, 0, 2.5)        sd                               q                \n student_t(3, 0, 2.5)        sd               Intercept       q                \n student_t(3, 0, 2.5)        sd                         subject                \n student_t(3, 0, 2.5)        sd               Intercept subject                \n bound       source\n            default\n       (vectorized)\n            default\n            default\n       (vectorized)\n       (vectorized)\n       (vectorized)\n       (vectorized)\n```\n:::\n\n```{.r .cell-code}\n#set informative priors for fixed effects\n#parameters normally distributed around the mean of the expected log coefficient\n#we expect low probability of accuracy in control [intercept] and in impasse, but higher variance in impasse\npriors <- c(\n  prior(normal(-1, 2), class = b),\n  prior(normal(-1, 4), class = b, coef=\"pretty_conditionimpasse\")\n)\n\n#fit model with informative priors\nB.mm.CrSQ <-  brm(\n  accuracy ~ pretty_condition + (1|subject) + (1|q),\n  prior = priors,\n  data = df_i,\n  family = bernoulli(link = \"logit\"),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The global prior 'normal(-1, 2)' of class 'b' will not be used in the\nmodel as all related coefficients have individual priors already. If you did not\nset those priors yourself, then maybe brms has assigned default priors. See ?\nset_prior and ?get_prior for more details.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f4faccb76.stan', line 6, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f4faccb76.stan', line 12, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f4faccb76.stan', line 18, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f4faccb76.stan', line 36, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\nWarning in '/var/folders/52/q436r3nd6kvcz73cchs_t98r0000gn/T/Rtmp3qhnjq/model-9c2f4faccb76.stan', line 38, column 2: Declaration\n    of arrays by placing brackets after a variable name is deprecated and\n    will be removed in Stan 2.32.0. Instead use the array keyword before the\n    type. This can be changed automatically using the auto-format flag to\n    stanc\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 10.3 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 10.5 seconds.\nChain 4 finished in 10.4 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 10.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 10.4 seconds.\nTotal execution time: 10.7 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#describe model\nsummary(B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1638) \n  Draws: 4 chains, each with iter = 1000; warmup = 0; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.66      0.20     0.34     1.13 1.00     1551     2668\n\n~subject (Number of levels: 126) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.50      0.51     3.60     5.58 1.00     1032     2502\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  -4.16      0.77    -5.83    -2.75 1.00      942\npretty_conditionimpasse     3.10      0.89     1.44     4.89 1.00      749\n                        Tail_ESS\nIntercept                   1717\npretty_conditionimpasse     1652\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n#compare to frequentist model\npaste(\"COMPARE TO UNFINFORMATIVE PRIOR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"COMPARE TO UNFINFORMATIVE PRIOR\"\n```\n:::\n\n```{.r .cell-code}\ncompare_models(FLAT_B.mm.CrSQ, B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter               |       FLAT_B.mm.CrSQ |            B.mm.CrSQ\n---------------------------------------------------------------------\n(Intercept)             | -4.26 (-5.84, -2.80) | -4.13 (-5.83, -2.75)\npretty_conditionimpasse |  3.26 ( 1.40,  5.22) |  3.07 ( 1.44,  4.89)\n---------------------------------------------------------------------\nObservations            |                 1638 |                 1638\n```\n:::\n:::\n\n_Here we see tha the model with the informative prior makes predictions similar to the uninformative prior model_. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#DIAGNOSTICS\n\n#set model \nm <- B.mm.CrSQ\n\n#POSTERIOR CHECKS\nlibrary(bayestestR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'bayestestR' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'bayestestR'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:gmodels':\n\n    ci\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggdist':\n\n    hdi\n```\n:::\n\n```{.r .cell-code}\ndiagnostic_posterior(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Parameter Rhat ESS   MCSE\n1               b_Intercept    1 936 0.0253\n2 b_pretty_conditionimpasse    1 741 0.0326\n```\n:::\n\n```{.r .cell-code}\npp_check(m, ndraws = 500)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-23-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#INTERPRET\nlibrary(bayestestR)\ndescribe_posterior(m, test = c(\"p_direction\", \"rope\", \"bayesfactor\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling priors, please wait...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter               | Median |         95% CI |   pd |          ROPE | % in ROPE |  Rhat |    ESS |     BF\n--------------------------------------------------------------------------------------------------------------\n(Intercept)             |  -4.13 | [-5.83, -2.75] | 100% | [-0.18, 0.18] |        0% | 1.004 | 936.00 | > 1000\npretty_conditionimpasse |   3.07 | [ 1.44,  4.89] | 100% | [-0.18, 0.18] |        0% | 1.004 | 741.00 | 111.31\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#set working model\nm <- B.mm.CrSQ\n\n\n#equivalence test \nresult <- equivalence_test(m, rule = \"cet\")\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.134\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 200 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#rope \nresult <- rope(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#direction of effect \nresult <- pd(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# all parameters\nm %>% \n  posterior_samples() %>% \n  select(-c(lp__, contains(\"[\"))) %>%\n  pivot_longer(cols = everything(),\n               names_to = \"variable\",\n               values_to = \"value\") %>% \n  ggplot(data = .,\n         mapping = aes(x = value)) +\n  stat_halfeye(point_interval = mode_hdi,\n               fill = \"lightblue\") + \n  facet_wrap(~ variable,\n             ncol = 2,\n             scales = \"free\") +\n  theme(text = element_text(size = 12))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#plot parameters\nstanplot(m, \n         type = \"areas\",\n         prob = 0.95) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Method 'stanplot' is deprecated. Please use 'mcmc_plot' instead.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#plot model\nplot_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT PARAMETERS\nresult <- model_parameters(m, exponentiate = TRUE, \n                           component = \"all\")\nplot(result) + \n  labs(\n  title = \"Accuracy ~ Condition + (1 | subject) + (1 | question)\",\n  subtitle = \"Logistic Mixed Effects Model\"\n)  + theme_clean() +  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")[[1]] + \n  ylim(0,1) + labs(\n    title = \"Model Prediction | Probability of Accurate Response\",\n    subtitle = \"Impasse increases Probability of Correct Response\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-25-8.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#report(m)\n```\n:::\n\n\n\n\n\n\n\n### TODO (ONLINE REPLICATION)\n\n\\*\\*TODO after verify correctness of approach for the lab-based sample (above)\n\n\n## H1B \\| OVERALL INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n-   **\"orthogonal-like\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n-   **\"unknown\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints) =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n-   **\"triangle-like\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions?                                          |\n+=======================+=================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q nin 6,9` (13 discriminant test phase items)                                                              |\n|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                          |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |\n|                       |                                                                                                                                                 |\n|                       | Alternative:                                                                                                                                    |\n|                       |                                                                                                                                                 |\n|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |\n|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf = df_items %>% filter(q %nin% c(6,9)) %>% mutate(\n  q = as.factor(q),\n  subject = as.factor(subject)\n) %>% dplyr::select(q,subject,state,pretty_condition,pretty_mode)\n\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(title = \"Test Phase Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. In the impasse condition, there are also more positive transition (i.e. triangle-like) and neutral (ie. blank or uncertain response types) than in the control condition.\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf_i <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, subject, q, state)\n\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.6973  0.3269 0.5092\n  unknown    0.0732  0.1923 0.1337\n  tri-like   0.2295  0.4808 0.3571\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse  Sum\n  orth-like     562     272  834\n  unknown        59     160  219\n  tri-like      185     400  585\n  Sum           806     832 1638\n```\n:::\n:::\n\n\n#### MIXED MULTINOMIAL REGRESSION\n\n**TODO** - add a 1 to the empty cell and re-run mblogit to show that estimates are more similar to the brms results - run individual mixed models to show results are similar to mblogit vs brms\n\n*Does condition affect the response state of of items across the task?*\n\n*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   Can use mclogit mblogit() with random effect *or* bayesian brms package b/c nlme, lme4 don't support random effects on multinomial (ie no categorical family on glmer())\n\n-   Alternative would be to manually run 2 X binomial mixed models \\[should compare outcomes\\]\n\n-   2 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit Model \\[MANUAL INDIVIDUAL BINOMIALS\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#VERIFY RESULTS BELOW VIA MULTIPLE INDIVIDUAL MODELS\n\npaste(\"ORTH vs. UNKNOWN\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. UNKNOWN\"\n```\n:::\n\n```{.r .cell-code}\nd1 <- df_i %>% filter(state %nin% c(\"tri-like\")) %>% droplevels()\ntable(d1$pretty_condition, d1$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         \n          orth-like unknown\n  control       562      59\n  impasse       272     160\n```\n:::\n\n```{.r .cell-code}\nplot(d1$pretty_condition, d1$state)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.unknown <- glmer(state ~ pretty_condition + ( 1 | subject) + (1 | q), family = \"binomial\", data = d1)\nsummary(m.unknown)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: d1\n\n     AIC      BIC   logLik deviance df.resid \n     802      822     -397      794     1049 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.377 -0.362 -0.177 -0.039  4.540 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 2.42     1.55    \n q       (Intercept) 2.22     1.49    \nNumber of obs: 1053, groups:  subject, 112; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -3.441      0.534   -6.44  1.2e-10 ***\npretty_conditionimpasse    2.924      0.427    6.85  7.3e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.496\n```\n:::\n:::\n\n\n*Being in the IMPASSE condition increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 19 ( logodds = 2.92, z = 6.89, p \\< 0.001) . Participants in the impasse condition were 19x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.67, marginal R2 = 0.21; SD(subject) = 1.55, SD(question) = 2.22)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaste(\"ORTH vs. TRIANGULAR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. TRIANGULAR\"\n```\n:::\n\n```{.r .cell-code}\nd2 <- df_i %>% filter(state %nin% c(\"unknown\")) %>% droplevels()\ntable(d2$pretty_condition, d2$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         \n          orth-like tri-like\n  control       562      185\n  impasse       272      400\n```\n:::\n\n```{.r .cell-code}\nplot(d2$pretty_condition, d2$state)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.tri <- glmer(state ~ pretty_condition + ( 1 | subject) + (1 | q), family = \"binomial\", data = d2)\nsummary(m.tri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: d2\n\n     AIC      BIC   logLik deviance df.resid \n     809      830     -400      801     1415 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.971 -0.153 -0.038  0.139  5.811 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 25.50    5.05    \n q       (Intercept)  1.18    1.09    \nNumber of obs: 1419, groups:  subject, 126; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -4.65       1.15   -4.06 0.000049 ***\npretty_conditionimpasse     5.72       1.38    4.14 0.000034 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.827\n```\n:::\n:::\n\n\n*Being in the IMPASSE condition increases* the odds of giving an triangle-like response by a factor of 305 ( logodds = 5.72, z = 4.14, p \\< 0.001) . Participants in the impasse condition were 305 times as likely to give an triangle-like response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.91, marginal R2 = 0.21; SD(subject) = 5.05, SD(q) = 1.09)\n\n##### Fit Model \\[mblogit\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://www.elff.eu/software/mclogit/manual/mblogit/\n#\"baseline category logit\" model matches multinom()\n\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df_i$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nm.mbl0 <- mblogit(state ~ pretty_condition ,  #no random intercepts; fixed only model \n                  data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 2991 - criterion = 0.441\nIteration 2 - deviance = 2980 - criterion = 0.00381\nIteration 3 - deviance = 2980 - criterion = 0.0000192\nIteration 4 - deviance = 2980 - criterion = 2.58e-10\nconverged\n```\n:::\n\n```{.r .cell-code}\n#summary(m.mbl0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nm.mbl1 <- mblogit(state ~ pretty_condition , \n                  random = list( ~ 1|subject, ~1|q), \n                  data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 2149 - criterion = 0.763\nIteration 2 - deviance = 1863 - criterion = 0.0867\nIteration 3 - deviance = 1771 - criterion = 0.0261\nIteration 4 - deviance = 1732 - criterion = 0.0045\nIteration 5 - deviance = 1708 - criterion = 0.0013\nIteration 6 - deviance = 1696 - criterion = 0.00032\nIteration 7 - deviance = 1690 - criterion = 0.0000694\nIteration 8 - deviance = 1688 - criterion = 0.0000144\nIteration 9 - deviance = 1687 - criterion = 2.98e-06\nIteration 10 - deviance = 1687 - criterion = 6.31e-07\nIteration 11 - deviance = 1687 - criterion = 1.37e-07\nIteration 12 - deviance = 1686 - criterion = 3.07e-08\nIteration 13 - deviance = 1686 - criterion = 7.02e-09\nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(m.mbl1)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(m.mbl0) > AIC(m.mbl1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.mbl0, m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |    Chi2 |      p\n---------------------------------------------------\nm.mbl0 |  mblogit |  4 |         |         |       \nm.mbl1 | mmblogit | 10 |       6 | 1954.42 | < .001\n```\n:::\n\n```{.r .cell-code}\n#DESCRIBE MODEL\nsummary(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df_i, random = list(~1 | \n    subject, ~1 | q))\n\nEquation for unknown vs orth-like:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.551      0.521   -4.90  9.5e-07 ***\npretty_conditionimpasse    2.464      0.380    6.48  8.9e-11 ***\n\nEquation for tri-like vs orth-like:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.614      0.697   -3.75  0.00018 ***\npretty_conditionimpasse    3.359      0.725    4.63  3.6e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Co-)Variances:\nGrouping level: subject \n           Estimate      Std.Err.   \nunknown~1   2.84         0.903      \ntri-like~1  4.92 13.52   3.106 8.278\n\nGrouping level: q \n           Estimate    Std.Err.   \nunknown~1  2.47         9.69      \ntri-like~1 1.97 2.55   14.07 16.47\n\nNull Deviance:     3600 \nResidual Deviance: 1690 \nNumber of Fisher Scoring iterations:  13\nNumber of observations\n  Groups by subject: 126\n  Groups by q: 13\n  Individual observations:  1638\n```\n:::\n\n```{.r .cell-code}\n#INTERPRET COEFFICIENTS\ncint <- confint(m.mbl1, level = 0.95)\nprint(\"ODDS RATIO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIO\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m.mbl1)), exp(cint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                          2.5 %  97.5 %\nunknown~(Intercept)               0.0780 0.0281   0.216\ntri-like~(Intercept)              0.0732 0.0187   0.287\nunknown~pretty_conditionimpasse  11.7514 5.5785  24.755\ntri-like~pretty_conditionimpasse 28.7503 6.9366 119.162\n```\n:::\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC       |       BIC |  RMSE | Sigma\n-------------------------------------\n13770.680 | 13824.692 | 0.270 | 1.016\n```\n:::\n\n```{.r .cell-code}\n#TABLE\ntab_model(m.mbl1, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Model Predicted Odds Ratio</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03&nbsp;&ndash;&nbsp;0.22</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.02&nbsp;&ndash;&nbsp;0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">11.75</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.58&nbsp;&ndash;&nbsp;24.75</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">28.75</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">6.94&nbsp;&ndash;&nbsp;119.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1638</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 12 (z = 6.48, p \\< 0.001) . **Participants in the impasse condition were 12x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 29 (z = 4.63, p \\< 0.001 ). **Participants in the impasse condition were more than 29x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model \nm <- m.mbl1\n\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, vline.color = \"red\", \n           transform = \"exp\", #for some reason have to manually add for mixed?\n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | State ~ condition\",\n       subtitle = \"(p for  two-tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(parameters)\n\n#PLOT PARAMETER ESTIMATES\nresult <- simulate_parameters(m)\nplot(result, stack = FALSE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-32-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- equivalence_test(m, rule = \"cet\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Could not estimate a good default ROPE range. Using 'c(-0.1, 0.1)'.\n```\n:::\n\n```{.r .cell-code}\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-32-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#raw coefficients\nplot_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-32-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT PARAMETERS\nresult <- model_parameters(m, exponentiate = TRUE, \n                           component = \"all\")\nplot(result) + \n  labs(\n  title = \"Accuracy ~ Condition + (1 | subject) + (1 | question)\",\n  subtitle = \"Logistic Mixed Effects Model\"\n)  + theme_clean() +  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-32-5.png){width=672}\n:::\n\n```{.r .cell-code}\ns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (...) \n{\n    mgcv::s(...)\n}\n<bytecode: 0x7fc50830ff68>\n<environment: namespace:brms>\n```\n:::\n\n```{.r .cell-code}\n#TODO CAN'T SEEM TO COMPUTE MARGINAL EFFECTS PLOT FOR THE MIXED MODEL\n# pr <- ggpredict(m, \"pretty_condition\", type = \"fixed\")\n# plot(pr)\n#PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")\n# plot_model(m, type = \"eff\")\n\n# TERNARY PLOT\n# library(plot3logit)\n# field3logit(ggpredict(m))\n#https://cran.r-project.org/web/packages/plot3logit/vignettes/plot3logit-overview.html\n\n\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.55</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.57&nbsp;&ndash;&nbsp;-1.53</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.61</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.98&nbsp;&ndash;&nbsp;-1.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.72&nbsp;&ndash;&nbsp;3.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.94&nbsp;&ndash;&nbsp;4.78</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1638</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### Diagnostics\n\n**COMPARE TO MANUAL MODELS**\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_models(m, m.unknown, m.tri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                        |                    m |            m.unknown |                m.tri\n-----------------------------------------------------------------------------------------------------\n(Intercept)                      |                      | -3.44 (-4.49, -2.39) | -4.65 (-6.90, -2.41)\nunknown~(Intercept)              | -2.55 (-3.57, -1.53) |                      |                     \ntri-like~(Intercept)             | -2.61 (-3.98, -1.25) |                      |                     \nunknown~pretty conditionimpasse  |  2.46 ( 1.72,  3.21) |                      |                     \ntri-like~pretty conditionimpasse |  3.36 ( 1.94,  4.78) |                      |                     \npretty condition (impasse)       |                      |  2.92 ( 2.09,  3.76) |  5.72 ( 3.01,  8.42)\n-----------------------------------------------------------------------------------------------------\nObservations                     |                 1638 |                 1053 |                 1419\n```\n:::\n:::\n\n\n##### Fit Model \\[brms\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#BAYESIAN MIXED VERSION\nmixcat.1 <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_mixedcat_state_LAB.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- mixcat.1\n\n#DESCRIBE MODEL\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muunknown = logit; mutrilike = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1638) \n  Draws: 4 chains, each with iter = 1000; warmup = 0; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muunknown_Intercept)     1.50      0.39     0.91     2.42 1.01     1202\nsd(mutrilike_Intercept)     1.11      0.29     0.68     1.80 1.00     1248\n                        Tail_ESS\nsd(muunknown_Intercept)     2074\nsd(mutrilike_Intercept)     2292\n\n~subject (Number of levels: 126) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muunknown_Intercept)     1.45      0.20     1.10     1.88 1.00     1387\nsd(mutrilike_Intercept)     4.35      0.47     3.54     5.36 1.01     1068\n                        Tail_ESS\nsd(muunknown_Intercept)     2513\nsd(mutrilike_Intercept)     1963\n\nPopulation-Level Effects: \n                                  Estimate Est.Error l-95% CI u-95% CI Rhat\nmuunknown_Intercept                  -3.18      0.52    -4.23    -2.18 1.00\nmutrilike_Intercept                  -3.52      0.74    -5.07    -2.13 1.01\nmuunknown_pretty_conditionimpasse     2.62      0.38     1.90     3.36 1.00\nmutrilike_pretty_conditionimpasse     4.13      0.93     2.36     6.06 1.00\n                                  Bulk_ESS Tail_ESS\nmuunknown_Intercept                    857     1438\nmutrilike_Intercept                    436     1128\nmuunknown_pretty_conditionimpasse     1586     2915\nmutrilike_pretty_conditionimpasse      446      896\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# report(mixcat.1)\n\n#TABLE\n# tab_model(m,\n          # show.r2 = FALSE) #, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n\n\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n```\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 43.86.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 6.64.\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95 ) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | State ~ condition\",\n       subtitle = \"(p for one two test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- estimate_density(m)\nplot(result, stack = FALSE, priors = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'b_muunknown_pretty_conditionimpasse', or one of its 'at' groups, is\n  empty and has no density information.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'b_mutrilike_pretty_conditionimpasse', or one of its 'at' groups, is\n  empty and has no density information.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- describe_posterior(m)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_pretty_conditionimpasse and b_mutrilike_Intercept (r = 0.71). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n```{.r .cell-code}\nplot(result, stack = FALSE, priors = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-3.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- p_direction(m)\nplot(result, stack = FALSE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#ROPE\nresult <- rope(m, ci = 0.89)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_pretty_conditionimpasse and b_mutrilike_Intercept (r = 0.71). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n```{.r .cell-code}\nplot(result) + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-5.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- equivalence_test(m)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_pretty_conditionimpasse and b_mutrilike_Intercept (r = 0.71). This might lead to inappropriate results. See 'Details' in '?equivalence_test'.\n```\n:::\n\n```{.r .cell-code}\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.0954\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 800 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#ERROR incompatible arguments to calculate multivariate normal distribution\n# result <- simulate_parameters(m)\n# plot(result)\n\n#check posterior\npp_check(m, ndraws=1000)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#PERFORMANCE\n# performance(m)\n\n#Plot parameters\nplot(model_parameters(m, exponentiate = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_pretty_conditionimpasse and b_mutrilike_Intercept (r = 0.71). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-8.png){width=672}\n:::\n\n```{.r .cell-code}\n#plot marginal predictions of model\nplot_model(m, type = \"pred\")[[1]] + \n  labs(\n    title = \"Model Predicted Marginal Probabilities\",\n    x = \"Condition\", \n    y = \"probability of being in each state\"\n  ) + theme_clean() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-36-9.png){width=672}\n:::\n:::\n\n\n##### COMPARE\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_models(m.unknown, m.tri, m.mbl1, mixcat.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_pretty_conditionimpasse and b_mutrilike_Intercept (r = 0.71). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                         |            m.unknown |                m.tri |               m.mbl1 |             mixcat.1\n-----------------------------------------------------------------------------------------------------------------------------\n(Intercept)                       | -3.44 (-4.49, -2.39) | -4.65 (-6.90, -2.41) |                      |                     \npretty condition (impasse)        |  2.92 ( 2.09,  3.76) |  5.72 ( 3.01,  8.42) |                      |                     \nunknown~(Intercept)               |                      |                      | -2.55 (-3.57, -1.53) |                     \ntri-like~(Intercept)              |                      |                      | -2.61 (-3.98, -1.25) |                     \nunknown~pretty conditionimpasse   |                      |                      |  2.46 ( 1.72,  3.21) |                     \ntri-like~pretty conditionimpasse  |                      |                      |  3.36 ( 1.94,  4.78) |                     \nmuunknown_Intercept               |                      |                      |                      | -3.18 (-4.23, -2.18)\nmutrilike_Intercept               |                      |                      |                      | -3.50 (-5.07, -2.13)\nmuunknown_pretty_conditionimpasse |                      |                      |                      |  2.62 ( 1.90,  3.36)\nmutrilike_pretty_conditionimpasse |                      |                      |                      |  4.10 ( 2.36,  6.06)\n-----------------------------------------------------------------------------------------------------------------------------\nObservations                      |                 1053 |                 1419 |                 1638 |                 1638\n```\n:::\n:::\n\nThe predictions of the manual, frequentist mixed multinomial and bayesian mixed multinomial models are comparable. \n\nDECISION: Report bayesian model, because for some reason the visualization of the marginal predictions is actually working?\n\n##### TODO\n\n-   priors? used default flat priors... ok?\n-   posterior predictive checks\n-   diagnostics on random effects\n-   reconcilliation of mblogit() vs brms versions of the model; seems like they should yield similar estimates\n\n\n## H1A \\| Q1 ACCURACY\n\n**Do Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?**\n\nThe graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                   |\n+=======================+========================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                    |\n|                       | -   outcome: *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                            |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                 |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |\n|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |\n|                       |                                                                                                                                                                                                                                        |\n|                       | Alternatives:                                                                                                                                                                                                                          |\n|                       |                                                                                                                                                                                                                                        |\n|                       | -   Chi-Square test of independence on outcome `accuracy` by `condition`                                                                                                                                                               |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \\~ continuous; though with regression we can quantify the size of the effect and overall model fit |\n|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |\n|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\n# #:::::::: GROUPED PROPORTIONAL BAR CHART\n# gf_props(~accuracy, fill = ~pretty_condition,\n#        position = position_dodge(), data = df) %>%\n#   gf_facet_grid(~pretty_mode) +\n#    labs(x = \"Correct Response on Q 1\",\n#        title = \"Accuracy on First Question by Condition\",\n#        subtitle=\"Impasse Condition yields a greater proportion of correct responses\") #theme(legend.position = \"none\")\n\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-Q1ACC-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of incorrect (vs) correct responses in each condition for each data collection modality (left/right facet) reveals that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition (marginal probability of incorrect). In the impasse condition, the difference in proportions is smaller than the control condition (conditional probability of success in impasse; (i.e) There are more correct responses in the impasse condition than the control condition).\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\n#::::::::::::DESCRIPTIVES\n\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n              111   121   Sum\n  incorrect 0.839 0.703 0.770\n  correct   0.161 0.297 0.230\n  Sum       1.000 1.000 1.000\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            111 121 Sum\n  incorrect  52  45  97\n  correct    10  19  29\n  Sum        62  64 126\n```\n:::\n:::\n\n\n#### LOGISTIC REGRESSION\n\nFit a logistic regression predicting accuracy (absolute score) (n = 126) by condition (k = 2).\\\n\n-   Parameter estimate: $\\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition\n-   $e^{\\beta_{0}}$ = ODDS of correct response in CONTROL condition\n-   Parameter estimate: $\\beta_{1}$ = $\\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])\n-   $e^{\\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\n-   **Null hypothesis**:$\\beta_{impasse} \\le 0$ the odds for a correct response does not change, or decreases\n-   **Alternative hypothesis:** $\\beta_{impasse} \\gt 0$ the odds of a correct response increases\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 3.31 | 0.069\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0687084837283363\"\n```\n:::\n:::\n\n\n*The Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .*\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.839  -0.839  -0.593  -0.593   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.345   -4.77  1.8e-06 ***\npretty_conditionimpasse    0.786      0.441    1.79    0.074 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 135.95  on 125  degrees of freedom\nResidual deviance: 132.63  on 124  degrees of freedom\nAIC: 136.6\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.31  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.074\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.037\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"adjusted confint for directional hypothesis\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"adjusted confint for directional hypothesis\"\n```\n:::\n\n```{.r .cell-code}\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                            5 %  95 %\n(Intercept)             -2.2578 -1.11\npretty_conditionimpasse  0.0749  1.53\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval â€”- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients â€”- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients â€”- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                5 %  95 %\n(Intercept)             0.192 0.105 0.329\npretty_conditionimpasse 2.196 1.078 4.631\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\npaste(\"Probability of success in control,\", pred.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.161290322580645\"\n```\n:::\n\n```{.r .cell-code}\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\npaste(\"Probability of success in impasse,\", pred.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.296875000000275\"\n```\n:::\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       title = \"LOGODDS | Q1 Accuracy ~ condition\",\n       subtitle = \"(p is for two tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-LAB-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Q1 Accuracy ~ condition\",\n       subtitle = \"(p for one sided test)\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-LAB-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.data = TRUE, jitter = TRUE,\n           title = \"MODEL PREDICTION | Q1 Accuracy ~ condition\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-LAB-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report)\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\n# report(m1)\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n136.632 | 142.305 |     0.026 | 0.415 | 1.034 |    0.526 |    -7.184 |           0.046 | 0.655\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-Q1ACC-LOG-LAB-1.png){width=672}\n:::\n:::\n\n\n##### Inference\n\n**We fit a logistic regression model to explore the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 1.79, p = 0.04, *one-tailed*). The model predicts that the odds of a correct response on the first question in the *impasse condition* increase by nearly 120% (**$e^{beta_{impasse}}$ **= 2.19, 95% CI \\[1.08, 4.63\\]) over the *control condition*. The intercept** $\\beta_{0}$ **parameter is also significant, (**$e^{b_{0}}$ **= 0.19, p \\< 0.001, 95% CI \\[0.11, 0.33\\]) indicating that the odds of a correct response in the control condition are significantly less than even (less than 50/50 chance of correct response in control condition).**\n\n*Equivalent statements:*\n\n-   being in impasse condition increases log odds of correct response by 0.79 (over control)\n-   being in impasse increases odds of correct response in impasse over control increases by factor of 2.19\n-   probability of correct response in impasse predicted as 30%, vs only 16% in control condition\n\n##### TODO\n\n-   Are these residuals OK? I didn't think normally distributed residuals were an assumption for logistic regression.\n-   interpretation/reporting of model fit?\n-   sanity check correct interpretation of coefficients & reporting\n-   SANITY CHECK:: meaning of b0 estimate\n    -   b0 parameter is odds of (+) response on reference \\[control\\]\n\n    -   *significant* b0 indicates that odds of a (+) are (significantly) different from 1:1 (i.e. not an equal probability of correct vs incorrect responses in control)\n\n### (ONLINE REPLICATION)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: ONLINE ONLY\ndf <- df_items %>% filter(mode == \"asynch\") %>% filter(q==1) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\n#::::::::::::DESCRIPTIVES\n\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n              111   121   Sum\n  incorrect 0.875 0.722 0.794\n  correct   0.125 0.278 0.206\n  Sum       1.000 1.000 1.000\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            111 121 Sum\n  incorrect  84  78 162\n  correct    12  30  42\n  Sum        96 108 204\n```\n:::\n:::\n\n\n#### LOGISTIC REGRESSION\n\n*Fit a logistic regression predicting accuracy (absolute score) (n = r nrow(df)) by condition. (k = 2).*\n\n-   *Parameter estimate:* $\\beta_{0}$ *= Log Odds of (correct) responses in CONTROL condition*\n-   $e^{\\beta_{0}}$ *= ODDS of correct response in CONTROL condition Parameter estimate:*\n-   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])*\n-   $e^{\\beta_{1}}$ *= ODDS RATIO of correct response in IMPASSE (vs) CONTROL*\n-   *Null hypothesis:* $\\beta_{impasse} \\le 0$ *the odds for a correct response does not change, or decreases*\n-   *Alternative hypothesis:* $\\beta_{impasse} \\gt 0$ *the odds of a correct response increases*\n\n##### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 7.49 | 0.006\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.00621908608981449\"\n```\n:::\n:::\n\n\n*The Condition predictor decreases AIC, and the Likelihood Ratio Test indicates the predictor model is a better fit.*\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.807  -0.807  -0.517  -0.517   2.039  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.946      0.309   -6.31  2.9e-10 ***\npretty_conditionimpasse    0.990      0.376    2.63   0.0084 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 207.45  on 203  degrees of freedom\nResidual deviance: 199.96  on 202  degrees of freedom\nAIC: 204\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)   \npretty_condition     7.49  1     0.0062 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.008\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.004\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"adjusted confint for directional hypothesis\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"adjusted confint for directional hypothesis\"\n```\n:::\n\n```{.r .cell-code}\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                           5 %  95 %\n(Intercept)             -2.489 -1.47\npretty_conditionimpasse  0.388  1.63\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval â€”- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients â€”- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients â€”- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                5 %  95 %\n(Intercept)             0.143 0.083 0.231\npretty_conditionimpasse 2.692 1.473 5.109\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\npaste(\"Probability of success in control,\", pred.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.125000000004466\"\n```\n:::\n\n```{.r .cell-code}\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\npaste(\"Probability of success in impasse,\", pred.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.277777777778245\"\n```\n:::\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       title = \"LOGODDS | Q1 Accuracy ~ condition\",\n       subtitle = \"(p is for two tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-ONLINE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Q1 Accuracy ~ condition\",\n       subtitle = \"(p for one sided test)\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-ONLINE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.data = TRUE, jitter = TRUE,\n           title = \"MODEL PREDICTION | Q1 Accuracy ~ condition\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC-LOG-ONLINE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell messsage='false'}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\n# report(m1)\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n203.962 | 210.598 |     0.036 | 0.397 | 0.995 |    0.490 |    -9.361 |           0.034 | 0.685\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-Q1ACC-LOG-ONLINE-1.png){width=672}\n:::\n:::\n\n\n##### Inference\n\n**We fit a logistic regression model to explore the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 2.63, p = 0.004, *one-tailed*). The model predicts that the odds of a correct response on the first question in the *impasse condition* increase by nearly 170% (**$e^{beta_{impasse}}$ = 2.69, 95% CI \\[1.47, 5,11\\]) over the *control condition*.**The intercept** $\\beta_{0}$ **parameter is also significant, (**$e^{b_{0}}$ **= 0.14, p \\< 0.001, 95% CI \\[0.08, 0.23\\]) indicating that the odds of a correct response in the control condition are significantly less than even (less than 50/50 chance of correct response in control condition).**\n\n*Equivalent statements:*\n\n-   being in impasse condition increases log odds of correct response by 0.99 (over control)\n-   being in impasse increases odds of correct response in impasse over control increases by factor of 2.69\n-   probability of correct response in impasse predicted as 28%, vs only 12% in control condition\n\n##### \n\n## H1A \\| Q1 INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n-   **\"orthogonal-like\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n-   **\"unknown\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints) =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n-   **\"triangle-like\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |\n+=======================+===========================================================================================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |\n|                       | -   outcome: `state` ( 3 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                                                                                                    |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |\n|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) \n\n# #:::::::: GROUPED PROPORTIONAL BAR CHART\n# gf_props(~high_interpretation, fill = ~pretty_condition,\n#        position = position_dodge(), data = df) %>%\n#   gf_facet_grid(~pretty_mode) +\n#    labs(x = \"Correct Response on Q 1\",\n#        title = \"Interpretation on First Question by Condition\",\n#        subtitle=\"\") #theme(legend.position = \"none\")\n\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Interpretation on First Question by Condition\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-Q1-INTERPRETATION-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. We see that around half of the 'incorrect' (i.e. not triangular) responses in the impasse condition are not orthogonal-like, but \"other/unknown\".\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q==1) \n\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.8065  0.3125 0.5556\n  unknown    0.0161  0.2812 0.1508\n  tri-like   0.1774  0.4062 0.2937\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse Sum\n  orth-like      50      20  70\n  unknown         1      18  19\n  tri-like       11      26  37\n  Sum            62      64 126\n```\n:::\n:::\n\n\n#### MULTINOMIAL REGRESSION\n\n*Does condition affect the response state of Q1?*\n\n*Fit a logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   2 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  6 (2 variable)\ninitial  value 138.425148 \nfinal  value 122.428550 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  9 (4 variable)\ninitial  value 138.425148 \niter  10 value 103.421004\niter  10 value 103.421004\nfinal  value 103.421004 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  2 |         |       |       \ncatm   | multinom |  4 |       2 | 38.02 | < .001\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# bm1 <- brm( state ~ pretty_condition, data = df, family = \"categorical\")\n# summary(bm1)\n# plot_model(bm1)\n# report(bm1)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nCoefficients:\n         (Intercept) pretty_conditionimpasse\nunknown        -3.91                    3.81\ntri-like       -1.51                    1.78\n\nStd. Errors:\n         (Intercept) pretty_conditionimpasse\nunknown        1.010                   1.061\ntri-like       0.333                   0.447\n\nResidual Deviance: 207 \nAIC: 215 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  6 (2 variable)\ninitial  value 138.425148 \nfinal  value 122.428550 \nconverged\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition       38  2    5.6e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(catm)$coefficients/summary(catm)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         p..Intercept. p.pretty_conditionimpasse\nunknown       1.07e-04                 0.0003330\ntri-like      5.45e-06                 0.0000692\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(catm)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         OR..Intercept. OR.pretty_conditionimpasse p..Intercept.\nunknown            0.02                      44.99    0.00010722\ntri-like           0.22                       5.91    0.00000545\n         p.pretty_conditionimpasse\nunknown                  0.0003330\ntri-like                 0.0000692\n```\n:::\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 45 (z = 3.58, p \\< 0.001) . **Participants in the impasse condition were 45x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 5.90 (z = 3.98, p \\< 0.001 ). **Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n-   \\[need to to double check interpretation, but I *think* that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the control condition. which makes sense. I think.?\\]\n\n-   IF I change reference category for condition... then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) \\[Yup! this works!\\]\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(catm, output = \"plot\", \n              # conf.level = 0.90,\n              exclude.intercept = FALSE) + \n  labs(x = \"Log Odds Estimate\", \n       title = \"LOGODDS | Q1 State ~ condition\",\n       subtitle = \"(p is for two tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(catm, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95 ) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Q1 State ~ condition\",\n       subtitle = \"(p for one two test)\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(catm, type=\"eff\",\n           title = \"MODEL PREDICTION | Q1 State ~ condition\",\n           axis.title = c(\"Condition\",\"Probability of Response State\")) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n#tab_model(catm)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\ntest <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\npred <- predict(catm, newdata = test, \"probs\")\npaste(\"Predicted Probability of Being in Each State\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Predicted Probability of Being in Each State\"\n```\n:::\n\n```{.r .cell-code}\n(cbind(test, pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pretty_condition orth-like unknown tri-like\n1          control     0.806  0.0161    0.177\n2          impasse     0.312  0.2812    0.406\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n214.842 | 226.187 | 0.155 |     0.147 | 0.404 | 1.302\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'DescTools':\n  method         from \n  reorder.factor gdata\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n     0.155      0.260      0.304 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\nchisq.test(df$state,predict(catm)) #actual states VS predicted states\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  df$state and predict(catm)\nX-squared = 34, df = 2, p-value = 4e-08\n```\n:::\n\n```{.r .cell-code}\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n#check_model(catm) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n\n##### TODO\n\n-   interpretation/reporting of model fit?\n-   sanity check correct interpretation of coefficients & reporting\n-   diagnostics on individual model equations\n-   calculate 1-tailed p values to match directional hypothesis\n\n### (ONLINE REPLICATION)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: ONLINE ONLY\ndf <- df_items %>% filter(mode == \"asynch\") %>% filter(q==1) \n\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.8229  0.2315 0.5098\n  unknown    0.0312  0.3889 0.2206\n  tri-like   0.1458  0.3796 0.2696\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse Sum\n  orth-like      79      25 104\n  unknown         3      42  45\n  tri-like       14      41  55\n  Sum            96     108 204\n```\n:::\n:::\n\n\n#### MULTINOMIAL REGRESSION\n\n*Does condition affect the response state of Q1?*\n\n*Fit a logistic regression predicting interpretation (k=3) by condition(k = 2).*\n\n-   2 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] does not change, or decreases*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  6 (2 variable)\ninitial  value 224.116907 \nfinal  value 210.176688 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  9 (4 variable)\ninitial  value 224.116907 \niter  10 value 168.708105\niter  10 value 168.708105\nfinal  value 168.708105 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  2 |         |       |       \ncatm   | multinom |  4 |       2 | 82.94 | < .001\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# m1 <- brm( state ~ condition, data = df, family = \"categorical\")\n# summary(m1)\n# plot_model(m1)\n# report(m1)\n```\n:::\n\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nCoefficients:\n         (Intercept) pretty_conditionimpasse\nunknown        -3.27                    3.79\ntri-like       -1.73                    2.22\n\nStd. Errors:\n         (Intercept) pretty_conditionimpasse\nunknown        0.588                   0.640\ntri-like       0.290                   0.385\n\nResidual Deviance: 337 \nAIC: 345 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  6 (2 variable)\ninitial  value 224.116907 \nfinal  value 210.176688 \nconverged\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     82.9  2     <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(catm)$coefficients/summary(catm)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         p..Intercept. p.pretty_conditionimpasse\nunknown       2.68e-08                  3.22e-09\ntri-like      2.41e-09                  7.73e-09\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(catm)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         OR..Intercept. OR.pretty_conditionimpasse p..Intercept.\nunknown           0.038                      44.22      2.68e-08\ntri-like          0.177                       9.25      2.41e-09\n         p.pretty_conditionimpasse\nunknown                   3.22e-09\ntri-like                  7.73e-09\n```\n:::\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 44 (z = 5.92, p \\< 0.001) . **Participants in the impasse condition were 44x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 9.25 (z = 5.77, p \\< 0.001 ). **Participants in the impasse condition were moret than 9x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(catm, output = \"plot\", \n              # conf.level = 0.90,\n              exclude.intercept = FALSE) + \n  labs(x = \"Log Odds Estimate\", \n       title = \"LOGODDS | Q1 State ~ condition\",\n       subtitle = \"(p is for two tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-ONLINE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(catm, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95 ) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Q1 State ~ condition\",\n       subtitle = \"(p for one two test)\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-ONLINE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(catm, type=\"eff\",\n           title = \"MODEL PREDICTION | Q1 State ~ condition\",\n           axis.title = c(\"Condition\",\"Probability of Response State\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-ONLINE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n#tab_model(catm)\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\ntest <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\npred <- predict(catm, newdata = test, \"probs\")\npaste(\"Predicted Probability of Being in Each State\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Predicted Probability of Being in Each State\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"[these should be consistent with effects plot, above\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"[these should be consistent with effects plot, above\"\n```\n:::\n\n```{.r .cell-code}\n(cbind(test, pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pretty_condition orth-like unknown tri-like\n1          control     0.823  0.0313    0.146\n2          impasse     0.232  0.3889    0.380\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n345.416 | 358.689 | 0.197 |     0.193 | 0.403 | 1.299\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n     0.197      0.334      0.383 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\nchisq.test(df$state,predict(catm)) #actual states VS predicted states\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  df$state and predict(catm)\nX-squared = 75, df = 2, p-value <2e-16\n```\n:::\n\n```{.r .cell-code}\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n#check_model(catm) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n\n\n## ARCHIVE\n\n### H1B \\| TEST PHASE ACCURACY\n\nDECISION: There is no need to differentiate between test phase and scaffold phase; can just consider all items, BECAUSE even during the scaffold phase, incorrect responses are available in the control condition. The satisfice stragey yields a 0 absolute score, just like an orthogonal. Including all items (i=13) rather than just test phase(i=8) gives a little more statistical power in the mixed effects models. \n\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Do Ss in the IMPASSE condition score higher across the test phase than those in the CONTROL group?                                                                                                                                                                                 |\n+=======================+====================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | (H1B) Participants in the IMPASSE condition will have higher test phase performance than those in the CONTROL condition.                                                                                                                                                           |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | **data**: `df_items` where `q nin 1,2,3,4,5,6,9` (the 8 discriminating test phase Qs ), `df_subjects`                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **outcome**:                                                                                                                                                                                                                                                                       |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   \\[at item level\\] : *accuracy* ( factor(incorrect/correct) from `score_niceABS` \\[absolute score\\]                                                                                                                                                                             |\n|                       | -   \\[subject level\\]: accuracy (number of test phase qs correct from total `s_NABS`)                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | **predictor**: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                             |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Wilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (`item_test_NABS`)                                                                                                                                                                         |\n|                       | 2.  Mixed Logistic Regression\\                                                                                                                                                                                                                                                     |\n|                       |     `accuracy` \\~ `condition` + (1 \\| `subject` )\\                                                                                                                                                                                                                                 |\n|                       |     model effect of condition on probability of correct response \\[during test phase\\] while accounting for subject (and item-level?) effects                                                                                                                                      |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Alternatives**      | -   Ordinal Mixed Logistic Regression\\                                                                                                                                                                                                                                             |\n|                       |     `interpretation` \\~ `condition` + (1 \\| `subject` )\\                                                                                                                                                                                                                           |\n|                       |     model effect of condition on \\[ordered correctness of interpretation\\] \\[during test phase\\] while accounting for subject (and item-level?) effects                                                                                                                            |\n|                       | -   Shift in Modal Mass (descriptive)\\                                                                                                                                                                                                                                             |\n|                       |     describe & visualize shift in deciles between conditions for `scaled_score` (at subject level)                                                                                                                                                                                 |\n|                       | -   OLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Notes**             | **Also exploring:**                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                    |\n|                       | -   Hurdle model (mixture model w/ binomial + \\[poisson or negbinom count; 0s from 1 DGP)                                                                                                                                                                                          |\n|                       | -   Zero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)                                                                                                                                                                                    |\n|                       | -   Beta regression hurdle model? (mixture with location and scale parameters \\[mean, variance\\] and hurdles for floor and ceiling effects)                                                                                                                                        |\n|                       | -   Other way to account for the severe bimodality?                                                                                                                                                                                                                                |\n+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#item level\ndf = df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n  q = as.factor(q)\n)\n\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(title = \"Test Phase Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS))\ngf_props(~item_test_NABS, \n         fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_grid(pretty_condition ~ pretty_mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"# Correct in Test Phase\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Absolute Score (# Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS/8))\ngf_props(~item_test_NABS/8, \n         fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_grid(pretty_condition ~ pretty_mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct in Test Phase\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-ACC-3.png){width=672}\n:::\n:::\n\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf_i <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\")\n) \n\ndf_s <- df_subjects %>% filter(mode == \"lab-synch\") %>% mutate(\n  test_score = item_test_NABS,\n  test_percent = item_test_NABS/8\n)\n```\n:::\n\n\n#### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Test Phase % Correct)\"\ntbl1 <- mosaic::favstats(~test_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Test Phase % Correct)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.316 </td>\n   <td style=\"text-align:right;\"> 0.415 </td>\n   <td style=\"text-align:right;\"> 126 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Test Phase % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(test_percent ~ condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Test Phase % Correct) BY CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 111 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n   <td style=\"text-align:right;\"> 0.125 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.214 </td>\n   <td style=\"text-align:right;\"> 0.381 </td>\n   <td style=\"text-align:right;\"> 62 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 121 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.25 </td>\n   <td style=\"text-align:right;\"> 0.875 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.416 </td>\n   <td style=\"text-align:right;\"> 0.426 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAcross both conditions, overall accuracy on the test phase ranges from 0 to 100 with a mean of 31.647. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.\n\nA score of 100% indicates that the participant correctly interpreted the interval-coordinate system throughout the task, *starting at the first question*. A score of 0% indicates the individual *never* correctly interpreted the coordinate system. A score somewhere inbetween indicates that an individual deciphered the coordinate system *sometime over the course the task*.\n\n#### WILCOXON RANK SUM (Mann-Whitney Test) --- SCORE\n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n##### Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$test_score ~ df_s$condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$test_score by df_s$condition\nW = 1438, p-value = 0.002\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in\nranks between df_s$test_score and df_s$condition suggests that the effect is\nnegative, statistically significant, and medium (W = 1438.00, p = 0.002; r\n(rank biserial) = -0.28, 95% CI [-1.00, -0.11])\n```\n:::\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#[manual one-sided test]\n(results <- statsExpressions::two_sample_test(y = test_score, x = condition, data = df_s,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 14\n  parameter1 parameter2 statistic p.value method alternative effectsize estimate\n  <chr>      <chr>          <dbl>   <dbl> <chr>  <chr>       <chr>         <dbl>\n1 test_score condition       1438 0.00161 Wilcoâ€¦ less        r (rank bâ€¦   -0.275\n# â€¦ with 6 more variables: conf.level <dbl>, conf.low <dbl>, conf.high <dbl>,\n#   conf.method <chr>, n.obs <int>, expression <list>\n```\n:::\n\n```{.r .cell-code}\n#:::::::: STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df_s,\n               results.subtitle = FALSE, #override default [two tailed] test dsiplay\n               subtitle = results$expression[[1]]\n              )\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-64-1.png){width=672}\n:::\n:::\n\n\n##### Inference\n\nA Mann-Whitney (Wilcoxon Rank Sum) test evaluating the difference in median accuracy score in the test phase of the graph comprehension task indicates that performance was better in the impasse (vs) control condition. \\[report stats\\]\n\n#### WILCOXON RANK SUM (Mann-Whitney Test) --- PERCENTAGE\n\n-   same as above, but on percentage rather than \\# correct\n\n##### Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df_s$test_percent ~ df_s$condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_s$test_percent by df_s$condition\nW = 1438, p-value = 0.002\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in\nranks between df_s$test_percent and df_s$condition suggests that the effect is\nnegative, statistically significant, and medium (W = 1438.00, p = 0.002; r\n(rank biserial) = -0.28, 95% CI [-1.00, -0.11])\n```\n:::\n\n```{.r .cell-code}\n# df_s %>% wilcox_effsize(test_percent ~ condition)\n```\n:::\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#[manual one-sided test]\n(results <- statsExpressions::two_sample_test(y = test_percent, x = condition, data = df_s,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã— 14\n  parameter1 parameter2 statistic p.value method alternative effectsize estimate\n  <chr>      <chr>          <dbl>   <dbl> <chr>  <chr>       <chr>         <dbl>\n1 test_percâ€¦ condition       1438 0.00161 Wilcoâ€¦ less        r (rank bâ€¦   -0.275\n# â€¦ with 6 more variables: conf.level <dbl>, conf.low <dbl>, conf.high <dbl>,\n#   conf.method <chr>, n.obs <int>, expression <list>\n```\n:::\n\n```{.r .cell-code}\n#:::::::: STATSPLOT | VIOLIN\nggbetweenstats(y = test_percent, x = condition, data = df_s,\n               results.subtitle = FALSE, #override default [two tailed] test dsiplay\n               subtitle = results$expression[[1]]\n              )\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-66-1.png){width=672}\n:::\n:::\n\n\n##### Inference\n\n**Reported in dissertation**\n\nBecause the distribution of the outcome variable is not normally distributed, we evaluate the effect of CONDITION on ACCURACY via a non-parametric test. Consistent with our hypothesis, a Wilcoxon rank sum test (with continuity correction) on ACCURACY by CONDITION indicates that data in each condition likely come from different population distributions (W = 1438.00, p = 0.002; one-tailed), and that the distribution of the control condition is less (i.e. shifted to the left/ lower scores) than the impasse condition (\\^{r} = -0.28, 95% CI \\[-1.00, -0.11\\]), a medium-sized effect.\n\n#### MIXED LOGISTIC REGRESSION\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  2 |       1 | 678.41 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  1.48371797931313e-149\"\n```\n:::\n:::\n\n\n*A likelihood ratio test indicates that a logistic regression model including SUBJECT as a random effect explains more variance in the data than an empty \\[intercept only\\] model.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrS <- glmer(accuracy ~ pretty_condition + (1|subject) ,\n                data = df_i, family = \"binomial\")\nsummary(mm.CrS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     582      597     -288      576     1005 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5079 -0.0674 -0.0217  0.1326  2.8082 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 54.1     7.36    \nNumber of obs: 1008, groups:  subject, 126\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -7.46       1.20   -6.21  5.2e-10 ***\npretty_conditionimpasse     4.03       1.67    2.42    0.016 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn 0.156 \n```\n:::\n\n```{.r .cell-code}\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rS)) > AIC(logLik(mm.CrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.CrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |     p\n-----------------------------------------------\nmm.rS  | glmerMod |  2 |         |      |      \nmm.CrS | glmerMod |  3 |       1 | 3.91 | 0.048\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.CrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.047907883063779\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# print(\"FIXED Condition + Subject & Item random intercepts\")\n# mm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n#                 data = df_i, family = \"binomial\")\n# summary(mm.CrSQ)\n```\n:::\n\n\n##### Describe\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm1 <- mm.CrS\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     582      597     -288      576     1005 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5079 -0.0674 -0.0217  0.1326  2.8082 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 54.1     7.36    \nNumber of obs: 1008, groups:  subject, 126\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -7.46       1.20   -6.21  5.2e-10 ***\npretty_conditionimpasse     4.03       1.67    2.42    0.016 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn 0.156 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)  \npretty_condition  5.83  1      0.016 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.01573\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.00787\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\nse <- sqrt(diag(stats::vcov(m1)))\n# table of estimates with 95% CI\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n    se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          Est     LL    UL\n(Intercept)             -7.46 -9.813 -5.11\npretty_conditionimpasse  4.03  0.759  7.30\n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- exp(tab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                              Est        LL         UL\n(Intercept)              0.000576 0.0000548    0.00606\npretty_conditionimpasse 56.086699 2.1356333 1472.96720\n```\n:::\n:::\n\n\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-71-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-71-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-71-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n\n\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list('N(subject) = 126 $\\tau_{00}$(subject) = 22.22',\n#              'N(question) = 13 $\\tau_{00}$(question) = 0.31',\n#                \"*** indicates p < 0.001\")\n# # \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"))\n\n#              # coef_omit = \"Intercept\",\n#              gof_omit = 'AIC|RMSE|ICC|BIC',\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n```\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\n# report(m1)\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |    AICc |     BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n----------------------------------------------------------------------------------------------------------------------\n582.024 | 582.048 | 596.771 |      0.946 |      0.066 | 0.943 | 0.213 | 1.000 |    0.145 |      -Inf |           0.021\n```\n:::\n\n```{.r .cell-code}\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-73-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Probably bad model fit. Only about 64% of the residuals are inside the error bounds.\n```\n:::\n:::\n\n\n##### TODO\n\n-   sanity check interpretation\n-   sanity check random effects structure :\n    -   do I need to have ITEM as random intercept? What does it mean to have two random intercepts?\n-   DIAGNOSTICS: What in the world is happening with the normality of random effects plot? Do the fixed effects residuals need to be normally distributed?\n-   Are there other plots or recommended diagnostics for mixed log regression\n-   consider multiple regression with rt, sequence cluster, confidence, etc.\n-   What else needs to be interpreted with respect to the item and subject random effects?\n-   Double check: can't have condition by subject or item slope bc subjects are nested in conditions, not crossed\n\n### TODO (ONLINE REPLICATION)\n\n\\*\\*TODO after verify correctness of approach for the lab-based sample (above)\n\n### SHIFT IN MODAL MASS\n\nThe Effect of Condition on Total Scaled Score can be described as a 'shift' in mass between the low and high modes of each distribution.\n\n*First, we use the Kolmogorov-Smirnov test as a Robust alternative to the t-test to test if the two distributions likely come from different populations.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#(requires shift function files loaded)\n#LOAD MODAL SHIFT FUNCTION RESOURCES\nsource(\"analysis/utils/shift_function/Rallfun-v30.txt\")\nsource(\"analysis/utils/shift_function/wilcox_modified.txt\")\nsource(\"analysis/utils/shift_function/rgar_visualisation.txt\")\nsource(\"analysis/utils/shift_function/rgar_utils.txt\")\n#NOTE: something in these breaks the stat_ecdf in ggplot2\n\n#PREP DATA \ndf <- df_subjects %>%\n  dplyr::select(s_SCALED, pretty_condition) %>%\n  mutate(\n    data = as.numeric(s_SCALED),\n    #flip order levels to correctly orient graph\n    # gr = recode_factor(pretty_condition, \"impasse\" = \"impasse\", \"control\"=\"control\")\n    gr = as.character(pretty_condition)\n  ) %>% dplyr::select(data,gr)\n\n\ng1 <- df %>% filter(gr == \"control\") %>% dplyr::pull(data)\ng2 <- df %>% filter(gr == \"impasse\") %>% dplyr::pull(data)\n\n\n#COMPARE DISTRIBUTIONS WITH ROBUST TESTS\n\n#What do common tests say about the difference?\n\n# Kolmogorov-Smirnov test\n#If y is numeric, a two-sample (Smirnov) test of the null hypothesis that x and y \n#were drawn from the same continuous distribution is performed. Alternatively, y ...\n\n#null is X is drawn from CDF EQUAL TO Y\nks.test(g1,g2) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2): p-value will be approximate in the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD = 0.5, p-value <2e-16\nalternative hypothesis: two-sided\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that impasse and control come from different population distributions\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that impasse and control come from different population distributions\"\n```\n:::\n\n```{.r .cell-code}\n# #null is X is NOT LESS THAN Y\nks.test(g1,g2, alternative = \"greater\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2, alternative = \"greater\"): p-value will be approximate\nin the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD^+ = 0.5, p-value <2e-16\nalternative hypothesis: the CDF of x lies above that of y\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\"\n```\n:::\n\n```{.r .cell-code}\n#REGULAR T-TEST\nt.test(g1,g2) # regular Welsh t-test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  g1 and g2\nt = -7, df = 325, p-value = 7e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -8.93 -5.06\nsample estimates:\nmean of x mean of y \n   -6.427     0.567 \n```\n:::\n:::\n\n::: {.cell warnings='false' messages='false'}\n\n```{.r .cell-code}\n#IF THIS ERRORS, consider loadling plyr (older than dplyr)\n# kernel density estimate + rug plot + superimposed deciles\nkde <- plot.kde_rug_dec2(df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: plyr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    compact\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:rstatix':\n\n    desc, mutate\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcdExtra':\n\n    summarise\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggpubr':\n\n    mutate\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:Hmisc':\n\n    is.discrete, summarize\n```\n:::\n\n```{.r .cell-code}\n# kde\n\n# compute shift function\nout <- shifthd( g1, g2, nboot=200)\n\n# plot shift function\nsf <- plot.sf(data=out) # function from rgar_visualisation.txt\n# sf\n\n# combine KDE + SF\ncowplot::plot_grid(kde, sf, labels=c(\"A\", \"B\"), ncol = 1, nrow = 2, rel_heights = c(1.5, 1),label_size = 18,hjust = -1,scale=.95)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'BarlowSemiCondensed-Bold' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SHIFT-FN-NABS-comb-1.png){width=672}\n:::\n:::\n\n\n## H1B \\| TEST PHASE INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n-   **\"orthogonal-like\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n-   **\"unknown\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints) =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n-   **\"triangle-like\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions in the test phase?                                          |\n+=======================+=================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across test phase items |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q nin 1,2,3,4,5,6,9` (8 discriminant test phase items)                                                              |\n|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                          |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |\n|                       |                                                                                                                                                 |\n|                       | Alternative:                                                                                                                                    |\n|                       |                                                                                                                                                 |\n|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |\n|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |\n+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PREP DATA\ndf = df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  q = as.factor(q),\n  subject = as.factor(subject)\n)\n\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(title = \"Test Phase Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SETUP-TEST-INTERPRETATION-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. In the impasse condition, there are also more positive transition (i.e. triangle-like) and neutral (ie. blank or uncertain response types) than in the control condition.\n\n### (LAB)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: IN PERSON ONLY\ndf <- df_items %>% filter(mode == \"lab-synch\") %>% filter(q %nin% c(1,2,3,4,5,6,9)) \n\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.7077  0.4297 0.5665\n  unknown    0.0605  0.1191 0.0903\n  tri-like   0.2319  0.4512 0.3433\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse  Sum\n  orth-like     351     220  571\n  unknown        30      61   91\n  tri-like      115     231  346\n  Sum           496     512 1008\n```\n:::\n:::\n\n\n#### MIXED MULTINOMIAL REGRESSION\n\n**TODO** - add a 1 to the empty cell and re-run mblogit to show that estimates are more similar to the brms results - run individual mixed models to show results are similar to mblogit vs brms\n\n*Does condition affect the response state of of items in the test phase?*\n\n*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   Can use mclogit mblogit() with random effect *or* bayesian brms package b/c nlme, lme4 don't support random effects on multinomial (ie no categorical family on glmer())\n\n-   Alternative would be to manually run 2 X binomial mixed models \\[should compare outcomes\\]\n\n-   2 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit Model \\[MANUAL INDIVIDUAL BINOMIALS\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#VERIFY RESULTS BELOW VIA MULTIPLE INDIVIDUAL MODELS\n\npaste(\"ORTH vs. UNKNOWN\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. UNKNOWN\"\n```\n:::\n\n```{.r .cell-code}\nd1 <- df %>% filter(state %nin% c(\"tri-like\")) %>% droplevels()\ntable(d1$condition, d1$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     \n      orth-like unknown\n  111       351      30\n  121       220      61\n```\n:::\n\n```{.r .cell-code}\nplot(d1$condition, d1$state)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-78-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.unknown <- glmer(state ~ pretty_condition + ( 1 | subject), family = \"binomial\", data = d1)\nsummary(m.unknown)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject)\n   Data: d1\n\n     AIC      BIC   logLik deviance df.resid \n     457      471     -226      451      659 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.619 -0.307 -0.134 -0.133  3.259 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 3.73     1.93    \nNumber of obs: 662, groups:  subject, 104\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -3.523      0.467   -7.55  4.4e-14 ***\npretty_conditionimpasse    2.041      0.559    3.65  0.00026 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.776\n```\n:::\n:::\n\n\n*Being in the IMPASSE condition increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 7.7 ( logodds = 2.041, z = 0.559, p \\< 0.001) . Participants in the impasse condition were 7.7x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.59, marginal R2 = 0.13; SD(subject) = 1.93)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaste(\"ORTH vs. TRIANGULAR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. TRIANGULAR\"\n```\n:::\n\n```{.r .cell-code}\nd2 <- df %>% filter(state %nin% c(\"unknown\")) %>% droplevels()\ntable(d2$condition, d2$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     \n      orth-like tri-like\n  111       351      115\n  121       220      231\n```\n:::\n\n```{.r .cell-code}\nplot(d2$condition, d2$state)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-79-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.tri <- glmer(state ~ pretty_condition + ( 1 | subject), family = \"binomial\", data = d2)\nsummary(m.tri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject)\n   Data: d2\n\n     AIC      BIC   logLik deviance df.resid \n     486      501     -240      480      914 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6054 -0.0937 -0.0223  0.0982  2.7691 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 68.7     8.29    \nNumber of obs: 917, groups:  subject, 126\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -7.33       1.06   -6.95  3.7e-12 ***\npretty_conditionimpasse     7.38       1.86    3.96  7.6e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.567\n```\n:::\n:::\n\n\n*Being in the IMPASSE condition increases* the odds of giving an triangle-like response by a factor of 1604 ( logodds = 7.38, z = 1.86, p \\< 0.001) . Participants in the impasse condition were 1604x as likely to give an triangle-like response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.96, marginal R2 = 0.0.16; SD(subject) = 8.29)\n\n##### Fit Model \\[mblogit\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://www.elff.eu/software/mclogit/manual/mblogit/\n#\"baseline category logit\" model matches multinom()\n\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nm.mbl0 <- mblogit(state ~ pretty_condition ,  #no random intercepts; fixed only model \n                  data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 1754 - criterion = 0.413\nIteration 2 - deviance = 1746 - criterion = 0.00446\nIteration 3 - deviance = 1746 - criterion = 0.0000478\nIteration 4 - deviance = 1746 - criterion = 8.67e-09\nconverged\n```\n:::\n\n```{.r .cell-code}\n#summary(m.mbl0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nm.mbl1 <- mblogit(state ~ pretty_condition , \n                  random = ~ 1 | subject , \n                  data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 1159 - criterion = 0.757\nIteration 2 - deviance = 985 - criterion = 0.0458\nIteration 3 - deviance = 911 - criterion = 0.00786\nIteration 4 - deviance = 913 - criterion = 0.00183\nIteration 5 - deviance = 853 - criterion = 0.0256\nIteration 6 - deviance = 852 - criterion = 0.0172\nIteration 7 - deviance = 908 - criterion = 0.00226\nIteration 8 - deviance = 890 - criterion = 0.0308\nIteration 9 - deviance = 899 - criterion = 0.0106\nIteration 10 - deviance = 917 - criterion = 0.00119\nIteration 11 - deviance = 893 - criterion = 0.00737\nIteration 12 - deviance = 876 - criterion = 0.0188\nIteration 13 - deviance = 877 - criterion = 0.00489\nIteration 14 - deviance = 908 - criterion = 0.000375\nIteration 15 - deviance = 917 - criterion = 0.000056\nIteration 16 - deviance = 920 - criterion = 0.0000127\nIteration 17 - deviance = 921 - criterion = 0.00000303\nIteration 18 - deviance = 921 - criterion = 6.77e-07\nIteration 19 - deviance = 922 - criterion = 1.44e-07\nIteration 20 - deviance = 922 - criterion = 3e-08\nIteration 21 - deviance = 922 - criterion = 6.28e-09\nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(m.mbl1)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(m.mbl0) > AIC(m.mbl1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.mbl0, m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |    Chi2 |      p\n---------------------------------------------------\nm.mbl0 |  mblogit |  4 |         |         |       \nm.mbl1 | mmblogit |  7 |       3 | 1579.53 | < .001\n```\n:::\n\n```{.r .cell-code}\n#DESCRIBE MODEL\nsummary(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in sqrt(diag(vcov.phi)): NaNs produced\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df, random = ~1 | \n    subject)\n\nEquation for unknown vs orth-like:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.436      0.294   -8.29  < 2e-16 ***\npretty_conditionimpasse    1.547      0.395    3.92 0.000089 ***\n\nEquation for tri-like vs orth-like:\n                        Estimate Std. Error z value  Pr(>|z|)    \n(Intercept)               -2.170      0.481   -4.51 0.0000065 ***\npretty_conditionimpasse    2.153      0.653    3.30   0.00098 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Co-)Variances:\nGrouping level: subject \n           Estimate      Std.Err. \nunknown~1   2.26          NaN     \ntri-like~1  3.36 10.05   1.57 4.61\n\nNull Deviance:     2210 \nResidual Deviance: 922 \nNumber of Fisher Scoring iterations:  21\nNumber of observations\n  Groups by subject: 126\n  Individual observations:  1008\n```\n:::\n\n```{.r .cell-code}\n# car::Anova(m.mbl1)\n\n#INTERPRET COEFFICIENTS\ncint <- confint(m.mbl1, level = 0.95)\nprint(\"ODDS RATIO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIO\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m.mbl1)), exp(cint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                         2.5 % 97.5 %\nunknown~(Intercept)              0.0875 0.0491  0.156\ntri-like~(Intercept)             0.1142 0.0445  0.294\nunknown~pretty_conditionimpasse  4.6963 2.1659 10.183\ntri-like~pretty_conditionimpasse 8.6136 2.3928 31.007\n```\n:::\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |  RMSE | Sigma\n-----------------------------------\n7974.169 | 8008.579 | 0.245 | 0.958\n```\n:::\n\n```{.r .cell-code}\n#TABLE\ntab_model(m.mbl1, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Model Predicted Odds Ratio</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.05&nbsp;&ndash;&nbsp;0.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04&nbsp;&ndash;&nbsp;0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.17&nbsp;&ndash;&nbsp;10.18</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.61</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.39&nbsp;&ndash;&nbsp;31.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1008</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 4.7 (z = 3.92, p \\< 0.001) . **Participants in the impasse condition were 4.7x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 8.61 (z = 3.30, p \\< 0.001 ). **Participants in the impasse condition were more than 8.6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n-   TODO: these estimates seem low to me, given the estimates for the Q1 only model. Also different from brms estimates (below) Suspect NaNs error thrown with mblogit() may be relevant\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m.mbl1, vline.color = \"red\", \n           transform = \"exp\", #for some reason have to manually add for mixed?\n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Test Phase State ~ condition\",\n       subtitle = \"(p for  two-tailed test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-INTERPRETATION-LAB-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m.mbl1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.44</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.01&nbsp;&ndash;&nbsp;-1.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.17</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.11&nbsp;&ndash;&nbsp;-1.23</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.55</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.77&nbsp;&ndash;&nbsp;2.32</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty<br>conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.15</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.87&nbsp;&ndash;&nbsp;3.43</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1008</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |  RMSE | Sigma\n-----------------------------------\n7974.169 | 8008.579 | 0.245 | 0.958\n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m.mbl1) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n\n##### Fit Model \\[brms\\]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#library(brms) #bayesian mixed regression models\n\n#BAYESIAN MIXED VERSION\nmixcat.1 <- brm( state ~ condition + (1|subject), data = df, family = \"categorical\",\n                                          file = \"analysis/models/sgc3a_brms_mixedcat_teststate_LAB.rds\") # cache model (can be removed)))\n\n#DESCRIBE MODEL\nsummary(mixcat.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muunknown = logit; mutrilike = logit \nFormula: state ~ condition + (1 | subject) \n   Data: df (Number of observations: 1008) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 126) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muunknown_Intercept)     1.89      0.32     1.32     2.61 1.00     1272\nsd(mutrilike_Intercept)     5.66      0.80     4.30     7.43 1.00     1292\n                        Tail_ESS\nsd(muunknown_Intercept)     2509\nsd(mutrilike_Intercept)     1952\n\nPopulation-Level Effects: \n                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nmuunknown_Intercept       -3.45      0.43    -4.35    -2.68 1.00     2508\nmutrilike_Intercept       -4.17      0.95    -6.22    -2.48 1.00      996\nmuunknown_condition121     1.91      0.53     0.90     2.97 1.00     2180\nmutrilike_condition121     3.82      1.19     1.58     6.26 1.01      827\n                       Tail_ESS\nmuunknown_Intercept        2751\nmutrilike_Intercept        1434\nmuunknown_condition121     2675\nmutrilike_condition121     1475\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# report(mixcat.1)\n\n#VISUALIZE\n\nplot(mixcat.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-83-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-83-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(mixcat.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-83-3.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_posterior_predictions(mixcat.1, draws=1000)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-83-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(bayesplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'bayesplot' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is bayesplot version 1.9.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- Online documentation and vignettes at mc-stan.org/bayesplot\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- bayesplot theme set to bayesplot::theme_default()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * Does _not_ affect other ggplot2 plots\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * See ?bayesplot_theme_set for details on theme setting\n```\n:::\n\n```{.r .cell-code}\nlibrary(bayestestR)\nplot(rope(mixcat.1, ci = 0.89))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_condition121 and b_mutrilike_Intercept (r = 0.75). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-83-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(mixcat.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'bayes_R2' is not defined for unordered categorical models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nELPD     | ELPD_SE |   LOOIC | LOOIC_SE |    WAIC | Sigma\n---------------------------------------------------------\n-449.046 |  27.678 | 898.092 |   55.355 | 877.628 | 1.000\n```\n:::\n\n```{.r .cell-code}\n#TABLE\ntab_model(mixcat.1,\n          show.r2 = FALSE) #, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: unknown</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state: trilike</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI (95%)</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI (95%)</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Intercept</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.01&nbsp;&ndash;&nbsp;0.07</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ID indicates randomly<br>assigned<br>condition(111->control,121->impasse):<br>condition 121</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">43.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.87&nbsp;&ndash;&nbsp;521.75</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">6.64</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.47&nbsp;&ndash;&nbsp;19.42</td>\n</tr>\n<tr>\n<td colspan=\"5\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.21</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.65</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.25</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">126</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">1008</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n```\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 43.86.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 6.64.\n\n-   TODO RECONCILE:: brms model provides *substantially* higher estimate for blank/uncertain response (vs) the mblogit frequentist model. I think these should be similar, as they were for the non-mixed veresions. Suspect NaNs error thrown with mblogit() may be relevant\n\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(mixcat.1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95 ) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | Test Phase State ~ condition\",\n       subtitle = \"(p for one two test)\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-84-1.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- estimate_density(mixcat.1)\nplot(result, stack = FALSE, priors = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'b_muunknown_condition121', or one of its 'at' groups, is empty and has\n  no density information.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'b_mutrilike_condition121', or one of its 'at' groups, is empty and has\n  no density information.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-84-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- describe_posterior(mixcat.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_mutrilike_condition121 and b_mutrilike_Intercept (r = 0.75). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n```{.r .cell-code}\nplot(result, stack = FALSE, priors = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-84-3.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- p_direction(mixcat.1)\nplot(result, stack = FALSE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-84-4.png){width=672}\n:::\n\n```{.r .cell-code}\nprior_summary(mixcat.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class         coef   group resp      dpar nlpar lb ub\n               (flat)         b                           mutrilike            \n               (flat)         b condition121              mutrilike            \n               (flat)         b                           muunknown            \n               (flat)         b condition121              muunknown            \n student_t(3, 0, 2.5) Intercept                           mutrilike            \n student_t(3, 0, 2.5) Intercept                           muunknown            \n student_t(3, 0, 2.5)        sd                           mutrilike        0   \n student_t(3, 0, 2.5)        sd                           muunknown        0   \n student_t(3, 0, 2.5)        sd              subject      mutrilike            \n student_t(3, 0, 2.5)        sd    Intercept subject      mutrilike            \n student_t(3, 0, 2.5)        sd              subject      muunknown            \n student_t(3, 0, 2.5)        sd    Intercept subject      muunknown            \n       source\n      default\n (vectorized)\n      default\n (vectorized)\n      default\n      default\n      default\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n (vectorized)\n```\n:::\n\n```{.r .cell-code}\nhypothesis(mixcat.1, \"muunknown_condition121 > 0 \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n1 (muunknown_condit... > 0     1.91      0.53     1.06     2.79       3999\n  Post.Prob Star\n1         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n:::\n\n\n##### Diagnostics\n\n##### TODO\n\n-   priors? used default flat priors... ok?\n-   posterior predictive checks\n-   diagnostics on random effects\n-   reconcilliation of mblogit() vs brms versions of the model; seems like they should yield similar estimates\n",
    "supporting": [
      "4_sgc3A_hypotesting_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}