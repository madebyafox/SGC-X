{
  "hash": "a89a34b6282b8148649d5e4287b2b07c",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 4 Hypothesis Testing'\n---\n\n\n\\newpage\n\n# Hypothesis Testing {#sec-SGC3A-hypotesting}\n\n**TODO**\n\n-   HURDLE MODEL? (mixture model w/ 0 + count)\n-   consider zero-inflated (poisson or neg binom) with \\_rt as predictor of count process and condition as predictor of excess zeros\n-   review models already created in ARCHIVE?\n-   explore response consistency\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study.*\n\n+---------------------+\n| Pre-Requisite       |\n+=====================+\n| 2_sgc3A_scoring.qmd |\n+---------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc) # %nin% operator\n\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \n\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(equatiomatic) #extract model equation\nlibrary(pscl) #zeroinfl / hurdle models \n\nlibrary(ggdist)\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#SET GGPLOT THEME\ntheme_set(theme_minimal())\n```\n:::\n\n\n**Research Questions**\n\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the graph comprehension task?\n\n**Experimental Hypothesis**\\\n*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the IMPASSE condition will score higher on the TEST Phase than learners in CONTROL.\n-   H1B \\| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.\n-   H1C \\| Learners in the IMPASSE condition will spend more time on the first question than learners in CONTROL.\n\n**Null Hypothesis**\\\n*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nmbp = \"/Users/amyfox/Sites/RESEARCH/SGCâ€”Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(mbp)\n\n#LOAD SHIFT FUNCTION RESOURCES\nsource(\"analysis/utils/shift_function/Rallfun-v30.txt\")\nsource(\"analysis/utils/shift_function/wilcox_modified.txt\")\nsource(\"analysis/utils/shift_function/rgar_visualisation.txt\")\nsource(\"analysis/utils/shift_function/rgar_utils.txt\")\n\n#IMPORT DATA \ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\n\n#TRANSFORMATIONS \n#1. test phase absolute score as percentage\ndf_subjects <- df_subjects %>% mutate(\n  DV_percent_test_NABS = (item_test_NABS/8) * 100 #for 8 Qs in test phase\n)\n\n#SEPARATE ITEM DATA BY QUESTION TYPE\ndf_scaffold <- df_items %>% filter(q < 6)\ndf_test <- df_items %>% filter(q > 6) %>% filter (q %nin% c(6,9))\ndf_nondiscrim <- df_items %>% filter (q %in% c(6,9))\n\ndf_lab <- df_subjects %>% filter(pretty_mode == \"laboratory\")\ndf_online <- df_subjects %>% filter(pretty_mode == \"online-replication\")\n```\n:::\n\n\n## H1A \\| TEST PHASE ACCURACY\n\nOn the TEST Phase of the graph comprehension task (the final 8 questions, encountered after the 5 scaffolded questions) does the impasse condition affect performance on the graph comprehension task?\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does posing a mental impasse improve performance?                                                                                      |\n+=======================+========================================================================================================================================+\n| **Hypothesis**        | (H1A) Participants in the IMPASSE condition will have significantly higher TEST PHASE performance than those in the CONTROL condition. |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | OLS Linear Regression `DV_percent_test_NABS` \\~ `condition` (absolute scoring)\\                                                        |\n|                       | OLS Linear Regression `item_test_SCALED` \\~ `condition` (scaled scoring)                                                               |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n| **Alternatives**      | **Exploring alternatives.**\\                                                                                                           |\n|                       | *Simple linear regression models do a poor job of fitting the (bimodal) outcome distributions (both absolute and scaled scores)*       |\n|                       |                                                                                                                                        |\n|                       | -   Hurdle model (mixture model w/ binomial + count)                                                                                   |\n|                       | -   Negative Binomial / Zero Inflated Negative Binom for overdispersed count?                                                          |\n|                       | -   Beta regression?                                                                                                                   |\n|                       | -   Other way to account for the severe bimodality?                                                                                    |\n|                       | -   \"shift function\" way to characterize difference in bimodal distributions                                                           |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | ***TODO*** **when done**                                                                                                               |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------+\n\n### Test Phase Absolute Score\n\n#### Shift in Modal Mass\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(DV_percent_test_NABS))\ngf_props(~DV_percent_test_NABS, \n         fill = ~pretty_condition, data = df_subjects) %>% gf_facet_grid(~pretty_condition) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-ABS-1.png){width=672}\n:::\n:::\n\n\nThe Effect of Condition on Total Absolute Test Score can be described as a 'shift' in mass between the two modes of each distribution.\n\n*FIRST, we use the Kolmogorov-Smirnov test as a Robust alternative to the t-test to test if the two distributions likely come from different populations.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#(requires shift function files loaded)\n\n#PREP DATA \ndf <- df_subjects %>% dplyr::select(DV_percent_test_NABS, pretty_condition) %>% \n  mutate(\n    data = as.numeric(DV_percent_test_NABS),\n    #flip order levels to correctly orient graph\n    # gr = recode_factor(pretty_condition, \"impasse\" = \"impasse\", \"control\"=\"control\")\n    gr = as.character(pretty_condition)\n  ) %>% dplyr::select(data,gr)\n\ng1 <- df %>% filter(gr == \"control\") %>% dplyr::pull(data)\ng2 <- df %>% filter(gr == \"impasse\") %>% dplyr::pull(data)\n\n\n#COMPARE DISTRIBUTIONS WITH ROBUST TESTS\n\n#What do common tests say about the difference?\n\n# Kolmogorov-Smirnov test\n#If y is numeric, a two-sample (Smirnov) test of the null hypothesis that x and y \n#were drawn from the same continuous distribution is performed. Alternatively, y ...\n\n#null is X is drawn from CDF EQUAL TO Y\nks.test(g1,g2) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2): p-value will be approximate in the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD = 0.2, p-value = 0.0001\nalternative hypothesis: two-sided\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that impasse and control come from different population distributions\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that impasse and control come from different population distributions\"\n```\n:::\n\n```{.r .cell-code}\n# #null is X is NOT LESS THAN Y\nks.test(g1,g2, alternative = \"greater\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2, alternative = \"greater\"): p-value will be approximate\nin the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD^+ = 0.2, p-value = 5e-05\nalternative hypothesis: the CDF of x lies above that of y\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\"\n```\n:::\n\n```{.r .cell-code}\n#REGULAR T-TEST\nt.test(g1,g2) # regular Welsh t-test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  g1 and g2\nt = -4, df = 325, p-value = 2e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -27.2 -10.2\nsample estimates:\nmean of x mean of y \n     19.0      37.7 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#IF THIS ERRORS, consider loadling plyr (older than dplyr)\n# kernel density estimate + rug plot + superimposed deciles\nkde <- plot.kde_rug_dec2(df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: plyr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    compact\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcdExtra':\n\n    summarise\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggpubr':\n\n    mutate\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:Hmisc':\n\n    is.discrete, summarize\n```\n:::\n\n```{.r .cell-code}\n# kde\n\n# compute shift function\nout <- shifthd( g1, g2, nboot=200)\n\n# plot shift function\nsf <- plot.sf(data=out) # function from rgar_visualisation.txt\n# sf\n\n# combine KDE + SF\ncowplot::plot_grid(kde, sf, labels=c(\"A\", \"B\"), ncol = 1, nrow = 2, rel_heights = c(1.5, 1),label_size = 18,hjust = -1,scale=.95)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SHIFT-FN-SCALED-1.png){width=672}\n:::\n:::\n\n\n\n#### TODO \\| Ordinal Regression on ITEM-Interpretation\n#### WIP \\| Mixed Logistic Regression ITEM-ABS\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lme4' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked _by_ '.GlobalEnv':\n\n    bdiag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q %nin% c(1,2,3,4,5,6,9))\ndf$q = as.factor(df$q)\n\n# SUBJECT INTERCEPT + FIXED CONDITION\nmm1 <- glmer(score_niceABS ~ condition + (1|subject), data = df,family = \"binomial\")\nsummary(mm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score_niceABS ~ condition + (1 | subject)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    1385     1402     -689     1379     2637 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5307 -0.0193 -0.0097  0.1135  2.7426 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 117      10.8    \nNumber of obs: 2640, groups:  subject, 330\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -9.182      0.677  -13.56   <2e-16 ***\ncondition121    1.632      0.753    2.17     0.03 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nconditin121 -0.394\n```\n:::\n\n```{.r .cell-code}\nreport(mm1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict score_niceABS with condition (formula: score_niceABS ~ condition). The model included subject as random effect (formula: ~1 | subject). The model's total explanatory power is substantial (conditional R2 = 0.97) and the part related to the fixed effects alone (marginal R2) is of 5.50e-03. The model's intercept, corresponding to condition = 111, is at -9.18 (95% CI [-10.51, -7.85], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 1.63, 95% CI [0.16, 3.11], p = 0.030; Std. beta = 1.63, 95% CI [0.16, 3.11])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n# CONDITION SLOPE per SUBJECT INTERCEPT + FIXED CONDITION\nmm2 <- glmer(score_niceABS ~ condition + (1|subject) + (1 | q) , data = df, family = \"binomial\")\nsummary(mm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score_niceABS ~ condition + (1 | subject) + (1 | q)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    1324     1348     -658     1316     2636 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.386 -0.014 -0.008  0.067  7.780 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 166.294  12.896  \n q       (Intercept)   0.543   0.737  \nNumber of obs: 2640, groups:  subject, 330; q, 8\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -10.562      0.733  -14.41   <2e-16 ***\ncondition121    1.501      0.775    1.94    0.053 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nconditin121 -0.485\n```\n:::\n\n```{.r .cell-code}\nreport(mm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict score_niceABS with condition (formula: score_niceABS ~ condition). The model included subject and q as random effects (formula: list(~1 | subject, ~1 | q)). The model's total explanatory power is substantial (conditional R2 = 0.98) and the part related to the fixed effects alone (marginal R2) is of 3.30e-03. The model's intercept, corresponding to condition = 111, is at -10.56 (95% CI [-12.00, -9.13], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically non-significant and positive (beta = 1.50, 95% CI [-0.02, 3.02], p = 0.053; Std. beta = 1.50, 95% CI [-0.02, 3.02])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n# check_model(mm2)\n\n# SUBJECT INTERCEPT + Q  INTERCEPT +  FIXED CONDITION\n# DOESN'T CONVERGE\n# mm3 <- glmer(score_niceABS ~ condition + q + (1 | subject), data = df, family = \"binomial\")\n# summary(mm3)\n# report(mm3)\n\n#RANDOM ONLY\nmm.r0 <- glmer(score_niceABS ~  (1 | subject), data = df, family = \"binomial\")\nsummary(mm.r0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score_niceABS ~ (1 | subject)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    1388     1400     -692     1384     2638 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5320 -0.0121 -0.0121  0.1117  2.7246 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 132      11.5    \nNumber of obs: 2640, groups:  subject, 330\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -8.66       0.55   -15.8   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nreport(mm.r0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict score_niceABS (formula: score_niceABS ~ 1). The model included subject as random effect (formula: ~1 | subject). . The model's intercept is at -8.66 (95% CI [-9.74, -7.59], p < .001). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n#RANDOM ONLY\nmm.r1 <- glmer(score_niceABS ~  (1 | subject) + (1 | q), data = df, family = \"binomial\")\nsummary(mm.r1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: score_niceABS ~ (1 | subject) + (1 | q)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n    1326     1344     -660     1320     2637 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.396 -0.011 -0.008  0.066  7.858 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 180.606  13.44   \n q       (Intercept)   0.563   0.75   \nNumber of obs: 2640, groups:  subject, 330; q, 8\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -9.995      0.596   -16.8   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nreport(mm.r1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict score_niceABS (formula: score_niceABS ~ 1). The model included subject and q as random effects (formula: list(~1 | subject, ~1 | q)). . The model's intercept is at -10.00 (95% CI [-11.16, -8.83], p < .001). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n#COMPARE PERFORMANCE\ncompare_performance(mm.r0, mm.r1, mm1,mm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName  |    Model |      AIC | AIC weights |      BIC | BIC weights | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n-------------------------------------------------------------------------------------------------------------------------------------------------------------\nmm.r0 | glmerMod | 1387.730 |     < 0.001 | 1399.487 |     < 0.001 |      0.976 |      0.000 | 0.976 | 0.203 | 1.000 |    0.129 |      -Inf |           0.015\nmm.r1 | glmerMod | 1326.298 |       0.277 | 1343.934 |       0.878 |      0.982 |      0.000 | 0.982 | 0.186 | 1.000 |    0.111 |      -Inf |           0.015\nmm1   | glmerMod | 1384.749 |     < 0.001 | 1402.385 |     < 0.001 |      0.973 |      0.005 | 0.973 | 0.203 | 1.000 |    0.130 |      -Inf |           0.015\nmm2   | glmerMod | 1324.375 |       0.723 | 1347.889 |       0.122 |      0.981 |      0.003 | 0.981 | 0.186 | 1.000 |    0.112 |      -Inf |           0.015\n```\n:::\n\n```{.r .cell-code}\n#SJ PLOTS\n#table of effects\nsjPlot:: tab_model(mm2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">score nice ABS</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ID indicates randomly<br>assigned<br>condition(111->control,121->impasse):<br>condition 121</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">4.49</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.98&nbsp;&ndash;&nbsp;20.52</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.053</td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">166.29</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.54</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.98</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">330</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">8</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">2640</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.003 / 0.981</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nsjPlot::plot_model(mm2)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsjPlot::plot_model(mm2, transform = \"plogis\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\nsjPlot::plot_model(mm2, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(lattice)\nrandoms <- ranef(mm2)\ndotplot(randoms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$subject\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$q\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-6-5.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(lmerTest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lmerTest'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    lmer\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\n# ranova(mm1,mm2)\n```\n:::\n\n\n\n#### Linear Regression\n\n##### (In Person)\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nlab.testabs.lm1 <- lm(DV_percent_test_NABS ~ pretty_condition, data = df_lab)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lab.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = DV_percent_test_NABS ~ pretty_condition, data = df_lab)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -41.6  -21.4  -21.4   45.9   78.6 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                21.37       5.13    4.16 0.000058 ***\npretty_conditionimpasse    20.23       7.20    2.81   0.0058 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 40.4 on 124 degrees of freedom\nMultiple R-squared:  0.0598,\tAdjusted R-squared:  0.0522 \nF-statistic: 7.89 on 1 and 124 DF,  p-value: 0.00579\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(lab.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: DV_percent_test_NABS\n                  Df Sum Sq Mean Sq F value Pr(>F)   \npretty_condition   1  12889   12889    7.89 0.0058 **\nResiduals        124 202638    1634                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(lab.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)             11.21   31.5\npretty_conditionimpasse  5.97   34.5\n```\n:::\n\n```{.r .cell-code}\nreport(lab.testabs.lm1) #sanity check\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict DV_percent_test_NABS with pretty_condition (formula: DV_percent_test_NABS ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.06, F(1, 124) = 7.89, p = 0.006, adj. R2 = 0.05). The model's intercept, corresponding to pretty_condition = control, is at 21.37 (95% CI [11.21, 31.53], t(124) = 4.16, p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 20.23, 95% CI [5.97, 34.49], t(124) = 2.81, p = 0.006; Std. beta = 0.49, 95% CI [0.14, 0.83])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n#print model equation\neq <- extract_eq(lab.testabs.lm1, use_coefs = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \nm <- lab.testabs.lm1\ndf <- df_lab \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(LAB) Test Phase Accuracy ~ Condition\", \n        x = \"model predicted mean (% correct)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\")\n  ) + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-TEST-ABS-LAB-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(lab.testabs.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-TEST-ABS-LAB-1.png){width=672}\n:::\n:::\n\n\n\\(1\\) RESIDUAL DISTRIBUTION: \\\n(2) HOMOGENEITY:  \\\n(3) HETERSCEDASTICITY:  (4) AUTOCORRELATION: \n\n###### Inference\n\nOLS Linear Regression on % correct in the TEST PHASE shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model is a poor fit to the data: (1) the model predictions for each group are closer to the anitimode of each of distribution than the group modes, and (2) the distribution of residuals is not normal.\n\n##### (Online Replication)\n\n###### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_online %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(DV_percent_test_NABS)*100)\ngmean = df_online %>% dplyr::summarise(mean = mean(DV_percent_test_NABS)*100)\ngf_props(~DV_percent_test_NABS*100, fill = ~pretty_condition, data = df_online) %>% \n  gf_facet_grid(~pretty_condition) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"(ONLINE) TEST Phase Absolute Score (% Correct)\",\n       subtitle = \"\") + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-ABS-ONLINE-1.png){width=672}\n:::\n:::\n\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nrep.testabs.lm1 <- lm(DV_percent_test_NABS ~ pretty_condition, data = df_online)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(rep.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = DV_percent_test_NABS ~ pretty_condition, data = df_online)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -35.4  -35.4  -17.4   39.6   82.5 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                17.45       3.98    4.39 0.000019 ***\npretty_conditionimpasse    17.97       5.47    3.29   0.0012 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 39 on 202 degrees of freedom\nMultiple R-squared:  0.0508,\tAdjusted R-squared:  0.0461 \nF-statistic: 10.8 on 1 and 202 DF,  p-value: 0.0012\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(rep.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: DV_percent_test_NABS\n                  Df Sum Sq Mean Sq F value Pr(>F)   \npretty_condition   1  16410   16410    10.8 0.0012 **\nResiduals        202 306868    1519                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(rep.testabs.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)              9.60   25.3\npretty_conditionimpasse  7.19   28.7\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n#print model equation\neq <- extract_eq(rep.testabs.lm1)\n```\n:::\n\n\n**Model equation** $$\n\\operatorname{DV\\_percent\\_test\\_NABS} = \\alpha + \\beta_{1}(\\operatorname{pretty\\_condition}_{\\operatorname{impasse}}) + \\epsilon\n$$\n\n\n**For online replication** an OLS linear regression predicting test-phase (% correct) by experimental condition explains a statistically significant though small 5% variance in accuracy (F(1,202) = 10.8, p \\< 0.01). The estimated beta coefficient ($\\beta$ = 0.18, 95% CI \\[0.07, 0.29\\]) predicts that participants in the impasse condition will on average score 18% higher than those in the control condition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \nm <- rep.testabs.lm1\ndf <- df_online \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(ONLINE) Test Phase Accuracy ~ Condition\", \n        x = \"model predicted mean (% correct)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\")\n  ) + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-TEST-ABS-ONLINE-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(rep.testabs.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-TEST-ABS-ONLINE-1.png){width=672}\n:::\n:::\n\n\n\\(1\\) RESIDUAL DISTRIBUTION:  (2) HOMOGENEITY:  (3) HETERSCEDASTICITY:  (4) AUTOCORRELATION:  (5) OUTLIERS: FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE\n\n###### Inference\n\n**For in person collection** OLS Linear Regression on % correct in the TEST PHASE shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model is a poor fit to the data: (1) the model predictions for each group are closer to the anitimode of each of distribution than the group modes, and (2) the distribution of residuals is not normal, and the LM assumptions of homogeneity of variance (between groups) and homogeneity of error variance appears to be violated.\n\n### Test Phase Scaled Score\n\nWhile Absolute Score (as \\# or % correct) gives an indication of accuracy, it does not differentiate between different kinds of incorrect answers. The Scaled score includes this extra information see @sec-scoring-scaledScore\n\n#### Shift in Modal Mass\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_SCALED))\ngf_props(~item_test_SCALED, \n         fill = ~pretty_condition, data = df_subjects) %>% gf_facet_grid(~pretty_condition) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Scaled Score\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-SCALED-1.png){width=672}\n:::\n:::\n\n\nThe Effect of Condition on Test Phase Scaled Score can be described as a 'shift' in mass between the two modes of each distribution.\n\n*FIRST, we use the Kolmogorov-Smirnov test as a Robust alternative to the t-test to test if the two distributions likely come from different populations.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#(requires shift function files loaded)\n\n\n#PREP DATA \ndf <- df_subjects %>% dplyr::select(item_test_SCALED, pretty_condition) %>% \n  mutate(\n    data = as.numeric(item_test_SCALED),\n    #flip order levels to correctly orient graph\n    # gr = recode_factor(pretty_condition, \"impasse\" = \"impasse\", \"control\"=\"control\")\n    gr = as.character(pretty_condition)\n  ) %>% dplyr::select(data,gr)\n\ng1 <- df %>% filter(gr == \"control\") %>% dplyr::pull(data)\ng2 <- df %>% filter(gr == \"impasse\") %>% dplyr::pull(data)\n\n\n#COMPARE DISTRIBUTIONS WITH ROBUST TESTS\n\n#What do common tests say about the difference?\n\n# Kolmogorov-Smirnov test\n#If y is numeric, a two-sample (Smirnov) test of the null hypothesis that x and y \n#were drawn from the same continuous distribution is performed. Alternatively, y ...\n\n#null is X is drawn from CDF EQUAL TO Y\nks.test(g1,g2) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2): p-value will be approximate in the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD = 0.3, p-value = 1e-06\nalternative hypothesis: two-sided\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that impasse and control come from different population distributions\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that impasse and control come from different population distributions\"\n```\n:::\n\n```{.r .cell-code}\n# #null is X is NOT LESS THAN Y\nks.test(g1,g2, alternative = \"greater\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test(g1, g2, alternative = \"greater\"): p-value will be approximate\nin the presence of ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo-sample Kolmogorov-Smirnov test\n\ndata:  g1 and g2\nD^+ = 0.3, p-value = 6e-07\nalternative hypothesis: the CDF of x lies above that of y\n```\n:::\n\n```{.r .cell-code}\nprint(\"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUGGESTS that true CDF of CONTROL is greater than that of IMPASSE [consistent with higher probability of low scores]\"\n```\n:::\n\n```{.r .cell-code}\n#REGULAR T-TEST\nt.test(g1,g2) # regular Welsh t-test\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  g1 and g2\nt = -5, df = 327, p-value = 8e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.77 -2.09\nsample estimates:\nmean of x mean of y \n   -4.032    -0.599 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#IF THIS ERRORS, consider loadling plyr (older than dplyr)\n# kernel density estimate + rug plot + superimposed deciles\nkde <- plot.kde_rug_dec2(df)\n# kde\n\n# compute shift function\nout <- shifthd( g1, g2, nboot=200)\n\n# plot shift function\nsf <- plot.sf(data=out) # function from rgar_visualisation.txt\n# sf\n\n# combine KDE + SF\nplot_grid(kde, sf, labels=c(\"A\", \"B\"), ncol = 1, nrow = 2, rel_heights = c(1.5, 1),label_size = 18,hjust = -1,scale=.95)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/SHIFT-FN-NABS-1.png){width=672}\n:::\n:::\n\n\n#### Linear Regression\n\n##### (In Person)\n\n###### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_lab %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_SCALED))\ngf_props(~item_test_SCALED, fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Test Phase Scaled Score [-8, +8]\",\n       y = \"proportion of subjects\",\n       title = \"(LAB) TEST Phase Scaled Score \",\n       subtitle = \"\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-SCALED-LAB-1.png){width=672}\n:::\n:::\n\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nlab.test_scaled.lm1 <- lm(item_test_SCALED ~ pretty_condition, data = df_lab)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lab.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_SCALED ~ pretty_condition, data = df_lab)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7.74  -3.98  -3.23   6.76  12.02 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               -4.024      0.818   -4.92  2.7e-06 ***\npretty_conditionimpasse    3.766      1.148    3.28   0.0013 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.44 on 124 degrees of freedom\nMultiple R-squared:  0.0798,\tAdjusted R-squared:  0.0724 \nF-statistic: 10.8 on 1 and 124 DF,  p-value: 0.00135\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(lab.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: item_test_SCALED\n                  Df Sum Sq Mean Sq F value Pr(>F)   \npretty_condition   1    447     447    10.8 0.0013 **\nResiduals        124   5150      42                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(lab.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)             -5.64  -2.40\npretty_conditionimpasse  1.49   6.04\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n#print model equation\neq <- extract_eq(lab.test_scaled.lm1, use_coefs = TRUE)\n```\n:::\n\n\n**Model equation** $$\n\\operatorname{\\widehat{item\\_test\\_SCALED}} = -4.02 + 3.77(\\operatorname{pretty\\_condition}_{\\operatorname{impasse}})\n$$\n\n\n**For (In Person)** an OLS linear regression predicting test-phase (% correct) by experimental condition explains a statistically significant though small 8% variance in accuracy (F(1,124) = 10.8, p \\< 0.005). The estimated beta coefficient ($\\beta$ = 3.77, 95% CI \\[1.49, 6.04\\]) predicts that participants in the impasse condition will on average 4 points higher than those in the control condition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \nm <- lab.test_scaled.lm1\ndf <- df_lab \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(LAB) Test Phase Scaled Score ~ Condition\", \n        x = \"model predicted mean\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\")\n  ) + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-TEST-SCALED-LAB-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(lab.test_scaled.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-TEST-SCALED-LAB-1.png){width=672}\n:::\n:::\n\n\n\\(1\\) RESIDUAL DISTRIBUTION: \\\n(2) HOMOGENEITY: \\\n(3) HETERSCEDASTICITY: \\\n(4) AUTOCORRELATION: \n\n###### Inference\n\nOLS Linear Regression on SCALED SCORE in the TEST PHASE shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model is a poor fit to the data: (1) the model predictions for each group are closer to the anitimode of each of distribution than the group modes, and (2) the distribution of residuals is not normal. (Assumptions of homogenity of variance across groups, and homogeneity of variance in residuals are met)\n\n##### (Online Replication)\n\n###### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_online %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_SCALED))\ngf_props(~item_test_SCALED, fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Test Phase Scaled Score [-8, +8]\",\n       y = \"proportion of subjects\",\n       title = \"(ONLINE) TEST Phase Scaled Score \",\n       subtitle = \"\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-SCALED-ONLINE-1.png){width=672}\n:::\n:::\n\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nrep.test_scaled.lm1 <- lm(item_test_SCALED ~ pretty_condition, data = df_online)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(rep.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_SCALED ~ pretty_condition, data = df_online)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7.20  -3.96  -2.46   6.80  12.04 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               -4.036      0.622   -6.49  6.4e-10 ***\npretty_conditionimpasse    3.236      0.854    3.79   0.0002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.09 on 202 degrees of freedom\nMultiple R-squared:  0.0663,\tAdjusted R-squared:  0.0617 \nF-statistic: 14.3 on 1 and 202 DF,  p-value: 0.000201\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(rep.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: item_test_SCALED\n                  Df Sum Sq Mean Sq F value Pr(>F)    \npretty_condition   1    532     532    14.3 0.0002 ***\nResiduals        202   7493      37                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(rep.test_scaled.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)             -5.26  -2.81\npretty_conditionimpasse  1.55   4.92\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n#print model equation\neq <- extract_eq(rep.test_scaled.lm1, use_coefs = TRUE)\n```\n:::\n\n\n**Model equation** $$\n\\operatorname{\\widehat{item\\_test\\_SCALED}} = -4.04 + 3.24(\\operatorname{pretty\\_condition}_{\\operatorname{impasse}})\n$$\n\n\n**For online replication** an OLS linear regression predicting test-phase (% correct) by experimental condition explains a statistically significant though small 7% variance in accuracy (F(1,202) = 14.3, p \\< 0.001). The estimated beta coefficient ($\\beta$ = 3.24, 95% CI \\[1.55, 4.62\\]) predicts that participants in the impasse condition will on average 3 points higher than those in the control condition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \nm <- rep.test_scaled.lm1\ndf <- df_online \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(LAB) Test Phase Scaled Score ~ Condition\", \n        x = \"model predicted mean (scaled score)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\")\n  ) + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-TEST-SCALED-ONLINE-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(rep.test_scaled.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-TEST-SCALED-ONLINE-1.png){width=672}\n:::\n:::\n\n\n\\(1\\) RESIDUAL DISTRIBUTION: \\\n(2) HOMOGENEITY: \\\n(3) HETERSCEDASTICITY: \\\n(4) AUTOCORRELATION: \n\n###### Inference\n\n**For online replication** an OLS Linear Regression on SCALED SCORE in the TEST PHASE shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model is a poor fit to the data: (1) the model predictions for each group are closer to the anitimode of each of distribution than the group modes, and (2) the distribution of residuals is not normal. (Assumptions of homogenity of variance across groups, and homogeneity of variance in residuals are met)\n\n\n\n## H1B \\| Q1 ACCURACY\n\nThe graph comprehension tasks includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.\n\nTODO: - does impasse yield different exploration behavior? (characterize mouse) - does impasse yield more time on task? (characterize response time ? number of answers then de-selected?)\n\nTODO: Think about characterizing how variable the interpretations are across a participant. Do they form an interpretation and hold it constant? Or do they change question to question.\n\n### Response Accuracy of First Question by Condition\n\n#### Chi Square \\| Accuracy \\~ Condition\n\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                                                                                                                                                                                                                                                                                                                   |\n+=======================+========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| **Analysis Strategy** | Chi-Square test of independence on outcome `score_niceABS` by `condition` for `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                                                                                                                                |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Justification**     | \\(0\\) simplest method to examine independence of two categorical factors; logistic regression is recommended for binomial \\~ continuous                                                                                                                                                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       | \\(1\\) independence assumption : as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                                                                                                                                                                                                                                                                                                                                   |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       | \\(2\\) frequency size assumption : expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                                                                                                                                                                                                                                                                                                                   |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Steps**             | \\(1\\) Express raw data as contingency table & visualize                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       | \\(2\\) Calculate Chi-Squared Statistic and p-value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       | \\(3\\) Interpret Odds-Ratio as effect size                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | **Lab** For the (In Person) (n=126) the Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. In this particular data sample, the odds ratio (2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition. |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|                       | **Online** For online data collection (n=204), a Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. The odds ratio (2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition.                                   |\n+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#FITER THE DATASET\ndf = df_items %>% filter(q==1) \n\n#PROPORTIONAL BAR CHART\ngf_props(~score_niceABS, data = df, fill = ~mode) %>% \n  gf_facet_grid(mode~condition, labeller = label_both) +\n  labs(x = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition (Both Modalities)\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses than control \")+\n  theme_minimal()+ theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC.by.COND-bar-1.png){width=672}\n:::\n:::\n\n\nA proportional bar chart visualizing the proportion of incorrect (x =0) vs correct (x = 1) responses in each condition (right/left facet) for each data collection modality (top/bottom) reveal that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition. In the impasse condition, the difference in proportions is smaller than the control condition (i.e. There are more correct responses in the impasse condition than the control condition).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#MOSAIC PLOT\nvcd::mosaic(main=\"Accuracy on First Question by Condition (Both Modalities)\",\n            data = df, score_niceABS ~ condition, rot_labels=c(0,90,0,0),\n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\")))\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-Q1ACC.by.COND-mosaic-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#PRINT CONTINGENCY TABLE\ntitle = \"Proportion of Correct Responses On First Item (Both Modalities)\"\nitem.contingency <-  df %>% dplyr::select(condition, score_niceABS) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Proportion of Correct Responses On First Item (Both Modalities)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 0 </th>\n   <th style=\"text-align:right;\"> 1 </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 111 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> 0.067 </td>\n   <td style=\"text-align:right;\"> 0.479 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 121 </td>\n   <td style=\"text-align:right;\"> 0.373 </td>\n   <td style=\"text-align:right;\"> 0.148 </td>\n   <td style=\"text-align:right;\"> 0.521 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:right;\"> 0.215 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nA mosaic plot condition by response accuracy on the first question (across both data collection modalities) reveals the same pattern (the mosaic plot is an alternative visualization technique to the proportional bar chart). The relative size of condition boxes (111 vs 121) reflects that the sample is roughly evenly split across experimental conditions. The difference in size between 0 (incorrect) and 1 (correct) reflects that the proportion of correct responses (1) is greater in the impasse condition (121).\n\nNext, we compute a contingency table and Pearson's Chi-Squared test for each data collection modality.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"lab-synch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        52 |        10 |        62 | \n             |    47.730 |    14.270 |           | \n             |     0.382 |     1.278 |           | \n             |     0.839 |     0.161 |     0.492 | \n             |     0.536 |     0.345 |           | \n             |     0.413 |     0.079 |           | \n-------------|-----------|-----------|-----------|\n         121 |        45 |        19 |        64 | \n             |    49.270 |    14.730 |           | \n             |     0.370 |     1.238 |           | \n             |     0.703 |     0.297 |     0.508 | \n             |     0.464 |     0.655 |           | \n             |     0.357 |     0.151 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |        97 |        29 |       126 | \n             |     0.770 |     0.230 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  3.27     d.f. =  1     p =  0.0707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  2.55     d.f. =  1     p =  0.111 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.18 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.0909 \n95% confidence interval:  0.86 5.84 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.979 \n95% confidence interval:  0 5.03 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.0547 \n95% confidence interval:  0.982 Inf \n\n\n \n```\n:::\n:::\n\n\n**For the (In Person)** (n=126) the Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. In this particular data sample, the odds ratio (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"asynch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  204 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        84 |        12 |        96 | \n             |    76.235 |    19.765 |           | \n             |     0.791 |     3.050 |           | \n             |     0.875 |     0.125 |     0.471 | \n             |     0.519 |     0.286 |           | \n             |     0.412 |     0.059 |           | \n-------------|-----------|-----------|-----------|\n         121 |        78 |        30 |       108 | \n             |    85.765 |    22.235 |           | \n             |     0.703 |     2.711 |           | \n             |     0.722 |     0.278 |     0.529 | \n             |     0.481 |     0.714 |           | \n             |     0.382 |     0.147 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       162 |        42 |       204 | \n             |     0.794 |     0.206 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  7.26     d.f. =  1     p =  0.00707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  6.35     d.f. =  1     p =  0.0117 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.68 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00894 \n95% confidence interval:  1.23 6.17 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.998 \n95% confidence interval:  0 5.42 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.00539 \n95% confidence interval:  1.37 Inf \n\n\n \n```\n:::\n:::\n\n\n**For online data collection** (n=204), a Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. The odds ratio (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]) indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) \nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  330 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |       136 |        22 |       158 | \n             |   124.006 |    33.994 |           | \n             |     1.160 |     4.232 |           | \n             |     0.861 |     0.139 |     0.479 | \n             |     0.525 |     0.310 |           | \n             |     0.412 |     0.067 |           | \n-------------|-----------|-----------|-----------|\n         121 |       123 |        49 |       172 | \n             |   134.994 |    37.006 |           | \n             |     1.066 |     3.887 |           | \n             |     0.715 |     0.285 |     0.521 | \n             |     0.475 |     0.690 |           | \n             |     0.373 |     0.148 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       259 |        71 |       330 | \n             |     0.785 |     0.215 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  10.3     d.f. =  1     p =  0.0013 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  9.5     d.f. =  1     p =  0.00205 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.46 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00131 \n95% confidence interval:  1.37 4.53 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  1 \n95% confidence interval:  0 4.12 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.000928 \n95% confidence interval:  1.49 Inf \n\n\n \n```\n:::\n:::\n\n\n**Combining data across both sessions** (n=330), a Pearson's Chi-squared test suggests a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi_2$ (1) = 10.3, p = 0.001. The sample odds ratio (2.46, p = 0.001, 95% CI \\[1.37, 4.53\\]) indicates that the odds of providing a correct response to the first question are 2.46 higher for subjects in the impasse condition than those in the control condition.\n\n#### TODO \\| (multiple) Logistic Regression Model \\| What predicts Q1 Accuracy?\n\n## H1C \\| Q1 LATENCY\n\n## RESPONSE LATENCY\n\n-   [TODO: Investigate super high and super low response times.]{style=\"color: red;\"}.\n-   [TODO: Investigate appropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/)]{style=\"color: red;\"}.\n-   Especially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data\n\n+-----------------------+--------------------------------------------+\n| Research Question     |                                            |\n+=======================+============================================+\n| **Hypothesis**        |                                            |\n+-----------------------+--------------------------------------------+\n| **Analysis Strategy** |                                            |\n+-----------------------+--------------------------------------------+\n| **Alternatives**      |                                            |\n+-----------------------+--------------------------------------------+\n| **Inference**         |                                            |\n+-----------------------+--------------------------------------------+\n\n### Q1 Response Latency\n\n#### Linear Regression (Log Transform)\n\n##### (In Person)\n\n###### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_lab %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_q1_rt))\ngf_dhistogram(~log(item_q1_rt), fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) +\n  # gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(title = \"(LAB) First Question Response Time\",,\n       # x = \"Response Time (seconds)\",\n       # y = \"proportion of participants\",\n       subtitle = \"\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-Q1TIME-1.png){width=672}\n:::\n:::\n\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nlab.q1t.lm1 <- lm(log(item_q1_rt) ~ pretty_condition, data = df_lab)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lab.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(item_q1_rt) ~ pretty_condition, data = df_lab)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8202 -0.3504  0.0503  0.3382  1.2862 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               3.4833     0.0687   50.69   <2e-16 ***\npretty_conditionimpasse   0.3142     0.0964    3.26   0.0014 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.541 on 124 degrees of freedom\nMultiple R-squared:  0.0789,\tAdjusted R-squared:  0.0714 \nF-statistic: 10.6 on 1 and 124 DF,  p-value: 0.00145\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(lab.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: log(item_q1_rt)\n                  Df Sum Sq Mean Sq F value Pr(>F)   \npretty_condition   1    3.1   3.108    10.6 0.0014 **\nResiduals        124   36.3   0.293                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(lab.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)             3.347  3.619\npretty_conditionimpasse 0.123  0.505\n```\n:::\n\n```{.r .cell-code}\nreport(lab.q1t.lm1) #sanity check\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFormula contains log- or sqrt-terms. See help(\"standardize\") for how such terms are standardized.\nFormula contains log- or sqrt-terms. See help(\"standardize\") for how such terms are standardized.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict item_q1_rt with pretty_condition (formula: log(item_q1_rt) ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.08, F(1, 124) = 10.61, p = 0.001, adj. R2 = 0.07). The model's intercept, corresponding to pretty_condition = control, is at 3.48 (95% CI [3.35, 3.62], t(124) = 50.69, p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 0.31, 95% CI [0.12, 0.51], t(124) = 3.26, p = 0.001; Std. beta = 0.21, 95% CI [0.09, 0.34])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n#print model equation\neq <- extract_eq(lab.q1t.lm1, use_coefs = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \n#lab.q1t.lm1 <- lm(log(item_q1_rt) ~ condition, data = df_lab)\nm <- lab.q1t.lm1\ndf <- df_lab \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf <- df  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) \n\n#transform log\ndf$.fitted <- exp(df$.fitted)\ndf$.se.fit <- exp(df$.se.fit)\n\ndf %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(LAB) Q1 Response Latency ~ Condition\", \n        x = \"model predicted mean (seconds)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\"),\n        caption = \"note: model log(predictions) have exponentiated to original scale\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-Q1-LATENCY-LAB-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(lab.q1t.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-Q1TIME-lab-1.png){width=672}\n:::\n:::\n\n\n(1) RESIDUAL DISTRIBUTION: \n(2) HOMOGENEITY: \n(3) HETERSCEDASTICITY: \n(4) AUTOCORRELATION: \n(5) OUTLIERS: FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE\n\n###### Inference\n\nOLS Linear Regression on Q1 response time shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model violates the assumption of normally distributed residuals.\n\n##### (Online Replication)\n\n###### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#HISTOGRAM\nstats = df_online %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_q1_rt))\ngf_dhistogram(~log(item_q1_rt), fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) +\n  # gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(title = \"(ONLINE) First Question Response Time\",\n       # x = \"Response Time (seconds)\",\n       # y = \"proportion of participants\",\n       subtitle = \"\") + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VIS-TEST-Q1TIME-online-1.png){width=672}\n:::\n:::\n\n\n###### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nrep.q1t.lm1 <- lm(log(item_q1_rt) ~ pretty_condition, data = df_online)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(rep.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(item_q1_rt) ~ pretty_condition, data = df_online)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0092 -0.3640 -0.0372  0.3785  2.0718 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               3.2505     0.0733   44.36  < 2e-16 ***\npretty_conditionimpasse   0.4200     0.1007    4.17 0.000045 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.718 on 202 degrees of freedom\nMultiple R-squared:  0.0793,\tAdjusted R-squared:  0.0747 \nF-statistic: 17.4 on 1 and 202 DF,  p-value: 0.0000451\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(rep.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: log(item_q1_rt)\n                  Df Sum Sq Mean Sq F value   Pr(>F)    \npretty_condition   1      9    8.97    17.4 0.000045 ***\nResiduals        202    104    0.52                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(rep.q1t.lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        2.5 % 97.5 %\n(Intercept)             3.106  3.395\npretty_conditionimpasse 0.221  0.619\n```\n:::\n\n```{.r .cell-code}\nreport(rep.q1t.lm1) #sanity check\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFormula contains log- or sqrt-terms. See help(\"standardize\") for how such terms are standardized.\nFormula contains log- or sqrt-terms. See help(\"standardize\") for how such terms are standardized.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict item_q1_rt with pretty_condition (formula: log(item_q1_rt) ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.08, F(1, 202) = 17.39, p < .001, adj. R2 = 0.07). The model's intercept, corresponding to pretty_condition = control, is at 3.25 (95% CI [3.11, 3.39], t(202) = 44.36, p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 0.42, 95% CI [0.22, 0.62], t(202) = 4.17, p < .001; Std. beta = 0.21, 95% CI [0.11, 0.31])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n#print model equation\neq <- extract_eq(rep.q1t.lm1, use_coefs = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references \n# rep.q1t.lm1 <- lm(log(item_q1_rt) ~ condition, data = df_online)\nm <- rep.q1t.lm1\ndf <- df_online \ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf <- df  %>%\n  data_grid(pretty_condition) %>%\n  augment(m, newdata = ., se_fit = TRUE) \n\n#transform log\ndf$.fitted <- exp(df$.fitted)\ndf$.se.fit <- exp(df$.se.fit)\n\ndf %>% \n  ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf, \n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) + \n  labs (title = \"(ONLINE) Q1 Response Latency ~ Condition\", \n        x = \"model predicted mean (seconds)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\"),\n        caption = \"note: model log(predictions) have exponentiated to original scale\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/VISMODEL-Q1-LATENCY-ONLINE-1.png){width=672}\n:::\n:::\n\n\n###### Diagnostics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\ncheck_model(rep.q1t.lm1, panel = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/DIAG-Q1TIME-online-1.png){width=672}\n:::\n:::\n\n\n(1) RESIDUAL DISTRIBUTION: \n(2) HOMOGENEITY: \n(3) HETERSCEDASTICITY: \n(4) AUTOCORRELATION: \n(5) OUTLIERS: FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE\n\n###### Inference\n\nOLS Linear Regression on Q1 response time shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model violates the assumption of normally distributed residuals.\n\n## RESOURCES\n\n-   https://rpkgs.datanovia.com/ggpubr/reference/index.html\n\n## WIP EXPLORING\n\n### Test Phase Absolute Score (# questions)\n\n#### Linear Regression\n\n*LM on Test Phase absolute score **as number of questions**, rather than % correct.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nlm.1 <- lm(item_test_NABS ~ condition, data = df_subjects)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_NABS ~ condition, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3.02  -2.77  -1.52   2.98   6.48 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     1.519      0.251    6.04  4.1e-09 ***\ncondition121    1.498      0.348    4.30  2.2e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.16 on 328 degrees of freedom\nMultiple R-squared:  0.0535,\tAdjusted R-squared:  0.0506 \nF-statistic: 18.5 on 1 and 328 DF,  p-value: 0.0000222\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: item_test_NABS\n           Df Sum Sq Mean Sq F value   Pr(>F)    \ncondition   1    185     185    18.5 0.000022 ***\nResiduals 328   3274      10                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  1.025   2.01\ncondition121 0.814   2.18\n```\n:::\n\n```{.r .cell-code}\nreport(lm.1) #sanity check\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict item_test_NABS with condition (formula: item_test_NABS ~ condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.05, F(1, 328) = 18.52, p < .001, adj. R2 = 0.05). The model's intercept, corresponding to condition = 111, is at 1.52 (95% CI [1.02, 2.01], t(328) = 6.04, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 1.50, 95% CI [0.81, 2.18], t(328) = 4.30, p < .001; Std. beta = 0.46, 95% CI [0.25, 0.67])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\ncheck_model(lm.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n#### Poisson Regression TODO\n\nhttps://stats.oarc.ucla.edu/r/dae/poisson-regression/\n\nThe outcome variable absolute score is clearly not normal. As it represents the cumulative number of items a participant has answered correctly, we can consider it a type of *count*, (ie. count of the number of questions the participant got correct) and attempt to model it using a General Linear Model with the Poisson distribution (and the default log-link function).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#POISSON\n\n#SCORE predicted by CONDITION --> POISSON DISTRIBUTION\np.1 <- glm(item_test_NABS ~ condition, data = df_subjects, family = \"poisson\")\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(p.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = item_test_NABS ~ condition, family = \"poisson\", \n    data = df_subjects)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n -2.46   -2.28   -1.74    1.51    3.69  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    0.4180     0.0645    6.48  9.4e-11 ***\ncondition121   0.6864     0.0781    8.79  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1579.3  on 329  degrees of freedom\nResidual deviance: 1496.7  on 328  degrees of freedom\nAIC: 1956\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(p.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: item_test_NABS\n\nTerms added sequentially (first to last)\n\n          Df Deviance Resid. Df Resid. Dev\nNULL                        329       1579\ncondition  1     82.7       328       1497\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(p.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  0.289  0.542\ncondition121 0.535  0.841\n```\n:::\n\n```{.r .cell-code}\nreport(p.1) #sanity check\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a poisson model (estimated using ML) to predict item_test_NABS with condition (formula: item_test_NABS ~ condition). The model's explanatory power is moderate (Nagelkerke's R2 = 0.22). The model's intercept, corresponding to condition = 111, is at 0.42 (95% CI [0.29, 0.54], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 0.69, 95% CI [0.53, 0.84], p < .001; Std. beta = 0.69, 95% CI [0.53, 0.84])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\ncheck_model(p.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n#### Zero Inflated Poisson\n\nhttps://stats.oarc.ucla.edu/r/dae/zip/\\\nPoisson count process with excess zeros\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ZERO INFLATED POISSON\n\nzinfp.1 <- zeroinfl(item_test_NABS ~  item_q1_rt| condition , data = df_subjects)\nsummary(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nzeroinfl(formula = item_test_NABS ~ item_q1_rt | condition, data = df_subjects)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.934 -0.821 -0.548  0.965  2.421 \n\nCount model coefficients (poisson with log link):\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 1.654243   0.059975   27.58   <2e-16 ***\nitem_q1_rt  0.001690   0.000849    1.99    0.047 *  \n\nZero-inflation model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     0.978      0.179    5.46  4.7e-08 ***\ncondition121   -1.055      0.236   -4.48  7.5e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 7 \nLog-likelihood: -531 on 4 Df\n```\n:::\n\n```{.r .cell-code}\nreport(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a zero-inflated poisson model to predict item_test_NABS with item_q1_rt and condition (formula: item_test_NABS ~ item_q1_rt). The model's explanatory power is substantial (R2 = 0.35, adj. R2 = 0.35). The model's intercept, corresponding to item_q1_rt = 0, is at 1.65 (95% CI [1.54, 1.77], p < .001). Within this model:\n\n  - The effect of item q1 rt is statistically significant and positive (beta = 1.69e-03, 95% CI [2.52e-05, 3.35e-03], p = 0.047; Std. beta = 0.06, 95% CI [7.11e-04, 0.12])\n  - The effect of condition [121] is statistically significant and negative (beta = -1.06, 95% CI [-1.52, -0.59], p < .001; Std. beta = -1.06, 95% CI [-1.52, -0.59])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\n```\n:::\n\n```{.r .cell-code}\nperformance(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n-------------------------------------------------------------------------------------\n1070.173 | 1085.370 | 0.354 |     0.350 | 3.131 | 3.150 |    -1.609 |           0.044\n```\n:::\n\n```{.r .cell-code}\n# check_model(zinfp.1)\n```\n:::\n\n\n#### Negative Binomial Regression\n\nhttps://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/ - overdispersed count data (variance much greater than mean)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#NEGATIVE BIONOMIAL REGRESSION\n# - https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/\n# - Overdispersed Count variables\n\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'MASS' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked _by_ '.GlobalEnv':\n\n    ltsreg\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n\n```{.r .cell-code}\nnb.1 <- glm.nb(item_test_NABS ~ condition, data = df_subjects)\nsummary(nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm.nb(formula = item_test_NABS ~ condition, data = df_subjects, \n    init.theta = 0.253501538, link = log)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.139  -1.102  -0.993   0.378   1.091  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)   \n(Intercept)     0.418      0.171    2.45   0.0143 * \ncondition121    0.686      0.232    2.95   0.0031 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.254) family taken to be 1)\n\n    Null deviance: 279.52  on 329  degrees of freedom\nResidual deviance: 270.97  on 328  degrees of freedom\nAIC: 1194\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.2535 \n          Std. Err.:  0.0315 \n\n 2 x log-likelihood:  -1188.1290 \n```\n:::\n\n```{.r .cell-code}\nreport(nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a negative-binomial model (estimated using ML) to predict item_test_NABS with condition (formula: item_test_NABS ~ condition). The model's explanatory power is weak (Nagelkerke's R2 = 0.04). The model's intercept, corresponding to condition = 111, is at 0.42 (95% CI [0.10, 0.77], p = 0.014). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 0.69, 95% CI [0.23, 1.14], p = 0.003; Std. beta = 0.69, 95% CI [0.23, 1.14])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\ncheck_model(nb.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#check model assumption\n#assumes conditional means are not equal to conditional variances\n#conduct likelihood ration test to compare and test [need poisson]\nm3 <- glm(item_test_NABS ~ condition, family = \"poisson\", data = df_subjects)\npchisq(2 * (logLik(nb.1) - logLik(m3)), df = 1, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'log Lik.' 4.3e-168 (df=3)\n```\n:::\n\n```{.r .cell-code}\n#A large (+) log likelihood suggests that the negative binomial is more appropriate than the Poisson model\n\n\n#EXPONENTIATE PARAMETER ESTIMATES\nest <- cbind(Estimate = coef(nb.1), confint(nb.1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n```{.r .cell-code}\n#exponentiate parameter estimates\nprint(\"Exponentiated Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Exponentiated Estimates\"\n```\n:::\n\n```{.r .cell-code}\nexp(est)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Estimate 2.5 % 97.5 %\n(Intercept)      1.52  1.10   2.15\ncondition121     1.99  1.26   3.13\n```\n:::\n:::\n\n\nThe variable condition has a coefficient of 0.67, (p \\< 0.005). This means that for the impasse condition, the expected log count \\# of questions increases by 0.67. By exponentiating the estimate we see that \\# question correct rate for the impasse condition is nearly 2x that of the control condition.\n\n**Diagnostics** ??\n\n#### Zero Inflated Negative Binomial Regression\n\nhttps://stats.oarc.ucla.edu/r/dae/zinb/ count data that are overdispersed and have excess zeros\n\nZero-inflated negative binomial regression is for modelling count variables with excessive zeros, and especially when the count data are overdispersed (mean is much larger than variance). It can help account for situations where theory suggests that excess zeros are generated by 2 separate processes, one that includes the other count values, and the other that is just the zeros, and thus that the *excess* zeros can be modelled independently.\n\nTotal Absolute Score (# items correct) may fit this situation, as the data are overdispersed (variance much greater than the mean) and there are are very large number of zeros. It is theoretically plausible that these excess zeros (no answers correct) are the result of a different 'process' ... (i.e) little understanding and/or resistance to restructuring understanding of the coordinate system. However, I am not certain if it is plausible to suggest that the zeros themselves are the result of two different processes: (ie. perhaps trying to understand, and not trying to understand?) \\<- this could maybe be disentangled by first question latency?\n\nThe model includes: - A logistic model to model which of the two processes the zero outcome is associated with - A negative binomial model to model the count process\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl) #  for zeroinfl negbinomial\n\n#ZERO INFLATED NEGATIVE BINOMIAL\nzinb.1 <- zeroinfl(s_NABS ~ condition | condition , data = df_subjects, dist = \"negbin\")\n#before the | is the count part, after the | is the logit model\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(zinb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nzeroinfl(formula = s_NABS ~ condition | condition, data = df_subjects, \n    dist = \"negbin\")\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.768 -0.584 -0.499  0.635  2.131 \n\nCount model coefficients (negbin with log link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    1.7144     0.1538   11.15   <2e-16 ***\ncondition121   0.0772     0.1753    0.44     0.66    \nLog(theta)    -0.0453     0.2377   -0.19     0.85    \n\nZero-inflation model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     0.223      0.214    1.04      0.3    \ncondition121   -1.745      0.399   -4.37 0.000012 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta = 0.956 \nNumber of iterations in BFGS optimization: 11 \nLog-likelihood: -721 on 5 Df\n```\n:::\n\n```{.r .cell-code}\nreport(zinb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a zero-inflated negative-binomial model to predict s_NABS with condition (formula: s_NABS ~ condition). The model's explanatory power is substantial (R2 = 0.68, adj. R2 = 0.67). The model's intercept, corresponding to condition = 111, is at 1.71 (95% CI [1.41, 2.02], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically non-significant and positive (beta = 0.08, 95% CI [-0.27, 0.42], p = 0.660; Std. beta = 0.08, 95% CI [-0.27, 0.42])\n  - The effect of condition [121] is statistically significant and negative (beta = -1.75, 95% CI [-2.53, -0.96], p < .001; Std. beta = -1.75, 95% CI [-2.53, -0.96])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\n```\n:::\n\n```{.r .cell-code}\nperformance(zinb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC      |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n-------------------------------------------------------------------------------------\n1452.157 | 1471.153 | 0.677 |     0.675 | 4.808 | 4.845 |    -2.221 |           0.039\n```\n:::\n\n```{.r .cell-code}\n# rootogram(zinb.1)\n\n\n\n# #EXPONENTIATE PARAMETER ESTIMATES\n# est <- cbind(Estimate = coef(zinb.1), confint(zinb.1))\n# #exponentiate parameter estimates\n# print(\"Exponentiated Estimates\")\n# exp(est)\n```\n:::\n\n\nIn the count model, the coefficient for the condition is very small, and not significant (suggesting it does not contribute to the count yielding process?).\n\nIn the zero-inflation model, the coefficient for the condition variable is -1.056 and statistically significant. This suggests that the log odds of being an excessive zero decrease by 1.06 if you are in the impasse condition (exponentiate it?)\n\n**TODO come back to this and discuss further**\\\n\n\n\n#### Model Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_performance(lm.1, p.1, nb.1, zinb.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: When comparing models, please note that probably not all models were fit from\n  same data.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName   |    Model |      AIC | AIC weights |      BIC | BIC weights |  RMSE | Sigma | Score_log | Score_spherical |    R2 | R2 (adj.) | Nagelkerke's R2\n-------------------------------------------------------------------------------------------------------------------------------------------------------\nlm.1   |       lm | 1699.782 |     < 0.001 | 1711.179 |     < 0.001 | 3.150 | 3.160 |           |                 | 0.053 |     0.051 |                \np.1    |      glm | 1955.788 |     < 0.001 | 1963.386 |     < 0.001 | 3.150 | 2.136 |    -2.957 |           0.042 |       |           |           0.223\nnb.1   |   negbin | 1194.129 |        1.00 | 1205.526 |        1.00 | 3.150 | 0.909 |    -2.137 |           0.046 |       |           |           0.045\nzinb.1 | zeroinfl | 1452.157 |     < 0.001 | 1471.153 |     < 0.001 | 4.808 | 4.845 |    -2.221 |           0.039 | 0.677 |     0.675 |                \n```\n:::\n:::\n\n\nFor modelling test phase absolute score (# items correct) it seems that the zero inflated negative binomial model is the best fit according to R2 and AIC, however, I am not clear on the implications of the interpretation (non significant in count process, significant on logit process), and also not clear if \\# items correct is truly a count process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#uncertainty model visualization\n# df %>%\n  # data_grid(pretty_condition) %>%\n  # augment(m, newdata = ., se_fit = TRUE) %>%\n  # ggplot(aes(y = pretty_condition)) +\n  # stat_halfeye(\n  #   aes(xdist = dist_student_t(df = df.residual(m), \n  #       mu = .fitted, sigma = .se.fit)), scale = .5) +\n  # # add raw data in too (scale = .5 above adjusts the halfeye height so\n  # # that the data fit in as well)\n  # geom_jitter(aes(x = x), data = df, pch = \"|\", size = 2, \n  #             position =   position_nudge(y = -.15), alpha = 0.5) +  \n  # labs (title = \"Model Estimates with Uncertainty\", x = \"model coefficient\") + \n  # theme_minimal()\n```\n:::\n\n\n#### WIP \\| HURDLE MODEL\n\n- https://data.library.virginia.edu/getting-started-with-hurdle-models/  \n- https://en.wikipedia.org/wiki/Hurdle_model#:\\~:text=A%20hurdle%20model%20is%20a,of%20the%20non%2Dzero%20values.\n\nclass of models for count data with both overdispersion and excess zeros;\\\ndifferent from zero-inflated models where the excess zeros are theorized to arise from two different processes; in the hurdle model, there is a model for P(x=0) and a separate model for P(x!=0)\n\nThe model includes: - A binary logit model to model whether the observation takes a positive count or not. - a truncated Poisson or Negative binomial model that only fits positive counts\n\nThis allows us to model: (1) Does the student get *any* questions right? (2) How many questions does the student get right?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl) #zero-inf and hurdle models \nlibrary(countreg) #rootogram\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 methods overwritten by 'countreg':\n  method                 from\n  print.zeroinfl         pscl\n  print.summary.zeroinfl pscl\n  summary.zeroinfl       pscl\n  coef.zeroinfl          pscl\n  vcov.zeroinfl          pscl\n  logLik.zeroinfl        pscl\n  predict.zeroinfl       pscl\n  residuals.zeroinfl     pscl\n  fitted.zeroinfl        pscl\n  terms.zeroinfl         pscl\n  model.matrix.zeroinfl  pscl\n  extractAIC.zeroinfl    pscl\n  print.hurdle           pscl\n  print.summary.hurdle   pscl\n  summary.hurdle         pscl\n  coef.hurdle            pscl\n  vcov.hurdle            pscl\n  logLik.hurdle          pscl\n  predict.hurdle         pscl\n  residuals.hurdle       pscl\n  fitted.hurdle          pscl\n  terms.hurdle           pscl\n  model.matrix.hurdle    pscl\n  extractAIC.hurdle      pscl\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'countreg'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:pscl':\n\n    hurdle, hurdle.control, hurdletest, zeroinfl, zeroinfl.control\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcd':\n\n    rootogram\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"countreg\", repos=\"http://R-Forge.R-project.org\")\n\n#SYNTAX OUTCOME ~ count model predictor | hurdle predictor\n\nh.1 <- pscl::hurdle(item_test_NABS ~ condition | condition , data = df_subjects,\n              zero.dist = \"binomial\", dist = \"poisson\", size = 8)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = zeroDist, gr = zeroGrad, par = c(start$zero, if (zero.dist\n== : unknown names in control: size\n```\n:::\n\n```{.r .cell-code}\nh.2 <- pscl::hurdle(item_test_NABS ~ condition | condition , data = df_subjects,\n              zero.dist = \"binomial\", dist = \"negbin\", size = 8)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n```\n:::\n\n```{.r .cell-code}\nsummary(h.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\npscl::hurdle(formula = item_test_NABS ~ condition | condition, data = df_subjects, \n    dist = \"poisson\", zero.dist = \"binomial\", size = 8)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.892 -0.818 -0.549  0.881  2.342 \n\nCount model coefficients (truncated poisson with log link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    1.7156     0.0653   26.29   <2e-16 ***\ncondition121   0.0447     0.0789    0.57     0.57    \nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -0.984      0.179   -5.50  3.7e-08 ***\ncondition121    1.054      0.235    4.48  7.4e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 10 \nLog-likelihood: -533 on 4 Df\n```\n:::\n\n```{.r .cell-code}\nsummary(h.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\npscl::hurdle(formula = item_test_NABS ~ condition | condition, data = df_subjects, \n    dist = \"negbin\", zero.dist = \"binomial\", size = 8)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.866 -0.794 -0.538  0.856  2.294 \n\nCount model coefficients (truncated negbin with log link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    1.7126     0.0728   23.54  < 2e-16 ***\ncondition121   0.0451     0.0880    0.51  0.60810    \nLog(theta)     3.1851     0.8732    3.65  0.00026 ***\nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -0.984      0.179   -5.50  3.7e-08 ***\ncondition121    1.054      0.235    4.48  7.4e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta: count = 24.169\nNumber of iterations in BFGS optimization: 20 \nLog-likelihood: -532 on 5 Df\n```\n:::\n\n```{.r .cell-code}\nrootogram(h.1)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n\n```{.r .cell-code}\nrootogram(h.2)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-45-2.png){width=672}\n:::\n\n```{.r .cell-code}\ncompare_performance(h.1,h.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName |  Model |      AIC | AIC weights |      BIC | BIC weights |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n---------------------------------------------------------------------------------------------------------------------------------\nh.1  | hurdle | 1073.583 |       0.537 | 1088.780 |       0.886 | 0.351 |     0.347 | 3.150 | 3.169 |    -2.479 |           0.043\nh.2  | hurdle | 1073.880 |       0.463 | 1092.876 |       0.114 | 0.363 |     0.359 | 3.150 | 3.174 |    -2.132 |           0.043\n```\n:::\n:::\n\n#### Beta Regression (% Correct)\n\nBeta regression on % correct (with standard transformation for including \\[0,1\\]) https://stats.stackexchange.com/questions/63350/how-to-interpret-the-coefficients-from-a-beta-regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(betareg)\n\nsub <- df_subjects %>% dplyr::select(condition, DV_percent_NABS)\nn = nrow(sub) %>% unlist()\nsub$dv_transformed = (sub$DV_percent_NABS * (n-1) + 0.5)/n\n\nhistogram(sub$dv_transformed)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhistogram(df_subjects$DV_percent_NABS)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmb <- betareg(dv_transformed ~ condition, data = sub)\n\nsummary(mb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nbetareg(formula = dv_transformed ~ condition, data = sub)\n\nStandardized weighted residuals 2:\n   Min     1Q Median     3Q    Max \n-1.057 -0.453 -0.216  0.541  1.690 \n\nCoefficients (mean model with logit link):\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -0.969      0.108   -8.97   <2e-16 ***\ncondition121    0.556      0.143    3.89   0.0001 ***\n\nPhi coefficients (precision model with identity link):\n      Estimate Std. Error z value Pr(>|z|)    \n(phi)   0.6604     0.0425    15.5   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  506 on 3 Df\nPseudo R-squared: 0.0725\nNumber of iterations: 12 (BFGS) + 1 (Fisher scoring) \n```\n:::\n\n```{.r .cell-code}\nplot(mb)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_hypotesting_files/figure-html/unnamed-chunk-46-6.png){width=672}\n:::\n:::\n",
    "supporting": [
      "4_sgc3A_hypotesting_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}