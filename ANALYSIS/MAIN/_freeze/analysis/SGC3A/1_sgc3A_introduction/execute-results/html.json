{
  "hash": "878edbab6a72b81fbcd52040e6a42f14",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | Introduction'\n---\n\n\\newpage\n\n# Introduction {#sec-SGC3A-introduction}\n\n**In Study 3A we explore the extent to which confronting a learner with an implicit obstacle (a mental impasse) influences their interpretation of the underlying coordinate system.** This is a hypothesis that emerged from analysis of Study 2, leading us to suspect that *presenting a learner with a situation that induces a state of impasse will increase the probability that learners experience a moment of insight, and in turn restructure their interpretation of the coordinate system.*\n\n+----------------------------------+-------------------------------------------------------------------------------------------------------+\n| ![](/analysis/utils/img/111.png) | **Control-Condition**\\                                                                                |\n|                                  | Demo: [111](https://limitless-plains-85018.herokuapp.com/?study=SGC3A&condition=111&session=WEB-DEMO) |\n+==================================+=======================================================================================================+\n| ![](/analysis/utils/img/121.png) | **Impasse-Condition**\\                                                                                |\n|                                  | Demo: [121](https://limitless-plains-85018.herokuapp.com/?study=SGC3A&condition=121&session=WEB-DEMO) |\n+----------------------------------+-------------------------------------------------------------------------------------------------------+\n\n: **SGC3A Study Conditions** {tbl-colwidths=\"\\[40,60\\]\"}\n\nIn the context of Study 2, an impasse state was (unintentionally) induced when the combination of question + data set yielded no available answer in the incorrect (cartesian) interpretation of the graph. In Study 3A, we test this hypothesis by comparing performance between a (treatment) group receiving impasse-inducing questions followed by normal questions, and a non-impasse control.\n\n::: {#fig-manipulation layout-ncol=\"2\"}\n![](static/stimuli/nonimpasse.png){#fig-control}\n\n![](static/stimuli/impasse.png){#fig-impasse}\n\nPosing a mental impasse\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(codebook) #data dictionary\nlibrary(kableExtra) #tables\nlibrary(tidyverse) #ALL THE THINGS\n\n#set some output options\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#IMPORT SUBJECTS DATA \ndf_subjects <- read_rds('analysis/SGC3A/data/1-study-level/sgc3a_participants.rds')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Participants by Condition and Data Collection Modality\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$mode, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Participants by Condition and Data Collection Modality</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Control Condition </th>\n   <th style=\"text-align:right;\"> Impasse Condition </th>\n   <th style=\"text-align:right;\"> Total for Period </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> lab-synch </td>\n   <td style=\"text-align:right;\"> 62 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 126 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> asynch </td>\n   <td style=\"text-align:right;\"> 96 </td>\n   <td style=\"text-align:right;\"> 108 </td>\n   <td style=\"text-align:right;\"> 204 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 158 </td>\n   <td style=\"text-align:right;\"> 172 </td>\n   <td style=\"text-align:right;\"> 330 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n### Hypotheses\n\n**Experimental Hypothesis**\\\n*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*\n\n-   H1A \\| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.\n-   H1B \\| Learners in the IMPASSE condition will score higher on the TEST Phase than learners in CONTROL.\n\n**Null Hypothesis**\\\n*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*\n\n**Exploratory Questions**\n\n-   Response Latency \\| Will learners in the IMPASSE condition will spend more time on the first question than learners in CONTROL?\\\n-   Consistency \\| How consistent are learners in their interpretation of the graph? Do they adopt an interpretation on the first question and hold constant? Or do they change interpretations from question to question? Are there any interpretations that serve as 'absorbing states' (i.e. once encountered, the learner does not exist this state).\\\n-   Time Course of Exploration \\| What is the relationship between response accuracy (and interpretation) and time spent on each item?\n-   Can exploration strategies be derived from mouse cursor activity?\n\n## METHODS\n\n### Design\n\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\n\nIndependent Variables:\n\n-   B-S (Scaffold: control,impasse)\n-   W-S (Item x 15)\n\nDependent Variables:\n\n-   Response Accuracy : Is the response triangular-correct?\n-   Response Interpretation : (derived) With which interpretation of the graph is the subject's response on an individual question consistent?\n-   Response Latency : Time from stimulus onset to clicking 'Submit' button: time in (s)\n\n### Materials\n\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. @fig-sample. The list of questions can be found [here](static/stimuli/sgcx_questions.csv).\n\n![Sample Question (Q=1) for Graph Comprehension Task](static/stimuli/sample_task.png){#fig-sample fig-alt=\"picture of multiple select question on the left, accompanied by a triangular model graph on the right\" fig-align=\"center\"}\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\n\n*The green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line. We hypothesize that this presents the reader with an obstacle, at which point they are forced to confront their interpretation of the coordinate system and (ideally) develop a new strategy.*\n\n![Sample Question (Q=1) graphs for each condition](static/stimuli/3A_conditions.png){#fig-conditions fig-alt=\"a triangle graph at left shows the correct (diagonal) path from the x-axis to the correct answer(datapoint f) in green, and an incorrect orthogonal projection from the x-axis to incorrect datapoint A.  At right, the same graph is depicted, but datapoint A no longer intersects the orthogonal projection from the xaxis.\"}\n\n### Procedure\n\nParticipants completed the study via a web-browser.\n\n\\(1\\) Upon starting, they submitted informed consent, before reading task instructions.\n\n\\(2\\) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n\n\\(3\\) Then participants completed an experimental block of 15 items.\n\n(3A) The first five items in the task are defined as the SCAFFOLDING block. In the IMPASSE condition, the first five questions included an IMPASSE problem state. For participants in the CONTROL condition, the dataset was structure such that there was always an available 'orthogonal answer' for the first 5 questions.\n\n(3B) The remaining 10 items are defined as the TESTING block. In both conditions, these questions were not structured as impasse (i.e. contained an available orthogonal answer)\n\n\\(4\\) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n### Sample\n\nData was collected by convenience sample of a university subject pool. Initial data (Fall 2017, Spring 2018) were collected in-person, with large groups of students simultaneously completing the study (independently) in a computer lab. In Fall 2021 and Winter 2022 we collected additional data to replicate results in a remote format (students completing the study asynchronously on their own computers).\n\n## ANALYSIS\n\n### Data Preparation {#sec-SGC3A-harmonize}\n\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\n-   completion status : \"success\" ; subject must have finished all parts of the study, including demographic questionnaire\n-   session ID: \\[in list\\] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\n-   browser interaction violations \\< 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\n-   self-rated effort \\> 2; subjects who reported, \"not trying hard/rushing through questions\" or \"started out trying hard but giving up at some point\" were excluded from analysis.\n-   attention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\nBefore analysis, data files from individual data collection periods are harmonized into a common data format.\n\n+-----------------------------------------------------------------------------------------------------------------+---------------------+\n| Pre-Requisite                                                                                                   | Followed By         |\n+=================================================================================================================+=====================+\n| spring17_clean_data.Rmd <br> spring18_clean_data.Rmd <br> fall21_clean_data.Rmd <br> winter2022_clean_sgc3a.Rmd | 2_sgc3A_scoring.qmd |\n+-----------------------------------------------------------------------------------------------------------------+---------------------+\n\nData for study SGC_3A were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n| Period      | Modality                               |\n|-------------|----------------------------------------|\n| Fall 2017   | in person, SONA groups in computer lab |\n| Spring 2018 | in person, SONA groups in computer lab |\n| Fall 2021   | asynchronous, online, SONA             |\n| Winter 2022 | asynchronous, online, SONA             |\n\nData collected in Fall 2017 (in person pilot) were analyzed and published as a Cognitive Science Society conference paper (\"When Graph Comprehension is an Insight Problem). Additional data were collected in person in Spring 2018. Combined, Fall 2017 and Spring 2018 constitute the original SGC_3A study, conducted in person. Data collected in Fall 2021, Winter 2022 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application. The replication study was conducted to validate the use of remote, asynchronous data collection during the Covid-19 pandemic.  \n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single *harmonized* data file for analysis (one for participants, one for items).\n\n#### Participants\n\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame `df_subjects` containing one row for each subject (across all periods). Note that we *are not* discarding any *response* data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\n\n*Note that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3A/data/0-session-level/fall17_sgc3a_participants.csv\" #COGSCI18 data\nspring18 <- \"analysis/SGC3A/data/0-session-level/spring18_sgc3a_participants.csv\"\nfall21 <- \"analysis/SGC3A/data/0-session-level/fall21_sgc3a_participants.csv\"\nwinter22 <- \"analysis/SGC3A/data/0-session-level/winter22_sgc3a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  dplyr::select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_condition = recode_factor(condition, \"111\" = \"control\", \"121\" =  \"impasse\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#IMPORT OSPAN DATA \nospan <- read_csv(\"analysis/SGC3A/data/0-session-level/fall21_scored_ospan.csv\") %>% mutate(\n  subject = SUBJECTID\n) %>% dplyr::select(-SUBJECTID)\n\n#MERGE OSPAN DATA WITH SGC DATA \n#special dataframe with just ospan subjects\n#should be 133 subjects. Some of the 200 who completed the task failed the \n#attention check question. Others were allocated to SGC4A pilot. \n#note that rather than adding OSPAN data to main dataframe, the after-scored data\n#will be manually joined to df_ospan during exploratory analysis\ndf_ospan <- df_subjects %>% filter(\n  subject %in% ospan$subject\n) %>% merge(ospan)  \n\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,fall21,spring18,winter22)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Participants by Condition and Data Collection Period</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Control Condition </th>\n   <th style=\"text-align:right;\"> Impasse Condition </th>\n   <th style=\"text-align:right;\"> Total for Period </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> fall17 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:right;\"> 54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> spring18 </td>\n   <td style=\"text-align:right;\"> 35 </td>\n   <td style=\"text-align:right;\"> 37 </td>\n   <td style=\"text-align:right;\"> 72 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fall21 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 71 </td>\n   <td style=\"text-align:right;\"> 139 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> winter22 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 37 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 158 </td>\n   <td style=\"text-align:right;\"> 172 </td>\n   <td style=\"text-align:right;\"> 330 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Subset of Participants who completed OSPAN TASK [Fall 2021]\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_ospan$mode, df_ospan$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Subset of Participants who completed OSPAN TASK [Fall 2021]</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Control Condition </th>\n   <th style=\"text-align:right;\"> Impasse Condition </th>\n   <th style=\"text-align:right;\"> Total for Period </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> lab-synch </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> asynch </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n#### Items\n\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame `df_items` containing one row for each *graph comprehension task question* (qs=15) (across all periods). A second data frame `df_freeresponse` contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we *do not* discard any *response* data. Rather, we *do* discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3A/data/0-session-level/fall17_sgc3a_blocks.csv\"\nspring18 <- \"analysis/SGC3A/data/0-session-level/spring18_sgc3a_blocks.csv\"\nfall21 <- \"analysis/SGC3A/data/0-session-level/fall21_sgc3a_blocks.csv\"\nwinter22 <- \"analysis/SGC3A/data/0-session-level/winter22_sgc3a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% dplyr::select(q,relation) %>% unique()\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% dplyr::select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% dplyr::select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#add back pretty condition \ndf_items <- df_items %>% mutate(\n  pretty_condition = recode_factor(condition, \"111\" = \"control\", \"121\" =  \"impasse\"),\n  pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,fall21,spring18,winter22, map_relations)\n```\n:::\n\n#### Validation\n\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n::: {.cell}\n\n```{.r .cell-code}\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n#### Export\n\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC3A/data/1-study-level/sgc3a_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC3A/data/1-study-level/sgc3a_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC3A/data/1-study-level/sgc3a_freeresponse.csv\", row.names = FALSE)\nwrite.csv(df_ospan,\"analysis/SGC3A/data/1-study-level/sgc3a_ospan.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC3A/data/1-study-level/sgc3a_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC3A/data/1-study-level/sgc3a_items.rds\") # to R data structure file\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}