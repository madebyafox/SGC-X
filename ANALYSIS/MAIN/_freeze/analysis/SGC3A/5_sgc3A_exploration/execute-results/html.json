{
  "hash": "976e3eb12428d254a91ac9dd190dfc20",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 5 Exploratory Analyses'\n---\n\n\\newpage\n\n# Exploratory Analyses {#sec-SGC3A-exploration}\n\n**TODO**\\\n- response consistency - clarify core questions being asked\\\n- review models already created in ARCHIVE?\\\n- explore response consistency - fix references\n- what predicts consistency?\n- consider zero inflated / hurdles with ospan score as preditor\n\n*The purpose of this notebook is exploratory analyses of data collected for study SGC3A.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#misc utilities\nlibrary(Hmisc) # %nin% operator\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\nlibrary(jtools)\nlibrary(pwr) #power analysis\nlibrary(mosaic) #favstats\n\n#visualization\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz \nlibrary(ggstatsplot) #plots with stats\n\n#models and performance\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(equatiomatic) #extract model equation\nlibrary(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models \nlibrary(lmerTest) #for CIs in glmer \nlibrary(ggeffects) #visualization log regr models\nlibrary(nnet) #multinomial logistic regression [not mixed]\nlibrary(mclogit) #frequentist mixed multinomial logistic regression [mblogit]\nlibrary(brms) #bayesian mixed multinomials [+ other bayesian reg models]\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\ntheme_set(theme_minimal()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT DATA \ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\n#weird... doesn't respect project level execute dir in yml unless included in index; otherwise breaks render\n```\n:::\n\nExploratory Questions\n\nConsistency \\| How consistent are learners in their interpretation of the graph? Do they adopt an interpretation on the first question and hold constant? Or do they change interpretations from question to question? Are there any interpretations that serve as 'absorbing states' (i.e. once encountered, the learner does not exist this state).\n\nTime Course of Exploration \\| What is the relationship between response accuracy (and interpretation) and time spent on each item?\n\nCan exploration strategies be derived from mouse cursor activity?\n\n-   does response time predict interpretation vs. non interpretation?\n\nTODO: - does impasse yield different exploration behavior? (characterize mouse) - does impasse yield more time on task? (characterize response time ? number of answers then de-selected?)\n\nTODO: Think about characterizing how variable the interpretations are across a participant. Do they form an interpretation and hold it constant? Or do they change question to question.\n\n## WORKING MEMORY \n\nDuring the 2021-2022 online replication study, participants completed a working memory task —the OSPAN task- after completing the SGC3A study.  We added this task to explore possible sources of variance between individuals on the graph comprehension task.  \n\n**Here we address the question: Does working memory (as measured by the OSPAN task) help explain performance on the interval graph comprehension task?**\n\n_First we join the load data for the subset of SGC3A participants who completed the OSPAN task. Note that this is a slightly lower n than the online replication, as a couple of participants failed to finish the OSPAN task, and will be excluded from this analysis._\n\n::: {.cell}\n\n```{.r .cell-code}\n#LOAD OSPAN PARTICIPANTS\ndf_ospan <- read_csv(\"analysis/SGC3A/data/1-study-level/sgc3a_ospan.csv\") #not scored\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 133 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (19): subject, term, mode, gender, language, schoolyear, country, effort...\ndbl  (7): condition, age, totaltime_m, order_num, math_acc, order_acc, weighted\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsgc3a <- read_rds(\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds\") #not scored\nsgc3a_items <- read_rds(\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds\") #not scored\n\n##ADD OSPAN DATA TO SUBJECT LEVEL DATA\n\n#select needed ospan columns\ndf_ospan <- df_ospan %>% rename( OSPAN.weighted = weighted, OSPAN.math_acc = math_acc,\n                                 OSPAN.order_acc = order_acc) %>% dplyr::select(\n                                 subject, OSPAN.weighted, OSPAN.math_acc, OSPAN.order_acc) %>% \n  mutate(\n      z_ospan = zscore(OSPAN.weighted),\n      ospan_split = as.factor(OSPAN.weighted > median(OSPAN.weighted)),\n      ospan_split = recode_factor(ospan_split, \"FALSE\" = \"low-memory\", \"TRUE\" = \"high-memory\")\n    \n  )\n\n#get only the participants for whom we have ospan data \ndf_sgc3a <- sgc3a %>% filter(subject %in% df_ospan$subject)\n\n#add q1 state field [3 category summary of interepretation]\ndf_sgc3a <- df_sgc3a %>% mutate(\n  item_q1_state =  recode_factor(item_q1_SCALED, \n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n)\n\n#join the ospan columns to the scored sgc3a data \ndf_sgc3a <- merge(df_sgc3a, df_ospan)\n\n\n##ADD OSPAN DATA TO ITEM LEVEL DATA\n#get only the participants for whom we have ospan data \ndf_sgc3a_items <- sgc3a_items %>% filter(subject %in% df_ospan$subject) \ndf_sgc3a_items <- merge(df_sgc3a_items, df_ospan)\n\n\n#define dataset\ndf_s <- df_sgc3a\ndf_i <- df_sgc3a_items\n```\n:::\n\n_What is the distribution of performance on the OSPAN task?_\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of OSPAN Task Accuracy\"\nospan.stats <- rbind(\n  \"MATH\" = df_s %>% dplyr::select(OSPAN.math_acc) %>% unlist() %>% favstats(),\n  \"ORDER\" = df_s %>%  dplyr::select(OSPAN.order_acc) %>% unlist() %>% favstats(),\n  \"WEIGHTED\" = df_s %>% dplyr::select(OSPAN.weighted) %>% unlist() %>% favstats()\n\n)\nospan.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"MATH = %correct of all math questions;\n           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct\", general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;border-bottom: 0;'>\n<caption>Descriptive Statistics of OSPAN Task Accuracy</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> MATH </td>\n   <td style=\"text-align:right;\"> 0.517 </td>\n   <td style=\"text-align:right;\"> 0.897 </td>\n   <td style=\"text-align:right;\"> 0.931 </td>\n   <td style=\"text-align:right;\"> 0.966 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.924 </td>\n   <td style=\"text-align:right;\"> 0.085 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ORDER </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.533 </td>\n   <td style=\"text-align:right;\"> 0.733 </td>\n   <td style=\"text-align:right;\"> 0.867 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.678 </td>\n   <td style=\"text-align:right;\"> 0.253 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WEIGHTED </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 13.448 </td>\n   <td style=\"text-align:right;\"> 20.276 </td>\n   <td style=\"text-align:right;\"> 24.828 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 19.082 </td>\n   <td style=\"text-align:right;\"> 7.391 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<span style=\"font-style: italic;\">Note: </span> <sup></sup> MATH = %correct of all math questions;<br>           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# #GGFORMULA | DENSITY HISTOGRAM \n  gf_dhistogram(~z_ospan, data = df_s) +\n  labs(x = \"OSPAN (weighted) score\",\n       y = \"% of subjects\",\n       title = \"Distribution of OSPAN SCORE\",\n       subtitle = \"\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-SUBJ-OSPAN-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_s, x = \"z_ospan\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\")) +\n  labs( title = \"Distribution of OSPAN Score\",\n        subtitle =\"The shape of the distribution of OSPAN scores is similar across conditions\",\n        x = \"OSPAN (weighted) score\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-SUBJ-OSPAN-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGSTATS\nggbetweenstats(y = z_ospan, x = pretty_condition, data = df_s,\n               type = \"parametric\", var.equal = FALSE,\n               title = \"Independent Samples T-Test indicates little difference between means by Condition\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-SUBJ-OSPAN-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#PROPORTIONAL BAR CHART OF MED SPLIT BY CONDITION\nggbarstats( x = pretty_condition, y = ospan_split, data = df_s) + labs(\n  title = \"The Proportion of high (vs) low WM scores by does appear to differ by condition\"\n)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-SUBJ-OSPAN-4.png){width=672}\n:::\n:::\n_As we would expect, there is not a meaningful difference between the means (or shape of distribution) of the outcome weighted OSPAN by condition, nor between the proportions of high (vs) low scores after taking a median split of the weighted OSPAN score._\n\n\n\n### OSPAN ~ Q1 Accuracy\n\n**Does the OSPAN score help explain variance in Q1 Accuracy?**\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA\ndf_s = df_s #just for reference\n\n\n##STATSPLOT\nggstatsplot::grouped_ggbarstats(data = df_s, \n                                    y = ospan_split, x = item_q1_NABS, \n                                    grouping.var = pretty_condition,\n                                    type = \"nonparametric\", equal.var = FALSE,\n                                    annotation.args = list(\n    title = \"Potential INTERACTION between condition and WM Score\"))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n_It appears as though there may be an interaction between WM score and CONDITION, such that in the control condition, participants perform equally well (or poorly, as the case may be), regardless of of WM score. In the impasse condition, readers with the impasse condition have a higher proportion of correct responses than readers with low WM scores. One possible explanation of these observations is that perhaps higher WM capacity enables readers to take advantage of the implicit scaffolding the impasse provides._\n\n#### Statistical Tests\n\n\nTo explore the relationship between ACCURACY, CONDITION and OSPAN score, we can run two separate CHI square tests evaluating independence of condition and accuracy, one for each level of working memory (the groups are roughly equal due to the median split). If WM interacts with condition, we should expect to see one chi square indicate independence (low working memory) and one not (high working memory).  Additionally, we can compute a Breslow-Day test for Homogeneity of Odds Ratios, to test the null hypothesis that the odds ratios for accuracy by condition do not differ across levels of working memory. \n::: {.cell}\n\n```{.r .cell-code}\n#IS ACCURACY INDEPENDENT OF CONDITION for low WM?\npaste(\"Accuracy independent of CONDITION for LOW WM?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Accuracy independent of CONDITION for LOW WM?\"\n```\n:::\n\n```{.r .cell-code}\nx <- df_s %>% filter(ospan_split == \"low-memory\")\n(t <- table(x$item_q1_NABS, x$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    111 121\n  0  28  31\n  1   3   5\n```\n:::\n\n```{.r .cell-code}\n# chisq.test(t)\nchiSquare(item_q1_NABS ~ condition, data = x)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(x, y): Chi-squared approximation may be incorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPearson Chi-square Tests    Response variable:item_q1_NABS\n\n          chisquare df chisquare-df     P  n\ncondition      0.02  1        -0.98 0.879 67\n```\n:::\n\n```{.r .cell-code}\n# YES, IT IS (EXPECTED)\n\n#IS ACCURACY INDEPENDENT OF CONDITION for low WM?\npaste(\"Accuracy independent of CONDITION for HIGH WM?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Accuracy independent of CONDITION for HIGH WM?\"\n```\n:::\n\n```{.r .cell-code}\nx <- df_s %>% filter(ospan_split == \"high-memory\")\n(t <- table(x$item_q1_NABS, x$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    111 121\n  0  30  21\n  1   4  11\n```\n:::\n\n```{.r .cell-code}\n# chisq.test(t)\nchiSquare(item_q1_NABS ~ condition, data = x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPearson Chi-square Tests    Response variable:item_q1_NABS\n\n          chisquare df chisquare-df      P  n\ncondition       3.6  1          2.6 0.0579 66\n```\n:::\n\n```{.r .cell-code}\n# YES, IT IS (EXPECTED)\n\nlibrary(DescTools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'DescTools':\n  method         from \n  reorder.factor gdata\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'DescTools'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggdist':\n\n    Mode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:mosaic':\n\n    MAD\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:jtools':\n\n    %nin%\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:Hmisc':\n\n    %nin%, Label, Mean, Quantile\n```\n:::\n\n```{.r .cell-code}\n#Calculates the Breslow-Day test of homogeneity for a 2 \\times 2 \\times k2×2×k table, in order to investigate if all #kk strata have the same OR. If OR is not given, the Mantel-Haenszel estimate is used.\nt <- table(df_s$item_q1_NABS, df_s$ospan_split, df_s$condition)\nBreslowDayTest(t, OR = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBreslow-Day test on Homogeneity of Odds Ratios\n\ndata:  t\nX-squared = 4, df = 1, p-value = 0.04\n```\n:::\n:::\n\n_A Brewslow-Day Test of homogeneity of Odds Ratios allows us to test the null hypothesis that the odds for each response outcome (correct, incorrect) are the same for each condition across each level of working memory. Essentially, that the odds ratio of a positive response for each condition does not differ by working memory.  The significant p-value for this test allows us to reject this null hypothesis and conclude we have evidence that working memory score changes the odds ratio of a correct vs incorrect response across conditions. \n\n#### Logistic Regression\n\n**Logistic Regression** Q1 Accuracy ~ Condition + OSPAN\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#DATASETUP\ndf <- df_i %>% filter(q==1) %>% mutate(\n  accuracy = as.factor(score_niceABS),\n  l_condition = fct_relevel(condition, \"121\"),\n  l_split = fct_relevel(ospan_split, \"high-memory\")\n)\n\n\n#:::::::: FIT MODELS\n\n#fit empty model\nm.0 <- glm(  accuracy ~ 1, data = df, family = \"binomial\")\n# summary(m.0)\n\n#fit condition as predictor \nm.c <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n#summary(m.c)\n\n#is condition better than empty model?\nprint(\"Is Condition model better than empty model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is Condition model better than empty model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect YES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect YES\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.0, m.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.c  |   glm |  2 |       1 | 3.88 | 0.049\n```\n:::\n\n```{.r .cell-code}\n#fit OSPAN as predictor \nm.o <- glm( accuracy ~ ospan_split, data = df, family = \"binomial\")\n#summary(m.o)\n\n#is ospan better than empty model?\nprint(\"Is OSPAN model better than empty model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is OSPAN model better than empty model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect NO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect NO\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.0, m.o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.o  |   glm |  2 |       1 | 2.74 | 0.098\n```\n:::\n\n```{.r .cell-code}\n# fit condition AND OSPAN MAIN EFFECTS\nm.co <- glm( accuracy ~ pretty_condition + ospan_split, data = df, family = \"binomial\")\nsummary(m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition + ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.870  -0.599  -0.559  -0.373   2.323  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.629      0.523   -5.03    5e-07 ***\npretty_conditionimpasse    1.002      0.499    2.01    0.045 *  \nospan_splithigh-memory     0.851      0.487    1.75    0.081 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 115.42  on 130  degrees of freedom\nAIC: 121.4\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# car::Anova(m.cw)\n\n#is CONDITION + OSPAN better than CONDITION model?\nprint(\"Is CONDITION + OSPAN model better than CONDITION model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is CONDITION + OSPAN model better than CONDITION model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect NO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect NO\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.c, m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.c  |   glm |  2 |         |      |      \nm.co |   glm |  3 |       1 | 3.19 | 0.074\n```\n:::\n\n```{.r .cell-code}\n# fit condition AND OSPAN with INTERACTION \nm.cio <- glm( accuracy ~  pretty_condition:ospan_split + pretty_condition + ospan_split , data = df, family = \"binomial\")\n# summary(m.cio)\n# car::Anova(m.ciw)\n\n#is CONDITION + OSPAN IXN better than CONDITION model?\nprint(\"Is CONDITION + OSPAN IXN model better than CONDITION model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is CONDITION + OSPAN IXN model better than CONDITION model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect YES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect YES\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.cio, m.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.cio |   glm |  4 |         |      |      \nm.c   |   glm |  2 |      -2 | 4.08 | 0.130\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(m.3$coefficients, lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(m.3$coefficients, lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n```\n:::\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition:ospan_split + pretty_condition + \n    ospan_split, family = \"binomial\", data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.918  -0.547  -0.500  -0.451   2.161  \n\nCoefficients:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.234      0.607   -3.68\npretty_conditionimpasse                           0.409      0.775    0.53\nospan_splithigh-memory                            0.219      0.808    0.27\npretty_conditionimpasse:ospan_splithigh-memory    0.959      1.011    0.95\n                                               Pr(>|z|)    \n(Intercept)                                     0.00024 ***\npretty_conditionimpasse                         0.59782    \nospan_splithigh-memory                          0.78656    \npretty_conditionimpasse:ospan_splithigh-memory  0.34295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 114.54  on 129  degrees of freedom\nAIC: 122.5\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                             LR Chisq Df Pr(>Chisq)  \npretty_condition                 4.33  1      0.037 *\nospan_split                      3.19  1      0.074 .\npretty_condition:ospan_split     0.89  1      0.346  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n##### Inference\n\nSignificant main effect condition, non significant main effect of OSPAN, non significant interaction.\n\nAlthough we can see (ref plots below) that high_working memory participants were more likely to correctly answer Q1, the difference in proportions for this sample size (~30 per cell in the 2x2 contingency table of condition X OSPAN score) failed to reach statistical significance at the 0.05 alpha level.\n\n##### Visualize\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m.c, type = \"eff\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m.cio, type = \"int\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n##### Diagnostics\n::: {.cell}\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n122.538 | 134.099 |     0.066 | 0.365 | 0.942 |    0.431 |    -4.234 |           0.064 | 0.733\n```\n:::\n\n```{.r .cell-code}\n#DIAGNOSTICS\ncheck_model(m.cio)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### OSPAN ~ Q1 Interpretation\n\n**Does the OSPAN score help explain variance in Q1 interpetation?**\n\n::: {.cell}\n\n```{.r .cell-code}\n##STATSPLOT\nggstatsplot::grouped_ggbarstats(data = df_s, \n                                    y = ospan_split, x = item_q1_state, \n                                    grouping.var = pretty_condition,\n                                    type = \"nonparametric\", equal.var = FALSE,\n                                    annotation.args = list(\n    title = \"Potential INTERACTION between condition and WM Score\"))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n_Again we see a potential interaction between WM score and CONDITION looking at the interpretation indicated by responses on the first question. In the control condition, low and high working memory participants offered very similar proportions of each type of interpretation (with the high working memory subjects offering slightly more unknown and tri-like interpretations). Alternatively in the impasse condition, high working memory Ss have substantially fewer orthogonal interpretations, with far more triangular and unknown interpretations._\n\n#### Statistical Tests\n\n\nTo explore the relationship between INTERPREATION STATE, CONDITION and OSPAN score, we can run two separate CHI square tests evaluating independence of condition and interpretation, one for each level of working memory (the groups are roughly equal due to the median split). If WM interacts with condition, we should expect to see one chi square indicate independence (low working memory) and one not (high working memory).  Additionally, we can compute a Breslow-Day test for Homogeneity of Odds Ratios, to test the null hypothesis that the odds ratios for accuracy by condition do not differ across levels of working memory. \n::: {.cell}\n\n```{.r .cell-code}\n#IS INTERPRETATION STATE INDEPENDENT OF CONDITION for low WM?\npaste(\"Accuracy independent of CONDITION for LOW WM?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Accuracy independent of CONDITION for LOW WM?\"\n```\n:::\n\n```{.r .cell-code}\nx <- df_s %>% filter(ospan_split == \"low-memory\")\n(t <- table(x$item_q1_state, x$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            111 121\n  orth-like  26  15\n  unknown     1  13\n  tri-like    4   8\n```\n:::\n\n```{.r .cell-code}\n# chisq.test(t)\nchiSquare(item_q1_state ~ condition, data = x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPearson Chi-square Tests    Response variable:item_q1_state\n\n          chisquare df chisquare-df      P  n\ncondition      14.3  2         12.3 0.0008 67\n```\n:::\n\n```{.r .cell-code}\n# NOT expected\n\n#IS ACCURACY INDEPENDENT OF CONDITION for HIGH WM?\npaste(\"Accuracy independent of CONDITION for HIGH WM?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Accuracy independent of CONDITION for HIGH WM?\"\n```\n:::\n\n```{.r .cell-code}\nx <- df_s %>% filter(ospan_split == \"high-memory\")\n(t <- table(x$item_q1_state, x$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            111 121\n  orth-like  27   3\n  unknown     2  13\n  tri-like    5  16\n```\n:::\n\n```{.r .cell-code}\n# chisq.test(t)\nchiSquare(item_q1_state ~ condition, data = x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPearson Chi-square Tests    Response variable:item_q1_state\n\n          chisquare df chisquare-df P  n\ncondition        33  2           31 0 66\n```\n:::\n\n```{.r .cell-code}\n# YES, IT IS (EXPECTED)\n\nlibrary(DescTools)\n#Calculates the Breslow-Day test of homogeneity for a 2 \\times 2 \\times k2×2×k table, in order to investigate if all #kk strata have the same OR. If OR is not given, the Mantel-Haenszel estimate is used.\nt <- table(df_s$item_q1_state, df_s$ospan_split, df_s$condition)\nBreslowDayTest(t, OR = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tBreslow-Day test on Homogeneity of Odds Ratios\n\ndata:  t\nX-squared = -56, df = 1, p-value = 1\n```\n:::\n:::\n\nA Brewslow-Day Test of homogeneity of Odds Ratios allows us to test the null hypothesis that the odds for each response outcome (orth-like, unknown, tri-like) are the same for each condition across each level of working memory. Essentially, that the odds ratio of a positive response for each condition does not differ by working memory.  \n\n_We must reject the null hypothesis that (for low-working memory participants) condition and interpretation are independent. They do appear to be related, such that even for low-working memory participants, the impasse condition yields many more unknown and triangle-like responses than the control condition.  Together with the non-significant p-value for that does not allow us to reject the null hypothesis of homogeneous odds ratios across levels of working memory score, we do not have evidence of an interaction between working memory score and INTERPRETATION on question 1. \n\n#### Logistic Regression\n\n**Logistic Regression** Q1 Accuracy ~ Condition + OSPAN\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#DATASETUP\ndf <- df_i %>% filter(q==1) %>% mutate(\n  accuracy = as.factor(score_niceABS),\n  l_condition = fct_relevel(condition, \"121\"),\n  l_split = fct_relevel(ospan_split, \"high-memory\")\n)\n\n#:::::::: FIT MODELS\n\n#fit empty model\nm.0 <- glm(  accuracy ~ 1, data = df, family = \"binomial\")\n# summary(m.0)\n\n#fit condition as predictor \nm.c <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n#summary(m.c)\n\n#is condition better than empty model?\nprint(\"Is Condition model better than empty model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is Condition model better than empty model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect YES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect YES\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.0, m.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.c  |   glm |  2 |       1 | 3.88 | 0.049\n```\n:::\n\n```{.r .cell-code}\n#fit OSPAN as predictor \nm.o <- glm( accuracy ~ ospan_split, data = df, family = \"binomial\")\n#summary(m.o)\n\n#is ospan better than empty model?\nprint(\"Is OSPAN model better than empty model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is OSPAN model better than empty model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect NO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect NO\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.0, m.o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.o  |   glm |  2 |       1 | 2.74 | 0.098\n```\n:::\n\n```{.r .cell-code}\n# fit condition AND OSPAN MAIN EFFECTS\nm.co <- glm( accuracy ~ pretty_condition + ospan_split, data = df, family = \"binomial\")\nsummary(m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition + ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.870  -0.599  -0.559  -0.373   2.323  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.629      0.523   -5.03    5e-07 ***\npretty_conditionimpasse    1.002      0.499    2.01    0.045 *  \nospan_splithigh-memory     0.851      0.487    1.75    0.081 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 115.42  on 130  degrees of freedom\nAIC: 121.4\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# car::Anova(m.cw)\n\n#is CONDITION + OSPAN better than CONDITION model?\nprint(\"Is CONDITION + OSPAN model better than CONDITION model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is CONDITION + OSPAN model better than CONDITION model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect NO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect NO\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.c, m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.c  |   glm |  2 |         |      |      \nm.co |   glm |  3 |       1 | 3.19 | 0.074\n```\n:::\n\n```{.r .cell-code}\n# fit condition AND OSPAN with INTERACTION \nm.cio <- glm( accuracy ~  pretty_condition:ospan_split + pretty_condition + ospan_split , data = df, family = \"binomial\")\n# summary(m.cio)\n# car::Anova(m.ciw)\n\n#is CONDITION + OSPAN IXN better than CONDITION model?\nprint(\"Is CONDITION + OSPAN IXN model better than CONDITION model?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Is CONDITION + OSPAN IXN model better than CONDITION model?\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Expect YES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Expect YES\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.cio, m.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.cio |   glm |  4 |         |      |      \nm.c   |   glm |  2 |      -2 | 4.08 | 0.130\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(m.3$coefficients, lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(m.3$coefficients, lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n```\n:::\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition:ospan_split + pretty_condition + \n    ospan_split, family = \"binomial\", data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.918  -0.547  -0.500  -0.451   2.161  \n\nCoefficients:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.234      0.607   -3.68\npretty_conditionimpasse                           0.409      0.775    0.53\nospan_splithigh-memory                            0.219      0.808    0.27\npretty_conditionimpasse:ospan_splithigh-memory    0.959      1.011    0.95\n                                               Pr(>|z|)    \n(Intercept)                                     0.00024 ***\npretty_conditionimpasse                         0.59782    \nospan_splithigh-memory                          0.78656    \npretty_conditionimpasse:ospan_splithigh-memory  0.34295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 114.54  on 129  degrees of freedom\nAIC: 122.5\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                             LR Chisq Df Pr(>Chisq)  \npretty_condition                 4.33  1      0.037 *\nospan_split                      3.19  1      0.074 .\npretty_condition:ospan_split     0.89  1      0.346  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n##### Inference\n\nMain effect of condition, no main effect of OSPAN and non significant interaction. \n\nAlthough we can see (ref plots below) that high_working memory participants were more likely to correctly answer Q1, the difference in proportions for this sample size (~30 per cell in the 2x2 contingency table of condition X OSPAN score) failed to reach statistical significance at the 0.05 alpha level.\n\n##### Visualize\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m.c, type = \"eff\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m.cio, type = \"int\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n:::\n\n##### Diagnostics\n::: {.cell}\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n122.538 | 134.099 |     0.066 | 0.365 | 0.942 |    0.431 |    -4.234 |           0.064 | 0.733\n```\n:::\n\n```{.r .cell-code}\n#DIAGNOSTICS\ncheck_model(m.cio)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### OSPAN ~ Test Phase Accuracy \n\n**Does the OSPAN score help explain variance in test phase accuracy?**\n\n::: {.cell}\n\n```{.r .cell-code}\n##SETUP DATA\ndf <- df_s\n\n##STATSPLOT\nggstatsplot::grouped_ggbetweenstats(data = df, \n                                    y = item_test_NABS, x = ospan_split, \n                                    grouping.var = pretty_condition,\n                                    type = \"nonparametric\", equal.var = FALSE,\n                                    annotation.args = list(\n    title = \"Potential INTERACTION between condition and WM Score\"))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n_There appears to be an interaction between CONDITION and OSPAN score such that only participants with high working memory scores had better performance in the impasse condition. This could potential be driving the effect of the impasse condition._\n\n#### Linear Regression\n\n##### Fit Model\n::: {.cell}\n\n```{.r .cell-code}\n#PREP DATA\ndf_s <- df_s %>% mutate(\n  c_acc = scale(item_test_NABS), #mean centered accuracy score\n  med_acc = scale(item_test_NABS, center = median(item_test_NABS), scale = F)\n)\n\n#:::::::: FIT MODELS\n\n#empty model\nm.0 <- lm( data = df_s, item_test_NABS ~ 1)\n# summ(m.0)\n\n#condition predictor\nm.c <- lm( data = df_s, item_test_NABS ~ pretty_condition)\n#summ(m.c)\n\npaste(\"Condition predictor improves fit?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Condition predictor improves fit?\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.c, m.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.c  |    lm |  3 |         |      |      \nm.0  |    lm |  2 |      -1 | 8.27 | 0.004\n```\n:::\n\n```{.r .cell-code}\n#add ospan predictor\nm.co <- lm( data = df_s, item_test_NABS ~ pretty_condition + ospan_split)\nsummary(m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_NABS ~ pretty_condition + ospan_split, \n    data = df_s)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3.25  -2.17  -1.17   1.83   7.39 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)   \n(Intercept)                0.608      0.459    1.32   0.1877   \npretty_conditionimpasse    1.564      0.518    3.02   0.0031 **\nospan_splithigh-memory     1.074      0.518    2.07   0.0403 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.98 on 130 degrees of freedom\nMultiple R-squared:  0.0894,\tAdjusted R-squared:  0.0754 \nF-statistic: 6.38 on 2 and 130 DF,  p-value: 0.00227\n```\n:::\n\n```{.r .cell-code}\npaste(\"Condition + OSPAN improves fit?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Condition + OSPAN improves fit?\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.c, m.co)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.c  |    lm |  3 |         |      |      \nm.co |    lm |  4 |       1 | 4.29 | 0.038\n```\n:::\n\n```{.r .cell-code}\n#add interaction term  \nm.cio <- lm( data = df_s, item_test_NABS ~ pretty_condition + ospan_split + pretty_condition:ospan_split)\nsummary(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_NABS ~ pretty_condition + ospan_split + \n    pretty_condition:ospan_split, data = df_s)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3.75  -1.72  -1.13   2.25   6.87 \n\nCoefficients:\n                                               Estimate Std. Error t value\n(Intercept)                                      1.1290     0.5307    2.13\npretty_conditionimpasse                          0.5932     0.7240    0.82\nospan_splithigh-memory                           0.0769     0.7338    0.10\npretty_conditionimpasse:ospan_splithigh-memory   1.9509     1.0265    1.90\n                                               Pr(>|t|)  \n(Intercept)                                       0.035 *\npretty_conditionimpasse                           0.414  \nospan_splithigh-memory                            0.917  \npretty_conditionimpasse:ospan_splithigh-memory    0.060 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.95 on 129 degrees of freedom\nMultiple R-squared:  0.114,\tAdjusted R-squared:  0.0936 \nF-statistic: 5.55 on 3 and 129 DF,  p-value: 0.0013\n```\n:::\n\n```{.r .cell-code}\npaste(\"Condition : OSPAN interaction improves fit?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Condition : OSPAN interaction improves fit?\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.co, m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.co  |    lm |  4 |         |      |      \nm.cio |    lm |  5 |       1 | 3.61 | 0.057\n```\n:::\n:::\n##### Describe \n\n::: {.cell}\n\n```{.r .cell-code}\n#Describe \nsummary(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = item_test_NABS ~ pretty_condition + ospan_split + \n    pretty_condition:ospan_split, data = df_s)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3.75  -1.72  -1.13   2.25   6.87 \n\nCoefficients:\n                                               Estimate Std. Error t value\n(Intercept)                                      1.1290     0.5307    2.13\npretty_conditionimpasse                          0.5932     0.7240    0.82\nospan_splithigh-memory                           0.0769     0.7338    0.10\npretty_conditionimpasse:ospan_splithigh-memory   1.9509     1.0265    1.90\n                                               Pr(>|t|)  \n(Intercept)                                       0.035 *\npretty_conditionimpasse                           0.414  \nospan_splithigh-memory                            0.917  \npretty_conditionimpasse:ospan_splithigh-memory    0.060 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.95 on 129 degrees of freedom\nMultiple R-squared:  0.114,\tAdjusted R-squared:  0.0936 \nF-statistic: 5.55 on 3 and 129 DF,  p-value: 0.0013\n```\n:::\n\n```{.r .cell-code}\nanova(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: item_test_NABS\n                              Df Sum Sq Mean Sq F value Pr(>F)   \npretty_condition               1     75    75.5    8.65 0.0039 **\nospan_split                    1     38    38.2    4.38 0.0384 * \npretty_condition:ospan_split   1     32    31.5    3.61 0.0596 . \nResiduals                    129   1126     8.7                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n$\\beta_0$ intercept is MEAN when both predictors are at reference: (control condition low memory) [M = 1.129]\n$\\beta_{1impasse}$ intercept is DIFFERENCE to (IMPASSE condition low memory) [M 1.72 - 1.129 = 0.591]\n$\\beta_{1high}$ intercept is DIFFERENCE to (CONTROL condition HIGH memory) [M 1.21 - 1.129 = 0.079]\n$\\beta_{1 impasse : high}$ is DIFFERENCE to ?? no idea can't figure this one out. its not to reference levels\n\nBUT don't fret re: significance of predictors in the model, rather, to see if effects are significant, just run anova on the model. \n\n##### Visualize\n\n**By comparing the average performance by condition ...**\n::: {.cell}\n\n```{.r .cell-code}\n#PLOT EFFECTS\nplot_model(m.c, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#TODO GET + ylim(0,8) to work\n```\n:::\n\n**...to the average by condition broken out by working memory, we see that perhaps working memory score drives some of the effect of improved performance in the impasse condition.**\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(m.cio, type = \"int\") \n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#+ ylim(0,8)\n```\n:::\n##### Diagnostics\n::: {.cell}\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.cio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n671.567 | 686.019 | 0.114 |     0.094 | 2.910 | 2.955\n```\n:::\n\n```{.r .cell-code}\n#DIAGNOSTICS\ncheck_model(m.cio)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n#### Mixed Logistic Regression\n\n::: {.cell}\n\n```{.r .cell-code}\n#PREP DATA\ndf_i <- df_sgc3a_items %>% filter(q %nin% c(6,9)) %>% mutate(\n  accuracy = as.factor(score_niceABS),\n  ospan = as.factor(ospan_split)\n) #test phase discrim only\n```\n:::\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\",\n               control=glmerControl(optimizer=\"bobyqa\",\n            optCtrl=list(maxfun=100000)))\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  2 |       1 | 996.89 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  8.51171579630337e-219\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD RANDOM INTERCEPT ITEM?\n\n#:: RANDOM INTERCEPT SUBJECT + INTERCEPT Q\n# print(\"Subject & Question random intercepts\")\n# mm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n# # summary(mm.rSQ)\n# \n# # :: TEST random effect\n# paste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)) )\n# test_lrt(mm.rS,mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n# paste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.rSQ))$p[2])\n\n## 3 | ADD FIXED EFFECT CONDITION\n\n# print(\"FIXED Condition + Subject & Question random intercepts\")\n# mm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q), \n#                 data = df_i, family = \"binomial\")\n# summary(mm.CrSQ)\n# \n# paste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n# test_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n# paste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n\nprint(\"FIXED Condition + Subject random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrS <- glmer(accuracy ~ pretty_condition + (1|subject) ,\n                data = df_i, family = \"binomial\")\n# summary(mm.CrS)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rS)) > AIC(logLik(mm.CrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.CrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.CrS | glmerMod |  3 |       1 | 15.16 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.CrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000989108940029305\"\n```\n:::\n\n```{.r .cell-code}\n## 4 | ADD FIXED EFFECT OSPAN only \nprint(\"FIXED OSPAN + Subject random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED OSPAN + Subject random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.OrS <- glmer(accuracy ~ ospan + (1|subject) ,\n                data = df_i, family = \"binomial\")\n# summary(mm.OrS)\npaste(\"OSPAN decreases AIC over random?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.OrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"OSPAN decreases AIC over random? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.OrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |     p\n-----------------------------------------------\nmm.rS  | glmerMod |  2 |         |      |      \nmm.OrS | glmerMod |  3 |       1 | 2.01 | 0.156\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.OrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.155998034743899\"\n```\n:::\n\n```{.r .cell-code}\n## 5 | MODEL OF INTEREST! OSPAN + CONDITION + suject\n\nprint(\"FIXED OSPAN + CONDITION + IXN + Subject random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED OSPAN + CONDITION + IXN + Subject random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.COrS <- glmer(accuracy ~ pretty_condition + ospan + (1|subject) ,\n                data = df_i, family = \"binomial\")\n# summary(mm.COrS)\npaste(\"OSPAN decreases AIC over CONDITION alone?\", AIC(logLik(mm.COrS)) > AIC(logLik(mm.CrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"OSPAN decreases AIC over CONDITION alone? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.COrS,mm.CrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nmm.COrS | glmerMod |  4 |         |      |      \nmm.CrS  | glmerMod |  3 |      -1 | 1.99 | 0.158\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.COrS,mm.CrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.158232854667994\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"FIXED OSPAN + CONDITION + IXN + Subject random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED OSPAN + CONDITION + IXN + Subject random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CIOrS <- glmer(accuracy ~ pretty_condition + ospan + pretty_condition:ospan + (1|subject) ,\n                data = df_i, family = \"binomial\")\n\npaste(\"IXN decreases AIC over main effects alone?\", AIC(logLik(mm.CIOrS)) > AIC(logLik(mm.COrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"IXN decreases AIC over main effects alone? FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.CIOrS,mm.COrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\nmm.CIOrS | glmerMod |  5 |         |      |      \nmm.COrS  | glmerMod |  4 |      -1 | 5.55 | 0.018\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.CIOrS,mm.COrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0184419694757536\"\n```\n:::\n:::\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm1 <- mm.CIOrS\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + ospan + pretty_condition:ospan +  \n    (1 | subject)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     926      953     -458      916     1724 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.241 -0.121 -0.050 -0.039  3.812 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 20.8     4.56    \nNumber of obs: 1729, groups:  subject, 133\n\nFixed effects:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                                -5.345      1.100   -4.86  1.2e-06\npretty_conditionimpasse                     1.514      1.296    1.17    0.243\nospanhigh-memory                           -0.724      1.229   -0.59    0.556\npretty_conditionimpasse:ospanhigh-memory    4.203      1.851    2.27    0.023\n                                            \n(Intercept)                              ***\npretty_conditionimpasse                     \nospanhigh-memory                            \npretty_conditionimpasse:ospanhigh-memory *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prtty_ ospnh-\nprtty_cndtn -0.644              \nospnhgh-mmr -0.614  0.530       \nprtty_cnd:-  0.269 -0.670 -0.669\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                       Chisq Df Pr(>Chisq)    \npretty_condition       13.12  1    0.00029 ***\nospan                   1.57  1    0.21040    \npretty_condition:ospan  5.15  1    0.02319 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#:::::::: MANUAL ONE-SIDED SIGTEST \n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,5))\n\n#:::::::: INTERPRET COEFFICIENTS\n\nse <- sqrt(diag(stats::vcov(m1)))\n# table of estimates with 95% CI\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n    se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                            Est     LL    UL\n(Intercept)                              -5.345 -7.502 -3.19\npretty_conditionimpasse                   1.514 -1.026  4.05\nospanhigh-memory                         -0.724 -3.131  1.68\npretty_conditionimpasse:ospanhigh-memory  4.203  0.574  7.83\n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- exp(tab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                              Est       LL        UL\n(Intercept)                               0.00477 0.000552    0.0412\npretty_conditionimpasse                   4.54669 0.358441   57.6732\nospanhigh-memory                          0.48505 0.043653    5.3895\npretty_conditionimpasse:ospanhigh-memory 66.87469 1.776070 2518.0447\n```\n:::\n:::\n\n##### Inference\n\nTODO\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (geom_errorbarh).\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-27-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n#tab_model(m1)\n```\n:::\n\n##### Narrative\n\n**By comparing the average performance by condition ...**\n::: {.cell}\n\n```{.r .cell-code}\n#PLOT EFFECTS\nplot_model(mm.CrS, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#TODO GET + ylim(0,8) to work\n```\n:::\n\n**...to the average by condition broken out by working memory, we see that perhaps working memory score drives some of the effect of improved performance in the impasse condition.**\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(mm.CIOrS, type = \"int\") \n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#+ ylim(0,8)\n```\n:::\n\n_It is compelling to see that only high_working memory participants achieved the high probabilites of correct response in impasse_.\n\n\n\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict accuracy with pretty_condition and ospan (formula: accuracy ~ pretty_condition + ospan + pretty_condition:ospan). The model included subject as random effect (formula: ~1 | subject). The model's total explanatory power is substantial (conditional R2 = 0.89) and the part related to the fixed effects alone (marginal R2) is of 0.16. The model's intercept, corresponding to pretty_condition = control and ospan = low-memory, is at -5.35 (95% CI [-7.50, -3.19], p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically non-significant and positive (beta = 1.51, 95% CI [-1.03, 4.05], p = 0.243; Std. beta = 1.51, 95% CI [-1.03, 4.05])\n  - The effect of ospan [high-memory] is statistically non-significant and negative (beta = -0.72, 95% CI [-3.13, 1.68], p = 0.556; Std. beta = -0.72, 95% CI [-3.13, 1.68])\n  - The interaction effect of ospan [high-memory] on pretty condition [impasse] is statistically significant and positive (beta = 4.20, 95% CI [0.57, 7.83], p = 0.023; Std. beta = 4.20, 95% CI [0.57, 7.83])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |    AICc |     BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n----------------------------------------------------------------------------------------------------------------------\n925.568 | 925.602 | 952.844 |      0.886 |      0.164 | 0.863 | 0.228 | 1.000 |    0.172 |      -Inf |           0.014\n```\n:::\n\n```{.r .cell-code}\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\n### TODO OSPAN ~ Test Phase Interpretation \n\n**Does the OSPAN score help explain variance in test phase interpretation?**\n\n::: {.cell}\n\n```{.r .cell-code}\n##STATSPLOT\nggstatsplot::grouped_ggbarstats(data = df_i, \n                                    y = ospan_split, x = pretty_condition, \n                                    grouping.var = score_STATE,\n                                    type = \"nonparametric\", equal.var = FALSE,\n                                    annotation.args = list(\n    title = \"Potential INTERACTION between condition and WM Score\"))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n## TODO SEQUENCE\n## TODO BEST FIT\n\n## ARCHIVE\n### Q1 ACCURACY \n\n**What explains Q1 Accuracy?**\n\n##### Multiple Logistic Regression [Q1 Absolute]\n\n::: {.cell}\n\n```{.r .cell-code}\n# #CREATE DATAFRAME OF Q1\n# df <- df_items %>% filter(q == 1) %>% mutate( accuracy = as.factor(score_niceABS))\n# \n# #MODEL\n# m2 <- glm( accuracy ~ rt_s, data = df, family = \"binomial\")\n# summary(m2)\n# confint(m2)\n# performance(m2)\n# report(m2)\n# \n# library(effects)\n# plot(allEffects(m2))\n# \n# \n# m3 <- glm( accuracy ~ condition + rt_s, data = df, family = \"binomial\")\n# summary(m3)\n# confint(m3)\n# performance(m3)\n# report(m3)\n# \n# plot(allEffects(m3))\n# \n# compare_performance(m,m2,m3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#evaluate model using kfold CV\n# https://www.statology.org/k-fold-cross-validation-in-r/\n\n# #specify the cross-validation method\n# ctrl <- trainControl(method = \"cv\", number = 5)\n# #fit a regression model and use k-fold CV to evaluate performance\n# mk <- train( accuracy ~ condition, data = df, method = \"glm\", trControl = ctrl, family = \"binomial\")\n# print(mk)\n# \n```\n:::\n\n\n\n#### Mass Movement\n\n\"movement of mass\" from one mode to another\n\nConsidering only families of unimodal distributions, the most probably distribution (as predicted by package `performance`) is negative-binomial.\n\n::: {.cell}\n\n```{.r .cell-code}\n# df <- df_subjects %>% filter(condition==111)\n# multimode::modetest(df$s_NABS)\n# n_modes = multimode::nmodes(data = df$s_NABS, bw=2)\n# multimode::locmodes(df$s_NABS,mod0 =  n_modes, display = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# df <- df_subjects %>% filter(condition==121)\n# multimode::modetest(df$s_NABS)\n# n_modes = multimode::nmodes(data = df$s_NABS, bw=2)\n# multimode::locmodes(df$s_NABS,mod0 =  n_modes, display = TRUE)\n```\n:::\n\n\n### RESPONSE LATENCY\n\n-   [TODO: Investigate super high and super low response times.]{style=\"color: red;\"}.\n-   [TODO: Investigate appropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/)]{style=\"color: red;\"}.\n-   Especially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data\n\n+-----------------------+----------------------------------------+\n| Research Question     |                                        |\n+=======================+========================================+\n| **Hypothesis**        |                                        |\n+-----------------------+----------------------------------------+\n| **Analysis Strategy** |                                        |\n+-----------------------+----------------------------------------+\n| **Alternatives**      |                                        |\n+-----------------------+----------------------------------------+\n| **Inference**         |                                        |\n+-----------------------+----------------------------------------+\n\n### Q1 Response Latency\n\n#### Linear Regression (Log Transform)\n\n##### (In Person)\n\n###### Visualization\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# df_lab <- df_subjects %>% filter(mode == \"lab-synch\")\n#  \n# #HISTOGRAM\n# stats = df_lab %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_q1_rt))\n# gf_dhistogram(~log(item_q1_rt), fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) +\n#   # gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n#   labs(title = \"(LAB) First Question Response Time\",,\n#        # x = \"Response Time (seconds)\",\n#        # y = \"proportion of participants\",\n#        subtitle = \"\") + \n#   theme_minimal()\n```\n:::\n\n###### Model\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# #SCORE predicted by CONDITION\n# lab.q1t.lm1 <- lm(log(item_q1_rt) ~ pretty_condition, data = df_lab)\n# paste(\"Model\")\n# summary(lab.q1t.lm1)\n# paste(\"Partition Variance\")\n# anova(lab.q1t.lm1)\n# paste(\"Confidence Interval on Parameter Estimates\")\n# confint(lab.q1t.lm1)\n# report(lab.q1t.lm1) #sanity check\n# #print model equation\n# eq <- extract_eq(lab.q1t.lm1, use_coefs = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# #| label: VISMODEL-Q1-LATENCY-LAB\n# \n# #MODEL ESTIMATES WITH UNCERTAINTY\n# \n# #setup references \n# #lab.q1t.lm1 <- lm(log(item_q1_rt) ~ condition, data = df_lab)\n# m <- lab.q1t.lm1\n# df <- df_lab \n# call <- m$call %>% as.character()\n# \n# # uncertainty model visualization\n# df <- df  %>%\n#   data_grid(pretty_condition) %>%\n#   augment(m, newdata = ., se_fit = TRUE) \n# \n# #transform log\n# df$.fitted <- exp(df$.fitted)\n# df$.se.fit <- exp(df$.se.fit)\n# \n# df %>% \n#   ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n#   stat_halfeye( scale = .5,\n#       aes(\n#         xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n#         fill = stat(cut_cdf_qi(cdf, \n#                 .width = c(.90, .95),\n#                 labels = scales::percent_format())))) +\n#   scale_fill_brewer(direction = -1) + \n#   labs (title = \"(LAB) Q1 Response Latency ~ Condition\", \n#         x = \"model predicted mean (seconds)\", y = \"Condition\", fill = \"Interval\",\n#         subtitle = paste(\"lm(\",call[2],\")\"),\n#         caption = \"note: model log(predictions) have exponentiated to original scale\") + theme(legend.position = \"blank\")\n```\n:::\n\n###### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# #model diagnostics\n# check_model(lab.q1t.lm1, panel = TRUE)\n```\n:::\n\n\n\n###### Inference\n\nOLS Linear Regression on Q1 response time shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model violates the assumption of normally distributed residuals.\n\n##### (Online Replication)\n\n###### Visualization\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# df_online <- df_subjects %>% filter(mode == \"asynch\")\n#  \n# #HISTOGRAM\n# stats = df_online %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_q1_rt))\n# gf_dhistogram(~log(item_q1_rt), fill = ~pretty_condition, data = df_lab) %>% gf_facet_grid(~pretty_condition) +\n#   # gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n#   labs(title = \"(ONLINE) First Question Response Time\",\n#        # x = \"Response Time (seconds)\",\n#        # y = \"proportion of participants\",\n#        subtitle = \"\") + \n#   theme_minimal()\n```\n:::\n\n###### Model\n\n::: {.cell}\n\n```{.r .cell-code}\n# #SCORE predicted by CONDITION\n# rep.q1t.lm1 <- lm(log(item_q1_rt) ~ pretty_condition, data = df_online)\n# paste(\"Model\")\n# summary(rep.q1t.lm1)\n# paste(\"Partition Variance\")\n# anova(rep.q1t.lm1)\n# paste(\"Confidence Interval on Parameter Estimates\")\n# confint(rep.q1t.lm1)\n# report(rep.q1t.lm1) #sanity check\n# #print model equation\n# eq <- extract_eq(rep.q1t.lm1, use_coefs = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n# \n# #setup references \n# # rep.q1t.lm1 <- lm(log(item_q1_rt) ~ condition, data = df_online)\n# m <- rep.q1t.lm1\n# df <- df_online \n# call <- m$call %>% as.character()\n# \n# # uncertainty model visualization\n# df <- df  %>%\n#   data_grid(pretty_condition) %>%\n#   augment(m, newdata = ., se_fit = TRUE) \n# \n# #transform log\n# df$.fitted <- exp(df$.fitted)\n# df$.se.fit <- exp(df$.se.fit)\n# \n# df %>% \n#   ggplot(aes(y = pretty_condition, color = pretty_condition)) +\n#   stat_halfeye( scale = .5,\n#       aes(\n#         xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n#         fill = stat(cut_cdf_qi(cdf, \n#                 .width = c(.90, .95),\n#                 labels = scales::percent_format())))) +\n#   scale_fill_brewer(direction = -1) + \n#   labs (title = \"(ONLINE) Q1 Response Latency ~ Condition\", \n#         x = \"model predicted mean (seconds)\", y = \"Condition\", fill = \"Interval\",\n#         subtitle = paste(\"lm(\",call[2],\")\"),\n#         caption = \"note: model log(predictions) have exponentiated to original scale\") + theme(legend.position = \"blank\")\n```\n:::\n\n###### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#model diagnostics\n# check_model(rep.q1t.lm1, panel = TRUE)\n```\n:::\n\n\n\n###### Inference\n\nOLS Linear Regression on Q1 response time shows that condition explains a small but statistically significant amount of variance (impasse \\> control). However, the model violates the assumption of normally distributed residuals.\n\n### TODO RESPONSE CONSISTENCY\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}