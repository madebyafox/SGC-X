{
  "hash": "9d6b49b3b530a70abdffe03bbeffa2e0",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 5 Exploratory Analyses'\n---\n\n\\newpage\n\n# Exploratory Analyses {#sec-SGC3A-exploration}\n\n**TODO**\\\n- response consistency - clarify core questions being asked\\\n- review models already created in ARCHIVE?\\\n- explore response consistency - fix references\n\n*The purpose of this notebook is exploratory analyses of data collected for study SGC3A.*\n\n+------------------------+\n| Pre-Requisite          |\n+========================+\n| 1_sgc3A_harmonize.qmd\\ |\n| 2_sgc3A_scoring.qmd    |\n+------------------------+\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/SETUP_2112c062b641076f792cc61d743ffac6'}\n\n```{.r .cell-code}\nlibrary(multimode) #mode mass tests\nlibrary(Hmisc) # %nin% operator\nlibrary(ggpubr) #arrange plots\nlibrary(ggformula) #easy graphs\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(tidyverse) #ALL THE THINGS\n\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n```\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/IMPORT-DATA_d8fc8ebe2aca5228b0c52c9386176a4e'}\n\n```{.r .cell-code}\n#IMPORT DATA \ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\n\n\n#SEPARATE ITEM DATA BY QUESTION TYPE\ndf_scaffold <- df_items %>% filter(q < 6)\ndf_test <- df_items %>% filter(q > 6) %>% filter (q %nin% c(6,9))\ndf_nondiscrim <- df_items %>% filter (q %in% c(6,9))\n```\n:::\n\nExploratory Questions\n\nConsistency \\| How consistent are learners in their interpretation of the graph? Do they adopt an interpretation on the first question and hold constant? Or do they change interpretations from question to question? Are there any interpretations that serve as 'absorbing states' (i.e. once encountered, the learner does not exist this state).\n\nTime Course of Exploration \\| What is the relationship between response accuracy (and interpretation) and time spent on each item?\n\nCan exploration strategies be derived from mouse cursor activity?\n\n-   does response time predict interpretation vs. non interpretation?\n\n#### Mass Movement\n\n\"movement of mass\" from one mode to another\n\nConsidering only families of unimodal distributions, the most probably distribution (as predicted by package `performance`) is negative-binomial.\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/MASS-111_2e0eb21ecd1ec93a0efc67757c43c96d'}\n\n```{.r .cell-code}\ndf <- df_subjects %>% filter(condition==111)\nmultimode::modetest(df$s_NABS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in multimode::modetest(df$s_NABS): A modification of the data was made\nin order to compute the excess mass or the dip statistic\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAmeijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df$s_NABS\nExcess mass = 0.09, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n```\n:::\n\n```{.r .cell-code}\nn_modes = multimode::nmodes(data = df$s_NABS, bw=2)\nmultimode::locmodes(df$s_NABS,mod0 =  n_modes, display = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in multimode::locmodes(df$s_NABS, mod0 = n_modes, display = TRUE): If\nthe density function has an unbounded support, artificial modes may have been\ncreated in the tails\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/MASS-111-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimated location\nModes: 0.136  12.6 \nAntimode: 7.63 \n\nEstimated value of the density\nModes: 0.268  0.0432 \nAntimode: 0.00648 \n\nCritical bandwidth: 1.05\n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/MASS-121_0dd2226845e75fba372975188436dc69'}\n\n```{.r .cell-code}\ndf <- df_subjects %>% filter(condition==121)\nmultimode::modetest(df$s_NABS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in multimode::modetest(df$s_NABS): A modification of the data was made\nin order to compute the excess mass or the dip statistic\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAmeijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df$s_NABS\nExcess mass = 0.1, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n```\n:::\n\n```{.r .cell-code}\nn_modes = multimode::nmodes(data = df$s_NABS, bw=2)\nmultimode::locmodes(df$s_NABS,mod0 =  n_modes, display = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in multimode::locmodes(df$s_NABS, mod0 = n_modes, display = TRUE): If\nthe density function has an unbounded support, artificial modes may have been\ncreated in the tails\n```\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/MASS-121-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimated location\nModes: 0.456    12 \nAntimode: 4.89 \n\nEstimated value of the density\nModes: 0.148  0.0703 \nAntimode: 0.025 \n\nCritical bandwidth: 1.27\n```\n:::\n:::\n\n## RESPONSE CONSISTENCY\n\n**TODO**\n\n## XYZ\n\n### XYZ\n\n#### XYZ\n\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+=======================+=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| **Analysis Strategy** | Chi-Square test of independence on outcome `score_niceABS` by `condition` for `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Justification**     | \\(0\\) simplest method to examine independence of two categorical factors; logistic regression is recommended for binomial \\~ continuous                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(1\\) independence assumption : as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(2\\) frequency size assumption : expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Steps**             | \\(1\\) Express raw data as contingency table & visualize                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(2\\) Calculate Chi-Squared Statistic and p-value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(3\\) Interpret Odds-Ratio as effect size                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | **Lab** A Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. In this particular data sample, the sample odds ratio 2.18 indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than if the control condition (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]). |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | **Online** A Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. The sample odds ratio = 2.68 indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]).                                         |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/VIS-LR-Q1.tri.by.Cond_bc57bcf49052dc03fc17468e4b45d633'}\n\n```{.r .cell-code}\n#FITER THE DATASET\ndf = df_items %>% filter(q==1) \n\n#PROPORTIONAL BAR CHART\ngf_props(~score_niceABS, data = df, fill = ~mode) %>% \n  gf_facet_grid(mode~condition, labeller = label_both) +\n  labs(x = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition (Both Modalities)\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses than control \")+\n  theme_minimal()+ theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-LR-Q1.tri.by.Cond-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#MOSAIC PLOT\nvcd::mosaic(main=\"Accuracy on First Question by Condition (Both Modalities)\",\n            data = df, score_niceABS ~ condition, rot_labels=c(0,90,0,0),\n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\")))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-LR-Q1.tri.by.Cond-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#PRINT CONTINGENCY TABLE\ntitle = \"Proportion of Correct Responses On First Item (Both Modalities)\"\nitem.contingency <-  df %>% dplyr::select(condition, score_niceABS) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Proportion of Correct Responses On First Item (Both Modalities)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 0 </th>\n   <th style=\"text-align:right;\"> 1 </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 111 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> 0.067 </td>\n   <td style=\"text-align:right;\"> 0.479 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 121 </td>\n   <td style=\"text-align:right;\"> 0.373 </td>\n   <td style=\"text-align:right;\"> 0.148 </td>\n   <td style=\"text-align:right;\"> 0.521 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:right;\"> 0.215 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/label - TBL-Q1.TRI.by.COND-LAB_cb359c869927e6c688b33eff00319b95'}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"lab-synch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        52 |        10 |        62 | \n             |    47.730 |    14.270 |           | \n             |     0.382 |     1.278 |           | \n             |     0.839 |     0.161 |     0.492 | \n             |     0.536 |     0.345 |           | \n             |     0.413 |     0.079 |           | \n-------------|-----------|-----------|-----------|\n         121 |        45 |        19 |        64 | \n             |    49.270 |    14.730 |           | \n             |     0.370 |     1.238 |           | \n             |     0.703 |     0.297 |     0.508 | \n             |     0.464 |     0.655 |           | \n             |     0.357 |     0.151 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |        97 |        29 |       126 | \n             |     0.770 |     0.230 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  3.27     d.f. =  1     p =  0.0707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  2.55     d.f. =  1     p =  0.111 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.18 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.0909 \n95% confidence interval:  0.86 5.84 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.979 \n95% confidence interval:  0 5.03 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.0547 \n95% confidence interval:  0.982 Inf \n\n\n \n```\n:::\n:::\n\nInspecting the output of the Chi-Squared test, we first see that we meet the assumption of expected frequency in each cell (indicated by the second row in each box, 'Expected N'. The model predicts more than 5 observations in each cell.) The Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is not equal to 1. In this particular data sample, the odds ratio 2.18 indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]).\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/label - TBL-Q1.TRI.by.COND-ONLINE_09e41da7b555b6ef67ce3b70a7dc13cf'}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"asynch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  204 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        84 |        12 |        96 | \n             |    76.235 |    19.765 |           | \n             |     0.791 |     3.050 |           | \n             |     0.875 |     0.125 |     0.471 | \n             |     0.519 |     0.286 |           | \n             |     0.412 |     0.059 |           | \n-------------|-----------|-----------|-----------|\n         121 |        78 |        30 |       108 | \n             |    85.765 |    22.235 |           | \n             |     0.703 |     2.711 |           | \n             |     0.722 |     0.278 |     0.529 | \n             |     0.481 |     0.714 |           | \n             |     0.382 |     0.147 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       162 |        42 |       204 | \n             |     0.794 |     0.206 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  7.26     d.f. =  1     p =  0.00707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  6.35     d.f. =  1     p =  0.0117 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.68 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00894 \n95% confidence interval:  1.23 6.17 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.998 \n95% confidence interval:  0 5.42 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.00539 \n95% confidence interval:  1.37 Inf \n\n\n \n```\n:::\n:::\n\nInspecting the output of the Chi-Squared test, we first see that we meet the assumption of expected frequency in each cell (indicated by the second row in each box, 'Expected N'. The model predicts more than 5 observations in each cell.) The Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is not equal to 1. The odds ratio = 2.68 indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]).\n\n## COPIED FROM 3\n\n**Does the IMPASSE condition more accurate interpretation?**\n\nTo address this question we assess how much variance in cumulative (absolute) score is explained by experimental condition.\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/MODEL-scaled-score-LAB_cad4420bf89d1ddbee5cf5d0ec7925f5'}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_SCALED ~ condition, data = df_subjects %>% filter(mode==\"lab-synch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"lab-synch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.51  -6.48  -4.48   9.38  19.52 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -6.52       1.19   -5.48  2.3e-07 ***\ncondition121     7.53       1.67    4.51  1.5e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.38 on 124 degrees of freedom\nMultiple R-squared:  0.141,\tAdjusted R-squared:  0.134 \nF-statistic: 20.3 on 1 and 124 DF,  p-value: 0.0000151\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value   Pr(>F)    \ncondition   1   1787    1787    20.3 0.000015 ***\nResiduals 124  10910      88                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  -8.88  -4.17\ncondition121  4.22  10.84\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n```\n:::\n\n**For in-lab data collection** an OLS linear regression predicting scaled score by experimental condition explains a statistically significant and moderate 15% variance in score (F(1,124) = 22.7, p \\< 0.001). The estimated beta coefficient ($/beta$ = 7.88, 95% CI \\[4.61, 11.2\\]) predicts that participants in the impasse condition will on average score around 8 points (31%) higher than those in the control condition.\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/MODEL-scaled-score-ONLINE_258b81bd02c4b6aee3287b210ec97324'}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_SCALED ~ condition, data = df_subjects %>% filter(mode==\"asynch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.31  -6.63  -3.63   7.74  19.36 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -6.365      0.883   -7.21  1.1e-11 ***\ncondition121    6.670      1.214    5.49  1.2e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.65 on 202 degrees of freedom\nMultiple R-squared:  0.13,\tAdjusted R-squared:  0.126 \nF-statistic: 30.2 on 1 and 202 DF,  p-value: 1.17e-07\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1   2261    2261    30.2 1.2e-07 ***\nResiduals 202  15128      75                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  -8.11  -4.62\ncondition121  4.28   9.06\n```\n:::\n\n```{.r .cell-code}\n#report(m1) #sanity check\n```\n:::\n\n**For the online replication**, an OLS linear regression model predicting scaled score by condition explains a statistically significant and moderate 14% of variance in absolute score (F(1,202) = 32.4, p \\< 0.001). The beta coefficient for condition indicates that on average, participants in the IMPASSE group scored 6.8 points higher on the task than those in the control condition (CI\\[4.43, 9.12\\]).\n\n::: callout-note\n**From these models we can reasonably conclude that the impasse condition yields a reliable, moderate sized effect of improved interpretation on the graph reading tasks.**\n:::\n\n## Item-Level Performance\n\nIndividual differences with a mixed model.\n\n## Model Peeking\n\nTODO\n\n-   multiple regression with condition and response time\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-10_4da5e71c63c8eb2acf31405c4d5f5251'}\n\n```{.r .cell-code}\nlibrary(supernova)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'supernova'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:scales':\n\n    number\n```\n:::\n\n```{.r .cell-code}\nlibrary(report)\nlibrary(lmerTest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lme4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lmerTest'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    lmer\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nlibrary(lme4)\nm1 <- lm( s_SCALED ~ condition, data = df_subjects %>% filter(mode=='asynch'))\nm1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nCoefficients:\n (Intercept)  condition121  \n       -6.36          6.67  \n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.31  -6.63  -3.63   7.74  19.36 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -6.365      0.883   -7.21  1.1e-11 ***\ncondition121    6.670      1.214    5.49  1.2e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.65 on 202 degrees of freedom\nMultiple R-squared:  0.13,\tAdjusted R-squared:  0.126 \nF-statistic: 30.2 on 1 and 202 DF,  p-value: 1.17e-07\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1   2261    2261    30.2 1.2e-07 ***\nResiduals 202  15128      75                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsuperanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Analysis of Variance Table (Type III SS)\n Model: s_SCALED ~ condition\n\n                                SS  df       MS      F    PRE     p\n ----- --------------- | --------- --- -------- ------ ------ -----\n Model (error reduced) |  2261.177   1 2261.177 30.193 0.1300 .0000\n Error (from model)    | 15128.156 202   74.892                    \n ----- --------------- | --------- --- -------- ------ ------ -----\n Total (empty model)   | 17389.333 203   85.662                    \n```\n:::\n\n```{.r .cell-code}\nplot(m1)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-4.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_histogram(~s_SCALED, data = df_subjects)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-5.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_histogram(~m1$residuals)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-10-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#Assess assumption of independence of errors\n#DW statistic should be close to 2\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'carData'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcdExtra':\n\n    Burt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n```{.r .cell-code}\ndurbinWatsonTest(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n lag Autocorrelation D-W Statistic p-value\n   1        -0.00262          1.99   0.962\n Alternative hypothesis: rho != 0\n```\n:::\n\n```{.r .cell-code}\n#Test for equality of variance\n#H0 is equality; p > 0.05 infer you can't reject null\nleveneTest(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)  \ngroup   1     6.3  0.013 *\n      202                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\nA simple linear regression model predicting cumulative scaled score (at subject level) by condition explains 13% of the total variance, F(1,329) = 47.8, p \\< 0.001. The model predicts that participants in the impasse condition will score on average 6.38 points higher than those in the control condition, 95% CI \\[4.56, 8.19\\].\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-11_e01701509adbeb1e7fbca546ae86dff3'}\n\n```{.r .cell-code}\nt.test(s_SCALED ~ condition, data = df_subjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  s_SCALED by condition\nt = -7, df = 325, p-value = 7e-12\nalternative hypothesis: true difference in means between group 111 and group 121 is not equal to 0\n95 percent confidence interval:\n -8.93 -5.06\nsample estimates:\nmean in group 111 mean in group 121 \n           -6.427             0.567 \n```\n:::\n\n```{.r .cell-code}\n#%>% report()\n```\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-12_c241c30696f87fed9ca3b98d16c5722e'}\n\n```{.r .cell-code}\n# report_participants(df_subjects)\nm1 %>% report()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with condition (formula: s_SCALED ~ condition). The model explains a statistically significant and moderate proportion of variance (R2 = 0.13, F(1, 202) = 30.19, p < .001, adj. R2 = 0.13). The model's intercept, corresponding to condition = 111, is at -6.36 (95% CI [-8.11, -4.62], t(202) = -7.21, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 6.67, 95% CI [4.28, 9.06], t(202) = 5.49, p < .001; Std. beta = 0.72, 95% CI [0.46, 0.98])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\nanova(m1) %>% report()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFor one-way between subjects designs, partial eta squared is equivalent to eta squared.\nReturning eta squared.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe ANOVA suggests that:\n\n  - The main effect of condition is statistically significant and medium (F(1, 202) = 30.19, p < .001; Eta2 = 0.13, 95% CI [0.07, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n```\n:::\n\n```{.r .cell-code}\n#significant intercept means that group is significantly different than zero\n```\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-13_5afdc26f9e735c818c3d665ff6e3b857'}\n\n```{.r .cell-code}\n#logistic regression on on scaled df_subjects because residuals not normal in lm?\nmlog <- glm(s_SCALED ~ condition , data = df_subjects, family = gaussian)\nsummary(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = s_SCALED ~ condition, family = gaussian, data = df_subjects)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-12.57   -6.57   -3.82    8.43   19.43  \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -6.427      0.709   -9.06  < 2e-16 ***\ncondition121    6.994      0.982    7.12  6.8e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 79.4)\n\n    Null deviance: 30088  on 329  degrees of freedom\nResidual deviance: 26059  on 328  degrees of freedom\nAIC: 2384\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nreport(mlog)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using ML) to predict s_SCALED with condition (formula: s_SCALED ~ condition). The model's explanatory power is moderate (R2 = 0.13). The model's intercept, corresponding to condition = 111, is at -6.43 (95% CI [-7.82, -5.04], t(328) = -9.06, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 6.99, 95% CI [5.07, 8.92], t(328) = 7.12, p < .001; Std. beta = 0.73, 95% CI [0.53, 0.93])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-14_ec2ae535e567edcf0f6634e747305f1f'}\n\n```{.r .cell-code}\n#logistic regression on niceABS by condition\n#pretends that questions are independent and not from same subjects INVALID\nmlog <- glm(score_niceABS ~ condition , data = df_items %>% filter(q<6), family = binomial())\nsummary(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = score_niceABS ~ condition, family = binomial(), \n    data = df_items %>% filter(q < 6))\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.980  -0.980  -0.649   1.389   1.823  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.4508     0.0907  -15.99   <2e-16 ***\ncondition121   0.9672     0.1147    8.43   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1986.2  on 1649  degrees of freedom\nResidual deviance: 1911.3  on 1648  degrees of freedom\nAIC: 1915\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nreport(mlog)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic model (estimated using ML) to predict score_niceABS with condition (formula: score_niceABS ~ condition). The model's explanatory power is weak (Tjur's R2 = 0.04). The model's intercept, corresponding to condition = 111, is at -1.45 (95% CI [-1.63, -1.28], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 0.97, 95% CI [0.74, 1.19], p < .001; Std. beta = 0.97, 95% CI [0.74, 1.19])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-15_58862ffc4b5aca6708ec7a3669c1f9c8'}\n\n```{.r .cell-code}\nm2 <- lm( s_NABS ~ condition, data = df_subjects)\nm2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_NABS ~ condition, data = df_subjects)\n\nCoefficients:\n (Intercept)  condition121  \n        2.47          2.46  \n```\n:::\n\n```{.r .cell-code}\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_NABS ~ condition, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.92  -3.67  -2.47   4.08  10.53 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     2.468      0.384    6.43  4.4e-10 ***\ncondition121    2.456      0.531    4.62  5.5e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.82 on 328 degrees of freedom\nMultiple R-squared:  0.0611,\tAdjusted R-squared:  0.0583 \nF-statistic: 21.4 on 1 and 328 DF,  p-value: 5.49e-06\n```\n:::\n\n```{.r .cell-code}\nanova(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_NABS\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1    497     497    21.4 5.5e-06 ***\nResiduals 328   7629      23                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsupernova(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Analysis of Variance Table (Type III SS)\n Model: s_NABS ~ condition\n\n                               SS  df      MS      F    PRE     p\n ----- --------------- | -------- --- ------- ------ ------ -----\n Model (error reduced) |  496.765   1 496.765 21.357 0.0611 .0000\n Error (from model)    | 7629.359 328  23.260                    \n ----- --------------- | -------- --- ------- ------ ------ -----\n Total (empty model)   | 8126.124 329  24.699                    \n```\n:::\n:::\n\nA simple linear regression model predicting cumulative absolute score by condition explains 5% of variance, F(1,328) = 16.36, p \\< 0.001. The model predicts that subjects in the impasse condition will score on average 2 points higher than those in the control condition (Beta = 2.02, 95% CI \\[1.04, 3.00\\])\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-16_2ae27ec5c848cc5e8b14466a055ccfa9'}\n\n```{.r .cell-code}\nreport(m2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict s_NABS with condition (formula: s_NABS ~ condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.06, F(1, 328) = 21.36, p < .001, adj. R2 = 0.06). The model's intercept, corresponding to condition = 111, is at 2.47 (95% CI [1.71, 3.22], t(328) = 6.43, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 2.46, 95% CI [1.41, 3.50], t(328) = 4.62, p < .001; Std. beta = 0.49, 95% CI [0.28, 0.70])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-17_060f863553aa04a527f881a6e921c7e0'}\n\n```{.r .cell-code}\nm.m1 <- lmer( score_SCALED ~ (1 + condition|subject), data = df_items)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00344864 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nm.m1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerModLmerTest']\nFormula: score_SCALED ~ (1 + condition | subject)\n   Data: df_items\nREML criterion at convergence: 9940\nRandom effects:\n Groups   Name         Std.Dev. Corr \n subject  (Intercept)  0.620         \n          condition121 0.865    -0.72\n Residual              0.601         \nNumber of obs: 4950, groups:  subject, 330\nFixed Effects:\n(Intercept)  \n     -0.126  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n```\n:::\n\n```{.r .cell-code}\nsummary(m.m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | subject)\n   Data: df_items\n\nREML criterion at convergence: 9940\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.902 -0.659 -0.299  0.533  2.718 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n subject  (Intercept)  0.384    0.620         \n          condition121 0.748    0.865    -0.72\n Residual              0.362    0.601         \nNumber of obs: 4950, groups:  subject, 330\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)  -0.1259     0.0346 328.5075   -3.64  0.00032 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00344864 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nreport(m.m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition and subject as random effects (formula: ~1 + condition | subject). . The model's intercept is at -0.13 (95% CI [-0.19, -0.06], t(4945) = -3.64, p < .001). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-18_718968ba63d697e7d24041979b17294e'}\n\n```{.r .cell-code}\nm.m2 <- lmer( score_SCALED ~ (1+ condition|q), data = df_items)\nm.m2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerModLmerTest']\nFormula: score_SCALED ~ (1 + condition | q)\n   Data: df_items\nREML criterion at convergence: 11669\nRandom effects:\n Groups   Name         Std.Dev. Corr \n q        (Intercept)  0.577         \n          condition121 0.517    -0.93\n Residual              0.778         \nNumber of obs: 4950, groups:  q, 15\nFixed Effects:\n(Intercept)  \n     0.0983  \n```\n:::\n\n```{.r .cell-code}\nsummary(m.m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | q)\n   Data: df_items\n\nREML criterion at convergence: 11669\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.830 -0.732 -0.424  0.910  2.147 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n q        (Intercept)  0.333    0.577         \n          condition121 0.267    0.517    -0.93\n Residual              0.605    0.778         \nNumber of obs: 4950, groups:  q, 15\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)\n(Intercept)   0.0983     0.0570 14.0000    1.73     0.11\n```\n:::\n\n```{.r .cell-code}\nreport(m.m2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition and q as random effects (formula: ~1 + condition | q). . The model's intercept is at 0.10 (95% CI [-0.01, 0.21], t(4945) = 1.73, p = 0.084). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-19_851e399b51eefb3afff314257e5bfab2'}\n\n```{.r .cell-code}\nm.m3 <- lmer( score_SCALED ~ (1+ condition|q) + (1+condition|subject), data = df_items)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0117282 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nm.m3 %>% summary() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | q) + (1 + condition | subject)\n   Data: df_items\n\nREML criterion at convergence: 8836\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.796 -0.585 -0.083  0.662  3.431 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n subject  (Intercept)  0.3334   0.577         \n          condition121 0.0951   0.308    -0.30\n q        (Intercept)  0.2445   0.494         \n          condition121 0.1848   0.430    -0.90\n Residual              0.2804   0.530         \nNumber of obs: 4950, groups:  subject, 330; q, 15\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)\n(Intercept)   0.0434     0.0706 24.8205    0.61     0.54\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.0117282 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nm.m3 %>% report()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition, q and subject as random effects (formula: list(~1 + condition | q, ~1 + condition | subject)). . The model's intercept is at 0.04 (95% CI [-0.10, 0.18], t(4942) = 0.61, p = 0.539). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell hash='5_sgc3A_exploration_cache/html/unnamed-chunk-20_09c71ddf04b9b422b7c8a7c8edfdc317'}\n\n```{.r .cell-code}\nanova(m.m1, m.m2, m.m3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nrefitting model(s) with ML (instead of REML)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_items\nModels:\nm.m1: score_SCALED ~ (1 + condition | subject)\nm.m2: score_SCALED ~ (1 + condition | q)\nm.m3: score_SCALED ~ (1 + condition | q) + (1 + condition | subject)\n     npar   AIC   BIC logLik deviance Chisq Df Pr(>Chisq)    \nm.m1    5  9945  9978  -4968     9935                        \nm.m2    5 11675 11708  -5832    11665     0  0               \nm.m3    8  8849  8901  -4416     8833  2832  3     <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n## RESOURCES",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}