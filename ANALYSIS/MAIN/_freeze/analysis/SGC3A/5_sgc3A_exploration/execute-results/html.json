{
  "hash": "0b6e8fb16a565420979649f187cf9fe0",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 5 Exploratory Analyses'\n---\n\n\\newpage\n\n# Exploratory Analyses {#sec-SGC3A-exploration}\n\n**TODO**  \n- clarify core questions being asked  \n- review models already created in ARCHIVE?  \n- explore response consistency\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) #ALL THE THINGS\nlibrary(Hmisc) # %nin% operator\nlibrary(ggpubr) #arrange plots\nlibrary(ggformula) #easy graphs\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \n\n\n#set some output options\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n```\n:::\n\n*The purpose of this notebook is exploratory analyses of data collected for study SGC3A.*\n\n+------------------------+\n| Pre-Requisite          |\n+========================+\n| 1_sgc3A_harmonize.qmd\\ |\n| 2_sgc3A_scoring.qmd  |\n+------------------------+\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT DATA \ndf_items <- read_rds('data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('data/2-scored-data/sgc3a_scored_participants.rds')\n\n\n#SEPARATE ITEM DATA BY QUESTION TYPE\ndf_scaffold <- df_items %>% filter(q < 6)\ndf_test <- df_items %>% filter(q > 6) %>% filter (q %nin% c(6,9))\ndf_nondiscrim <- df_items %>% filter (q %in% c(6,9))\n```\n:::\n\n**TODO**\n\n\n\n\n## XYZ\n\n\n\n### XYZ\n\n#### XYZ\n\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \\[Is response accuracy independent of condition?\\]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+=======================+=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+\n| **Analysis Strategy** | Chi-Square test of independence on outcome `score_niceABS` by `condition` for `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Justification**     | \\(0\\) simplest method to examine independence of two categorical factors; logistic regression is recommended for binomial \\~ continuous                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(1\\) independence assumption : as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(2\\) frequency size assumption : expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Steps**             | \\(1\\) Express raw data as contingency table & visualize                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(2\\) Calculate Chi-Squared Statistic and p-value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | \\(3\\) Interpret Odds-Ratio as effect size                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Inference**         | **Lab** A Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. In this particular data sample, the sample odds ratio 2.18 indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than if the control condition (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]). |\n|                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|                       | **Online** A Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is equal to 1. The sample odds ratio = 2.68 indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]).                                         |\n+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n::: {.cell}\n\n```{.r .cell-code}\n#FITER THE DATASET\ndf = df_items %>% filter(q==1) \n\n#PROPORTIONAL BAR CHART\ngf_props(~score_niceABS, data = df, fill = ~mode) %>% \n  gf_facet_grid(mode~condition, labeller = label_both) +\n  labs(x = \"Correct Response on Q 1\",\n       title = \"Accuracy on First Question by Condition (Both Modalities)\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses than control \")+\n  theme_minimal()+ theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-LR-Q1.tri.by.Cond-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#MOSAIC PLOT\nvcd::mosaic(main=\"Accuracy on First Question by Condition (Both Modalities)\",\n            data = df, score_niceABS ~ condition, rot_labels=c(0,90,0,0),\n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\")))\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/VIS-LR-Q1.tri.by.Cond-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#PRINT CONTINGENCY TABLE\ntitle = \"Proportion of Correct Responses On First Item (Both Modalities)\"\nitem.contingency <-  df %>% dplyr::select(condition, score_niceABS) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Proportion of Correct Responses On First Item (Both Modalities)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> 0 </th>\n   <th style=\"text-align:right;\"> 1 </th>\n   <th style=\"text-align:right;\"> Sum </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 111 </td>\n   <td style=\"text-align:right;\"> 0.412 </td>\n   <td style=\"text-align:right;\"> 0.067 </td>\n   <td style=\"text-align:right;\"> 0.479 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 121 </td>\n   <td style=\"text-align:right;\"> 0.373 </td>\n   <td style=\"text-align:right;\"> 0.148 </td>\n   <td style=\"text-align:right;\"> 0.521 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 0.785 </td>\n   <td style=\"text-align:right;\"> 0.215 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"lab-synch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        52 |        10 |        62 | \n             |    47.730 |    14.270 |           | \n             |     0.382 |     1.278 |           | \n             |     0.839 |     0.161 |     0.492 | \n             |     0.536 |     0.345 |           | \n             |     0.413 |     0.079 |           | \n-------------|-----------|-----------|-----------|\n         121 |        45 |        19 |        64 | \n             |    49.270 |    14.730 |           | \n             |     0.370 |     1.238 |           | \n             |     0.703 |     0.297 |     0.508 | \n             |     0.464 |     0.655 |           | \n             |     0.357 |     0.151 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |        97 |        29 |       126 | \n             |     0.770 |     0.230 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  3.27     d.f. =  1     p =  0.0707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  2.55     d.f. =  1     p =  0.111 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.18 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.0909 \n95% confidence interval:  0.86 5.84 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.979 \n95% confidence interval:  0 5.03 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.0547 \n95% confidence interval:  0.982 Inf \n\n\n \n```\n:::\n:::\n\nInspecting the output of the Chi-Squared test, we first see that we meet the assumption of expected frequency in each cell (indicated by the second row in each box, 'Expected N'. The model predicts more than 5 observations in each cell.) The Pearson's Chi-squared test (of independence) indicates a relationship between response accuracy on the first question and experimental condition approaching statistical significance, $\\chi^2$ (1) = 10.3, p = 0.07. Thus we have insufficient evidence to reject the null hypothesis that the odds ratio is not equal to 1. In this particular data sample, the odds ratio 2.18 indicates that the odds of producing a correct response on the first question were 2.18 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.18, p = 0.055, 95% CI \\[0.982, +Inf\\]).\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = df_items %>% filter(q==1) %>% filter(mode == \"asynch\")\nCrossTable( x = df$condition, y = df$score_niceABS, fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  204 \n\n \n             | df$score_niceABS \ndf$condition |         0 |         1 | Row Total | \n-------------|-----------|-----------|-----------|\n         111 |        84 |        12 |        96 | \n             |    76.235 |    19.765 |           | \n             |     0.791 |     3.050 |           | \n             |     0.875 |     0.125 |     0.471 | \n             |     0.519 |     0.286 |           | \n             |     0.412 |     0.059 |           | \n-------------|-----------|-----------|-----------|\n         121 |        78 |        30 |       108 | \n             |    85.765 |    22.235 |           | \n             |     0.703 |     2.711 |           | \n             |     0.722 |     0.278 |     0.529 | \n             |     0.481 |     0.714 |           | \n             |     0.382 |     0.147 |           | \n-------------|-----------|-----------|-----------|\nColumn Total |       162 |        42 |       204 | \n             |     0.794 |     0.206 |           | \n-------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  7.26     d.f. =  1     p =  0.00707 \n\nPearson's Chi-squared test with Yates' continuity correction \n------------------------------------------------------------\nChi^2 =  6.35     d.f. =  1     p =  0.0117 \n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nSample estimate odds ratio:  2.68 \n\nAlternative hypothesis: true odds ratio is not equal to 1\np =  0.00894 \n95% confidence interval:  1.23 6.17 \n\nAlternative hypothesis: true odds ratio is less than 1\np =  0.998 \n95% confidence interval:  0 5.42 \n\nAlternative hypothesis: true odds ratio is greater than 1\np =  0.00539 \n95% confidence interval:  1.37 Inf \n\n\n \n```\n:::\n:::\n\nInspecting the output of the Chi-Squared test, we first see that we meet the assumption of expected frequency in each cell (indicated by the second row in each box, 'Expected N'. The model predicts more than 5 observations in each cell.) The Pearson's Chi-squared test (of independence) indicates a statistically significant relationship between response accuracy on the first question and experimental condition, $\\chi^2$ (1) = 7.26, p = 0.009. Thus we have sufficient evidence to reject the null hypothesis that the odds ratio is not equal to 1. The odds ratio = 2.68 indicates that the odds of producing a correct response on the first question were 2.68 times greater if a subject was in the impasse condition, than in the control condition (Odds Ratio = 2.68, p = 0.005, 95% CI \\[1.37, +Inf\\]).\n\n\n\n## COPIED FROM 3\n\n**Does the IMPASSE condition more accurate interpretation?**\n\nTo address this question we assess how much variance in cumulative (absolute) score is explained by experimental condition.\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_SCALED ~ condition, data = df_subjects %>% filter(mode==\"lab-synch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"lab-synch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-12.75  -6.87  -4.87   9.03  19.13 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -6.13       1.18   -5.20  8.0e-07 ***\ncondition121     7.88       1.65    4.76  5.2e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.28 on 124 degrees of freedom\nMultiple R-squared:  0.155,\tAdjusted R-squared:  0.148 \nF-statistic: 22.7 on 1 and 124 DF,  p-value: 5.21e-06\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1   1955    1955    22.7 5.2e-06 ***\nResiduals 124  10681      86                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  -8.46   -3.8\ncondition121  4.61   11.2\n```\n:::\n\n```{.r .cell-code}\n# report(m1) #sanity check\n```\n:::\n\n**For in-lab data collection** an OLS linear regression predicting scaled score by experimental condition explains a statistically significant and moderate 15% variance in score (F(1,124) = 22.7, p \\< 0.001). The estimated beta coefficient ($/beta$ = 7.88, 95% CI \\[4.61, 11.2\\]) predicts that participants in the impasse condition will on average score around 8 points (31%) higher than those in the control condition.\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nm1 <- lm(s_SCALED ~ condition, data = df_subjects %>% filter(mode==\"asynch\"))\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13.16  -7.16  -3.02   7.12  18.62 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -5.620      0.866   -6.49  6.5e-10 ***\ncondition121    6.777      1.190    5.70  4.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.48 on 202 degrees of freedom\nMultiple R-squared:  0.138,\tAdjusted R-squared:  0.134 \nF-statistic: 32.4 on 1 and 202 DF,  p-value: 4.3e-08\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1   2334    2334    32.4 4.3e-08 ***\nResiduals 202  14536      72                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             2.5 % 97.5 %\n(Intercept)  -7.33  -3.91\ncondition121  4.43   9.12\n```\n:::\n\n```{.r .cell-code}\n#report(m1) #sanity check\n```\n:::\n\n**For the online replication**, an OLS linear regression model predicting scaled score by condition explains a statistically significant and moderate 14% of variance in absolute score (F(1,202) = 32.4, p \\< 0.001). The beta coefficient for condition indicates that on average, participants in the IMPASSE group scored 6.8 points higher on the task than those in the control condition (CI\\[4.43, 9.12\\]).\n\n::: callout-note\n**From these models we can reasonably conclude that the impasse condition yields a reliable, moderate sized effect of improved interpretation on the graph reading tasks.**\n:::\n\n## Item-Level Performance\n\nIndividual differences with a mixed model.\n\n## Model Peeking\n\nTODO\n\n-   multiple regression with condition and response time\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(supernova)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'supernova'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:scales':\n\n    number\n```\n:::\n\n```{.r .cell-code}\nlibrary(report)\nlibrary(lmerTest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lme4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 methods overwritten by 'lme4':\n  method                          from\n  cooks.distance.influence.merMod car \n  influence.merMod                car \n  dfbeta.influence.merMod         car \n  dfbetas.influence.merMod        car \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lmerTest'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    lmer\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nlibrary(lme4)\nm1 <- lm( s_SCALED ~ condition, data = df_subjects %>% filter(mode=='asynch'))\nm1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nCoefficients:\n (Intercept)  condition121  \n       -5.62          6.78  \n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ condition, data = df_subjects %>% filter(mode == \n    \"asynch\"))\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13.16  -7.16  -3.02   7.12  18.62 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -5.620      0.866   -6.49  6.5e-10 ***\ncondition121    6.777      1.190    5.70  4.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.48 on 202 degrees of freedom\nMultiple R-squared:  0.138,\tAdjusted R-squared:  0.134 \nF-statistic: 32.4 on 1 and 202 DF,  p-value: 4.3e-08\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1   2334    2334    32.4 4.3e-08 ***\nResiduals 202  14536      72                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsuperanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Analysis of Variance Table (Type III SS)\n Model: s_SCALED ~ condition\n\n                                SS  df       MS      F    PRE     p\n ----- --------------- | --------- --- -------- ------ ------ -----\n Model (error reduced) |  2334.346   1 2334.346 32.439 0.1384 .0000\n Error (from model)    | 14536.196 202   71.961                    \n ----- --------------- | --------- --- -------- ------ ------ -----\n Total (empty model)   | 16870.543 203   83.106                    \n```\n:::\n\n```{.r .cell-code}\nplot(m1)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-4.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_histogram(~s_SCALED, data = df_subjects)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-5.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_histogram(~m1$residuals)\n```\n\n::: {.cell-output-display}\n![](5_sgc3A_exploration_files/figure-html/unnamed-chunk-9-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#Assess assumption of independence of errors\n#DW statistic should be close to 2\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'carData'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcdExtra':\n\n    Burt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n```{.r .cell-code}\ndurbinWatsonTest(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n lag Autocorrelation D-W Statistic p-value\n   1         -0.0134          2.01   0.878\n Alternative hypothesis: rho != 0\n```\n:::\n\n```{.r .cell-code}\n#Test for equality of variance\n#H0 is equality; p > 0.05 infer you can't reject null\nleveneTest(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)  \ngroup   1     5.4  0.021 *\n      202                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\nA simple linear regression model predicting cumulative scaled score (at subject level) by condition explains 13% of the total variance, F(1,329) = 47.8, p \\< 0.001. The model predicts that participants in the impasse condition will score on average 6.38 points higher than those in the control condition, 95% CI \\[4.56, 8.19\\].\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(s_SCALED ~ condition, data = df_subjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  s_SCALED by condition\nt = -7, df = 322, p-value = 1e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -9.10 -5.29\nsample estimates:\nmean in group 111 mean in group 121 \n            -5.82              1.38 \n```\n:::\n\n```{.r .cell-code}\n#%>% report()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# report_participants(df_subjects)\nm1 %>% report()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with condition (formula: s_SCALED ~ condition). The model explains a statistically significant and moderate proportion of variance (R2 = 0.14, F(1, 202) = 32.44, p < .001, adj. R2 = 0.13). The model's intercept, corresponding to condition = 111, is at -5.62 (95% CI [-7.33, -3.91], t(202) = -6.49, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 6.78, 95% CI [4.43, 9.12], t(202) = 5.70, p < .001; Std. beta = 0.74, 95% CI [0.49, 1.00])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\nanova(m1) %>% report()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFor one-way between subjects designs, partial eta squared is equivalent to eta squared.\nReturning eta squared.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe ANOVA suggests that:\n\n  - The main effect of condition is statistically significant and medium (F(1, 202) = 32.44, p < .001; Eta2 = 0.14, 95% CI [0.07, 1.00])\n```\n:::\n\n```{.r .cell-code}\n#significant intercept means that group is significantly different than zero\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#logistic regression on on scaled df_subjects because residuals not normal in lm?\nmlog <- glm(s_SCALED ~ condition , data = df_subjects, family = gaussian)\nsummary(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = s_SCALED ~ condition, family = gaussian, data = df_subjects)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-13.38   -7.18   -3.28    8.50   18.82  \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -5.820      0.698   -8.34  2.1e-15 ***\ncondition121    7.198      0.967    7.45  8.6e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 77)\n\n    Null deviance: 29508  on 329  degrees of freedom\nResidual deviance: 25242  on 328  degrees of freedom\nAIC: 2374\n\nNumber of Fisher Scoring iterations: 2\n```\n:::\n\n```{.r .cell-code}\nreport(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using ML) to predict s_SCALED with condition (formula: s_SCALED ~ condition). The model's explanatory power is moderate (R2 = 0.14). The model's intercept, corresponding to condition = 111, is at -5.82 (95% CI [-7.19, -4.45], t(328) = -8.34, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 7.20, 95% CI [5.30, 9.09], t(328) = 7.45, p < .001; Std. beta = 0.76, 95% CI [0.56, 0.96])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#logistic regression on niceABS by condition\n#pretends that questions are independent and not from same subjects INVALID\nmlog <- glm(score_niceABS ~ condition , data = df_items %>% filter(q<6), family = binomial())\nsummary(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = score_niceABS ~ condition, family = binomial(), \n    data = df_items %>% filter(q < 6))\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.980  -0.980  -0.649   1.389   1.823  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.4508     0.0907  -15.99   <2e-16 ***\ncondition121   0.9672     0.1147    8.43   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1986.2  on 1649  degrees of freedom\nResidual deviance: 1911.3  on 1648  degrees of freedom\nAIC: 1915\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nreport(mlog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic model (estimated using ML) to predict score_niceABS with condition (formula: score_niceABS ~ condition). The model's explanatory power is weak (Tjur's R2 = 0.04). The model's intercept, corresponding to condition = 111, is at -1.45 (95% CI [-1.63, -1.28], p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 0.97, 95% CI [0.74, 1.19], p < .001; Std. beta = 0.97, 95% CI [0.74, 1.19])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm( s_NABS ~ condition, data = df_subjects)\nm2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_NABS ~ condition, data = df_subjects)\n\nCoefficients:\n (Intercept)  condition121  \n        2.47          2.46  \n```\n:::\n\n```{.r .cell-code}\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_NABS ~ condition, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.92  -3.67  -2.47   4.08  10.53 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     2.468      0.384    6.43  4.4e-10 ***\ncondition121    2.456      0.531    4.62  5.5e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.82 on 328 degrees of freedom\nMultiple R-squared:  0.0611,\tAdjusted R-squared:  0.0583 \nF-statistic: 21.4 on 1 and 328 DF,  p-value: 5.49e-06\n```\n:::\n\n```{.r .cell-code}\nanova(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_NABS\n           Df Sum Sq Mean Sq F value  Pr(>F)    \ncondition   1    497     497    21.4 5.5e-06 ***\nResiduals 328   7629      23                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsupernova(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Analysis of Variance Table (Type III SS)\n Model: s_NABS ~ condition\n\n                               SS  df      MS      F    PRE     p\n ----- --------------- | -------- --- ------- ------ ------ -----\n Model (error reduced) |  496.765   1 496.765 21.357 0.0611 .0000\n Error (from model)    | 7629.359 328  23.260                    \n ----- --------------- | -------- --- ------- ------ ------ -----\n Total (empty model)   | 8126.124 329  24.699                    \n```\n:::\n:::\n\nA simple linear regression model predicting cumulative absolute score by condition explains 5% of variance, F(1,328) = 16.36, p \\< 0.001. The model predicts that subjects in the impasse condition will score on average 2 points higher than those in the control condition (Beta = 2.02, 95% CI \\[1.04, 3.00\\])\n\n::: {.cell}\n\n```{.r .cell-code}\nreport(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict s_NABS with condition (formula: s_NABS ~ condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.06, F(1, 328) = 21.36, p < .001, adj. R2 = 0.06). The model's intercept, corresponding to condition = 111, is at 2.47 (95% CI [1.71, 3.22], t(328) = 6.43, p < .001). Within this model:\n\n  - The effect of condition [121] is statistically significant and positive (beta = 2.46, 95% CI [1.41, 3.50], t(328) = 4.62, p < .001; Std. beta = 0.49, 95% CI [0.28, 0.70])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm.m1 <- lmer( score_SCALED ~ (1 + condition|subject), data = df_items)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Model failed to converge with 1 negative eigenvalue: -8.1e-04\n```\n:::\n\n```{.r .cell-code}\nm.m1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerModLmerTest']\nFormula: score_SCALED ~ (1 + condition | subject)\n   Data: df_items\nREML criterion at convergence: 9773\nRandom effects:\n Groups   Name         Std.Dev. Corr \n subject  (Intercept)  0.632         \n          condition121 0.827    -0.71\n Residual              0.591         \nNumber of obs: 4950, groups:  subject, 330\nFixed Effects:\n(Intercept)  \n    -0.0617  \n```\n:::\n\n```{.r .cell-code}\nsummary(m.m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | subject)\n   Data: df_items\n\nREML criterion at convergence: 9773\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9664 -0.6738 -0.0461  0.5889  2.7646 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n subject  (Intercept)  0.400    0.632         \n          condition121 0.685    0.827    -0.71\n Residual              0.349    0.591         \nNumber of obs: 4950, groups:  subject, 330\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)  \n(Intercept)  -0.0617     0.0344 326.4131   -1.79    0.074 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nreport(m.m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition and subject as random effects (formula: ~1 + condition | subject). . The model's intercept is at -0.06 (95% CI [-0.13, 5.71e-03], t(4945) = -1.79, p = 0.073). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm.m2 <- lmer( score_SCALED ~ (1+ condition|q), data = df_items)\nm.m2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerModLmerTest']\nFormula: score_SCALED ~ (1 + condition | q)\n   Data: df_items\nREML criterion at convergence: 11500\nRandom effects:\n Groups   Name         Std.Dev. Corr \n q        (Intercept)  0.602         \n          condition121 0.530    -0.93\n Residual              0.765         \nNumber of obs: 4950, groups:  q, 15\nFixed Effects:\n(Intercept)  \n      0.172  \n```\n:::\n\n```{.r .cell-code}\nsummary(m.m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | q)\n   Data: df_items\n\nREML criterion at convergence: 11500\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.972 -0.794 -0.093  0.887  2.164 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n q        (Intercept)  0.363    0.602         \n          condition121 0.281    0.530    -0.93\n Residual              0.585    0.765         \nNumber of obs: 4950, groups:  q, 15\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)   \n(Intercept)   0.1717     0.0575 14.0014    2.98   0.0099 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nreport(m.m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition and q as random effects (formula: ~1 + condition | q). . The model's intercept is at 0.17 (95% CI [0.06, 0.28], t(4945) = 2.98, p = 0.003). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm.m3 <- lmer( score_SCALED ~ (1+ condition|q) + (1+condition|subject), data = df_items)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00208782 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nm.m3 %>% summary() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: score_SCALED ~ (1 + condition | q) + (1 + condition | subject)\n   Data: df_items\n\nREML criterion at convergence: 8593\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.724 -0.644 -0.016  0.697  3.599 \n\nRandom effects:\n Groups   Name         Variance Std.Dev. Corr \n subject  (Intercept)  0.339    0.583         \n          condition121 0.218    0.467    -0.46\n q        (Intercept)  0.268    0.517         \n          condition121 0.197    0.443    -0.91\n Residual              0.266    0.516         \nNumber of obs: 4950, groups:  subject, 330; q, 15\n\nFixed effects:\n            Estimate Std. Error     df t value Pr(>|t|)\n(Intercept)    0.117      0.071 24.208    1.65     0.11\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00208782 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nm.m3 %>% report()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a constant (intercept-only) linear mixed model (estimated using REML and nloptwrap optimizer) to predict score_SCALED (formula: score_SCALED ~ 1). The model included condition, q and subject as random effects (formula: list(~1 + condition | q, ~1 + condition | subject)). . The model's intercept is at 0.12 (95% CI [-0.02, 0.26], t(4942) = 1.65, p = 0.098). Within this model:\n\n  -  ()\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(m.m1, m.m2, m.m3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nrefitting model(s) with ML (instead of REML)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nData: df_items\nModels:\nm.m1: score_SCALED ~ (1 + condition | subject)\nm.m2: score_SCALED ~ (1 + condition | q)\nm.m3: score_SCALED ~ (1 + condition | q) + (1 + condition | subject)\n     npar   AIC   BIC logLik deviance Chisq Df Pr(>Chisq)    \nm.m1    5  9778  9811  -4884     9768                        \nm.m2    5 11506 11539  -5748    11496     0  0               \nm.m3    8  8605  8657  -4295     8589  2907  3     <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n## RESOURCES\n",
    "supporting": [
      "5_sgc3A_exploration_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}