{
  "hash": "6c8ad180937612969a4799e6827ac554",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | 2 Response Scoring'\n---\n\n\\newpage\n\n# Response Scoring {#sec-SGC3A-scoring}\n\n**TODO**\n\n-   mine for inline TODOs\n-   finish item level response exploration\n-   complete raw key for Q 6 - Q 15\n\n*The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC_3A study. This is required because the question type on the graph comprehension task used a 'Multiple Response' (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.)*\n\n| Pre-Requisite         |\n|-----------------------|\n| 1_sgc3A_harmonize.qmd |\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=1, digits=3)\n\nlibrary(tidyverse) #ALL THE THINGS\nlibrary(kableExtra) #printing tables \nlibrary(ggformula) #quick graphs\nlibrary(ggpubr) #better graphs\nlibrary(pbapply) #progress bar and time estimate for *apply fns\nlibrary(Hmisc) # %nin% operator\n```\n:::\n\n## MULTIPLE RESPONSE SCORING\n\nThe *graph comprehension task* of study SGC 3A presents readers with a graph, a question, and a series of checkboxes. Participants are instructed to use the graph to answer the question, and respond by selecting all the checkboxes that apply, where each checkbox corresponds to a datapoint in the graph.\n\n![**Figure 1. Sample Graph Comprehension (Question \\# 6)**](static/img/sample_graphComprehensionTask.png)\n\nIn the psychology and education literatures on Tests & Measures, the format of this type of question is referred to as Multiple Response (MR), (also: Multiple Choice Multiple Answer (MCMA) and Multiple Answer Multiple Choice (MAMC)). It has a number of properties that make it different from traditional Single Answer Multiple Choice (SAMC) questions, where the respondent marks a single response from a number of options. In particular, there are a number of very different ways that MAMC questions can be *scored*.\n\nIn tranditional SAMC format questions, one point is given for selecting the option designated as correct, and zero points given for marking any of the alternative (i.e. distractor) options. Individual response options on MAMC questions, however might be partially correct ($i$), while responses on other answer options within the same item might be incorrect ($n – i$). In MR, it is not obvious how to allocate points when the respondent marks a true-correct option (i.e. options that *should* be selected, denoted $p$), as well as one or more false-correct options (i.e. options that *should not* be selected, denoted $q$). Should partial credit be awarded? If so, are options that respondents false-selected and false-unselected items equally penalized?\n\n@schmidtRelationExamineesTrue2021 performed a systematic literature review of publications proposing MAMC (or equivalent) scoring schemes, ultimately synthesizing over 80 sources into 27 distinct scoring approaches. Upon reviewing the benefits of trade-offs of each approach, for this study we choose utilize two of the schemes: **dichotomous scoring** ( @schmidtRelationExamineesTrue2021 scheme #1), and **partial scoring** $[-1/q,0, +1/p]$ ( @schmidtRelationExamineesTrue2021 scheme #26), as well as a scaled **discriminant score** that leverages partial scoring to discriminate between strategy-specific patterns of response.\n\n### Response Encoding\n\nFirst, we note that the question type evaluated by @schmidtRelationExamineesTrue2021 is referred to as *Multiple True-False* (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to *not respond* to a particular option (i.e. leave the item 'blank'). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of 'select all that apply' can be coded as a series of T/F responses to each response option\n\n![**Figure 2. SAMC (vs) MAMC (vs) MTF**](static/img/MAMC-MTF.png){#fig-ItemTypes}\n\nIn this example (@fig-ItemTypes), we see an example of a question with four response options ($n=4$) in each question type. In the **SAMC** approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) $(\\text{number of possible responses} = n)$. With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an 'ideal subset' of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the *same number of response options* ($n=4$) yield a much greater number $(\\text{number of possible responses} = 2^{n})$. We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent *selects* in MAMC are can be coded as T, and options they leave *unselected* can be coded as F. Thus, for response options (ABCD), a response of \\[AB\\] can also be encoded as \\[TTFF\\].\n\n### Scoring Schemes\n\nIn the sections that follow, we use the terminology:\n\n**Properties of the Stimulus-Question**\n\n```{=tex}\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\ \n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)} \n\\end{align}\n```\n**Properties of the Subject's Response**\n\n```{=tex}\n\\begin{align} \ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\ \nf &= \\text{resulting score} \n\\end{align}\n```\n#### Dichotomous Scoring {#sec-absolute-scoring}\n\n**Dichotomous Scoring** is the strictest scoring scheme, where a response only receives points if it is *exactly* correct, meaning the respondent includes *only correct-select* options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as *all or nothing scoring*, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us *only* about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\n\n**In Dichotomous Scoring**\n\n-   score for the question is either 0 or 1\n-   full credit is only given if all responses are correct; otherwise no credit\n-   does not account for *partial knowledge*. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for **dichotomous scoring** is given by:\n\n\\begin{gather*}\nf = \n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*} \\text{where } 0 \\le i \\le n\n\n::: {.cell}\n\n```{.r .cell-code}\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n```\n:::\n\n#### Partial Scoring \\[-1/n, +1/n\\]\n\n**Partial Scoring** refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. @schmidtRelationExamineesTrue2021 identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\n\nA particularly elegant approach to partial scoring is referred to as the $[-1/n, +1/n]$ approach ( @schmidtRelationExamineesTrue2021 #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\n\n**In Partial Scoring** $[-1/n, +1/n]$:\n\n-   Scores range from \\[-1, +1\\]\n-   One point is awarded if all options are *correct*\n-   One point point is subtracted if all options are *incorrect*.\n-   Intermediate results are credited as fractions accordingly ($+1/n$ for each correct, $-1/n$ for each incorrect)\n-   This results in *at chance performance* (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation *is incorrect*, which may yield blank responses where the respondent is essentially saying, 'there is no correct answer to this question'.\n\n@schmidtRelationExamineesTrue2021 describe the *Partial* ${[-1/n, +1/n]}$ scoring scheme as the *only* scoring method (of the 27 described) where respondents' scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select *any* options. In the case (such as ours) where there are many more response options $n$ than there are options meant to be selected $p$, this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\n\nThe algorithm for **partial scoring**$[-1/n, +1/n]$ is given by:\n\n```{=tex}\n\\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n} \n\\end{align}\n```\n::: {.cell}\n\n```{.r .cell-code}\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n```\n:::\n\n#### Partial Scoring \\[-1/q, +1/p\\]\n\nOne drawback of the Partial Scoring $[-1/n, +1/n]$ approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent's understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. \"select all correct options\") vs MTF (i.e. \"Mark each option as true or false\") questions.\n\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option *might* mean the individual has a different interpretation, or that they failed to find *all* the data points consistent with the interpretation.\n\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly *not selected*. (See @schmidtRelationExamineesTrue2021 method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or 'default') response for any given item is the null, or blank response. Blank responses indicate *no understanding*, perhaps *confusion*, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an *incorrect* option is effortful, and is indicative of *incorrect understanding*.\n\n**Partial Scoring** $[-1/q, +1/p]$:\n\n-   awards +1/p for each correctly selected option ($p_s$), and subtracts $1/(n-p) = 1/q$ for each incorrectly selected option ($q_s$)\n-   only considers *selected* options; does not penalize nor reward *unselected* options\n\n**Properties of Item**\n\n```{=tex}\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n```\n**Properties of Response**\n\n```{=tex}\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n```\nThe algorithm for **partial scoring** $[-1/q, +1/p]$ is given by:\n\n```{=tex}\n\\begin{align}\nf &= (p_s / p) - ({q_s}/{q}) \\\\\n\\end{align}\n```\n::: {.cell}\n\n```{.r .cell-code}\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  \n  \n  ifelse( (p == 0), return(NA), \"\") #handle empty response set gracefully by returning nothing rather than 0\n  ifelse( (p != 0), return( (t / p) - (f/q)), \"\")\n  \n}\n```\n:::\n\n### Comparison of Schemes\n\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\n\nConsider the following example:\n\n*For a question with* $n = 5$ response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:unnamed-chunk-9}Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]}\n\\centering\n\\begin{tabular}[t]{l|l|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{Response Scenario } & \\multicolumn{3}{c}{Scores} \\\\\n\\cline{1-3} \\cline{4-6}\nCorrect Answer & Response & i  & Dichotomous & Partial [-1/n, +1/n] & Partial[-1/q, +1/p]\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Perfect Response}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & A\\_\\_\\_\\_ & 5 & 1 & 1.0 & 1.00\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Correct + Extra Incorrect Selections}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & AB\\_\\_\\_ & 4 & 0 & 0.6 & 0.75\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & A\\_\\_\\_E & 4 & 0 & 0.6 & 0.75\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & AB\\_\\_E & 3 & 0 & 0.2 & 0.50\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Only Incorrect Selections}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_\\_E & 3 & 0 & 0.2 & -0.25\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_DE & 2 & 0 & -0.2 & -0.50\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Completely Inverse Response }}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_BCDE & 0 & 0 & -1.0 & -1.00\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Selected ALL or NONE}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & ABCDE & 1 & 0 & -0.6 & 0.00\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_\\_\\_ & 4 & 0 & 0.6 & 0.00\\\\\n\\hline\n\\multicolumn{6}{l}{\\rule{0pt}{1em}\\textit{Note: } i = number of options in correct state; \\_ indicates option not selected}\\\\\n\\end{tabular}\n\\end{table}\n:::\n\n```{.r .cell-code}\n#cleanup\nrm(dt, abs, correct,i,names,partial1,partial2,response,title)\n```\n:::\n\n-   We see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\n\n-   The Partial $[-1/n, +1/n]$ scheme yields a range from $[-1,1]$, differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\n\n-   The Partial $[-1/q, +1/p]$ scheme also yields a range of scores from $[-1,1]$. A blank response (bottom row) yields the same score ($0$) as the selection of *all* answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with $n = 15$ options and $p = 1$ correct option to be selected.\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:unnamed-chunk-11}Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  }\n\\centering\n\\begin{tabular}[t]{l|l|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{Response Scenario } & \\multicolumn{3}{c}{Scores} \\\\\n\\cline{1-3} \\cline{4-6}\nCorrect Answer & Response & \\$i\\$  & Dichotomous & Partial [-1/n, +1/n] & Partial [-1/q, +1/p]\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Perfect Response}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & A\\_\\_...\\_\\_ & 15 & 1 & 1.000 & 1.000\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Correct + Extra Incorrect Selections}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & AB\\_...\\_\\_ & 14 & 0 & 0.867 & 0.929\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & A\\_\\_...\\_O & 14 & 0 & 0.867 & 0.929\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & AB\\_...\\_O & 13 & 0 & 0.733 & 0.857\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Only Incorrect Selections}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_...\\_O & 13 & 0 & 0.733 & -0.071\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_...NO & 12 & 0 & 0.600 & -0.143\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Completely Inverse Response }}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_BC...NO & 0 & 0 & -1.000 & -1.000\\\\\n\\hline\n\\multicolumn{6}{l}{\\textbf{Selected ALL or NONE}}\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & ABC...NO & 1 & 0 & -0.867 & 0.000\\\\\n\\hline\n\\hspace{1em}A\\_\\_\\_\\_ & \\_\\_\\_...\\_\\_ & 14 & 0 & 0.867 & 0.000\\\\\n\\hline\n\\multicolumn{6}{l}{\\rule{0pt}{1em}\\textit{Note: } i = number of options in correct state; \\_ indicates option not selected}\\\\\n\\end{tabular}\n\\end{table}\n:::\n\n```{.r .cell-code}\n#cleanup\nrm(dt, abs, correct,i,names,partial1,partial2,response,title)\n```\n:::\n\nHere again we see that the Partial $[-1/q, +1/p]$ scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n::: {.callout-caption appearance=\"simple\" icon=\"false\"}\n## Decision\n\nThe Partial $[-1/q, +1/p]$ scheme is more appropriate for scoring the graph comprehension task than the Partial $[-1/n, +1/n]$ scheme because it allows us to differentially penalize incorrectly *selected* and incorrectly *not selected* answer options.\n:::\n\n## SCORE SGC DATA\n\nIn SGC_3A we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The **graph comprehension task** asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant's performance, for each question (q=15) we will calculate the following scores:\n\nTODO UPDATE SCORE DEFS\n\n*An overall, strict score:*\\\n1. **Absolute Score** : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\n\n*Sub-scores, for each alternative graph interpretation*\\\n2. **Triangular Score** : using partial scoring \\[-1/q, +1/p\\] referencing true (Triangular) answer key.\n\n3\\. **Orthogonal Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect Orthogonal) answer key.\n\n4\\. **Tversky Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect connecting-lines strategy) answer key.\n\n5\\. **Satisficing Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect satisficing stategy) answer key.\n\n### Prepare Answer Keys\n\nWe start by importing three answer keys: (1) Q1 - Q5 \\[control condition\\], (2) Q1-Q5 \\[impasse condition\\], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n::: {.cell}\n\n```{.r .cell-code}\nkey_111_raw <- read_csv('data/keys/SGC3A_scaffold_111_key.csv') %>% mutate(condition = 111, phase = \"scaffold\")\nkey_121_raw <- read_csv('data/keys/SGC3A_scaffold_121_key.csv')%>% mutate(condition = 121, phase = \"scaffold\")\ncs = rep('c', 23) %>% str_c(collapse=\"\") #create column spec \nkey_test_raw <- read_csv('data/keys/SGC3A_test_key.csv', col_types = cs)%>% mutate(condition = \"\", phase = \"test\") \n\nkeys_raw <- rbind(key_111_raw, key_121_raw, key_test_raw )\nrm(key_111_raw, key_121_raw, key_test_raw)\n```\n:::\n\nIn order to calculate scores using the $[-1/q, +1/p]$ algorithm, we need to define the subset of all response options (set N) that should be selected (set P) and should not be selected (set Q). In order to calculate subscores for each graph interpretation (i.e. triangular, orthogonal, tversky) we must define these sets independently for each interpretation. For each question, the `keys_raw` dataframe gives us set N (all response options), and a set P (options that should be selected) for *each interpretation*. From these we must derive set Q for each interpretation.\n\n-   SET $N$, all response options (superset) . This set is the same across all interpretations (a property of the question) and is given in the answer key.\n\n-   SET $P$, $P \\subset N$ , the subset of options that **should** be selected (rewarded as +1/p) . This set differs by interpretation, and is given in the answer key.\n\n-   SET $A, A \\subset N, A \\sqcup P$ , the subset of options that **should not** be selected, *but if they are, aren't penalized* (i.e. these options are ignored. Not rewarded, nor penalized). These include any options referenced in the question (i.e. select shifts that start at the same time as X; don't penalize if they also select 'X'), as well as options within 0.5hr offset from the data point to accommodate reasonable visual errors. This set differs by interpretation, and is given in the answer key (columns `REF_POINT` and `_also`).\n\n-   SET $Q$, the subset of options that **should not be selected** and are penalized (as -1/q). This set differs by interpretation and is not given in the answer key. We can derive set Q for each interpretation by $Q = N - (P \\cup A)$\n\nThe next step in scoring is preparing interpretation-specific answer keys that specify sets N, P, A and Q for each question.\n\n#### Triangular Key\n\nFirst we construct a key set based on the 'Triangular' interpretation (i.e. the actually correct answers).\n\n::: {.cell}\n\n```{.r .cell-code}\nverify_tri = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TRIANGULAR KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tri <- keys_raw %>% \n  select(Q, condition, OPTIONS, TRIANGULAR, TRI_allow, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    TRI_allow = str_replace_na(TRI_allow,\"\"),\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TRIANGULAR,\n    set_p = str_replace_na(set_p,\"\"),#replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TRI_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"),#replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_tri)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tri[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tri[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tri[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tri[x,'set_q'] = Q\n  keys_tri[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tri[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tri <- keys_tri %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n```\n:::\n\nThis leaves us a dataframe `keys_tri` that define the sets of response options consistent with the triangular graph interpretation.\n\nTo verify we have generated the correct sets, we verify that for each question, each option in N is included in either set P, A or Q (once and only once).\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n#### Orthogonal Key\n\nNext we construct a key set based on the 'Orthogonal' interpretation.\n\n::: {.cell}\n\n```{.r .cell-code}\nverify_orth = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT ORTHOGONAL KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_orth <- keys_raw %>% \n  select(Q, condition, OPTIONS, ORTHOGONAL, ORTH_allow, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    ORTH_allow = str_replace_na(ORTH_allow,\"\"),\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = ORTHOGONAL,\n    set_p = str_replace_na(set_p,\"\"),#replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(ORTH_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answer options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_orth)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_orth[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_orth[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_orth[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_orth[x,'set_q'] = Q\n  keys_orth[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  # print(tempunion)\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n\n  verify_orth[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_orth <- keys_orth %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x, cs)\n```\n:::\n\nThis leaves us a dataframe `keys_orth` that define the sets of response options consistent with the orthogonal graph interpretation.\n\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n#### Satisficing Key\n\nNext we construct two keys based on the 'Satisficing' strategy. Satisficing involves selecting any data points within 0.5hr visual offset of the orthogonal interpretation of the graph (because no orthogonal response option is available). One key represents selecting a point slightly to the left of the orthogonal, and the other key represents selecting a point slightly to the right of the orthogonal.\n\n::: {.cell}\n\n```{.r .cell-code}\nverify_satisfice_right = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT SATISFICE RIGHT KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_satisfice_right <- keys_raw %>% \n  select(Q, condition, OPTIONS, SATISFICE_right, REF_POINT) %>% \n  mutate(\n    #replace NAs\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n\n    #P options that SHOULD be selected (rewarded)\n    set_p = SATISFICE_right,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n\n    #A options that are ignored if selected\n    set_a = str_c(REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n\n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_satisfice_right)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_satisfice_right[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_satisfice_right[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_satisfice_right[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to data frame\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_satisfice_right[x,'set_q'] = Q\n  keys_satisfice_right[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_satisfice_right[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_satisfice_right <- keys_satisfice_right %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q)%>% mutate(verify = n_p + n_a + n_q)\n\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n\n\n\nverify_satisfice_left = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT SATISFICE left KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_satisfice_left <- keys_raw %>% \n  select(Q, condition, OPTIONS, SATISFICE_left, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = SATISFICE_left,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_satisfice_left)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_satisfice_left[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_satisfice_left[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_satisfice_left[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to data frame\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_satisfice_left[x,'set_q'] = Q\n  keys_satisfice_left[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_satisfice_left[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_satisfice_left <- keys_satisfice_left %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q)%>% mutate(verify = n_p + n_a + n_q)\n\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n```\n:::\n\nThis leaves us a dataframe `keys_satisfice` that define the sets of response options consistent with the orthogonal graph interpretation.\n\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n#### Tversky Keys\n\nNext we construct the key set based on a partial-understanding strategy we refer to as 'Tversky'. We use the label Tversky as shorthand for a partial interpretation of the coordinate system where subjects select a set of responses that lay along a connecting line from the referenced data point or referenced time for that item. The term is named for Barbara Tversky based on her work on graphical primitives (e.g. \"lines connect, arrows direct, boxes contain\").\n\n::: {.cell}\n\n```{.r .cell-code}\nverify_max = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-MAX\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_max <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_max, TV_max_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_max = str_replace_na(TV_max,\"\"),\n    TV_max_allow = str_replace_na(TV_max_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_max,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_max_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_max)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_max[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_max[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_max[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_max[x,'set_q'] = Q\n  keys_tversky_max[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_max[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_max <- keys_tversky_max %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\nverify_tversky_start = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-START\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_start <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_start, TV_start_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_start = str_replace_na(TV_start,\"\"),\n    TV_start_allow = str_replace_na(TV_start_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_start,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_start_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_start)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_start[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_start[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_start[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_start[x,'set_q'] = Q\n  keys_tversky_start[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_start[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_start <- keys_tversky_start %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\nverify_tversky_end = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-END\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_end <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_end, TV_end_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_end = str_replace_na(TV_end,\"\"),\n    TV_end_allow = str_replace_na(TV_end_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_end,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_end_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_end)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_end[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_end[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_end[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_end[x,'set_q'] = Q\n  keys_tversky_end[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_end[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_end <- keys_tversky_end %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\nverify_tversky_duration = c()\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-DURATION\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_duration <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_dur, TV_dur_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_dur = str_replace_na(TV_dur,\"\"),\n    TV_dur_allow = str_replace_na(TV_dur_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_dur,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_dur_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_duration)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_duration[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_duration[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_duration[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_duration[x,'set_q'] = Q\n  keys_tversky_duration[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_duration[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_duration <- keys_tversky_duration %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n```\n:::\n\nThis leaves us four dataframes, each corresponding to a different variant of a 'lines connecting to reference point' strategy.\\\n- `keys_tversky_max` : the superset of lines connecting options - `keys_tversky_start` : lines connecting to the rightward diagonal (start time) of the reference point - `keys_tversky_end`: lines connecting to the leftward diagonal (end time) of the reference point - `keys_tversky_duration`: lines connecting to the horizontal y-intercept (duration) of the reference point\n\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n::: {.cell}\n\n```{.r .cell-code}\n#cleanup\nrm(verify_tri, verify_orth, verify_max, verify_tversky_duration, verify_tversky_end, verify_tversky_start, verify_satisfice_right, verify_satisfice_left)\n```\n:::\n\n### Score Items\n\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response `df_items$response` with the answer keys in each interpretation (e.g. `keys_orth`, `keys_tri`, etc...), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial\\[-1/q, +1/p\\] scores for each interpretation. The resulting scores are then stored on each item in `df_items`, and can be used to determine which graph interpretation the subject held.\n\nSpecifically, the following scores are calculated for each item:\n\n**Interpretation Subscores**\n\n-   `score_TRI` How consistent is the response with the **triangular**interpretation?\n-   `score_ORTH` How consistent is the response with the **orthogonal**interpretation?\n-   `score_SATISFICE` is calculated by taking the maximum value of :\n    -   `score_SAT_left` How consistent is the response with the **(left side) Satisficing** interpretation?\n\n    -   `score_SAT_right` How consistent is the response with the **(right side) Satisficing** interpretation\n-   `score_TVERSKY` is calculated by taking the maximum value of:\n    -   `score_TV_max` How consistent is the response with the **(maximal) Tversky** interpretation?\n\n    -   `score_TV_start` How consistent is the response with the **(start-time) Tversky** interpretation?\n\n    -   `score_TV_end` How consistent is the response with the **(end-time) Tversky**i nterpretation?\n\n    -   `score_TV_duration` How consistent is the response with the **(duration) Tversky** interpretation?\n-   `score_REF` Did the response select only the **reference point**?\n-   `score_BOTH` How consistent is the response with **both** the orthogonal and triangular interpretations?\n\n**Absolute Scores**\n\n-   `score_ABS` Is the response strictly correct? (triangular interpretation)\n-   `score_niceABS` Is the response strictly correct? (triangular interpretation, not penalizing ref points)\n\n::: {.cell}\n\n```{.r .cell-code}\nbackup <- read_rds('data/1-study-level/sgc3a_items.rds')\ndf_items <- read_rds('data/1-study-level/sgc3a_items.rds')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_sub_score2 <- function(question, cond, response, keyframe){\n\n  # print(paste(question, cond, response))\n\n    #STEP 1 GET KEY\n  if (question < 6) #for q1 - q5 find key for question by condition\n  {\n    # print(keyframe)\n    #GET KEY FOR THIS SCORE TYPE, QUESTION AND CONDITION\n    p =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    q =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    pn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_p)\n    qn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_q)\n\n    # print(p)\n    # print(q)\n    # print(paste(\"pn \",pn))\n    # print(paste(\"qn \",qn))\n    \n  } else {\n    #GET KEY FOR THIS SCORE TYPE, QUESTION\n    p =  keyframe %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    q =  keyframe %>% filter(Q == question) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    pn = keyframe %>% filter(Q == question) %>% select(n_p)\n    qn = keyframe %>% filter(Q == question) %>% select(n_q)\n  }\n\n  #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n  \n  #if response is not empty, split apart response for set comparison\n    if(response != \"\")\n    { response = response %>% str_split(\"\") %>% unlist()}\n  \n  #set comparisons \n  ps = length(intersect(response,p))\n  # print(paste(\"correct selected\" ,ps))\n  qs = length(intersect(response,q))\n  # print(paste(\"incorrect selected\", qs))\n  # df_items[x,'tri_ps'] = tri_ps\n  # df_items[x,'tri_qs'] = tri_qs\n\n  #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION\n  x = f_partialP(ps,pn,qs,qn) %>% unlist() %>% as.numeric()\n  # print(x)\n  #cleanup\n  rm(p,q,pn,qn,ps,qs)\n\n  return(x)\n}\n\n#CALCULATE THE REFERENCE SCORES\ncalc_ref_score2 <- function(question, cond, response){\n  \n  #1. GET reference point from REF_POINT column in raw keys\n  if (question < 6) {\n    ref_p = keys_raw %>% filter(Q == question) %>% filter(condition == cond) %>% select(REF_POINT) %>% pull(REF_POINT) %>% str_split(\"\") %>% unlist()\n  } else {\n    ref_p = keys_raw %>% filter(Q == question) %>%select(REF_POINT) %>% \n      pull(REF_POINT) %>% str_split(\"\") %>% unlist()\n  }\n    \n    #2. Is the response PRECISELY the REFERENCE POINT?\n    x = identical(ref_p,response)\n    x = as.numeric(x)  \n  \n    # paste(\"ref: \",ref_p)\n    # paste(\"response: \",response)\n    # paste(\"x: \",ref_p == response)\n    \n    #cleanup\n    rm(ref_p, response, question, cond)   \n    return(x) #1 = match, 0 = not match\n}\n\n#CALCULATE SCORE BASED ON UNION OF ORTH & TRI (SUBJECT SELECTS BOTH ANSWERS )\ncalc_both_score2 <- function(question, cond, response){\n  \n  \n  #TRAPDOOR \n  #since no orth responses exist for impasse condition q1 - q5, set to 0\n  if (question < 6 & cond == 121) {x = NA}\n  \n  #ELSE \n  #calculate union of ORTH and TRI\n  else {\n    if (question < 6 & cond == 111) #for q1 - q5 find key for question by condition\n  {\n     #grab the tri and orth keys for this question as well as N option set\n     tri_p =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_p = keys_orth %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     set_n =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n     #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n     both_p = union(tri_p, orth_p) #the selection of tri and p\n     #2. calc answers that should't be selected as diffrence between N [same for all keys] and both_p\n     both_q = setdiff(set_n,both_p)\n     both_pn = length(both_p)\n     both_qn = length(both_q)\n  } else{\n    \n     #grab the tri and orth keys for this question as well as N option set\n     tri_p =  keys_tri %>%  filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_p = keys_orth %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     set_n =  keys_tri %>%  filter(Q == question) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n     #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n     both_p = union(tri_p, orth_p) #the selection of tri and p\n     #2. calc answers that shouldn't be selected as difference between N [same for all keys] and both_p\n     both_q = setdiff(set_n,both_p)\n     both_pn = length(both_p)\n     both_qn = length(both_q)\n  }\n    \n  #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n  \n  #if response is not empty, split apart response for set comparison\n    if(response != \"\")\n    { response = response %>% str_split(\"\") %>% unlist()}\n  \n    both_ps = length(intersect(response,both_p))\n    both_qs = length(intersect(response,both_q))\n  \n \n  #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n  x = f_partialP(both_ps,both_pn,both_qs,both_qn)%>% unlist() %>% as.numeric()\n  \n  #cleanup\n  rm(both_p,both_q,both_pn,both_qn,both_ps,both_qs, question, cond, response )   \n  }\n  \n  return(x) #true correct, trues, false correct, false\n}\n\n\n#REORDER THE CHARACTERS IN A STRING\nreorder_inplace <- function(x)\n{\n  y =  x %>% str_split(\"\") %>% unlist() %>% sort() %>% str_c(collapse=\"\")\n  return (y)\n}\n```\n:::\n\n*note: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records*\n\n::: {.cell hash='2_sgc3A_scoring_cache/pdf/CALCULATE-SCORES-MAPPLY_8c52daf0cccb7956b85b08e9ce1d5faf'}\n\n```{.r .cell-code}\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n# #STRATEGY SUBSCORES\ndf_items$score_TRI = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tri))\ndf_items$score_ORTH = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_SAT_left = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_sub_score2, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#TODO SPECIAL SUBSCORES\ndf_items$score_REF = pbmapply(calc_ref_score2, df_items$q, df_items$condition, df_items$response)\ndf_items$score_BOTH = pbmapply(calc_both_score2, df_items$q, df_items$condition, df_items$response)\n  \n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1))\n\n# alt_scored = df_items\n```\n:::\n\nTODO: generate heat maps of Q9. Same answer but very different optimal operation paths!\n\n### Derive Interpretation\n\nFinally, we compare the interpretation subscores and decide which is highest. This indicates the interpretation that the individual's response most closely approximates. This algorithm makes assigns one of the following values to each item response:\n\n-   Orthogonal\n\n-   Triangular\n\n-   Tversky\n\n-   both Tri + Orth\n\n-   reference\n\n-   blank\n\n-   frenzy\n\n-   ? TODO ADJUST 'both' to select for both tri/satisfice or both tri/orth? See Q1 121 'CO'\n\n::: {.cell hash='2_sgc3A_scoring_cache/pdf/DERIVE-INTERPRETATION_318675055b43996f97a789f8ba2b7589'}\n\n```{.r .cell-code}\nthreshold_range = 0.5 #set required variance in subscores to be discriminant\nthreshold_frenzy = 4\n\nfor (x in 1:nrow(df_items)) {\n  \n  #CALCULATE MAX TVERSKY SUBSCORE\n  t = df_items[x,] %>% select(score_TV_max, score_TV_start, score_TV_end, score_TV_duration) #reshape\n  t.long = gather(t,score, value, 1:4)\n  t.long[t.long == \"\"] = NA #replace empty scores with NA so we can ignore them\n  if(length(unique(t.long$value)) == 1 ){\n    if(is.na(unique(t.long$value))){\n      df_items[x,'score_TVERSKY'] = NA\n      df_items[x,'tv_type'] = NA   \n    }\n  } else {\n    df_items[x,'score_TVERSKY'] = as.numeric(max(t.long$value,na.rm = TRUE))\n    df_items[x,'tv_type'] = t.long[which.max(t.long$value),'score']\n  }\n  \n  #CALCULATE MAX SATISFICING SUBSCORE\n  t = df_items[x,] %>% select(score_SAT_left, score_SAT_right)\n  t.long = gather(t,score, value, 1:2)\n  t.long[t.long == \"\"] = NA #replace empty scores\n  if(length(unique(t.long$value)) == 1 ){\n    if(is.na(unique(t.long$value))){\n      df_items[x,'score_SATISFICE'] = NA\n      df_items[x,'sat_type'] = NA   \n    }\n  } else {\n    df_items[x,'score_SATISFICE'] = as.numeric(max(t.long$value,na.rm = TRUE))\n    df_items[x,'sat_type'] = t.long[which.max(t.long$value),'score']  \n  }\n  \n  #NOW CALCULATE RANGE AMONG SUBSCORES\n  #order of this selection matters in breaking ties! \n  t = df_items[x,] %>% select(score_TRI, score_TVERSKY, score_SATISFICE, score_ORTH)\n  t.long = gather(t,score, value, 1:4)\n  t.long[t.long == \"\"] = NA\n  \n  df_items[x,'top_score'] = as.numeric(max(t.long$value,na.rm = TRUE))\n  df_items[x,'top_type'] = t.long[which.max(t.long$value),'score']\n  \n  #calculate the range between highest and lowest scores \n  r = as.numeric(range(t.long$value,na.rm = TRUE))\n  r = diff(r)\n  df_items[x,'range'] = r\n  \n  #DISCRIMINANT BETWEEN SUBSCORES TO PREDICT BEST FIT INTERPRETATION\n  \n  if (r < threshold_range) {\n      #then we can't predict the interpretation, leave it as \"?\"\n    df_items[x,'best'] = \"?\"\n  } else {\n      p =  df_items[x,'top_type']\n      if (p == \"score_TRI\") {df_items[x,'best'] = \"Triangular\"\n      } else if(p == \"score_ORTH\") {df_items[x,'best'] = \"Orthogonal\"\n      } else if(p == \"score_TVERSKY\") {df_items[x,'best'] = \"Tversky\"\n      } else if(p == \"score_SATISFICE\") {df_items[x,'best'] = \"Satisfice\"}\n  }\n  \n  #CHECK SPECIAL SITUATIONS\n\n  #BOTH TRI AND ORTH?  \n  if (!is.na(df_items[x,'score_BOTH'])) { #only check if both is not null\n      if( df_items[x,'score_BOTH'] == 1) {\n        df_items[x,'best'] = \"both tri + orth\"}\n  }\n  \n  #IS BLANK?\n  if( df_items[x,'num_o'] == 0) {  \n    df_items[x,'best'] = \"blank\"\n  }\n  \n  #IS FRENZY?\n  if( df_items[x,'num_o'] > threshold_frenzy) { \n      df_items[x,'best'] = \"frenzy\"\n  }\n\n  #IS REF POINT?\n  if (!is.na(df_items[x,'score_REF'])) { #only check if the score is NOT null\n      if( df_items[x,'score_REF'] == 1) {\n          df_items[x,'best'] = \"reference\"\n      }\n  }\n\n}#end loop\n\n#cleanup \nrm(t, t.long, x, r,p)\nrm(threshold_frenzy, threshold_range)\n\n#set order of levels\ndf_items$interpretation <- factor(df_items$best,\n                                  levels = c(\"Triangular\", \"Tversky\",\n                                             \"Satisfice\", \"Orthogonal\", \"reference\", \"both tri + orth\", \"blank\",\"frenzy\",\"?\"))\n\n\ndf_items$sorted_interpretation <- factor(df_items$best,\n                                  levels = c(\"Triangular\", \"Tversky\", \"both tri + orth\",\n                                             \"reference\",\"frenzy\",\"blank\",\"?\",\n                                             \"Satisfice\", \"Orthogonal\"))\n\n#recode as numeric inase they are char \n# df_items$score_TV_duration <- df_items$score_TV_duration %>% as.numeric()\n# df_items$score_SATISFICE <- df_items$score_SATISFICE %>% as.numeric()\n```\n:::\n\n### Derive Discriminant Score\n\n\"Orthogonal\" = -1, \"Satisfice\" = -1, \"Triangular\" = 1, \"Tversky\" = 0.5, \"both tri + orth\" = 0.5, \"reference\" = 0, \"blank\" = 0, \"frenzy\" = 0, \"?\" = 0)\n\nTODO should 'both' be coded as 0 or 1 or 0.5?\n\nTODO write description TODO recode with satisfice as -1\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_items$score_SCALED <- recode(df_items$interpretation,\n                          \"Orthogonal\" = -1,\n                          \"Satisfice\" = -1,\n                          \"Triangular\" = 1,\n                          \"Tversky\" = 0.5,\n                          \"both tri + orth\" = 0.5,\n                          \"reference\" = 0,\n                          \"blank\" = 0, \n                          \"frenzy\" = 0,\n                          \"?\" = 0)\n```\n:::\n\n## EXPLORE RESPONSES\n\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n### Scaffold Phase\n\nThe first five questions constitute the 'scaffold' (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\n#### Question #1\n\n##### Q1. Control Condition\n\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (`condition` = 111).\n\n![Question 1 --- Control Condition](static/questions/Q1_111.png){#fig-Q1-111}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 111) %>% filter(Q==1)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q1-CONTROL-KEY}Answer Key | Q1 Control Condition :  Which shift(s) start at 11 am?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & F & Z\\\\\n\\hline\nOrthgonal & A & OI\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & CF & Z\\\\\n\\hline\nTversky [start diagonal] & F & Z\\\\\n\\hline\nTversky [end diagonal] & C & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nHere we summarize the distinct response options given by participants on this item. Each letter in `response` indicates a checkbox selected by the participant (See @fig-Q1-111 ). `n` indicates the number of participants who gave this response, while `interpretation` indicates the *graph interpretation* most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\n\nNotice that for this Question, the *Triangular* answer is the same as the *Tversky \\[start diagonal\\]* answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Lines-Connect\", 2, 2) %>% \n  pack_rows(\"Orthogonal\", 3, 3) %>% \n  pack_rows(\"Other\", 4, 4)  %>% \n  pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q1-CONTROL-RESPONSES}Frequency of Selected Response Options for Question #1 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}F & 22 & Triangular & 1 & 1.000 & 1.000 & NA & -0.083 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}CF & 3 & Tversky & 0 & 0.923 & 1.000 & NA & -0.167 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}A & 129 & Orthogonal & 0 & -0.077 & -0.071 & NA & 1.000 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}AF & 1 & both tri + orth & 0 & 0.923 & 0.923 & NA & 0.917 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}DIJ & 1 & ? & 0 & -0.231 & -0.214 & NA & -0.167 & 0.0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.077 & -0.071 & NA & -0.083 & 0.0\\\\\n\\hline\n\\hspace{1em}Z & 1 & ? & 0 & 0.000 & 0.000 & NA & -0.083 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\rule{0pt}{1em}\\textit{Note: } n = number of responses in sample}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as `?` .\n\n+--------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Which shifts start at 11am?                            |                                                                                                                                                                                                |\n+========================================================+================================================================================================================================================================================================+\n| ![](static/interpretations/Q1_111_A.png){width=\"500\"}  | **Response: A**                                                                                                                                                                                |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   indicates an **orthogonal** (incorrect) interpretation of the coordinate system                                                                                                            |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   Consistent with the reader identifying the reference point (11am) on the x-axis, *projecting an invisible orthogonal line upward*, and locating data point **A**.                          |\n+--------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q1_111_F.png){width=\"500\"}  | **Response: F**                                                                                                                                                                                |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   indicates the **triangular** (correct) interpretation of the coordinate system                                                                                                             |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   Consistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point **F**.                                  |\n+--------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q1_111_CF.png){width=\"500\"} | **Response: C, F**                                                                                                                                                                             |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   indicates a **maximal-Tversky** strategy following connecting lines                                                                                                                        |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   Consistent with the reader identifying the reference point (11am) on the x-axis, and following *both* the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C. |\n+--------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q1_111_AF.png){width=\"500\"} | **Response: A , F**                                                                                                                                                                            |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   The reader selects both triangular and orthogonal-consistent data points                                                                                                                   |\n|                                                        |                                                                                                                                                                                                |\n|                                                        | -   Possibly indicates uncertainty or confusion                                                                                                                                                |\n+--------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: {tbl-colwidths=\"\\[25,75\\]\"}\n\nThree responses were given that were not consistent with any of the identified interpretations. *Note that options highlighted in light grey are considered within the range of 'visual error', defined by 0.5hr offset from the interpretation-specific projection.*\n\n+---------------------------------------------------------+------------------------------------------+----------------------------------------------------------------+\n| **D I J**                                               | **X**                                    | **Z**                                                          |\n|                                                         |                                          |                                                                |\n|                                                         |                                          | TODO find this person, did they subsequently give tri answers? |\n+=========================================================+==========================================+================================================================+\n| ![](static/interpretations/Q1_111_IJD.png){width=\"500\"} | ![](static/interpretations/Q1_111_X.png) | ![](static/interpretations/Q1_111_Z.png)                       |\n+---------------------------------------------------------+------------------------------------------+----------------------------------------------------------------+\n\n: {tbl-colwidths=\"\\[30,30,30\\]\"}\n\n##### Q1. Impasse Condition\n\nNext we explore the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (`condition` = 111).\n\n![Question 1 --- Impasse Condition](static/questions/Q1_121.png){#fig-Q1-121}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 121) %>% filter(Q==1)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q1-IMPASSE-KEY}Answer Key | Q1 Impasse Condition :  Which shift(s) start at 11 am?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & F & \\\\\n\\hline\nOrthgonal &  & \\\\\n\\hline\nSatisficing [left] & O & \\\\\n\\hline\nSatisficing [right] & AI & \\\\\n\\hline\nTversky [maximal] & CF & \\\\\n\\hline\nTversky [start diagonal] & F & \\\\\n\\hline\nTversky [end diagonal] & C & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nNotice that there **is no orthogonal answer** for this question. This is the purpose of the impasse condition, to remove the possibility of selecting the orthogonal answer, we expect learners will be more likely to restructure their understanding of the coordinate system, and arrive at a correct (triangular) interpretation.\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Lines-Connect\", 2, 4) %>% \n  pack_rows(\"Satisfice\", 5, 9) %>% \n  pack_rows(\"Other\", 10, 10) %>% \n  pack_rows(\"Unknown\", 11, 12) %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q1-IMPASSE-RESPONSES}Frequency of Selected Response Options for Question #1 (Impasse Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}F & 49 & Triangular & 1 & 1.000 & 1.000 & -0.071 & NA & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}CF & 14 & Tversky & 0 & 0.929 & 1.000 & -0.143 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}C & 3 & Tversky & 0 & -0.071 & 1.000 & -0.071 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}CO & 1 & Tversky & 0 & -0.143 & 0.929 & 0.929 & NA & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Satisfice}}\\\\\n\\hline\n\\hspace{1em}O & 28 & Satisfice & 0 & -0.071 & -0.071 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AI & 9 & Satisfice & 0 & -0.143 & -0.143 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}A & 4 & Satisfice & 0 & -0.071 & -0.071 & 0.500 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AO & 2 & Satisfice & 0 & -0.143 & -0.143 & 0.929 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}I & 2 & Satisfice & 0 & -0.071 & -0.071 & 0.500 & NA & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 57 & blank & 0 & 0.000 & 0.000 & NA & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}E & 2 & ? & 0 & -0.071 & -0.071 & -0.071 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.071 & -0.071 & -0.071 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\rule{0pt}{1em}\\textit{Note: } n = number of responses in sample}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as `?` .\n\nTODO ADJUST 'both' to select for both tri/satisfice or both tri/orth\n\n+--------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Which shifts start at 11am?                            |                                                                                                                                                                                                         |\n+========================================================+=========================================================================================================================================================================================================+\n| ![](static/interpretations/Q1_121_F.png)               | **Response: F**                                                                                                                                                                                         |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   indicates the **triangular** (correct) interpretation of the coordinate system                                                                                                                      |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   Consistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point **F**.                                           |\n+--------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q1_111_CF.png){width=\"500\"} | **Response: \\[C, F\\]**                                                                                                                                                                                  |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   indicates a **maximal-Tversky** strategy following connecting lines                                                                                                                                 |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   Consistent with the reader identifying the reference point (11am) on the x-axis, and following *both* the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C gridline. |\n+--------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q1_121_SATISFICE.png)       | **Responses: \\[AOI\\]**                                                                                                                                                                                  |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   indicates a **satisficing** strategy                                                                                                                                                                |\n|                                                        |                                                                                                                                                                                                         |\n|                                                        | -   Consistent with the reader identifying the datapoints nearest to the orthogonal projection from the reference point point                                                                           |\n+--------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: {tbl-colwidths=\"\\[25,75\\]\"}\n\nTwo responses were given that were not consistent with any of the identified interpretations.\n\n| **\\[E\\],\\[X\\]**                           |\n|-------------------------------------------|\n| ![](static/interpretations/Q1_121_EX.png) |\n\n: {tbl-colwidths=\"\\[30\\]\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q1-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q1-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #2\n\n##### Q2. Control Condition\n\n![Q2---Control Condition](static/questions/Q2_111.png){#fig-Q2-111}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 111) %>% filter(Q==2)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q2-CONTROL-KEY}Answer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & K & Z\\\\\n\\hline\nOrthgonal & E & G\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & AKJX & Z\\\\\n\\hline\nTversky [start diagonal] & AK & Z\\\\\n\\hline\nTversky [end diagonal] & X & \\\\\n\\hline\nTversky [duration line] & J & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>%\n  pack_rows(\"Lines-Connect\", 3, 4) %>% \n  pack_rows(\"Orthogonal\", 5, 7) %>%\n  pack_rows(\"Other\", 8, 8)  %>% \n  pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q2-CONTROL-RESPONSES}Frequency of Selected Response Options for Question #2 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}K & 24 & Triangular & 1 & 1.000 & 0.500 & NA & -0.083 & 1.0\\\\\n\\hline\n\\hspace{1em}DK & 1 & Triangular & 1 & 1.000 & 0.500 & NA & -0.083 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}J & 4 & Tversky & 0 & -0.083 & 1.000 & NA & -0.083 & 0.5\\\\\n\\hline\n\\hspace{1em}AK & 1 & Tversky & 0 & 0.917 & 1.000 & NA & -0.167 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}E & 121 & Orthogonal & 0 & -0.083 & -0.077 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}DE & 3 & Orthogonal & 0 & -0.083 & -0.077 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}EG & 1 & Orthogonal & 0 & -0.167 & -0.154 & NA & 1.000 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}D & 1 & reference & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}B & 1 & ? & 0 & -0.083 & -0.077 & NA & -0.083 & 0.0\\\\\n\\hline\n\\hspace{1em}C & 1 & ? & 0 & -0.083 & -0.077 & NA & -0.083 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\rule{0pt}{1em}\\textit{Note: } n = number of responses in sample}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point *in addition* to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Which shift(s) start at the same time as D?**          |                                                                                                                                                                                                                                                                         |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q2_111_ORTH.png){width=\"500\"} | **Reponse: E** (also EG, DE)                                                                                                                                                                                                                                            |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   indicates an **orthogonal** (incorrect) interpretation of the coordinate system                                                                                                                                                                                     |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   Consistent with the reader identifying the reference point (D) on the graph, *projecting an invisible orthogonal line through it*, and locating data point **E**.                                                                                                   |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q2_111_TRI.png){width=\"500\"}  | **Response: K** (also KD)                                                                                                                                                                                                                                               |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   indicates an **triangular** (correct) interpretation of the coordinate system                                                                                                                                                                                       |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   Consistent with the reader identifying the reference point (D) on the graph, and following its *descending-leftward* *diagonal gridline*, and locating data point **K**.                                                                                            |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q2_111_AK.png){width=\"500\"}   | **Response: AK**                                                                                                                                                                                                                                                        |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   indicates an **Tversky** strategy following connecting lines                                                                                                                                                                                                        |\n|                                                          | -   Consistent with the reader identifying the reference point (D) on the graph, and following its *descending-leftward* *diagonal gridline*, and locating data point **K** then *continuing* *along the connecting ascending leftward diagonal* locating data point A. |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q2_111_J.png){width=\"500\"}    | **Response: J**                                                                                                                                                                                                                                                         |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   indicates an **Tversky** strategy following connecting lines                                                                                                                                                                                                        |\n|                                                          | -   Consistent with the reader identifying the reference point (D) on the graph, and following its horizontal gridline to the y-axis, locating data point J.                                                                                                            |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q2_111_D.png){width=\"500\"}    | **Response: D**                                                                                                                                                                                                                                                         |\n|                                                          |                                                                                                                                                                                                                                                                         |\n|                                                          | -   the reader selected only the **reference point**                                                                                                                                                                                                                    |\n|                                                          | -   Consistent with the reader identifying the reference point (D) on the graph                                                                                                                                                                                         |\n|                                                          | -   Possibly indicates uncertainty or confusion                                                                                                                                                                                                                         |\n+----------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: {tbl-colwidths=\"\\[25,75\\]\"}\n\n| B                                                     | C                                        |\n|-------------------------------------------------------|------------------------------------------|\n| ![](static/interpretations/Q2_111_B.png){width=\"500\"} | ![](static/interpretations/Q2_111_C.png) |\n\n: {tbl-colwidths=\"\\[30,30\\]\"}\n\n##### Q2. Impasse Condition\n\n![Q2---Impasse Condition](static/questions/Q2_121.png){#fig-Q2-121}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 121) %>% filter(Q==2)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q2-IMPASSE-KEY}Answer Key | Q2 Impasse Condition :  Which shift(s) start at the same time as D?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & K & Z\\\\\n\\hline\nOrthgonal &  & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] & G & \\\\\n\\hline\nTversky [maximal] & JKE & Z\\\\\n\\hline\nTversky [start diagonal] & K & Z\\\\\n\\hline\nTversky [end diagonal] & E & \\\\\n\\hline\nTversky [duration line] & J & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #2 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>%\n  pack_rows(\"Lines-Connect\", 3, 10) %>% \n  pack_rows(\"Satisfice\", 11, 12) %>%\n  pack_rows(\"Other\", 13, 16)  %>% \n  pack_rows(\"Unknown\", 17, 18)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q2-IMPASSE-RESPONSES}Frequency of Selected Response Options for Question #2 (Impasse Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}K & 69 & Triangular & 1 & 1.000 & 1.000 & -0.077 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}DK & 1 & Triangular & 1 & 1.000 & 1.000 & -0.077 & NA & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}J & 12 & Tversky & 0 & -0.083 & 1.000 & -0.077 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}EK & 3 & Tversky & 0 & 0.917 & 0.923 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}EX & 2 & Tversky & 0 & -0.167 & 0.923 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}BEG & 1 & Tversky & 0 & -0.250 & 0.846 & 0.846 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}E & 1 & Tversky & 0 & -0.083 & 1.000 & -0.077 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}EKX & 1 & Tversky & 0 & 0.833 & 0.846 & -0.231 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}HJZ & 1 & Tversky & 0 & -0.167 & 0.846 & -0.231 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}JK & 1 & Tversky & 0 & 0.917 & 0.923 & -0.154 & NA & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Satisfice}}\\\\\n\\hline\n\\hspace{1em}G & 19 & Satisfice & 0 & -0.083 & -0.077 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}BG & 2 & Satisfice & 0 & -0.167 & -0.154 & 0.923 & NA & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}D & 7 & reference & 0 & 0.000 & NA & 0.000 & NA & 0.0\\\\\n\\hline\n\\hspace{1em} & 43 & blank & 0 & 0.000 & NA & 0.000 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ACDFHIJKOUXZ & 1 & frenzy & 0 & 0.250 & 0.250 & -0.846 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}BEGKUZ & 1 & frenzy & 0 & 0.667 & 0.667 & 0.615 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}C & 6 & ? & 0 & -0.083 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}FO & 1 & ? & 0 & -0.167 & -0.154 & -0.154 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\rule{0pt}{1em}\\textit{Note: } n = number of responses in sample}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q2-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q2-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #3\n\n##### Q3. Control Condition\n\n![Q3---Control Condition](static/questions/Q3_111.png){#fig-Q3-111}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 111) %>% filter(Q==3)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q3-CONTROL-KEY}Answer Key | Q3 Control Condition :  Which shift(s) begin when C ends?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & F & Z\\\\\n\\hline\nOrthgonal & Z & FIO\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & AUBFOJ & \\\\\n\\hline\nTversky [start diagonal] & OJ & \\\\\n\\hline\nTversky [end diagonal] & F & Z\\\\\n\\hline\nTversky [duration line] & AUB & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Lines-Connect\", 3, 7) %>% \n  pack_rows(\"Orthogonal\", 8, 8) %>% \n  pack_rows(\"Other\", 9, 10) %>% \n  pack_rows(\"Unknown\", 11, 17)  \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q3-CONTROL-RESPONSES}Frequency of Selected Response Options for Question #3 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}F & 24 & Triangular & 1 & 1.000 & 1.000 & NA & 0.0 & 1.0\\\\\n\\hline\n\\hspace{1em}EFK & 1 & Triangular & 0 & 0.833 & 0.833 & NA & -0.2 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}ABU & 4 & Tversky & 0 & -0.250 & 1.000 & NA & -0.3 & 0.5\\\\\n\\hline\n\\hspace{1em}O & 3 & Tversky & 0 & -0.083 & 0.500 & NA & 0.0 & 0.5\\\\\n\\hline\n\\hspace{1em}JO & 2 & Tversky & 0 & -0.167 & 1.000 & NA & -0.1 & 0.5\\\\\n\\hline\n\\hspace{1em}DJO & 1 & Tversky & 0 & -0.250 & 0.917 & NA & -0.2 & 0.5\\\\\n\\hline\n\\hspace{1em}KO & 1 & Tversky & 0 & -0.167 & 0.417 & NA & -0.1 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}Z & 94 & Orthogonal & 0 & 0.000 & 0.000 & NA & 1.0 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}C & 1 & reference & 0 & 0.000 & NA & NA & 0.0 & 0.0\\\\\n\\hline\n\\hspace{1em}ABDEFGHIJKOUXZ & 1 & frenzy & 0 & 0.000 & NA & NA & 0.0 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}A & 18 & ? & 0 & -0.083 & 0.333 & NA & -0.1 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 3 & ? & 0 & -0.083 & -0.083 & NA & -0.1 & 0.0\\\\\n\\hline\n\\hspace{1em}AH & 1 & ? & 0 & -0.167 & 0.242 & NA & -0.2 & 0.0\\\\\n\\hline\n\\hspace{1em}DE & 1 & ? & 0 & -0.167 & -0.167 & NA & -0.2 & 0.0\\\\\n\\hline\n\\hspace{1em}E & 1 & ? & 0 & -0.083 & -0.083 & NA & -0.1 & 0.0\\\\\n\\hline\n\\hspace{1em}EU & 1 & ? & 0 & -0.167 & 0.242 & NA & -0.2 & 0.0\\\\\n\\hline\n\\hspace{1em}U & 1 & ? & 0 & -0.083 & 0.333 & NA & -0.1 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nTODO\n\n-   address RESPONSE FKE which is classified as Triangular but doesn't seem to fit this interpretation?\n-   Should O,K be considered Tvresky ?\n-   consider adding trapdoor on n_q, such that score is penalized (OR interpretation is not predicted?) if the Ss selects more than 1 extra options, or is missing more than 2 options?\n-   LEFT OFF HERE\n\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| What shift(s) begin when C ends?               |                                                                                                                                                                                                                                                                                           |\n+================================================+===========================================================================================================================================================================================================================================================================================+\n| ![](static/interpretations/Q3_111_Z.png)       | **Response: Z**                                                                                                                                                                                                                                                                           |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   indicates an **orthogonal** (incorrect) interpretation of the coordinate system                                                                                                                                                                                                       |\n|                                                | -   Consistent with the reader identifying the reference point (C) then using the duration encoded on the y-axis (2) , project along the horizontal gridline by two hours, and then *project an invisible orthogonal line through that time (12PM)* locating data point **Z**.            |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q3_111_F.png)       | **Response: F**                                                                                                                                                                                                                                                                           |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   indicates a (correct) **triangular** interpretation of the coordinate system                                                                                                                                                                                                          |\n|                                                | -   Consistent with the reader identifying the reference point (C) on the graph, and following the *descending gridline* to the x-axis to identify the end-time (11AM) and then following the *ascending gridline* to identify datapoints starting at 11AM and locating data point **F**. |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q3_111_AUB.png)     | **Response: AUB (also A)**                                                                                                                                                                                                                                                                |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   indicates a Tversky strategy following connecting lines (duration)                                                                                                                                                                                                                    |\n|                                                | -   Consistent with the reader identifying the reference point (C) on the graph, and following the *horizontal y-axis gridline* and locating data points **A U B**.                                                                                                                       |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![]()![](static/interpretations/Q3_111_OJ.png) | **Response: OJ**                                                                                                                                                                                                                                                                          |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   indicates a Tversky strategy following connecting lines (start-time)                                                                                                                                                                                                                  |\n|                                                | -   Consistent with the reader identifying the reference point (C) on the graph, and following the *ascending diagonal gridline* and locating data points **O J**.                                                                                                                        |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q3_111_C.png)       | **Response: C**                                                                                                                                                                                                                                                                           |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   the participant selected the point referenced in the question                                                                                                                                                                                                                         |\n|                                                | -   possibly indicates confusion or uncertainty                                                                                                                                                                                                                                           |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| ![](static/interpretations/Q3_111_frenzy.png)  | **Response: AIOZFHJXKUDEGB**                                                                                                                                                                                                                                                              |\n|                                                |                                                                                                                                                                                                                                                                                           |\n|                                                | -   the participant selects *all* (or nearly all) the data points                                                                                                                                                                                                                         |\n|                                                | -   possibly indicates confusion or uncertainty                                                                                                                                                                                                                                           |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: {tbl-colwidths=\"\\[25,75\\]\"}\n\nSix responses (from 9 participants) appear inconsistent with any interpretation.\n\n| K (**n=3)**                                   | AH (n=1)                                  | DE (n=1)                                  |\n|-----------------------------------------------|-------------------------------------------|-------------------------------------------|\n| ![]()![](static/interpretations/Q3_111_K.png) | ![](static/interpretations/Q3_111_AH.png) | ![](static/interpretations/Q3_111_ED.png) |\n| **UE (n=1)**                                  | **U (n=1)**                               | **E (n=1)**                               |\n| ![](static/interpretations/Q3_111_UE.png)     | ![](static/interpretations/Q3_111_U.png)  | ![](static/interpretations/Q3_111_E.png)  |\n\n: {tbl-colwidths=\"\\[30,30,30\\]\"}\n\n##### Q3. Impasse Condition\n\n![Q3---Impasse Condition](static/questions/Q3_121.png){#fig-Q3-121}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 121) %>% filter(Q==3)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q3-IMPASSE-KEY}Answer Key | Q3 Impasse Condition :  Which shift(s) begin when C ends?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & F & \\\\\n\\hline\nOrthgonal &  & \\\\\n\\hline\nSatisficing [left] & AI & \\\\\n\\hline\nSatisficing [right] & F & \\\\\n\\hline\nTversky [maximal] & BJ & \\\\\n\\hline\nTversky [start diagonal] & J & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] & B & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nTODO investigate these responses 17 at O?\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #3 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 5) %>% \n  pack_rows(\"Lines-Connect\", 3, 5) %>% \n  pack_rows(\"Satisfice\", 6, 15) %>% \n  pack_rows(\"Other\", 16, 21) %>% \n  pack_rows(\"Unknown\", 22, 29) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q3-IMPASSE-RESPONSES}Frequency of Selected Response Options for Question #3 (Impasse Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}F & 61 & Triangular & 1 & 1.000 & -0.077 & 1.000 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AF & 5 & Triangular & 0 & 0.923 & -0.154 & 0.923 & NA & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}\\hspace{1em}AFG & 1 & Triangular & 0 & 0.846 & -0.231 & 0.846 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}\\hspace{1em}B & 8 & Tversky & 0 & -0.077 & 1.000 & -0.077 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}\\hspace{1em}J & 3 & Tversky & 0 & -0.077 & 1.000 & -0.077 & NA & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Satisfice}}\\\\\n\\hline\n\\hspace{1em}BE & 1 & Tversky & 0 & -0.154 & 0.923 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}BJ & 1 & Tversky & 0 & -0.154 & 1.000 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}HJZ & 1 & Tversky & 0 & -0.231 & 0.846 & -0.231 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}A & 7 & Satisfice & 0 & -0.077 & -0.077 & 0.500 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AH & 5 & Satisfice & 0 & -0.154 & -0.154 & 0.417 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AI & 3 & Satisfice & 0 & -0.154 & -0.154 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AOU & 3 & Satisfice & 0 & -0.231 & -0.231 & 0.333 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AFI & 2 & Satisfice & 0 & 0.846 & -0.231 & 0.917 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AIO & 2 & Satisfice & 0 & -0.231 & -0.231 & 0.917 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AO & 2 & Satisfice & 0 & -0.154 & -0.154 & 0.417 & NA & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}C & 2 & reference & 0 & 0.000 & 0.000 & NA & NA & 0.0\\\\\n\\hline\n\\hspace{1em} & 36 & blank & 0 & 0.000 & 0.000 & NA & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ABDEFGHIJKOUXZ & 1 & frenzy & 0 & 0.000 & 0.000 & NA & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ABDEFGHJKUZ & 1 & frenzy & 0 & 0.231 & 0.250 & 0.231 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}BDEFGHJKU & 1 & frenzy & 0 & 0.385 & 0.417 & 0.385 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}BDEFGHJKUXZ & 1 & frenzy & 0 & 0.231 & 0.250 & 0.231 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}O & 17 & ? & 0 & -0.077 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}DK & 2 & ? & 0 & -0.154 & -0.154 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}FJZ & 1 & ? & 0 & 0.846 & 0.846 & 0.846 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}K & 1 & ? & 0 & -0.077 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}KO & 1 & ? & 0 & -0.154 & -0.154 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}U & 1 & ? & 0 & -0.077 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.077 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}Z & 1 & ? & 0 & -0.077 & -0.077 & -0.077 & NA & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q3-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q3-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #4\n\n\\[PLACEHOLDER --- NOT YET CONSIDERED THIS QUESTION\\]\n\n###### Q4. Control Condition\n\n![Q4---Control Condition](static/questions/Q4_111.png){#fig-Q4-111}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 111) %>% filter(Q==4)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q4-CONTROL-KEY}Answer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & H & \\\\\n\\hline\nOrthgonal & U & OF\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & BH & \\\\\n\\hline\nTversky [start diagonal] & B & \\\\\n\\hline\nTversky [end diagonal] & H & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Lines-Connect\", 3, 3) %>% \n  pack_rows(\"Orthogonal\", 4, 8) %>% \n  pack_rows(\"Other\", 9, 10) %>% \n  pack_rows(\"Unknown\", 11, 16) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q4-CONTROL-RESPONSES}Frequency of Selected Response Options for Question #4 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}H & 29 & Triangular & 1 & 1.000 & 1.000 & NA & -0.083 & 1.0\\\\\n\\hline\n\\hspace{1em}AH & 1 & Triangular & 0 & 0.929 & 0.929 & NA & -0.167 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}B & 3 & Tversky & 0 & -0.071 & 1.000 & NA & -0.083 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}U & 87 & Orthogonal & 0 & -0.071 & -0.071 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}FU & 2 & Orthogonal & 0 & -0.143 & -0.143 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}DEOU & 1 & Orthogonal & 0 & -0.286 & -0.286 & NA & 0.833 & -1.0\\\\\n\\hline\n\\hspace{1em}DEU & 1 & Orthogonal & 0 & -0.214 & -0.214 & NA & 0.833 & -1.0\\\\\n\\hline\n\\hspace{1em}KU & 1 & Orthogonal & 0 & -0.143 & -0.143 & NA & 0.917 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 6 & blank & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}ACFHIJKOUXZ & 1 & frenzy & 0 & 0.286 & 0.286 & NA & 0.333 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}DE & 14 & ? & 0 & -0.143 & -0.143 & NA & -0.167 & 0.0\\\\\n\\hline\n\\hspace{1em}E & 6 & ? & 0 & -0.071 & -0.071 & NA & -0.083 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 2 & ? & 0 & -0.071 & -0.071 & NA & -0.083 & 0.0\\\\\n\\hline\n\\hspace{1em}O & 2 & ? & 0 & -0.071 & -0.071 & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}D & 1 & ? & 0 & -0.071 & -0.071 & NA & -0.083 & 0.0\\\\\n\\hline\n\\hspace{1em}G & 1 & ? & 0 & -0.071 & -0.071 & NA & -0.083 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n| Orthogonal                                                                                                                                                                                                             | Orthogonal-LinesConnecting                                                                                                                                                                                                                                                                                                                                                                      |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ![](static/interpretations/Q4_111_ORTH.png) \\|                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                 |\n| If the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U 'end time' intersects with the (incorrect) orthogonal projection of 4:00PM. | Alternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an 'orthogonal-lines connect\" strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that *start* at 4:00pm in order to find those that *end* at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm. |\n\n: TBL4 test {tbl-colwidths=\"\\[50,50\\]\"}\n\n###### Q4. Impasse Condition\n\n![Q4---Impasse Condition](static/questions/Q4_121.png){#fig-Q4-121}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 121) %>% filter(Q==4)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q4-IMPASSE-KEY}Answer Key | Q4 Impasse Condition :  Which shift(s) end at 4 pm?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & H & \\\\\n\\hline\nOrthgonal &  & \\\\\n\\hline\nSatisficing [left] & FO & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & BH & \\\\\n\\hline\nTversky [start diagonal] & B & \\\\\n\\hline\nTversky [end diagonal] & H & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nTODO investigate D? add to tversky or orth?\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #4 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Lines-Connect\", 3, 6) %>% \n  pack_rows(\"Satisfice\", 7, 10) %>% \n  pack_rows(\"Other\", 11, 12) %>% \n  pack_rows(\"Unknown\", 13, 19) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q4-IMPASSE-RESPONSES}Frequency of Selected Response Options for Question #4 (Impasse Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}H & 64 & Triangular & 1 & 1.000 & 1.000 & -0.077 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}DH & 1 & Triangular & 0 & 0.929 & 0.929 & -0.154 & NA & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}B & 6 & Tversky & 0 & -0.071 & 1.000 & -0.077 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}BD & 2 & Tversky & 0 & -0.143 & 0.929 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}BH & 2 & Tversky & 0 & 0.929 & 1.000 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}BDEG & 1 & Tversky & 0 & -0.286 & 0.786 & -0.308 & NA & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Satisfice}}\\\\\n\\hline\n\\hspace{1em}O & 11 & Satisfice & 0 & -0.071 & -0.071 & 0.500 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}F & 8 & Satisfice & 0 & -0.071 & -0.071 & 0.500 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}FO & 7 & Satisfice & 0 & -0.143 & -0.143 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}AFG & 1 & Satisfice & 0 & -0.214 & -0.214 & 0.346 & NA & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 20 & blank & 0 & 0.000 & 0.000 & 0.000 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ACFHIJKOUZ & 1 & frenzy & 0 & 0.357 & 0.357 & 0.385 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}D & 35 & ? & 0 & -0.071 & -0.071 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}A & 5 & ? & 0 & -0.071 & -0.071 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}K & 3 & ? & 0 & -0.071 & -0.071 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}G & 2 & ? & 0 & -0.071 & -0.071 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}AI & 1 & ? & 0 & -0.143 & -0.143 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}DK & 1 & ? & 0 & -0.143 & -0.143 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}J & 1 & ? & 0 & -0.071 & -0.071 & -0.077 & NA & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q4-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q4-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #5\n\n###### Q5. Control Condition\n\n![Q5---Control Condition](static/questions/Q5_111.png){#fig-Q5-111}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 111) %>% filter(Q==5)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q5-CONTROL-KEY}Answer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & O & AZ\\\\\n\\hline\nOrthgonal & U & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & UGX & AZKD\\\\\n\\hline\nTversky [start diagonal] & X & \\\\\n\\hline\nTversky [end diagonal] & UG & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 4) %>% \n  pack_rows(\"Lines-Connect\", 5, 7) %>% \n  pack_rows(\"Orthogonal\", 8, 9) %>% \n  pack_rows(\"Other\", 10, 11) %>% \n  pack_rows(\"Unknown\", 12, 22) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q5-CONTROL-RESPONSES}Frequency of Selected Response Options for Question #5 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}O & 50 & Triangular & 1 & 1.000 & -0.077 & NA & -0.077 & 1.0\\\\\n\\hline\n\\hspace{1em}FO & 3 & Triangular & 0 & 0.909 & -0.154 & NA & -0.154 & 1.0\\\\\n\\hline\n\\hspace{1em}HO & 1 & Triangular & 0 & 0.909 & -0.154 & NA & -0.154 & 1.0\\\\\n\\hline\n\\hspace{1em}KO & 1 & Triangular & 0 & 0.909 & -0.143 & NA & -0.154 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}FG & 2 & Tversky & 0 & -0.182 & 0.417 & NA & -0.154 & 0.5\\\\\n\\hline\n\\hspace{1em}G & 1 & Tversky & 0 & -0.091 & 0.500 & NA & -0.077 & 0.5\\\\\n\\hline\n\\hspace{1em}X & 1 & Tversky & 0 & -0.091 & 1.000 & NA & -0.077 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}U & 64 & Orthogonal & 0 & -0.091 & 0.500 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}HU & 1 & Orthogonal & 0 & -0.182 & 0.417 & NA & 0.923 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}I & 1 & reference & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em} & 6 & blank & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}F & 10 & ? & 0 & -0.091 & -0.077 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}H & 3 & ? & 0 & -0.091 & -0.077 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}J & 3 & ? & 0 & -0.091 & -0.077 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}B & 2 & ? & 0 & -0.091 & -0.077 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}DJ & 2 & ? & 0 & -0.182 & -0.143 & NA & -0.154 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 2 & ? & 0 & -0.091 & 0.000 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}C & 1 & ? & 0 & -0.091 & -0.077 & NA & -0.077 & 0.0\\\\\n\\hline\n\\hspace{1em}DEHJ & 1 & ? & 0 & -0.364 & -0.308 & NA & -0.308 & 0.0\\\\\n\\hline\n\\hspace{1em}FK & 1 & ? & 0 & -0.182 & -0.143 & NA & -0.154 & 0.0\\\\\n\\hline\n\\hspace{1em}HJ & 1 & ? & 0 & -0.182 & -0.154 & NA & -0.154 & 0.0\\\\\n\\hline\n\\hspace{1em}Z & 1 & ? & 0 & 0.000 & 0.000 & NA & -0.077 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n##### Q5. Impasse Condition\n\n![Q5---Impasse Condition](static/questions/Q5_121.png){#fig-Q5-121}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(condition == 121) %>% filter(Q==5)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q5-IMPASSE-KEY}Answer Key | Q5 Impasse Condition :  Coffee breaks happen halfway through a shift.</br> Which shift(s) share a break with I?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & A & \\\\\n\\hline\nOrthgonal &  & \\\\\n\\hline\nSatisficing [left] & K & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & OX & \\\\\n\\hline\nTversky [start diagonal] & OX & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  AIKGXJDBCHUZOFE}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 7) %>% \n  pack_rows(\"Lines-Connect\", 8, 13) %>% \n  pack_rows(\"Orthogonal\", 14, 16) %>% \n  pack_rows(\"Other\", 17, 21) %>% \n  pack_rows(\"Unknown\", 22, 31) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q5-IMPASSE-RESPONSES}Frequency of Selected Response Options for Question #5 (Control Condition)}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}A & 83 & Triangular & 1 & 1.000 & -0.083 & -0.077 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AFG & 5 & Triangular & 0 & 0.846 & -0.250 & -0.231 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AF & 4 & Triangular & 0 & 0.923 & -0.167 & -0.154 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AO & 2 & Triangular & 0 & 0.923 & 0.417 & -0.154 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AI & 1 & Triangular & 1 & 1.000 & -0.083 & -0.077 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AU & 1 & Triangular & 0 & 0.923 & -0.167 & -0.154 & NA & 1.0\\\\\n\\hline\n\\hspace{1em}AZ & 1 & Triangular & 0 & 0.923 & -0.167 & -0.154 & NA & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}O & 6 & Tversky & 0 & -0.077 & 0.500 & -0.077 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}CO & 1 & Tversky & 0 & -0.154 & 0.417 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}JO & 1 & Tversky & 0 & -0.154 & 0.417 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}OX & 1 & Tversky & 0 & -0.154 & 1.000 & -0.154 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}UXZ & 1 & Tversky & 0 & -0.231 & 0.333 & -0.231 & NA & 0.5\\\\\n\\hline\n\\hspace{1em}X & 1 & Tversky & 0 & -0.077 & 0.500 & -0.077 & NA & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}K & 5 & Satisfice & 0 & -0.077 & -0.083 & 1.000 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}HK & 3 & Satisfice & 0 & -0.154 & -0.167 & 0.923 & NA & -1.0\\\\\n\\hline\n\\hspace{1em}HKUZ & 1 & Satisfice & 0 & -0.308 & -0.333 & 0.769 & NA & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}I & 2 & reference & 0 & 0.000 & 0.000 & 0.000 & NA & 0.0\\\\\n\\hline\n\\hspace{1em} & 24 & blank & 0 & 0.000 & 0.000 & 0.000 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ABCFGUZ & 1 & frenzy & 0 & 0.538 & -0.583 & -0.538 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}ACDEFHIJKOUXZ & 1 & frenzy & 0 & 0.154 & 0.167 & 0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}FHJKX & 1 & frenzy & 0 & -0.385 & 0.167 & 0.692 & NA & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}H & 11 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}J & 3 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}C & 2 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}DJ & 2 & ? & 0 & -0.154 & -0.167 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}F & 2 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}FU & 2 & ? & 0 & -0.154 & -0.167 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}DG & 1 & ? & 0 & -0.154 & -0.167 & -0.154 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}FHZ & 1 & ? & 0 & -0.231 & -0.250 & -0.231 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}U & 1 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\hspace{1em}Z & 1 & ? & 0 & -0.077 & -0.083 & -0.077 & NA & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q5-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q5-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n### Testing Phase\n\nThe following 10 questions were the same for both conditions.\n\n#### Question #6 NONDISCRIM\n\n![Q6-Question](static/questions/Q6.png){#fig-Q6}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q6-KEY}Answer Key | Q :  Which shift(s) are six hours long?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & EG & \\\\\n\\hline\nOrthgonal & EG & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] &  & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\nTODO discuss non discriminant\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q6-RESPONSES}Frequency of Selected Response Options for Question #6}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\nEG & 330 & both tri + orth & 1 & 1 & NA & NA & 1 & 0.5\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q6-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q6-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #7\n\n![Q7-Question](static/questions/Q7.png){#fig-Q7}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q7-KEY}Answer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & OX & \\\\\n\\hline\nOrthgonal & FB & M\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & IJZNCHOX & \\\\\n\\hline\nTversky [start diagonal] & OX & \\\\\n\\hline\nTversky [end diagonal] & IJZN & \\\\\n\\hline\nTversky [duration line] & CH & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 5) %>%\n  pack_rows(\"Lines-Connect\", 6, 9) %>%\n  pack_rows(\"Orthogonal\", 10, 13) %>%\n  pack_rows(\"Other\", 14, 14) %>%\n  pack_rows(\"Unknown\", 15, 17)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q7-RESPONSES}Frequency of Selected Response Options for Question #7}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}OX & 93 & Triangular & 1 & 1.000 & 1.000 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}MO & 2 & Triangular & 0 & 0.438 & 0.438 & NA & -0.067 & 1.0\\\\\n\\hline\n\\hspace{1em}AX & 1 & Triangular & 0 & 0.438 & 0.438 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}MOX & 1 & Triangular & 0 & 0.938 & 0.938 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}MX & 1 & Triangular & 0 & 0.438 & 0.438 & NA & -0.067 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}IJ & 3 & Tversky & 0 & -0.125 & 0.500 & NA & -0.133 & 0.5\\\\\n\\hline\n\\hspace{1em}CH & 1 & Tversky & 0 & -0.125 & 1.000 & NA & -0.133 & 0.5\\\\\n\\hline\n\\hspace{1em}DJNX & 1 & Tversky & 0 & 0.312 & 0.357 & NA & -0.267 & 0.5\\\\\n\\hline\n\\hspace{1em}HK & 1 & Tversky & 0 & -0.125 & 0.438 & NA & -0.133 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}BF & 203 & Orthogonal & 0 & -0.125 & -0.125 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}FZ & 16 & Orthogonal & 0 & -0.125 & 0.179 & NA & 0.433 & -1.0\\\\\n\\hline\n\\hspace{1em}B & 1 & Orthogonal & 0 & -0.062 & -0.062 & NA & 0.500 & -1.0\\\\\n\\hline\n\\hspace{1em}F & 1 & Orthogonal & 0 & -0.062 & -0.062 & NA & 0.500 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 2 & blank & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}GK & 1 & ? & 0 & -0.125 & -0.125 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}JM & 1 & ? & 0 & -0.125 & 0.179 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}KM & 1 & ? & 0 & -0.125 & -0.125 & NA & -0.067 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q7-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q7-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #8\n\n![Q8-Question](static/questions/Q8.png){#fig-Q8}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q8-KEY}Answer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & G & \\\\\n\\hline\nOrthgonal & E & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] &  & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 10) %>%\n  pack_rows(\"Orthogonal\", 11, 16) %>%\n  pack_rows(\"Other\", 17, 21) %>%\n  pack_rows(\"Unknown\", 22, 45)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q8-RESPONSES}Frequency of Selected Response Options for Question #8}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}G & 64 & Triangular & 1 & 1.000 & NA & NA & -0.067 & 1\\\\\n\\hline\n\\hspace{1em}AGK & 4 & Triangular & 0 & 0.867 & NA & NA & -0.200 & 1\\\\\n\\hline\n\\hspace{1em}CG & 3 & Triangular & 0 & 0.933 & NA & NA & -0.133 & 1\\\\\n\\hline\n\\hspace{1em}FG & 3 & Triangular & 0 & 0.933 & NA & NA & -0.133 & 1\\\\\n\\hline\n\\hspace{1em}AG & 2 & Triangular & 0 & 0.933 & NA & NA & -0.133 & 1\\\\\n\\hline\n\\hspace{1em}CFGO & 2 & Triangular & 0 & 0.800 & NA & NA & -0.267 & 1\\\\\n\\hline\n\\hspace{1em}ACGP & 1 & Triangular & 0 & 0.800 & NA & NA & -0.267 & 1\\\\\n\\hline\n\\hspace{1em}CFG & 1 & Triangular & 0 & 0.867 & NA & NA & -0.200 & 1\\\\\n\\hline\n\\hspace{1em}CGM & 1 & Triangular & 0 & 0.867 & NA & NA & -0.200 & 1\\\\\n\\hline\n\\hspace{1em}GM & 1 & Triangular & 0 & 0.933 & NA & NA & -0.133 & 1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}E & 157 & Orthogonal & 0 & -0.067 & NA & NA & 1.000 & -1\\\\\n\\hline\n\\hspace{1em}EIJ & 5 & Orthogonal & 0 & -0.200 & NA & NA & 0.867 & -1\\\\\n\\hline\n\\hspace{1em}EFIJ & 3 & Orthogonal & 0 & -0.267 & NA & NA & 0.800 & -1\\\\\n\\hline\n\\hspace{1em}EF & 2 & Orthogonal & 0 & -0.133 & NA & NA & 0.933 & -1\\\\\n\\hline\n\\hspace{1em}EI & 2 & Orthogonal & 0 & -0.133 & NA & NA & 0.933 & -1\\\\\n\\hline\n\\hspace{1em}EFI & 1 & Orthogonal & 0 & -0.200 & NA & NA & 0.867 & -1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 12 & blank & 0 & 0.000 & NA & NA & 0.000 & 0\\\\\n\\hline\n\\hspace{1em}DEHIJNOZ & 2 & frenzy & 0 & -0.533 & NA & NA & 0.533 & 0\\\\\n\\hline\n\\hspace{1em}EFGIJ & 2 & frenzy & 0 & 0.733 & NA & NA & 0.733 & 0\\\\\n\\hline\n\\hspace{1em}CDGHLNOXZ & 1 & frenzy & 0 & 0.533 & NA & NA & -0.533 & 0\\\\\n\\hline\n\\hspace{1em}DEIJN & 1 & frenzy & 0 & -0.333 & NA & NA & 0.733 & 0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}IJ & 17 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}I & 7 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}EFG & 3 & ? & 0 & 0.867 & NA & NA & 0.867 & 0\\\\\n\\hline\n\\hspace{1em}J & 3 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}O & 3 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}A & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}AK & 2 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}C & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}DN & 2 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}F & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}IJM & 2 & ? & 0 & -0.200 & NA & NA & -0.200 & 0\\\\\n\\hline\n\\hspace{1em}L & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}M & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}CM & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}CX & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}D & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}DHNZ & 1 & ? & 0 & -0.267 & NA & NA & -0.267 & 0\\\\\n\\hline\n\\hspace{1em}DIJN & 1 & ? & 0 & -0.267 & NA & NA & -0.267 & 0\\\\\n\\hline\n\\hspace{1em}EFGI & 1 & ? & 0 & 0.800 & NA & NA & 0.800 & 0\\\\\n\\hline\n\\hspace{1em}HLO & 1 & ? & 0 & -0.200 & NA & NA & -0.200 & 0\\\\\n\\hline\n\\hspace{1em}IO & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}JM & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}KL & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}N & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q8-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q8-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #9 NONDISCRIM\n\n![Q9-Question](static/questions/Q9.png){#fig-Q9}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q9-KEY}Answer Key | Q :  Which shift(s) begins before J begins and ends during B?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & I & \\\\\n\\hline\nOrthgonal & I & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] &  & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Other\", 1, 2) %>%\n  pack_rows(\"Unknown\", 3, 19)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q9-RESPONSES}Frequency of Selected Response Options for Question #9}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}I & 247 & both tri + orth & 1 & 1.000 & NA & NA & 1.000 & 0.5\\\\\n\\hline\n\\hspace{1em} & 23 & blank & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}E & 29 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}F & 6 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}M & 4 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}EI & 3 & ? & 0 & 0.933 & NA & NA & 0.933 & 0.0\\\\\n\\hline\n\\hspace{1em}FI & 3 & ? & 0 & 0.933 & NA & NA & 0.933 & 0.0\\\\\n\\hline\n\\hspace{1em}J & 3 & ? & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 2 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}AGN & 1 & ? & 0 & -0.200 & NA & NA & -0.200 & 0.0\\\\\n\\hline\n\\hspace{1em}B & 1 & ? & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}C & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}CHO & 1 & ? & 0 & -0.200 & NA & NA & -0.200 & 0.0\\\\\n\\hline\n\\hspace{1em}D & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}DK & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}IJ & 1 & ? & 1 & 1.000 & NA & NA & 1.000 & 0.0\\\\\n\\hline\n\\hspace{1em}IM & 1 & ? & 0 & 0.933 & NA & NA & 0.933 & 0.0\\\\\n\\hline\n\\hspace{1em}IO & 1 & ? & 0 & 0.933 & NA & NA & 0.933 & 0.0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q9-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q9-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #10\n\n![Q10-Question](static/questions/Q10.png){#fig-Q10}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q10-KEY}Answer Key | Q :  Which shift(s) end at the same time as F?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & E & \\\\\n\\hline\nOrthgonal & X & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & EGZ & \\\\\n\\hline\nTversky [start diagonal] & G & \\\\\n\\hline\nTversky [end diagonal] & E & \\\\\n\\hline\nTversky [duration line] & Z & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>%\n  pack_rows(\"Lines-Connect\", 3, 7) %>%\n  pack_rows(\"Orthogonal\", 8, 11) %>%\n  pack_rows(\"Other\", 12, 14) %>%\n  pack_rows(\"Unknown\", 15, 27)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q10-RESPONSES}Frequency of Selected Response Options for Question #10}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}E & 103 & Triangular & 1 & 1.000 & 1.000 & NA & -0.062 & 1.0\\\\\n\\hline\n\\hspace{1em}EF & 1 & Triangular & 1 & 1.000 & 1.000 & NA & -0.062 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}Z & 23 & Tversky & 0 & -0.062 & 1.000 & NA & -0.062 & 0.5\\\\\n\\hline\n\\hspace{1em}XZ & 2 & Tversky & 0 & -0.125 & 0.938 & NA & 0.938 & 0.5\\\\\n\\hline\n\\hspace{1em}CG & 1 & Tversky & 0 & -0.125 & 0.938 & NA & -0.125 & 0.5\\\\\n\\hline\n\\hspace{1em}G & 1 & Tversky & 0 & -0.062 & 1.000 & NA & -0.062 & 0.5\\\\\n\\hline\n\\hspace{1em}HLPZ & 1 & Tversky & 0 & -0.250 & 0.812 & NA & -0.250 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}X & 139 & Orthogonal & 0 & -0.062 & -0.062 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}BX & 2 & Orthogonal & 0 & -0.125 & -0.125 & NA & 0.938 & -1.0\\\\\n\\hline\n\\hspace{1em}FX & 2 & Orthogonal & 0 & -0.062 & -0.062 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}AMX & 1 & Orthogonal & 0 & -0.188 & -0.188 & NA & 0.875 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}F & 1 & reference & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em} & 6 & blank & 0 & 0.000 & NA & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}CEGIO & 1 & frenzy & 0 & 0.750 & 0.750 & NA & -0.312 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}B & 27 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}J & 6 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}IJ & 2 & ? & 0 & -0.125 & -0.125 & NA & -0.125 & 0.0\\\\\n\\hline\n\\hspace{1em}P & 2 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}BO & 1 & ? & 0 & -0.125 & -0.125 & NA & -0.125 & 0.0\\\\\n\\hline\n\\hspace{1em}C & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}H & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}HLP & 1 & ? & 0 & -0.188 & -0.188 & NA & -0.188 & 0.0\\\\\n\\hline\n\\hspace{1em}I & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}JM & 1 & ? & 0 & -0.125 & -0.125 & NA & -0.125 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}L & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}O & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q10-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q10-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #11\n\n![Q11-Question](static/questions/Q11.png){#fig-Q11}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q11-KEY}Answer Key | Q :  Which shift(s) start at 12pm?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & ML & \\\\\n\\hline\nOrthgonal & FB & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] &  & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 4) %>%\n  pack_rows(\"Orthogonal\", 5, 9) %>%\n  pack_rows(\"Other\", 10, 12) %>%\n  pack_rows(\"Unknown\", 13, 17)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q11-RESPONSES}Frequency of Selected Response Options for Question #11}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}LM & 99 & Triangular & 1 & 1.000 & NA & NA & -0.125 & 1\\\\\n\\hline\n\\hspace{1em}M & 7 & Triangular & 0 & 0.500 & NA & NA & -0.062 & 1\\\\\n\\hline\n\\hspace{1em}BLM & 2 & Triangular & 0 & 0.938 & NA & NA & 0.375 & 1\\\\\n\\hline\n\\hspace{1em}EKM & 1 & Triangular & 0 & 0.375 & NA & NA & -0.188 & 1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}BF & 201 & Orthogonal & 0 & -0.125 & NA & NA & 1.000 & -1\\\\\n\\hline\n\\hspace{1em}B & 4 & Orthogonal & 0 & -0.062 & NA & NA & 0.500 & -1\\\\\n\\hline\n\\hspace{1em}F & 2 & Orthogonal & 0 & -0.062 & NA & NA & 0.500 & -1\\\\\n\\hline\n\\hspace{1em}BFXZ & 1 & Orthogonal & 0 & -0.250 & NA & NA & 0.875 & -1\\\\\n\\hline\n\\hspace{1em}BH & 1 & Orthogonal & 0 & -0.125 & NA & NA & 0.438 & -1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 4 & blank & 0 & 0.000 & NA & NA & 0.000 & 0\\\\\n\\hline\n\\hspace{1em}ACDGHKLMNOPXZ & 1 & frenzy & 0 & 0.312 & NA & NA & -0.812 & 0\\\\\n\\hline\n\\hspace{1em}DHLMNOXZ & 1 & frenzy & 0 & 0.625 & NA & NA & -0.500 & 0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}J & 2 & ? & 0 & -0.062 & NA & NA & -0.062 & 0\\\\\n\\hline\n\\hspace{1em}CX & 1 & ? & 0 & -0.125 & NA & NA & -0.125 & 0\\\\\n\\hline\n\\hspace{1em}N & 1 & ? & 0 & -0.062 & NA & NA & -0.062 & 0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.062 & NA & NA & -0.062 & 0\\\\\n\\hline\n\\hspace{1em}XZ & 1 & ? & 0 & -0.125 & NA & NA & -0.125 & 0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q11-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q11-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #12\n\n![Q12-Question](static/questions/Q12.png){#fig-Q12}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q12-KEY}Answer Key | Q :  Which shift(s) start at the same time as F?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & G & \\\\\n\\hline\nOrthgonal & B & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & GZ & \\\\\n\\hline\nTversky [start diagonal] & G & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] & Z & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 3) %>%\n  pack_rows(\"Lines-Connect\", 4, 6) %>%\n  pack_rows(\"Orthogonal\", 7, 8) %>%\n  pack_rows(\"Other\", 9, 10) %>%\n  pack_rows(\"Unknown\", 11, 14)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q12-RESPONSES}Frequency of Selected Response Options for Question #12}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}G & 98 & Triangular & 1 & 1.000 & 1.000 & NA & -0.062 & 1.0\\\\\n\\hline\n\\hspace{1em}FG & 3 & Triangular & 1 & 1.000 & 1.000 & NA & -0.062 & 1.0\\\\\n\\hline\n\\hspace{1em}GP & 1 & Triangular & 0 & 0.938 & 0.938 & NA & -0.125 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}Z & 4 & Tversky & 0 & -0.062 & 1.000 & NA & -0.062 & 0.5\\\\\n\\hline\n\\hspace{1em}BZ & 1 & Tversky & 0 & -0.125 & 0.938 & NA & 0.938 & 0.5\\\\\n\\hline\n\\hspace{1em}B & 206 & Orthogonal & 0 & -0.062 & -0.062 & NA & 1.000 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}BF & 5 & Orthogonal & 0 & -0.062 & -0.062 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em} & 3 & blank & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}CEGIO & 1 & frenzy & 0 & 0.750 & 0.750 & NA & -0.312 & 0.0\\\\\n\\hline\n\\hspace{1em}J & 3 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}E & 2 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}FM & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}N & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\hspace{1em}X & 1 & ? & 0 & -0.062 & -0.062 & NA & -0.062 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q12-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q12-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #13\n\n![Q13-Question](static/questions/Q13.png){#fig-Q13}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q13-KEY}Answer Key | Q :  Which 2 shifts end when Z begins?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & EF & \\\\\n\\hline\nOrthgonal & FX & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] &  & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 3) %>%\n  pack_rows(\"Orthogonal\", 4, 13) %>%\n  pack_rows(\"Other\", 14, 14) %>%\n  pack_rows(\"Unknown\", 15, 36)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q13-RESPONSES}Frequency of Selected Response Options for Question #13}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}EF & 91 & Triangular & 1 & 1.000 & NA & NA & 0.433 & 1\\\\\n\\hline\n\\hspace{1em}CE & 1 & Triangular & 0 & 0.433 & NA & NA & -0.133 & 1\\\\\n\\hline\n\\hspace{1em}E & 1 & Triangular & 0 & 0.500 & NA & NA & -0.067 & 1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}FX & 141 & Orthogonal & 0 & 0.433 & NA & NA & 1.000 & -1\\\\\n\\hline\n\\hspace{1em}X & 9 & Orthogonal & 0 & -0.067 & NA & NA & 0.500 & -1\\\\\n\\hline\n\\hspace{1em}OX & 4 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\hspace{1em}KX & 3 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\hspace{1em}ACX & 1 & Orthogonal & 0 & -0.200 & NA & NA & 0.367 & -1\\\\\n\\hline\n\\hspace{1em}BX & 1 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\hspace{1em}CX & 1 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\hspace{1em}DJNX & 1 & Orthogonal & 0 & -0.267 & NA & NA & 0.300 & -1\\\\\n\\hline\n\\hspace{1em}GX & 1 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\hspace{1em}JX & 1 & Orthogonal & 0 & -0.133 & NA & NA & 0.433 & -1\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 5 & blank & 0 & 0.000 & NA & NA & 0.000 & 0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}HN & 13 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}BF & 11 & ? & 0 & 0.433 & NA & NA & 0.433 & 0\\\\\n\\hline\n\\hspace{1em}F & 10 & ? & 0 & 0.500 & NA & NA & 0.500 & 0\\\\\n\\hline\n\\hspace{1em}EX & 6 & ? & 0 & 0.433 & NA & NA & 0.433 & 0\\\\\n\\hline\n\\hspace{1em}HL & 5 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}HLP & 5 & ? & 0 & -0.200 & NA & NA & -0.200 & 0\\\\\n\\hline\n\\hspace{1em}BM & 2 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}CO & 2 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}DN & 2 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}AG & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}BO & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}C & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}CG & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}CGO & 1 & ? & 0 & -0.200 & NA & NA & -0.200 & 0\\\\\n\\hline\n\\hspace{1em}CH & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}D & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}DKM & 1 & ? & 0 & -0.200 & NA & NA & -0.200 & 0\\\\\n\\hline\n\\hspace{1em}H & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}HZ & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\hspace{1em}LP & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}NO & 1 & ? & 0 & -0.133 & NA & NA & -0.133 & 0\\\\\n\\hline\n\\hspace{1em}NZ & 1 & ? & 0 & -0.067 & NA & NA & -0.067 & 0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q13-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q13-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #14\n\n![Q14-Question](static/questions/Q14.png){#fig-Q14}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q14-KEY}Answer Key | Q :  Which shift(s) end at 3pm?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & X & \\\\\n\\hline\nOrthgonal & B & \\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & XJND & \\\\\n\\hline\nTversky [start diagonal] &  & \\\\\n\\hline\nTversky [end diagonal] & X & \\\\\n\\hline\nTversky [duration line] & JND & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 4) %>%\n  pack_rows(\"Orthogonal\", 5, 7) %>%\n  pack_rows(\"Other\", 8, 9) %>%\n  pack_rows(\"Unknown\", 10, 22)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q14-RESPONSES}Frequency of Selected Response Options for Question #14}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}X & 107 & Triangular & 1 & 1.000 & 1.000 & NA & -0.059 & 1.0\\\\\n\\hline\n\\hspace{1em}FX & 2 & Triangular & 0 & 0.941 & 0.941 & NA & -0.118 & 1.0\\\\\n\\hline\n\\hspace{1em}EX & 1 & Triangular & 0 & 0.941 & 0.941 & NA & -0.118 & 1.0\\\\\n\\hline\n\\hspace{1em}OX & 1 & Triangular & 0 & 0.941 & 0.941 & NA & -0.118 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}B & 150 & Orthogonal & 0 & -0.059 & -0.059 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}BF & 12 & Orthogonal & 0 & -0.118 & -0.118 & NA & 0.941 & -1.0\\\\\n\\hline\n\\hspace{1em}BIO & 2 & Orthogonal & 0 & -0.176 & -0.176 & NA & 0.882 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em}BX & 2 & both tri + orth & 0 & 0.941 & 0.941 & NA & 0.941 & 0.5\\\\\n\\hline\n\\hspace{1em} & 29 & blank & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}O & 5 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}F & 3 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}G & 3 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}A & 2 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}HLP & 2 & ? & 0 & -0.176 & -0.176 & NA & -0.176 & 0.0\\\\\n\\hline\n\\hspace{1em}K & 2 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}AH & 1 & ? & 0 & -0.118 & -0.118 & NA & -0.118 & 0.0\\\\\n\\hline\n\\hspace{1em}DHO & 1 & ? & 0 & -0.176 & 0.200 & NA & -0.176 & 0.0\\\\\n\\hline\n\\hspace{1em}FG & 1 & ? & 0 & -0.118 & -0.118 & NA & -0.118 & 0.0\\\\\n\\hline\n\\hspace{1em}HL & 1 & ? & 0 & -0.118 & -0.118 & NA & -0.118 & 0.0\\\\\n\\hline\n\\hspace{1em}IJ & 1 & ? & 0 & -0.118 & 0.267 & NA & -0.118 & 0.0\\\\\n\\hline\n\\hspace{1em}M & 1 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\hspace{1em}P & 1 & ? & 0 & -0.059 & -0.059 & NA & -0.059 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q14-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q14-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n#### Question #15\n\n![Q15-Question](static/questions/Q15.png){#fig-Q15}\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q15-KEY}Answer Key | Q :  Coffee breaks happen halfway through a shift. </br>Which shifts share a break at 2pm?}\n\\centering\n\\begin{tabular}[t]{l|l|l}\n\\hline\ninterpretation & answer & not penalized\\\\\n\\hline\nTriangular & XK & \\\\\n\\hline\nOrthgonal & EF & B\\\\\n\\hline\nSatisficing [left] &  & \\\\\n\\hline\nSatisficing [right] &  & \\\\\n\\hline\nTversky [maximal] & XKZ & \\\\\n\\hline\nTversky [start diagonal] & Z & \\\\\n\\hline\nTversky [end diagonal] &  & \\\\\n\\hline\nTversky [duration line] &  & \\\\\n\\hline\n\\multicolumn{3}{l}{\\rule{0pt}{1em}\\textit{Note: } 15 response options:  ABCDEFGHIJKLMNOPZX}\\\\\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(interpretation),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Triangular\", 1, 10) %>%\n  pack_rows(\"Lines-Connect\", 11, 13) %>%\n  pack_rows(\"Orthogonal\", 14, 22) %>%\n  pack_rows(\"Other\", 23, 23) %>%\n  pack_rows(\"Unknown\", 24, 44)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:Q15-RESPONSES}Frequency of Selected Response Options for Question #15}\n\\centering\n\\begin{tabular}[t]{l|r|l|r|r|r|r|r|r}\n\\hline\n\\multicolumn{3}{c|}{ } & \\multicolumn{1}{c|}{Strict Score} & \\multicolumn{4}{c|}{Interpretation Scores} & \\multicolumn{1}{c}{Discriminant} \\\\\n\\cline{4-4} \\cline{5-8} \\cline{9-9}\nresponse & n & interpretation & absolute & tri & tversky & satisfice & orthogonal & scaled score\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Triangular}}\\\\\n\\hline\n\\hspace{1em}KX & 100 & Triangular & 1 & 1.000 & 0.667 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}X & 6 & Triangular & 0 & 0.500 & 0.333 & NA & -0.067 & 1.0\\\\\n\\hline\n\\hspace{1em}CX & 2 & Triangular & 0 & 0.438 & 0.267 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}DJNX & 2 & Triangular & 0 & 0.312 & 0.133 & NA & -0.267 & 1.0\\\\\n\\hline\n\\hspace{1em}AKPX & 1 & Triangular & 0 & 0.875 & 0.533 & NA & -0.267 & 1.0\\\\\n\\hline\n\\hspace{1em}CK & 1 & Triangular & 0 & 0.438 & 0.267 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}GK & 1 & Triangular & 0 & 0.438 & 0.267 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}JX & 1 & Triangular & 0 & 0.438 & 0.267 & NA & -0.133 & 1.0\\\\\n\\hline\n\\hspace{1em}K & 1 & Triangular & 0 & 0.500 & 0.333 & NA & -0.067 & 1.0\\\\\n\\hline\n\\hspace{1em}LX & 1 & Triangular & 0 & 0.438 & 0.267 & NA & -0.133 & 1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Lines-Connect}}\\\\\n\\hline\n\\hspace{1em}FZ & 3 & Tversky & 0 & -0.125 & 0.941 & NA & 0.433 & 0.5\\\\\n\\hline\n\\hspace{1em}OZ & 1 & Tversky & 0 & -0.125 & 0.941 & NA & -0.133 & 0.5\\\\\n\\hline\n\\hspace{1em}Z & 1 & Tversky & 0 & -0.062 & 1.000 & NA & -0.067 & 0.5\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Orthogonal}}\\\\\n\\hline\n\\hspace{1em}EF & 118 & Orthogonal & 0 & -0.125 & -0.118 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}BF & 17 & Orthogonal & 0 & -0.125 & -0.118 & NA & 0.500 & -1.0\\\\\n\\hline\n\\hspace{1em}F & 13 & Orthogonal & 0 & -0.062 & -0.059 & NA & 0.500 & -1.0\\\\\n\\hline\n\\hspace{1em}E & 8 & Orthogonal & 0 & -0.062 & -0.059 & NA & 0.500 & -1.0\\\\\n\\hline\n\\hspace{1em}BE & 4 & Orthogonal & 0 & -0.125 & -0.118 & NA & 0.500 & -1.0\\\\\n\\hline\n\\hspace{1em}BEF & 1 & Orthogonal & 0 & -0.188 & -0.176 & NA & 1.000 & -1.0\\\\\n\\hline\n\\hspace{1em}EFZ & 1 & Orthogonal & 0 & -0.188 & 0.882 & NA & 0.933 & -1.0\\\\\n\\hline\n\\hspace{1em}EI & 1 & Orthogonal & 0 & -0.125 & -0.118 & NA & 0.433 & -1.0\\\\\n\\hline\n\\hspace{1em}FI & 1 & Orthogonal & 0 & -0.125 & -0.118 & NA & 0.433 & -1.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Other}}\\\\\n\\hline\n\\hspace{1em} & 11 & blank & 0 & 0.000 & 0.000 & NA & 0.000 & 0.0\\\\\n\\hline\n\\multicolumn{9}{l}{\\textbf{Unknown}}\\\\\n\\hline\n\\hspace{1em}G & 4 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}B & 3 & ? & 0 & -0.062 & -0.059 & NA & 0.000 & 0.0\\\\\n\\hline\n\\hspace{1em}C & 3 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}O & 3 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}AG & 2 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}BM & 2 & ? & 0 & -0.125 & -0.118 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}CG & 2 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}M & 2 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}A & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}BG & 1 & ? & 0 & -0.125 & -0.118 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}DN & 1 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}FK & 1 & ? & 0 & 0.438 & 0.267 & NA & 0.433 & 0.0\\\\\n\\hline\n\\hspace{1em}FX & 1 & ? & 0 & 0.438 & 0.267 & NA & 0.433 & 0.0\\\\\n\\hline\n\\hspace{1em}H & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}HN & 1 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}HO & 1 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}I & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}IJ & 1 & ? & 0 & -0.125 & -0.118 & NA & -0.133 & 0.0\\\\\n\\hline\n\\hspace{1em}J & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}L & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\hspace{1em}N & 1 & ? & 0 & -0.062 & -0.059 & NA & -0.067 & 0.0\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q15-distribution-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~sorted_interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/Q15-distribution-2.pdf){fig-pos='H'}\n:::\n:::\n\n### Peeking\n\n#### Score Distributions\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_density(~ score_SCALED, fill = ~condition, data = df_items) %>% \n  gf_facet_grid( q ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-79-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n# mosaic( formula = ~question + interpretation,\n#        data = df_items %>% filter(condition == 111),\n#        main=\"INTERPRETATION by Graph and Direction\",\n#        sub = \"\",\n#        spacing = spacing_equal(unit(1, \"lines\")),\n#        split_vertical = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_density(~ score_niceABS, fill = ~condition, data = df_items) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Item Absolute Score\", title = \"Distribution of Absolute Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-81-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_density(~ score_TRI, fill = ~condition, data = df_items) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Item TRIANGULAR Score\", title = \"Distribution of Triangular Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-81-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_props(~ sorted_interpretation, fill = ~condition, data = df_items) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-81-3.pdf){fig-pos='H'}\n:::\n:::\n\n#### Scores through Time\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~ score_niceABS, fill = ~condition, data = df_items) %>% \n  gf_facet_grid(q ~ condition, labeller = label_both) + \n  labs( x = \"Item Absolute Score\", title = \"Distribution of Absolute Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-83-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_density(~ score_TRI, fill = ~condition, data = df_items) %>% \n  gf_facet_grid(q ~ condition, labeller = label_both) + \n  labs( x = \"Item TRIANGULAR Score\", title = \"Distribution of Triangular Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-83-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_density(~ score_ORTH, fill = ~condition, data = df_items) %>% \n  gf_facet_grid(q ~ condition, labeller = label_both) + \n  labs( x = \"Item ORTHGONAL Score\", title = \"Distribution of Orthogonal Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 860 rows containing non-finite values (stat_density).\n```\n:::\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-83-3.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_bar(~ sorted_interpretation, fill = ~condition, data = df_items) %>% \n  gf_facet_grid( q ~condition, labeller = label_both) + \n  labs( title = \"Distribution of Interpretations\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-83-4.pdf){fig-pos='H'}\n:::\n:::\n\n#### Score Relationships\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_jitter( score_TRI ~ score_ORTH, fill = ~condition, alpha = 0.5, data = df_items) %>% \n  gf_facet_wrap( ~ condition, labeller = label_both) + \n  labs( x = \"ORTH score\", y = \"TRI score\", \n        title = \"Relationship between ORTH and TRI scores\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 860 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-85-1.pdf){fig-pos='H'}\n:::\n:::\n\n#### Scores by Subject\n\n::: {.cell}\n\n```{.r .cell-code}\nsubject_scores <- df_items %>% group_by(subject) %>% dplyr::summarize(\n  TRI = sum(score_TRI),\n  ORTH = sum(score_ORTH),\n  # DISCRIM = sum(score_TRI + score_ORTH),\n  ABSOLUTE = sum(score_niceABS),\n  condition = unique(condition)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` ungrouping output (override with `.groups` argument)\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_histogram(~ ABSOLUTE, fill = ~condition, data = subject_scores) %>% \n  gf_facet_wrap( ~ condition, labeller = label_both) + \n  labs( x = \"Item Absolute Score\", title = \"Distribution of Absolute Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-89-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ngf_density(~ TRI, fill = ~condition, data = subject_scores) %>% \n  gf_facet_wrap( ~ condition, labeller = label_both) + \n  labs( x = \"Item TRIANGULAR Score\", title = \"Distribution of Triangular Score\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-89-2.pdf){fig-pos='H'}\n:::\n:::\n\nTODO TRAPDOOR?\n\nSET T = options that result in -1 score (trapdoor)\n\nTODO: TEST first with NO trapdoor, and see what the scores yield, then if the responses can be scaled based on comparing subscores\n\nf_partialP \\<- function(t,p,f,q) {\n\nt = number of correct-selected options p = number of true options f = number of incorrect-selected options q = number of false options n = number of options + p + q return( (t / p) - (f/q)) }\n\nTo prepare for partial scoring \\[-1/q, + 1/p\\], we first need to define the parameters t, p , f, q\n\nOur approach to calculating an ORTHOGONAL PARTIAL score is as follows:\n\n-   1/p for each correct-selected\n\n-   -1/q for each incorrect-selected (except 'allowed' based on reference point and visual error)\n\n-   trapdoor : default to -1 if select triangular\n\n## EXPORT\n\nSummarize by subject Export subjects Export items\n\n-   does response time predict interpretation vs. non interpretation?\n\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects)\n\n::: {.cell}\n\n```{.r .cell-code}\n#prep items\ndf_items <- df_items %>% mutate(\n  tv_type = as.factor(tv_type),\n  top_type = as.factor(top_type)\n)\n\n#summarize SCORES and TIME by subject\nsubjects <- df_items %>% filter(q %nin% c(6,9)) %>% group_by(subject) %>% dplyr::summarise (\n  subject = as.character(subject),\n  s_TRI = sum(score_TRI),\n  s_ORTH = sum(score_ORTH),\n  s_TVERSKY = sum(score_TVERSKY),\n  s_SATISFICE = sum(score_SATISFICE),\n  s_REF = sum(score_REF),\n  s_ABS = sum(score_ABS),\n  s_NABS = sum(score_niceABS),\n  s_SCALED = sum(score_SCALED),\n  rt_m = sum(rt_s)/60\n) %>% arrange(subject) %>% slice(1L)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` regrouping output by 'subject' (override with `.groups` argument)\n```\n:::\n\n```{.r .cell-code}\n#import subjects\ndf_subjects <- read_rds('data/1-study-level/sgc3a_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#TODO DOUBLE CHECK THIS!  \nx = merge(subjects, df_subjects)\ndf_subjects <- x %>% select(-absolute_score) #drop absolute score from webapp that includes Q6 and Q9\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstats = df_subjects %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(s_SCALED))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` regrouping output by 'condition' (override with `.groups` argument)\n```\n:::\n\n```{.r .cell-code}\ngf_bar(~s_SCALED, data = df_subjects) %>% \n  gf_facet_grid(condition~mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Cumulative Scaled Score for Subject\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc3A_scoring_files/figure-pdf/unnamed-chunk-92-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SAVE FILES\nwrite.csv(df_subjects,\"data/2-scored-data/sgc3a_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"data/2-scored-data/sgc3a_scored_items.csv\", row.names = FALSE)\n\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"data/2-scored-data/sgc3a_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"data/2-scored-data/sgc3a_scored_items.rds\") # to R data structure file\n```\n:::\n\n## RESOURCES\n\n*set operations*\n\n<https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html>\n\n*kableExtra tables*\n\n<https://haozhu233.github.io/kableExtra/awesome_table_in_html.html#grouped_columns__rows>\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.0.2 (2020-06-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS  10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] Hmisc_4.6-0      Formula_1.2-4    survival_3.1-12  lattice_0.20-41 \n [5] pbapply_1.4-3    ggpubr_0.4.0     ggformula_0.10.1 ggridges_0.5.3  \n [9] scales_1.1.1     ggstance_0.3.5   kableExtra_1.3.1 forcats_0.5.0   \n[13] stringr_1.4.0    dplyr_1.0.2      purrr_0.3.4      readr_1.4.0     \n[17] tidyr_1.1.2      tibble_3.1.2     ggplot2_3.3.5    tidyverse_1.3.0 \n\nloaded via a namespace (and not attached):\n [1] fs_1.5.0            lubridate_1.7.9     RColorBrewer_1.1-2 \n [4] webshot_0.5.2       httr_1.4.2          tools_4.0.2        \n [7] backports_1.2.1     utf8_1.2.1          R6_2.5.0           \n[10] rpart_4.1-15        DBI_1.1.0           colorspace_2.0-2   \n[13] nnet_7.3-14         withr_2.4.2         gridExtra_2.3      \n[16] tidyselect_1.1.0    curl_4.3            compiler_4.0.2     \n[19] cli_3.3.0           rvest_0.3.6         htmlTable_2.4.0    \n[22] xml2_1.3.2          labeling_0.4.2      checkmate_2.0.0    \n[25] mosaicCore_0.9.0    digest_0.6.27       foreign_0.8-80     \n[28] rmarkdown_2.11      rio_0.5.16          jpeg_0.1-8.1       \n[31] base64enc_0.1-3     pkgconfig_2.0.3     htmltools_0.5.2    \n[34] labelled_2.8.0      dbplyr_1.4.4        fastmap_1.1.0      \n[37] htmlwidgets_1.5.2   rlang_0.4.11        readxl_1.3.1       \n[40] rstudioapi_0.13     farver_2.1.0        generics_0.0.2     \n[43] jsonlite_1.7.1      zip_2.1.1           car_3.0-10         \n[46] magrittr_2.0.1      Matrix_1.2-18       Rcpp_1.0.5         \n[49] munsell_0.5.0       fansi_0.5.0         abind_1.4-5        \n[52] lifecycle_1.0.0     stringi_1.7.3       yaml_2.2.1         \n[55] carData_3.0-4       MASS_7.3-51.6       plyr_1.8.6         \n[58] grid_4.0.2          blob_1.2.1          parallel_4.0.2     \n[61] crayon_1.4.1        splines_4.0.2       haven_2.3.1        \n[64] hms_0.5.3           knitr_1.37          pillar_1.6.1       \n[67] ggsignif_0.6.0      codetools_0.2-16    reprex_0.3.0       \n[70] glue_1.6.2          evaluate_0.14       latticeExtra_0.6-29\n[73] data.table_1.13.2   modelr_0.1.8        png_0.1-7          \n[76] vctrs_0.3.8         tweenr_1.0.2        cellranger_1.1.0   \n[79] gtable_0.3.0        polyclip_1.10-0     assertthat_0.2.1   \n[82] xfun_0.29           ggforce_0.3.3       openxlsx_4.2.3     \n[85] broom_0.7.12        rstatix_0.7.0       viridisLite_0.4.0  \n[88] cluster_2.1.0       ellipsis_0.3.2     \n```\n:::\n:::\n\n### ARCHIVE\n\nfunctions for for-loop version of scoring\n\n::: {.cell}\n\n```{.r .cell-code}\n# #CALCULATE THE TRIANGULAR, ORTHOGONAL OR TVERSKIAN SUBSCORES FROM KEYFRAME\n# calc_sub_score <- function(question, cond, response,keyframe){\n# \n#   #STEP 1 GET KEY\n#   if (question < 6) #for q1 - q5 find key for question by condition\n#   {\n#     # print(keyframe)\n#     #GET KEY FOR THIS SCORE TYPE, QUESTION AND CONDITION\n#     p =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#     q =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n#     pn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_p)\n#     qn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_q)\n# \n#   } else {\n#     #GET KEY FOR THIS SCORE TYPE, QUESTION\n#     p =  keyframe %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#     q =  keyframe %>% filter(Q == question) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n#     pn = keyframe %>% filter(Q == question) %>% select(n_p)\n#     qn = keyframe %>% filter(Q == question) %>% select(n_q)\n#   }\n# \n#   #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n#   \n#   #if response is not empty, split apart response for set comparison\n#     if(response != \"\")\n#     { response = response %>% str_split(\"\") %>% unlist()}\n#     \n#   ps = length(intersect(response,p))\n#   qs = length(intersect(response,q))\n#   # df_items[x,'tri_ps'] = tri_ps\n#   # df_items[x,'tri_qs'] = tri_qs\n# \n#   #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION\n#   x = f_partialP(ps,pn,qs,qn) %>% unlist() %>% as.numeric()\n#   \n#   #cleanup\n#   rm(p,q,pn,qn,ps,qs)\n#   return(x)\n# \n# }\n# \n# #CALCULATE THE REFERENCE SCORES\n# calc_ref_score <- function(question, cond, response){\n#   \n#     #1. GET reference point from REF_POINT column in raw keys\n#     ref_p = keys_raw %>% filter(Q == question) %>% filter(condition == cond) %>% select(REF_POINT) %>% pull(REF_POINT) %>% str_split(\"\") %>% unlist()\n#      \n#     #2. if response has more than one character, it can't be correct\n#     #there is only ever 1 reference character\n#     n = nchar(response)\n#     if (n == 0) {x = 0}\n#     else if(n>1) {x = 0}\n#     else {\n#       #3 is the response PRECISELY the REFERENCE POINT?\n#       x = ref_p == response\n#       x = as.numeric(x)  \n#     }\n#     \n#     #cleanup\n#     rm(ref_p, response, question, cond)   \n#     return(x) #1 = match, 0 = not match\n# }\n# \n# \n# #CALCULATE SCORE BASED ON UNION OF ORTH & TRI (SUBJECT SELECTS BOTH ANSWERS )\n# calc_both_score <- function(question, cond, response){\n#   \n#TRAPDOOR \n#   #since no orth responses exist for impasse condition q1 - q5, set to 0\n#   if (question < 6 & cond == 121) {x = NA}\n#   \n#   #ELSE \n#   #calculate union of ORTH and TRI\n#   else {\n#     if (question < 6 & cond == 111) #for q1 - q5 find key for question by condition\n#   {\n#      #grab the tri and orth keys for this question as well as N option set\n#      tri_p =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      orth_p = keys_orth %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      set_n =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n#      #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n#      both_p = union(tri_p, orth_p) #the selection of tri and p\n#      #2. calc answers that should't be selected as diffrence between N [same for all keys] and both_p\n#      both_q = setdiff(set_n,both_p)\n#      both_pn = length(both_p)\n#      both_qn = length(both_q)\n#   } else{\n#     \n#      #grab the tri and orth keys for this question as well as N option set\n#      tri_p =  keys_tri %>%  filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      orth_p = keys_orth %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      set_n =  keys_tri %>%  filter(Q == question) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n#      #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n#      both_p = union(tri_p, orth_p) #the selection of tri and p\n#      #2. calc answers that shouldn't be selected as difference between N [same for all keys] and both_p\n#      both_q = setdiff(set_n,both_p)\n#      both_pn = length(both_p)\n#      both_qn = length(both_q)\n#   }\n#     \n#   #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n#   \n#   #if response is not empty, split apart response for set comparison\n#     if(response != \"\")\n#     { response = response %>% str_split(\"\") %>% unlist()}\n#   \n#     both_ps = length(intersect(response,both_p))\n#     both_qs = length(intersect(response,both_q))\n#   \n#  \n#   #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n#   x = f_partialP(both_ps,both_pn,both_qs,both_qn)%>% unlist() %>% as.numeric()\n#   \n#   #cleanup\n#   rm(both_p,both_q,both_pn,both_qn,both_ps,both_qs, question, cond, response )   \n#   }\n#   \n#   return(x) #true correct, trues, false correct, falses\n# }\n```\n:::\n\nlooping to do the scoring\n\n::: {.cell}\n\n```{.r .cell-code}\n#RUN THIS OR THE CALCULATE-SCORES-MAPPLY\n# df_items = trad \n# \n# pb <- timerProgressBar() \n# on.exit(close(pb)) \n#  \n# #CALCULATE SUBSCORES (in loop)\n# \n# for (x in 1:nrow(df_items)) {\n#   \n#   #show progress bar \n#   setTimerProgressBar(pb, x) \n#   \n#   #PREPARE ITEMS FOR SCORING\n#   #sort response vectors alphabetically\n#   #doesn't impact scoring, but does impact response display tables\n#    df_items[x,'response'] <-  df_items[x,'response'] %>% str_split(\"\") %>% unlist() %>% sort() %>% str_c(collapse=\"\")\n# \n#   #get properties of the RESPONSE ITEM\n#   qu = df_items[x,'q'] %>% as.numeric()\n#   cond = as.character(df_items[x,'condition']) %>% as.numeric()\n#   r = df_items[x,'response'] \n# \n#   #calculate the main subscores\n#   df_items[x,'score_TRI'] = calc_sub_score(qu, cond, r,keys_tri)\n#   df_items[x,'score_ORTH'] = calc_sub_score(qu, cond, r,keys_orth)\n#   df_items[x,'score_SATISFICE'] = calc_sub_score(qu, cond, r,keys_satisfice)\n#   df_items[x,'score_TV_max'] = calc_sub_score(qu, cond, r,keys_tversky_max)\n#   df_items[x,'score_TV_start'] = calc_sub_score(qu, cond, r,keys_tversky_start)\n#   df_items[x,'score_TV_end'] = calc_sub_score(qu, cond, r,keys_tversky_end)\n#   df_items[x,'score_TV_duration'] = calc_sub_score(qu, cond, r, keys_tversky_duration)\n#   \n#   #calculate special subscores\n#   df_items[x,'score_REF'] = calc_ref_score(qu, cond, r)\n#   df_items[x,'score_BOTH'] = calc_both_score(qu, cond, r)\n# }\n# \n# #CALCULATE ABSOLUTE SCORES\n# #calculate absolute scores dichotomous\n# df_items$score_ABS = as.integer(df_items$correct)\n# #niceABS indicates if the response is correct without penalizing the allowable triangular options(ie. the ref point)\n# df_items$score_niceABS  <- as.integer((df_items$score_TRI == 1))\n#  \n# #cleanup\n# rm(qu,cond,r, x)\n\n# trad_scored = df_items\n```\n:::\n\nsanity check equivalence of for-loop and mapply scoring\n\n::: {.cell}\n\n```{.r .cell-code}\n#CHECK EQUIVALENCE OF LOOP AND MAPPLY SCORING \n# tests = data.frame (\n#   alt_tri = alt_scored$score_TRI,\n#   trad_tri = trad_scored$score_TRI,\n#   alt_orth = alt_scored$score_ORTH,\n#   trad_orth = trad_scored$score_ORTH,\n#   alt_ref = alt_scored$score_REF,\n#   trad_ref = trad_scored$score_REF,\n#   alt_tv_max = alt_scored$score_TV_max,\n#   trad_tv_max = trad_scored$score_TV_max,\n#   alt_tv_dur = alt_scored$score_TV_duration,\n#   trad_tv_dur = trad_scored$score_TV_duration,\n#   alt_tv_start = alt_scored$score_TV_start,\n#   trad_tv_start = trad_scored$score_TV_start,\n#   alt_tv_end = alt_scored$score_TV_end,\n#   trad_tv_end = trad_scored$score_TV_end,\n#   alt_both = alt_scored$score_BOTH,\n#   trad_both = trad_scored$score_BOTH,\n#   trad_response = trad_scored$response,\n#   alt_response = alt_scored$response,\n#   q_match = trad_scored$q == alt_scored$q,\n#   q = trad_scored$q,\n#   c_match = trad_scored$condition == alt_scored$condition,\n#   condition = trad_scored$condition\n# )\n# \n# tests$tri = tests$alt_tri == tests$trad_tri\n# tests$orth = tests$alt_orth == tests$trad_orth\n# tests$ref = tests$alt_ref == tests$trad_ref\n# tests$tvdur = tests$alt_tv_dur == tests$trad_tv_dur\n# tests$tvstart = tests$alt_tv_start == tests$trad_tv_start\n# tests$tvend = tests$alt_tv_end == tests$trad_tv_end\n# tests$both = tests$alt_both == tests$trad_both\n# \n# #CHECKS \n# unique(tests$tri)\n# unique(tests$orth)\n# unique(tests$ref)\n# unique(tests$tvdur)\n# unique(tests$tvstart)\n# unique(tests$tvend)\n# unique(tests$both)\n# \n# unique(alt_scored$score_ABS == trad_scored$score_ABS)\n# unique(alt_scored$score_niceABS == trad_scored$score_niceABS)\n```\n:::\n\n### TODO A Discriminant Score\n\n\\[TODO old text from creating discriminant score; reconsider this\\]\n\nThough it appears the Partial $[-1/q, +1/p]$ scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options in the same way.\n\nIn the case of the SGC study paradigm, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus. Specifically, there are certain patterns of options that correspond to a *triangular* versus *orthogonal* interpretations. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under $[-1/q, +1/q]$. These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are *more incorrect* than others. We want to be able to differentiate between these responses.\n\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define **four interpretations** for which to define options. We can think of these as four different answer keys, each defining the set of 'correct' options (those that should be selected) under each interpretation of the graph.\n\n1.  Triangular : the (true, actually correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\n2.  Orthogonal: the (incorrect but most common) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\n3.  Lines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the *correct* projection).\n4.  Satisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nTODO FIX THIS SECTION ONWARDS ... RESPONSE SETS NEED NOT BE MUTUTALLY EXCLUSIVE\n\nThus for *each* item, in the graph comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\n```{=tex}\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n```\nFor example, for the following sample stimuli, TODO IMAGE\n\n```{=tex}\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n```\nTo capture this important source of variation, we can apply the idea behind the partial scoring $[-1/q, +1/p]$ scheme in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from $-1$ to $+1$) that captures the *nature* of the respondent's partial knowledge.\n\nA **Discriminant Score** will offer:\n\n-   +1 for a complete triangular response\n-   -1 for a complete orthogonal response\n-   +/- fraction of complete triangular or orthogonal response\n-   0 for non-strategy responses\n-   0 for blank (empty) responses\n\n```{=tex}\n\\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r) \n\\end{align}\n```\nWhere:\n\n-   $t = |T|$ number of triangular-correct options (consistent with triangular interpretation)\n-   $r = |R| =$ number of orthogonal-correct options (consistent with orthogonal interpretation)\n-   $d$ = number of non-strategy options (not consistent with either interpretation)\n-   $n$ = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n-   $n = t + r + d$ (15 for scaffold phase, 18 for test phase)\n-   $t_s \\ge 0$ number of triangular-correct options selected\n-   $r_s \\ge 0$ = number of orthogonal-correct options selected\n-   $d_s \\ge 0$ = number of non-strategy options options selected\n-   $s \\ge 0$ = number of options selected\n-   $s = t_s + r_s + d_s$\n\nTODO:: add 0.5*(tversky) - 0.5*(satisficing)\n\n::: {.cell}\n\n```{.r .cell-code}\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}