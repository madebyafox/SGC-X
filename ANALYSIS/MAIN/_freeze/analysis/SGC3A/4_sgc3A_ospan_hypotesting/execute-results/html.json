{
  "hash": "2438ab010bbe1d5b7e6c6b0bbe955cf1",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC3A | (OSPAN) Hypothesis Testing'\n# YAML FOR generating modelsummary tables\n# uncomment to run those  cells only \n# \\usepackage{booktabs}\n# \\usepackage{siunitx}\n# \\newcolumntype{d}{S[input-symbols = ()]}\n---\n\n\\newpage\n\n# SGC3 (OSPAN) Hypothesis Testing {#sec-SGC3A-ospan-hypotesting}\n\n*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study WITH OSPAN.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#UTILITIES\nlibrary(Hmisc) # %nin% operator\nlibrary(broom) #tidy model output\nlibrary(broom.mixed) #tidy mixed models\nlibrary(mosaic) #favstats\nlibrary(svglite) #saving plots as svg\nlibrary(distributional)\n\n#VISUALIZATION\n# library(ggpubr) #arrange plots\n# library(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\n# # library(vcd) #mosaic plots\n# # library(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables\nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggdist) #uncertainty viz\nlibrary(modelr) #needed for ggdist\nlibrary(gghalves) # plots. in half\nlibrary(ggbeeswarm) # violin plot stuffs\nlibrary(statsExpressions)\nlibrary(ggstatsplot) #plots with stats\nlibrary(modelsummary) #latex tables for models!\nlibrary(cowplot) #arrange plots\n\n#MODELLING\n# library(rstatix) #helpful testing functions incl wilcoxon, etc\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(parameters) #easystats model summary and vis\n# library(qqplotr) #confint on qq plot\n# library(gmodels) #contingency table and CHISQR\n# library(equatiomatic) #extract model equation\n# library(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models\nlibrary(lmerTest) #for CIs in glmer\nlibrary(merTools) #predictInterval\nlibrary(emmeans) #estimated marginal effects and posthocs on interactions\n# library(ggeffects) #visualization log regr models\n#MULTINOMIAL \nlibrary(nnet) #multinomial logistic regression [not mixed] #no p values\nlibrary(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values\n#BAYESIAN\nlibrary(cmdstanr) #executing stan\nlibrary(brms) #bayesian mixed multinomials [+ other bayesian reg models]\nlibrary(bayestestR) \nlibrary(tidybayes)\nlibrary(posterior)\n\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\n# theme_set(theme_minimal()) \n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"BarlowSemiCondensed-Bold\"),\n          axis.title = element_text(family = \"BarlowSemiCondensed-Medium\"),\n          strip.text = element_text(family = \"BarlowSemiCondensed-Bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA))\n}\n\nset_theme(base = theme_clean())\n\nset.seed(12345)\n```\n:::\n\n**TODO UPDATE Research Questions**\n\nIn SGC3A-OSPAN we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task? Does WORKING MEMORY CAPACITY (as measured by the OSPAN task) explain performance on the graph comprehension task?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#IMPORT DATA \n\ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_OSPAN.rds') %>% mutate(\n  task_percent = DV_percent_NABS,\n  ospan_split = recode_factor(ospan_split, \n                                \"low-memory\" = \"low-memory\", \"high-memory\"=\"high-memory\")) %>% #recode ospan_split as factor with low as reference \n  droplevels()\n\ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_OSPAN.rds') %>% \n   mutate (\n    q = as.factor(q), \n    subject = as.factor(subject),\n    accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n    # CODES TVERSKY AS TRI-LIKE\n    # state = recode_factor(score_SCALED, #for ordinal\n    #                      \"-1\" = \"orth-like\",\n    #                      \"-0.5\" = \"unknown\",\n    #                      \"0\" = \"unknown\",\n    #                      \"0.5\" = \"tri-like\",\n    #                      \"1\" = \"tri-like\"),\n    # CODES TVERSKY AS OTHER\n    state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orthogonal\",\n                         \"-0.5\" = \"other\",\n                         \"0\" = \"other\",\n                         \"0.5\" = \"angular\",\n                         \"1\" = \"triangular\"),\n    state = as.ordered(state))\n    \n\n\n\n\n##ADD OSPAN SCORE TO ITEM RECORD\nsubjects <- df_subjects %>% dplyr::select(subject,OSPAN.weighted, ospan_split)\nitems <- df_items \nitems <- merge(items,subjects)\ndf_items <- items\nrm(subjects,items)\n```\n:::\n\n## SAMPLE\n\n### Data Collection\n\nData was collected (online, via SONA) in Fall 2021. Note that approximately 200 subjects were run in Fall 2021, but only 133 of them completed the OSPAN task. Therefore subjects who did not complete the task are discarded from analysis.\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Participants by Condition and Data Collection Period</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Control Condition </th>\n   <th style=\"text-align:right;\"> Impasse Condition </th>\n   <th style=\"text-align:right;\"> Total for Period </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> fall21 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Sum </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n### Participants\n\n::: {.cell}\n\n```{.r .cell-code}\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;border-bottom: 0;'>\n<caption>Descriptive Statistics of Participant Age and Gender</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n   <th style=\"text-align:right;\"> percent.male </th>\n   <th style=\"text-align:right;\"> percent.female </th>\n   <th style=\"text-align:right;\"> percent.other </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 31 </td>\n   <td style=\"text-align:right;\"> 20.6 </td>\n   <td style=\"text-align:right;\"> 2.18 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.316 </td>\n   <td style=\"text-align:right;\"> 0.669 </td>\n   <td style=\"text-align:right;\"> 0.015 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<span style=\"font-style: italic;\">Note: </span> <sup></sup> Age in Years</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n**REPORTED**\n\n\n**Overall** 133 participants (32 % male, 67 % female, 2 % other)  undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 31 years).\n\n[230 subjects were recorded to study database in FA21 - 32 pilot sgc3b] \n\n\n### OSPAN\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of OSPAN Task Accuracy\"\nospan.stats <- rbind(\n  \"MATH\" = df_subjects %>% dplyr::select(OSPAN.math_acc) %>% unlist() %>% favstats(),\n  \"ORDER\" = df_subjects %>%  dplyr::select(OSPAN.order_acc) %>% unlist() %>% favstats(),\n  \"WEIGHTED\" = df_subjects %>% dplyr::select(OSPAN.weighted) %>% unlist() %>% favstats()\n\n)\nospan.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"MATH = %correct of all math questions;\n           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct\", general_title = \"Note: \",footnote_as_chunk = T)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;border-bottom: 0;'>\n<caption>Descriptive Statistics of OSPAN Task Accuracy</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> MATH </td>\n   <td style=\"text-align:right;\"> 0.517 </td>\n   <td style=\"text-align:right;\"> 0.897 </td>\n   <td style=\"text-align:right;\"> 0.931 </td>\n   <td style=\"text-align:right;\"> 0.966 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.924 </td>\n   <td style=\"text-align:right;\"> 0.085 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ORDER </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.533 </td>\n   <td style=\"text-align:right;\"> 0.733 </td>\n   <td style=\"text-align:right;\"> 0.867 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.678 </td>\n   <td style=\"text-align:right;\"> 0.253 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> WEIGHTED </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 13.448 </td>\n   <td style=\"text-align:right;\"> 20.276 </td>\n   <td style=\"text-align:right;\"> 24.828 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 19.082 </td>\n   <td style=\"text-align:right;\"> 7.391 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<span style=\"font-style: italic;\">Note: </span> <sup></sup> MATH = %correct of all math questions;<br>           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# #GGFORMULA | DENSITY HISTOGRAM \n med = median(df_subjects$OSPAN.weighted)\n  gf_dhistogram(~OSPAN.weighted, data = df_subjects) %>% \n  gf_vline(xintercept = ~med, color = \"red\") +\n  labs(x = \"OSPAN (weighted) score\",\n       y = \"% of subjects\",\n       title = \"Distribution of OSPAN SCORE\",\n       subtitle = \"line indicates median split\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-SUBJ-OSPAN-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = ospan_split)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~ospan_split) + \n   labs(title = \"OSPAN SPLIT\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"After taking a median split, comparable high(vs) low in each condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-SUBJ-OSPAN-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\n## OVERALL ACCURACY\n\n\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q, ospan_split)\n\ndf_s <- df_subjects %>% \n  dplyr::select(pretty_condition, ospan_split, task_percent)\n```\n:::\n\n#### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\", width = 0.75 ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"lisa::FridaKahlo\", 2))+\n  facet_wrap(~ospan_split)+\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::Jewel_Bright\", 2))+\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 2))+\n  # scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n  # coord_flip() +\n  theme(legend.position=\"bottom\")+\n   labs(title = \"Study 3C | DISTRIBUTION of Question Accuracy\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"Impasse is particularly effective for subjects with high-working memory\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/DESC-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: LABELLED \n# \n# temp <- df_i %>% mutate(\n#   accuracy = fct_rev(accuracy)\n# )  \n# \n# #CREATE PLOT WITH LABELS\n# p <- grouped_ggbarstats(data = temp, x = accuracy, y = pretty_condition,\n#                grouping.var = ospan_split,\n#                results.subtitle = FALSE,\n#                ggplot.component = ## modify further with `{ggplot2}` functions\n#                 list(\n#                   scale_fill_manual(values = paletteer::paletteer_d(\"lisa::FridaKahlo\", 2))\n#                   # theme(axis.text.x = element_text(angle = 90)))\n#                ))  + theme_clean() \n# \n# #FIX LABELS\n# p1 <- p[[1]] +  labs(\n#   subtitle = \"Impasse is particularly effective for subjects with high-working memory\",\n#     x = \"Condition\", y = \"Probability of Response\"\n#   ) + theme_clean() + theme(legend.position = \"blank\") \n#  \n# p2 <-   p[[2]] + labs(\n#     x = \"Condition\", y = \"Probability of Response\",\n#     subtitle = \"   \"\n#   ) + theme_clean() + theme(legend.position = \"blank\") +\n#   ggeasy::easy_remove_axes(which=\"y\", what=c(\"text\",\"title\"))\n#   # ggeasy::easy_remove_axes(which=\"y\", what= \"\"))\n# \n# #CREATE ROW\n# \n# plot_row <- plot_grid(p1,p2, rel_widths = c(1,0.85))\n# \n# title <- ggdraw() + \n#   draw_label(\n#     \"DISTRIBUTION | Question Accuracy\",\n#     fontface = 'bold',\n#     x = 0,\n#     hjust = 0\n#   ) +\n#   theme(\n#     # add margin on the left of the drawing canvas,\n#     # so title is aligned with left edge of first plot\n#     plot.margin = margin(0, 0, 0, 7)\n#   )\n# \n# \n# pg <- plot_grid(\n#   title,\n#   plot_row,\n#   ncol = 1,\n#   # rel_heights values control vertical title margins\n#   rel_heights = c(0.1, 1)\n# ) + theme_clean()\n#   \n# pg\n# ggsave(pg, filename = \"figures/SGC3A_OSPAN_Accuracy.png\", width = 6, height =4)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap( q ~ ospan_split) +\n   labs(title = \"Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  gf_facet_grid(pretty_condition ~ ospan_split) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Overall Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n### Describe\n::: {.cell}\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.462 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.252 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> pretty_condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.155 </td>\n   <td style=\"text-align:right;\"> 0.303 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> impasse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.788 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.345 </td>\n   <td style=\"text-align:right;\"> 0.405 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT\"\ntbl2 <- mosaic::favstats(task_percent ~ ospan_split, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> ospan_split </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> low-memory </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.192 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.195 </td>\n   <td style=\"text-align:right;\"> 0.314 </td>\n   <td style=\"text-align:right;\"> 67 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> high-memory </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.769 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.310 </td>\n   <td style=\"text-align:right;\"> 0.413 </td>\n   <td style=\"text-align:right;\"> 66 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT & CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ ospan_split+pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n<caption>Descriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT &amp; CONDITION</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> ospan_split.pretty_condition </th>\n   <th style=\"text-align:right;\"> min </th>\n   <th style=\"text-align:right;\"> Q1 </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> Q3 </th>\n   <th style=\"text-align:right;\"> max </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:right;\"> missing </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> low-memory.control </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.149 </td>\n   <td style=\"text-align:right;\"> 0.297 </td>\n   <td style=\"text-align:right;\"> 31 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> high-memory.control </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.161 </td>\n   <td style=\"text-align:right;\"> 0.314 </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> low-memory.impasse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 0.423 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.235 </td>\n   <td style=\"text-align:right;\"> 0.327 </td>\n   <td style=\"text-align:right;\"> 36 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> high-memory.impasse </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.308 </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0.469 </td>\n   <td style=\"text-align:right;\"> 0.451 </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\nAcross both conditions, overall accuracy on the task ranges from 0 to 100 with a mean of 25.217. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.\n\nTask level accuracy on the graph comprehension task follows the same pattern of behaviour observed in Study 3A: the distribution is bimodal. Total scores were higher in the impasse condition (M = 35\\%, SD = 41\\%, n = 65)  than control condition (M = 15\\%, SD = 30\\%, n = 68), implying a likely main effect of scaffold condition.  Comparing total scores across the median split on the OSPAN task (high working memory (vs) low working memory), we see readers with high working memory (M = 31 \\%, SD = 41\\%, n = 66) performed better than readers with low working memory (M = 19 \\%, SD = 31\\%, n = 67). In Figure \\ref{fig_3C_ospan_raw_accuracy} we see that while readers in the impasse condition performed consistently better than those in the control condition, the effect is particularly pronounced for readers with high-working memory, implying a potential interaction between condition and working memory. \n\n#### WILCOXON RANK SUM (Mann-Whitney Test) \n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n\n\n##### Test\n\n::: {.cell}\n\n```{.r .cell-code}\n#WILCOXON ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY\ndf_low <- df_s %>% filter(ospan_split == \"low-memory\")\n(w <- wilcox.test(df_low$task_percent ~ df_low$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_low$task_percent by df_low$pretty_condition\nW = 458, p-value = 0.09\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\n#WILCOXON ON ACCURACY X OSPAN-SPLIT in HIGH\ndf_high <- df_s %>% filter(ospan_split == \"high-memory\")\n(w <- wilcox.test(df_high$task_percent ~ df_high$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df_high$task_percent by df_high$pretty_condition\nW = 304, p-value = 0.0005\nalternative hypothesis: true location shift is less than 0\n```\n:::\n\n```{.r .cell-code}\ngrouped_ggbetweenstats( data = df_s, type = \"nonparametric\",\n                        y = task_percent, x = pretty_condition, grouping.var = ospan_split)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/TEST-ACC-1.png){width=672}\n:::\n:::\n\n\n##### Inference â€” EFFECT\n\nA Wilcoxon-Rank sum test on task accuracy x condition for the low-memory participants indicate that impasse is not significantly higher. A Wilcoxon rank sum test on task accuracy x condition for high-memory participants indicate that impasse IS higher. Taken together, this indiates there may be an interaction between working memory and condition. \n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#TODO   \np <- grouped_ggbetweenstats(data = df_s,\n                       y = task_percent, x = pretty_condition, grouping.var = ospan_split,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               results.subtitle = FALSE,\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               # point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  labs(y = \"Percentage of correct responses across task\", x = \"\"),\n                  aes(color = pretty_condition, fill = pretty_condition),\n                  scale_fill_grey(), scale_color_grey()\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3))\n                  # theme(axis.text.x = element_text(angle = 90)\n                )) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\n```\n:::\n\n```{.r .cell-code}\np1 <- p[[1]] + coord_flip() + theme_clean() +\n   ggeasy::easy_remove_legend()\n\np2 <- p[[2]] + coord_flip() + \n  labs(\n       subtitle = \"High working memory yields higher scores and greater variance in impasse condition\") + \n  theme_clean() + ggeasy::easy_remove_axes(which = \"x\") + ggeasy::easy_remove_legend()\n\n\npg <- plot_grid(p2, p1, ncol=1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n```\n:::\n\n```{.r .cell-code}\npg\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n#### MIXED LOGISTIC REGRESSION [IXN!!]\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy) && is.factor(df_i$ospan_split)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Empty fixed model\"\n```\n:::\n\n```{.r .cell-code}\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Subject Intercept + Item intercept random model\"\n```\n:::\n\n```{.r .cell-code}\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(m0)) > AIC(logLik(mm.rSQ)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |    Chi2 |      p\n---------------------------------------------------\nm0     |      glm |  1 |         |         |       \nmm.rSQ | glmerMod |  3 |       2 | 1067.62 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0, mm.rSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  1.47511626235535e-232\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n#summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |       |       \nmm.CrSQ | glmerMod |  4 |       1 | 17.23 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0000330410023284755\"\n```\n:::\n\n```{.r .cell-code}\n## 3 | ADD INTERACTION OSPAN\n\nprint(\"FIXED Condition * FIXED OSPAN + Subject & Item random intercepts\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"FIXED Condition * FIXED OSPAN + Subject & Item random intercepts\"\n```\n:::\n\n```{.r .cell-code}\nmm.COrSQ <- glmer(accuracy ~ pretty_condition *ospan_split + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n# summary(mm.COrSQ)\n# car::Anova(mm.COrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.CrSQ)) > AIC(logLik(mm.COrSQ)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC decreases w/ new model TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.CrSQ,mm.COrSQ) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\nmm.CrSQ  | glmerMod |  4 |         |      |      \nmm.COrSQ | glmerMod |  6 |       2 | 6.93 | 0.031\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.CrSQ,mm.COrSQ))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0312599524800637\"\n```\n:::\n:::\n\n*A likelihood ratio test indicates adding OSPAN as a fixed effect to a logistic regression model including a fixed effect for CONDITION and random intercepts for SUBJECT and QUESTION explains more variance in the data than the CONDITION + random-effects only model.*\n\n**Condition is better than random effects alone**\n$chi^2(4,6) = 17.23, p < 0.001$\n\n**Adding OSPAN and interaction term better than condition**\n$chi^2(4,6) = 6.93, p < 0.05$\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm <- mm.COrSQ\nm %>% write_rds(file = \"analysis/SGC3A/models/sgc3a_glmer_acc_mm.COrSQ_OSPAN.rds\")\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition * ospan_split + (1 | subject) + (1 |  \n    q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     873      906     -430      861     1723 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-7.040 -0.129 -0.031  0.024 11.797 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 31.30    5.59    \n q       (Intercept)  1.18    1.09    \nNumber of obs: 1729, groups:  subject, 133; q, 13\n\nFixed effects:\n                                               Estimate Std. Error z value\n(Intercept)                                      -6.832      1.463   -4.67\npretty_conditionimpasse                           2.348      1.599    1.47\nospan_splithigh-memory                           -0.669      1.432   -0.47\npretty_conditionimpasse:ospan_splithigh-memory    4.845      2.255    2.15\n                                               Pr(>|z|)    \n(Intercept)                                       3e-06 ***\npretty_conditionimpasse                           0.142    \nospan_splithigh-memory                            0.640    \npretty_conditionimpasse:ospan_splithigh-memory    0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prtty_ ospn_-\nprtty_cndtn -0.602              \nospn_splth- -0.594  0.531       \nprtty_cn:_-  0.183 -0.657 -0.625\n```\n:::\n\n```{.r .cell-code}\nprint(\"SIGNIFICANCE TEST [non directional]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGNIFICANCE TEST [non directional]\"\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m, type=3) #TYPE 3 SS FOR IXNS\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: accuracy\n                             Chisq Df Pr(>Chisq)    \n(Intercept)                  21.80  1      3e-06 ***\npretty_condition              2.15  1      0.142    \nospan_split                   0.22  1      0.640    \npretty_condition:ospan_split  4.62  1      0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n# se <- sqrt(diag(stats::vcov(m)))\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Intâ€¦   -6.83       1.46    -4.67   3.03e-6   -9.70      -3.96\n2 fixed    <NA>   pretâ€¦    2.35       1.60     1.47   1.42e-1   -0.787      5.48\n3 fixed    <NA>   ospaâ€¦   -0.669      1.43    -0.467  6.40e-1   -3.47       2.14\n4 fixed    <NA>   pretâ€¦    4.84       2.25     2.15   3.17e-2    0.425      9.26\n5 ran_pars subjeâ€¦ sd__â€¦    5.59      NA       NA     NA         NA         NA   \n6 ran_pars q      sd__â€¦    1.09      NA       NA     NA         NA         NA   \n```\n:::\n\n```{.r .cell-code}\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n# (e <- exp(tab))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Intâ€¦  1.08e-3   0.00158    -4.67   3.03e-6  6.13e-5   1.90e-2\n2 fixed    <NA>   pretâ€¦  1.05e+1  16.7         1.47   1.42e-1  4.55e-1   2.40e+2\n3 fixed    <NA>   ospaâ€¦  5.12e-1   0.733      -0.467  6.40e-1  3.10e-2   8.47e+0\n4 fixed    <NA>   pretâ€¦  1.27e+2 286.          2.15   3.17e-2  1.53e+0   1.05e+4\n5 ran_pars subjeâ€¦ sd__â€¦  5.59e+0  NA          NA     NA       NA        NA      \n6 ran_pars q      sd__â€¦  1.09e+0  NA          NA     NA       NA        NA      \n```\n:::\n\n```{.r .cell-code}\npaste(\"PROBABILITIES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PROBABILITIES\"\n```\n:::\n\n```{.r .cell-code}\n#sanity check\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\nnewdata <- df_i %>% dplyr::select(pretty_condition, ospan_split, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: executing %dopar% sequentially: no parallel backend registered\n```\n:::\n\n```{.r .cell-code}\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(pretty_condition, ospan_split, fit, lwr, upr) %>% \n  group_by(pretty_condition, ospan_split) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 Ã— 5\n# Groups:   pretty_condition [2]\n  pretty_condition ospan_split   median     lower   upper\n  <fct>            <fct>          <dbl>     <dbl>   <dbl>\n1 control          low-memory  0.00119  0.000115  0.0118 \n2 control          high-memory 0.000589 0.0000722 0.00473\n3 impasse          low-memory  0.0118   0.00134   0.0931 \n4 impasse          high-memory 0.424    0.0899    0.845  \n```\n:::\n:::\n\n##### INFERENCE\n\n**REPORTED**\n\nTo explore the effect of working memory capacity on ACCURACY, we fit a mixed effects logistic regression model with random intercepts for subjects and questions, with CONDITION, WORKING MEMORY and their interaction term as fixed effects.  A likelihood ratio test indicates that a model including the fixed effect of CONDITION  explains significantly more variance in the data than an intercepts-only baseline model ($\\chi^2 (3,4) = 17.23, p < 0.001$). The final model including fixed effects and interaction term of OSPAN is a significantly better fit than the CONDITION-only model  ($\\chi^2(4,6) = 6.93, p < 0.05$). The explanatory power of the entire model is substantial ($conditional \\ R^2 = 0.92$) and the part related to the fixed effects CONDITION and WORKING MEMORY ($marginal \\ R^2$) explains 18\\% of variance. \n\nAlthough Wald Chi-Square tests revealed no significant main effects, there was a significant interaction between CONDITION and OSPAN, ($\\chi^2 (1) = 4.62, p < 0.05$).  [SEE POSTHOCS BELOW]\n\nThe model predicts that, in the control condition, the probability of a correct response for a participant with high vs. low working memory increases from (0.1 to 0.5%) a negligible difference. In the impasse condition, however, the probability of a correct response increases from only 1% for participants with low working memory, to 42% for participants with high working memory.  These results are consistent with the intuition we develop from Figure TODO. Participants with high working memory capacity are most able to take advantage of the impasse scaffold.\n\n##### Interactions\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html#simple\n# https://stats.oarc.ucla.edu/stata/faq/how-can-i-understand-a-categorical-by-categorical-interaction-in-logistic-regression-stata-12/\n# https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/\n  \nlibrary(emmeans)\n\n#sanity check reference grid\nref_grid(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'emmGrid' object with variables:\n    pretty_condition = control, impasse\n    ospan_split = low-memory, high-memory\nTransformation: \"logit\" \n```\n:::\n\n```{.r .cell-code}\n#PRINT ESTIMATED MARGINAL MEANS\n#should be same as summ_preds\nemmeans(m,  ~ pretty_condition + ospan_split, type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n pretty_condition ospan_split  prob     SE  df asymp.LCL asymp.UCL\n control          low-memory  0.001 0.0016 Inf    0.0001     0.019\n impasse          low-memory  0.011 0.0151 Inf    0.0008     0.142\n control          high-memory 0.001 0.0007 Inf    0.0000     0.007\n impasse          high-memory 0.423 0.2877 Inf    0.0679     0.881\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n```\n:::\n\n```{.r .cell-code}\n##POST-HOC COMPARISONS\nprint(\"POSTHOC COMPARISONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"POSTHOC COMPARISONS\"\n```\n:::\n\n```{.r .cell-code}\nemmeans(m,  pairwise ~ pretty_condition + ospan_split, \n        type = \"response\" , adjust = \"none\") #sidak, tukey\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n pretty_condition ospan_split  prob     SE  df asymp.LCL asymp.UCL\n control          low-memory  0.001 0.0016 Inf    0.0001     0.019\n impasse          low-memory  0.011 0.0151 Inf    0.0008     0.142\n control          high-memory 0.001 0.0007 Inf    0.0000     0.007\n impasse          high-memory 0.423 0.2877 Inf    0.0679     0.881\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n\n$contrasts\n contrast                                      odds.ratio    SE  df null\n (control low-memory) / (impasse low-memory)         0.10  0.15 Inf    1\n (control low-memory) / (control high-memory)        1.95  2.80 Inf    1\n (control low-memory) / (impasse high-memory)        0.00  0.00 Inf    1\n (impasse low-memory) / (control high-memory)       20.42 30.13 Inf    1\n (impasse low-memory) / (impasse high-memory)        0.02  0.03 Inf    1\n (control high-memory) / (impasse high-memory)       0.00  0.00 Inf    1\n z.ratio p.value\n  -1.470  0.1420\n   0.470  0.6400\n  -3.560  <.0001\n   2.040  0.0410\n  -2.370  0.0180\n  -4.220  <.0001\n\nTests are performed on the log odds ratio scale \n```\n:::\n\n```{.r .cell-code}\n##PLOT INTERACTION\n#equivalent to plot_model, type = \"int\"\nemmip(m, ospan_split ~ pretty_condition ,\n      type = \"response\",\n      CIs = TRUE,\n      linearg = list(linetype = \"dashed\"),\n      engine = \"ggplot\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##PLOT PROBABILITY\nplot(ref_grid(m), by = \"ospan_split\", type = \"response\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n**REPORTED**\n\nPosthoc paired comparisons reveal that there is not a significant difference in accuracy between the control and impasse condition for participants in the low-memory group (OR = 0.1, SE  = 0.15, z = -1.47, p = 0.46). \nFor those with low working memory capacity, performance with comparably low, regardless of condition.  \n\nFor those who were assigned to the control condition, working memory capacity did not change performance. There was not significant difference in accuracy between participants with low vs. high working memory (OR = 1.95, SE= 2.80, z = 0.47  p = 0.97).  \n\nFor those assigned to the impasse condition, however, if you had high working memory capacity, you had significantly higher probability of accurate responses (OR = 0.02, SE = 0.03, z = -2.370  p = 0.0180).  \n\n##### Print\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# title = \"Study 3C (OSPAN) | Question Accuracy | Mixed Logistic Regression\"\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              paste(\"n = \",n_obs(m), \"R^2(Conditional) =\", round(r2(m)[[1]],2),\n#                    \"R^2(Marginal) =\", round(r2(m)[[2]],2)),\n#              \"Accuracy  ~ Condition * OSPAN +  (1 | subject) + (1 | q)\")\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = title,\n#              notes = notes,\n#              output = \"tables/SGC3C_OSPAN_GLMER_OverallAccuracy.tex\")\n#              # coef_omit = \"Intercept\",\n\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n```\n:::\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-5.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m, type = \"eff\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-6.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-7.png){width=672}\n:::\n\n```{.r .cell-code}\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n#GGDIST | MODEL | PREDICTED PROBABILITIES\npreds %>% \n  ggplot(aes( x = fit, y = pretty_condition, fill = ospan_split)) + \n  stat_halfeye(alpha = 0.5, normalize = \"panels\") + \n  xlim(0,0.3) + theme_clean() + labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"TODO check preds to see if fixed or includes random\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 416 rows containing missing values (stat_slabinterval).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-ACC-8.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list('\"* p < 0.05, ** p < 0.01, *** p < 0.001\"',\n#                'N(subject) = 133 $\\tau_{00}$(subject) = 34.85',\n#              'N(question) = 13 $\\tau_{00}$(question) = 1.14')\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex\")\n# # #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-DIAG-ACC-1.png){width=672}\n:::\n:::\n\n## OVERALL INTERPRETATION STATE\n\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n\n#### Setup\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition, ospan_split) %>% droplevels()\n```\n:::\n\n#### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  facet_wrap(~ospan_split) +\n   labs(title = \"Interpretation across all Questions\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  # scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(q ~ ospan_split) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: LABELLED \n\n# temp <- df_i %>% mutate(\n#   state = fct_rev(state)\n# )  \n# \n# p <-   grouped_ggbarstats(data = temp, x = state, y = pretty_condition,\n#                           grouping.var = ospan_split,\n#                results.subtitle = FALSE,\n#                ggplot.component = ## modify further with `{ggplot2}` functions\n#                 list(\n#                   scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))\n#                   # theme(axis.text.x = element_text(angle = 90)))\n#                ))  + theme_clean() + theme(legend.position = \"bottom\")\n# \n# p <- p + labs(title = \"DISTRIBUTION | Question Accuracy\",\n#          y = \"Proportion of Questions\", x = \"Condition\",\n#          subtitle = \"Impasse condition yields more correct responses\")\n# \n# p\n# # ggsave(p, filename = \"figures/SGC3A_LAB_Accuracy.png\", width = 6, height =4)\n\n\n#:::::::: LABELLED \n# \n# temp <- df_i \n# # %>% mutate(\n# #   accuracy = fct_rev(accuracy)\n# # )\n# \n# #CREATE PLOT WITH LABELS\n# p <- grouped_ggbarstats(data = temp, x = state, y = pretty_condition,\n#                grouping.var = ospan_split,\n#                results.subtitle = FALSE,\n#                ggplot.component = ## modify further with `{ggplot2}` functions\n#                 list(\n#                   scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))\n#                   # theme(axis.text.x = element_text(angle = 90)))\n#                )) \n# \n# #FIX LABELS\n# p1 <- p[[1]] +  labs(\n#   subtitle = \"Impasse is particularly effective for subjects with high-working memory\",\n#     x = \"Condition\", y = \"Probability of Response\"\n#   ) + theme_clean() + theme(legend.position = \"blank\") \n#  \n# p2 <-   p[[2]] + labs(\n#     x = \"Condition\", y = \"Probability of Response\",\n#     subtitle = \"   \"\n#   ) + theme_clean() + theme(legend.position = \"blank\") +\n#   ggeasy::easy_remove_axes(which=\"y\", what=c(\"text\",\"title\"))\n#   # ggeasy::easy_remove_axes(which=\"y\", what= \"\"))\n# \n# #CREATE ROW\n# \n# plot_row <- plot_grid(p1,p2, rel_widths = c(1,0.85))\n# \n# title <- ggdraw() + \n#   draw_label(\n#     \"DISTRIBUTION | Question Accuracy\",\n#     fontface = 'bold',\n#     x = 0,\n#     hjust = 0\n#   ) +\n#   theme(\n#     # add margin on the left of the drawing canvas,\n#     # so title is aligned with left edge of first plot\n#     plot.margin = margin(0, 0, 0, 7)\n#   )\n# \n# \n# pg <- plot_grid(\n#   title,\n#   plot_row,\n#   ncol = 1,\n#   # rel_heights values control vertical title margins\n#   rel_heights = c(0.1, 1)\n# ) + theme_clean()\n#   \n# \n# update_geom_defaults(\"text\", list(colour = \"grey20\", family = theme_get()$text$family))\n# \n# \n# pg\n\n\n# ggsave(pg, filename = \"figures/SGC3A_OSPAN_Accuracy.png\", width = 6, height =4)\n```\n:::\n\n#### Describe\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse    Sum\n  orthogonal  0.6686  0.3224 0.4916\n  other       0.1361  0.2704 0.2047\n  angular     0.0402  0.0622 0.0515\n  triangular  0.1550  0.3450 0.2522\n  Sum         1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df_i$state, df_i$pretty_condition, df_i$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, ,  = low-memory\n\n            \n             control impasse Sum\n  orthogonal     269     171 440\n  other           58     151 209\n  angular         16      36  52\n  triangular      60     110 170\n  Sum            403     468 871\n\n, ,  = high-memory\n\n            \n             control impasse Sum\n  orthogonal     296     114 410\n  other           57      88 145\n  angular         18      19  37\n  triangular      71     195 266\n  Sum            442     416 858\n```\n:::\n:::\n\n#### MIXED MULTINOMIAL REGRESSION\n\n\n*Does condition affect the response state of of items across the task?*\n\n*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   mblogit version wouldn't coverge, so using brms\n\n##### Fit Model \\[brms\\]\n\n::: {.cell}\n\n```{.r .cell-code}\ninf_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\")\n)\n\nixn_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on CONDITION COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\"),\n  #prior on OSPAN COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"mutriangular\"),\n  #prior on IXN COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"mutriangular\")\n)\n\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.rSQ_OSPAN.rds\")\n\n\n# CONDITION ONLY MODEL\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = inf_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.CrSQ_OSPAN.rds\")\n\n\n##MODEL COMPARISON\n# print(\"MODEL COMPARISON: random effects (vs) CONDITION\")\n# bayesfactor(Bmm.cat.rSQ, Bmm.cat.CrSQ)\n#substantial evidence in favor of conditon model over random only BF 1.64e+16\n\n# CONDITION + OSPAN MODEL\nBmm.cat.COrSQ <- brm( state ~ pretty_condition*ospan_split + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = ixn_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.COrSQ_OSPAN.rds\")\n# summary(mm.cat.COrSQ)\n\n##MODEL COMPARISON\n# print(\"MODEL COMPARISON: COND*OSPAN (vs) CONDITION\")\n# bayesfactor(Bmm.cat.COrSQ, Bmm.cat.CrSQ)\n#commment out bc we'll do this in next block\n\n#which model is better?\ncompare_models(Bmm.cat.CrSQ, Bmm.cat.COrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                                                   |         Bmm.cat.CrSQ |        Bmm.cat.COrSQ\n---------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           | -2.03 (-2.82, -1.27) | -1.95 (-2.80, -1.18)\nmuangular_Intercept                                         | -3.94 (-5.19, -2.71) | -4.10 (-5.53, -2.72)\nmutriangular_Intercept                                      | -4.70 (-6.43, -3.14) | -4.82 (-6.86, -2.93)\nmuother_pretty_conditionimpasse                             |  1.80 ( 1.37,  2.25) |  1.81 ( 1.23,  2.45)\nmuangular_pretty_conditionimpasse                           |  1.67 ( 0.90,  2.50) |  1.85 ( 0.79,  3.00)\nmutriangular_pretty_conditionimpasse                        |  3.56 ( 1.61,  5.54) |  2.45 ( 0.24,  4.68)\nmuother_ospan_splithighMmemory                              |                      | -0.18 (-0.81,  0.45)\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |                      | -0.08 (-0.98,  0.81)\nmutriangular_ospan_splithighMmemory                         |                      |  0.07 (-2.25,  2.28)\nmuangular_ospan_splithighMmemory                            |                      |  0.16 (-1.01,  1.32)\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |                      | -0.33 (-1.84,  1.23)\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |                      |  2.76 (-0.12,  5.52)\n---------------------------------------------------------------------------------------------------------\nObservations                                                |                 1729 |                 1729\n```\n:::\n\n```{.r .cell-code}\n# compare_performance(Bmm.cat.CrSQ, Bmm.cat.COrSQ)\n# car::Anova(mm.cat.CrSQ, mm.cat.COrSQ)\n# car::Anova(mm.cat.COrSQ)\n```\n:::\n\n\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n# best model\nm <- Bmm.cat.COrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ pretty_condition * ospan_split + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1729) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.28      0.32     0.81     2.07 1.00     1338\nsd(muangular_Intercept)        1.97      0.56     1.18     3.36 1.00     1556\nsd(mutriangular_Intercept)     1.50      0.37     0.95     2.37 1.00     1924\n                           Tail_ESS\nsd(muother_Intercept)          2804\nsd(muangular_Intercept)        2534\nsd(mutriangular_Intercept)     3273\n\n~subject (Number of levels: 133) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          0.90      0.13     0.66     1.17 1.00     2005\nsd(muangular_Intercept)        1.65      0.28     1.15     2.24 1.00     1800\nsd(mutriangular_Intercept)     5.33      0.62     4.25     6.65 1.00     1149\n                           Tail_ESS\nsd(muother_Intercept)          3045\nsd(muangular_Intercept)        3459\nsd(mutriangular_Intercept)     2307\n\nPopulation-Level Effects: \n                                                            Estimate Est.Error\nmuother_Intercept                                              -1.96      0.42\nmuangular_Intercept                                            -4.11      0.71\nmutriangular_Intercept                                         -4.85      1.00\nmuother_pretty_conditionimpasse                                 1.82      0.31\nmuother_ospan_splithighMmemory                                 -0.18      0.32\nmuother_pretty_conditionimpasse:ospan_splithighMmemory         -0.07      0.45\nmuangular_pretty_conditionimpasse                               1.86      0.56\nmuangular_ospan_splithighMmemory                                0.16      0.59\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory       -0.32      0.78\nmutriangular_pretty_conditionimpasse                            2.47      1.12\nmutriangular_ospan_splithighMmemory                             0.05      1.17\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory     2.74      1.46\n                                                            l-95% CI u-95% CI\nmuother_Intercept                                              -2.80    -1.18\nmuangular_Intercept                                            -5.53    -2.72\nmutriangular_Intercept                                         -6.86    -2.93\nmuother_pretty_conditionimpasse                                 1.23     2.45\nmuother_ospan_splithighMmemory                                 -0.81     0.45\nmuother_pretty_conditionimpasse:ospan_splithighMmemory         -0.98     0.81\nmuangular_pretty_conditionimpasse                               0.79     3.00\nmuangular_ospan_splithighMmemory                               -1.01     1.32\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory       -1.84     1.23\nmutriangular_pretty_conditionimpasse                            0.24     4.68\nmutriangular_ospan_splithighMmemory                            -2.25     2.28\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory    -0.12     5.52\n                                                            Rhat Bulk_ESS\nmuother_Intercept                                           1.00     1051\nmuangular_Intercept                                         1.00     1411\nmutriangular_Intercept                                      1.00     1109\nmuother_pretty_conditionimpasse                             1.00     2022\nmuother_ospan_splithighMmemory                              1.00     2358\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      1.00     1927\nmuangular_pretty_conditionimpasse                           1.00     1894\nmuangular_ospan_splithighMmemory                            1.00     1947\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    1.00     1990\nmutriangular_pretty_conditionimpasse                        1.00      819\nmutriangular_ospan_splithighMmemory                         1.01     1166\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory 1.00     1281\n                                                            Tail_ESS\nmuother_Intercept                                               2068\nmuangular_Intercept                                             2534\nmutriangular_Intercept                                          1663\nmuother_pretty_conditionimpasse                                 2940\nmuother_ospan_splithighMmemory                                  3218\nmuother_pretty_conditionimpasse:ospan_splithighMmemory          3157\nmuangular_pretty_conditionimpasse                               2465\nmuangular_ospan_splithighMmemory                                3299\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory        2629\nmutriangular_pretty_conditionimpasse                            1699\nmutriangular_ospan_splithighMmemory                             2366\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory     2310\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n(d <- describe_posterior(ci=.95, m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter                                                   | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n--------------------------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           |  -1.95 | [-2.80, -1.18] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1040.00\nmuangular_Intercept                                         |  -4.10 | [-5.53, -2.72] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1378.00\nmutriangular_Intercept                                      |  -4.82 | [-6.86, -2.93] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1102.00\nmuother_pretty_conditionimpasse                             |   1.81 | [ 1.23,  2.45] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1993.00\nmuother_ospan_splithighMmemory                              |  -0.18 | [-0.81,  0.45] | 71.52% | [-0.18, 0.18] |    38.68% | 1.001 | 2323.00\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |  -0.08 | [-0.98,  0.81] | 56.37% | [-0.18, 0.18] |    32.33% | 1.001 | 1907.00\nmuangular_pretty_conditionimpasse                           |   1.85 | [ 0.79,  3.00] | 99.98% | [-0.18, 0.18] |        0% | 1.001 | 1900.00\nmuangular_ospan_splithighMmemory                            |   0.16 | [-1.01,  1.32] | 60.73% | [-0.18, 0.18] |    25.18% | 1.002 | 1892.00\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |  -0.33 | [-1.84,  1.23] | 66.37% | [-0.18, 0.18] |    17.42% | 1.000 | 1986.00\nmutriangular_pretty_conditionimpasse                        |   2.45 | [ 0.24,  4.68] | 98.75% | [-0.18, 0.18] |        0% | 1.002 |  824.00\nmutriangular_ospan_splithighMmemory                         |   0.07 | [-2.25,  2.28] | 52.40% | [-0.18, 0.18] |    12.63% | 1.005 | 1164.00\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |   2.76 | [-0.12,  5.52] | 97.03% | [-0.18, 0.18] |     1.37% | 1.001 | 1268.00\n```\n:::\n\n```{.r .cell-code}\nprint(\"BAYES FACTOR [comparison to CONDITION only]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BAYES FACTOR [comparison to CONDITION only]\"\n```\n:::\n\n```{.r .cell-code}\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(Bmm.cat.CrSQ, m))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRecompiling the model with 'rstan'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRecompilation done\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBayes Factors for Model Comparison\n\n    Model                                                       BF\n[2] pretty_condition * ospan_split + (1 | subject) + (1 | q) 0.380\n\n* Against Denominator: [1] pretty_condition + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n```\n:::\n\n```{.r .cell-code}\n# already calculated this in step above\n\nprint(\"DESCRIBE POSTERIOR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DESCRIBE POSTERIOR\"\n```\n:::\n\n```{.r .cell-code}\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(l <- describe_posterior(m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter                                                   | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n--------------------------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           |  -1.95 | [-2.80, -1.18] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1040.00\nmuangular_Intercept                                         |  -4.10 | [-5.53, -2.72] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1378.00\nmutriangular_Intercept                                      |  -4.82 | [-6.86, -2.93] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1102.00\nmuother_pretty_conditionimpasse                             |   1.81 | [ 1.23,  2.45] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1993.00\nmuother_ospan_splithighMmemory                              |  -0.18 | [-0.81,  0.45] | 71.52% | [-0.18, 0.18] |    38.68% | 1.001 | 2323.00\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |  -0.08 | [-0.98,  0.81] | 56.37% | [-0.18, 0.18] |    32.33% | 1.001 | 1907.00\nmuangular_pretty_conditionimpasse                           |   1.85 | [ 0.79,  3.00] | 99.98% | [-0.18, 0.18] |        0% | 1.001 | 1900.00\nmuangular_ospan_splithighMmemory                            |   0.16 | [-1.01,  1.32] | 60.73% | [-0.18, 0.18] |    25.18% | 1.002 | 1892.00\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |  -0.33 | [-1.84,  1.23] | 66.37% | [-0.18, 0.18] |    17.42% | 1.000 | 1986.00\nmutriangular_pretty_conditionimpasse                        |   2.45 | [ 0.24,  4.68] | 98.75% | [-0.18, 0.18] |        0% | 1.002 |  824.00\nmutriangular_ospan_splithighMmemory                         |   0.07 | [-2.25,  2.28] | 52.40% | [-0.18, 0.18] |    12.63% | 1.005 | 1164.00\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |   2.76 | [-0.12,  5.52] | 97.03% | [-0.18, 0.18] |     1.37% | 1.001 | 1268.00\n```\n:::\n\n```{.r .cell-code}\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- model_parameters(m, exponentiate = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                                                   |   Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS\n------------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           |     0.14 | [0.06,   0.31] |   100% |        0% | 1.001 | 1040.00\nmuangular_Intercept                                         |     0.02 | [0.00,   0.07] |   100% |        0% | 1.000 | 1378.00\nmutriangular_Intercept                                      | 8.07e-03 | [0.00,   0.05] |   100% |        0% | 1.000 | 1102.00\nmuother_pretty_conditionimpasse                             |     6.13 | [3.42,  11.53] |   100% |        0% | 1.001 | 1993.00\nmuother_ospan_splithighMmemory                              |     0.83 | [0.44,   1.56] | 71.52% |    38.68% | 1.001 | 2323.00\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |     0.93 | [0.38,   2.25] | 56.37% |    32.33% | 1.001 | 1907.00\nmuangular_pretty_conditionimpasse                           |     6.39 | [2.21,  20.08] | 99.98% |        0% | 1.001 | 1900.00\nmuangular_ospan_splithighMmemory                            |     1.18 | [0.37,   3.74] | 60.73% |    25.18% | 1.002 | 1892.00\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |     0.72 | [0.16,   3.41] | 66.37% |    17.42% | 1.000 | 1986.00\nmutriangular_pretty_conditionimpasse                        |    11.64 | [1.27, 107.34] | 98.75% |        0% | 1.002 |  824.00\nmutriangular_ospan_splithighMmemory                         |     1.07 | [0.11,   9.76] | 52.40% |    12.63% | 1.005 | 1164.00\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |    15.73 | [0.89, 249.91] | 97.03% |     1.37% | 1.001 | 1268.00\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n```\n:::\n\n```{.r .cell-code}\npaste(\"PROBABILITIES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PROBABILITIES\"\n```\n:::\n\n```{.r .cell-code}\n#PREDICT METHOD\nnewdata <- df_i %>% dplyr::select(pretty_condition, ospan_split, subject, q)\npreds <- predict(m, newdata = newdata, type = \"response\")\npreds <- cbind(newdata, preds)\n# lengthen data frame to handle multinomial\npreds <- preds %>%\n  dplyr::select(-subject, -q) %>% #marginalize over subject and q\n  pivot_longer(\n  cols = !pretty_condition & !ospan_split,\n  values_to = \"preds\",\n  names_to = \"state\",\n)\n\n(p <- preds %>%\n  group_by(pretty_condition, ospan_split, state ) %>%\n  summarise(\n    median = median(preds),\n    se = sd(preds)/sqrt(n()),\n    lwr = median - 1.96*se,\n    upr = median + 1.96*se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 Ã— 7\n# Groups:   pretty_condition, ospan_split [4]\n   pretty_condition ospan_split state             median      se      lwr    upr\n   <fct>            <fct>       <chr>              <dbl>   <dbl>    <dbl>  <dbl>\n 1 control          low-memory  P(Y = angular)   0.0137  0.00377  0.00627 0.0211\n 2 control          low-memory  P(Y = orthogonaâ€¦ 0.755   0.0141   0.728   0.783 \n 3 control          low-memory  P(Y = other)     0.133   0.00577  0.122   0.144 \n 4 control          low-memory  P(Y = triangulaâ€¦ 0.00983 0.0145  -0.0186  0.0383\n 5 control          high-memory P(Y = angular)   0.0158  0.00296  0.0100  0.0216\n 6 control          high-memory P(Y = orthogonaâ€¦ 0.774   0.0142   0.746   0.801 \n 7 control          high-memory P(Y = other)     0.0963  0.00566  0.0852  0.107 \n 8 control          high-memory P(Y = triangulaâ€¦ 0.00717 0.0146  -0.0215  0.0359\n 9 impasse          low-memory  P(Y = angular)   0.037   0.00473  0.0277  0.0463\n10 impasse          low-memory  P(Y = orthogonaâ€¦ 0.337   0.0119   0.314   0.361 \n11 impasse          low-memory  P(Y = other)     0.324   0.00986  0.305   0.343 \n12 impasse          low-memory  P(Y = triangulaâ€¦ 0.0512  0.0152   0.0214  0.0811\n13 impasse          high-memory P(Y = angular)   0.0123  0.00371  0.00507 0.0196\n14 impasse          high-memory P(Y = orthogonaâ€¦ 0.161   0.0140   0.133   0.188 \n15 impasse          high-memory P(Y = other)     0.110   0.0112   0.0885  0.133 \n16 impasse          high-memory P(Y = triangulaâ€¦ 0.341   0.0215   0.298   0.383 \n```\n:::\n\n```{.r .cell-code}\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n```\n:::\n\n##### INFERENCE\n\n**Reported** \n\nTo quantify the effect of working memory capacity on INTERPRETATION, we fit a (bayesian) mixed multinomial regression model with random intercepts for subjects and questions. A Bayes Factor model comparison (against a random intercepts + CONDITION model) indicates strong evidence for a a final model including fixed effects of CONDITION, OSPAN and their interaction term  (BF = 8.52).\n\n(note, the BF may change as it is estimated via simulation each time)\n\n##### Interactions\n\n::: {.cell}\n\n```{.r .cell-code}\n#EMMEANS doesn't support multinomial brms models. BUMMER\n#BUT brms has some built in stuffs. \n\n# FOR MAIN EFFECTS PLOTS \nprint(\"MAIN EFFECTS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MAIN EFFECTS\"\n```\n:::\n\n```{.r .cell-code}\nconditional_effects(m, categorical = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Interactions cannot be plotted directly if 'categorical' is TRUE.\nPlease use argument 'conditions' instead.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-26-2.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(\"INTERACTION PLOT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"INTERACTION PLOT\"\n```\n:::\n\n```{.r .cell-code}\n# conditions <- make_conditions(m, vars = c(\"pretty_condition\",\"ospan_split\"))\nconditions <- make_conditions(m, vars = c(\"pretty_condition\"))\nconditional_effects(m, \"ospan_split\", conditions = conditions,\n                    categorical = TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-26-3.png){width=672}\n:::\n\n```{.r .cell-code}\nprint(\"INTERACTION PLOT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"INTERACTION PLOT\"\n```\n:::\n\n```{.r .cell-code}\nplot_model(m, type=\"int\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-26-4.png){width=672}\n:::\n:::\n**REPORTED**\n\nThe model predicts similar probabilities for orthogonal, other, and angular interpretations by high vs. low working memory participants. It is only the (correct) triangular interpretation in which we have evidence for a reliable interaction between OSPAN and CONDITION. Much like the pattern of results for accuracy, it is high working memory participants with higher probability of triangular responses, but only in impasse condition. \n\n\n##### Print \n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n#model summary doesn't work for brms multinomial\n\n# DOESN'T WORK FOR BRMS\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n# \n# \n# #GET MODEL ESTIMATES\n# t <- as.data.frame(model_parameters(m, exponentiate = TRUE))\n# # \n# # #REFORMAT\n# x <- t %>%\n#   mutate(\n#     Parameter = str_remove_all(Parameter,\"_pretty\"),\n#     Parameter = str_remove_all(Parameter,\"b_mu\"),\n#     Interpretation = word(Parameter, 1, sep = \"_\"),\n#     Interpretation = fct_relevel(Interpretation, levels = c(\"other\",\"angular\",\"triangular\")),\n#     Factor = word(Parameter, 2, sep = \"_\"),\n#     Factor = recode_factor(Factor,\n#                          \"Intercept\" = \"(Intercept)\",\n#                          \"conditionimpasse\" = \"Condition[impasse]\",\n#                          \"ospan\" = \"OSPAN[high-memory]\",\n#                          \"conditionimpasse:ospan\" = \"Condition:OSPAN\"),\n#     Median = round(Median,2),\n#     CI_low = round(CI_low,2),\n#     CI_high = round(CI_high,2),\n#     pd = round(pd,2),\n#     ROPE_Percentage = round(ROPE_Percentage,2)) %>%\n#   arrange(Interpretation) %>%\n#   dplyr::select(-CI, -Rhat, -ESS) %>%\n#   rename( \"%_in_ROPE\"=\"ROPE_Percentage\",\n#   \"(Odds Ratio)\" = \"Median\") %>%\n#   dplyr::select(Interpretation, Factor, `(Odds Ratio)`, CI_low, CI_high, pd, `%_in_ROPE`)\n# \n# # #KNIT\n# title = \"Study 3C (OSPAN) | Question Interpretation | Mixed Multinomial Regression\"\n# tab <- kbl(x, format = \"latex\", caption = title,\n#            booktabs = FALSE) %>% kable_classic() %>%\n# footnote(general = paste(\"Model Interpretation ~ \",b$Model[2], \"Bayes Factor \", format( exp(b$log_BF[2]), digits =2 ) ), footnote_as_chunk = T, general_title = \"\")\n# writeLines(tab, \"tables/SGC3C_OSPAN_BRMS_state.tex\")\n```\n:::\n##### Visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\", \n#            show.intercept = TRUE, \n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test   \n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-BRMS-STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# + theme_clean()\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.0938\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 7200 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-BRMS-STATE-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- rope(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-BRMS-STATE-3.png){width=672}\n:::\n\n```{.r .cell-code}\n##TODO see documentation for removing, reorganizing parameters\nresult <- pd(m, effects = \"fixed\", component = \"all\")\nplot(result, show_intercept = FALSE,\n     n_columns = 3)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-BRMS-STATE-4.png){width=672}\n:::\n\n```{.r .cell-code}\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-BRMS-STATE-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")  \n# plot_model(m, type = \"eff\")  \n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\ndraws <- df_i %>%\n  data_grid(pretty_condition, ospan_split, subject, q) %>%\n  add_epred_draws(m,\n                   # ndraws = 100, # n = 100,\n                   # dpar = TRUE,\n                   transform = TRUE, #gives prob%, otherwise OR\n                   re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\n# d <- \n\nd <- draws %>% sample_n(10) %>% \n  ggplot(aes(x = .epred,  y = pretty_condition, fill = ospan_split)) +\n  stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\") +\n  facet_wrap(~.category) +\n  #   #normalize = all, panels, xy, groups, none\n  xlim(0,1) + labs(\n    title = \"Model Predicted Probability of Correct Response\",\n    x = \"probability of correct response\",\n    y = \"Interpretation\"\n  ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # \n# # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\nd\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#CHECK Fit of posterior predictive to data\npp_check(m, ndraws=1000)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#CHECK posterior vs. priors\nresult <- estimate_density(m)\nplot(result, stack = FALSE, priors= TRUE)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#CHECK model\nplot(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-5.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-30-6.png){width=672}\n:::\n:::\n\n## Q1 ACCURACY\n\n\n\n#### Setup\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q==1) %>% dplyr::select(accuracy, pretty_condition, ospan_split)\n```\n:::\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1ACC-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Proportions of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse   Sum\n  incorrect   0.892   0.765 0.827\n  correct     0.108   0.235 0.173\n  Sum         1.000   1.000 1.000\n```\n:::\n\n```{.r .cell-code}\npaste(\"Number of Correct Responses by Condition\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Number of Correct Responses by Condition\"\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, ,  = low-memory\n\n           \n            control impasse Sum\n  incorrect      28      31  59\n  correct         3       5   8\n  Sum            31      36  67\n\n, ,  = high-memory\n\n           \n            control impasse Sum\n  incorrect      30      21  51\n  correct         4      11  15\n  Sum            34      32  66\n```\n:::\n:::\n\n#### CHI SQUARE [YES]\n\n::: {.cell}\n\n```{.r .cell-code}\n#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY\ndf_low <- df %>% filter(ospan_split == \"low-memory\")\n# table(df_low$pretty_condition, df_low$accuracy)\nchisq.test( x = df_low$pretty_condition, y = df_low$accuracy, correct = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(x = df_low$pretty_condition, y = df_low$accuracy, : Chi-\nsquared approximation may be incorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  df_low$pretty_condition and df_low$accuracy\nX-squared = 0.02, df = 1, p-value = 0.9\n```\n:::\n\n```{.r .cell-code}\n#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in HIGH WORKING MEMORY\ndf_high <- df %>% filter(ospan_split == \"high-memory\")\n#table(df_high$pretty_condition, df_high$accuracy)\nchisq.test( x = df_high$pretty_condition, y = df_high$accuracy,correct = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  df_high$pretty_condition and df_high$accuracy\nX-squared = 4, df = 1, p-value = 0.06\n```\n:::\n\n```{.r .cell-code}\n#significant if correct = FALSE\n```\n:::\nTODO why do these chisqrs not match the grouped bar stats?\n::: {.cell}\n\n```{.r .cell-code}\n# INTERACTION (OSPAN X CONDITION)\ngrouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, \n                    grouping.var = ospan_split,\n                    type = \"nonparametric\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# MAIN EFFECT CONDITION (yes)\n# ggbarstats( data = df, x = accuracy, y = pretty_condition, \n#                     type = \"nonparametric\")\n\n# MAIN EFFECT OSPAN (none)\n# ggbarstats( data = df, x = accuracy, y = ospan_split, \n#                     type = \"nonparametric\")\n```\n:::\n\n\nThere is no non-parametric version of two-way ANOVA, so we perform individual CHI-SQR tests. We split the data into two groups (low memory, and high memory, based on the median split). For each, we run a CHI SQR test of independence testing the null hypothesis that Q1 ACCURACY is independent of CONDITION.  In the low-working memory group, we cannot reject the null hypothesis, suggesting that accuracy does not differ by condition. But in the HIGH working memory group we do reject the null hypothesis.  The proportion of correct responses in IMPASSE is much higher than in CONTROL, but only in the HIGH WORKING MEMORY group. \n\n\n#### LOGISTIC REGRESSION (MAIN EFFECT CONDITION)\n\nTODO:: consider weighted(centered) continuous vs ospan split\n\nFit a logistic regression predicting accuracy (absolute score) (n = 133) by condition (k = 2).\\\n\n-   Parameter estimate: $\\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition\n-   $e^{\\beta_{0}}$ = ODDS of correct response in CONTROL condition\n-   Parameter estimate: $\\beta_{1}$ = $\\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])\n-   $e^{\\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\n-   **Null hypothesis**:$\\beta_{impasse} \\le 0$ the odds for a correct response does not change, or decreases\n-   **Alternative hypothesis:** $\\beta_{impasse} \\gt 0$ the odds of a correct response increases\n\n##### Fit CONDITION Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n::: {.cell}\n\n```{.r .cell-code}\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm.0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm.C <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 2 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m.0$aic > m.C$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.0,m.C) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.C  |   glm |  2 |       1 | 3.88 | 0.049\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m.0,m.C))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0489409367734944\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m.C)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.733  -0.733  -0.477  -0.477   2.111  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.115      0.400   -5.28  1.3e-07 ***\npretty_conditionimpasse    0.936      0.492    1.90    0.057 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 118.62  on 131  degrees of freedom\nAIC: 122.6\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n##### Fit OSPAN Models\n\n#: 3 OSPAN ONLY MODEL \nm.O = glm(accuracy ~ ospan_split, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC OSPAN predictor is lower than CONDITION model?\", m.C$aic > m.O$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC OSPAN predictor is lower than CONDITION model? FALSE\"\n```\n:::\n\n```{.r .cell-code}\n#: 4 OSPAN + CONDITION model\nm.CO <- glm( accuracy ~ pretty_condition + ospan_split, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m.CO)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition + ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.870  -0.599  -0.559  -0.373   2.323  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.629      0.523   -5.03    5e-07 ***\npretty_conditionimpasse    1.002      0.499    2.01    0.045 *  \nospan_splithigh-memory     0.851      0.487    1.75    0.081 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 115.42  on 130  degrees of freedom\nAIC: 121.4\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m.CO, type=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     4.33  1      0.037 *\nospan_split          3.19  1      0.074 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#: 4 TEST SUPERIOR FIT\npaste(\"AIC wth OSPAN is lower than CONDITION only model?\", m.C$aic > m.CO$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth OSPAN is lower than CONDITION only model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.C,m.CO) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.C  |   glm |  2 |         |      |      \nm.CO |   glm |  3 |       1 | 3.19 | 0.074\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m.C,m.CO))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.0739762476630023\"\n```\n:::\n\n```{.r .cell-code}\n##Adding OSPAN as a predictor (no interaction) decreases AIC, but does not improve fit (LRT)\n\n\n#: 5 OSPAN + CONDITION INTERACTION model\nm.C.O <- glm( accuracy ~ pretty_condition * ospan_split, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m.C.O)\n# car::Anova(m.C.O, type =3)\n\n#: 5 TEST SUPERIOR FIT\npaste(\"AIC wth OSPAN IXN lower than CONDITION + OSPAN only model?\", m.CO$aic > m.C.O$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth OSPAN IXN lower than CONDITION + OSPAN only model? FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.CO,m.C.O) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.CO  |   glm |  3 |         |      |      \nm.C.O |   glm |  4 |       1 | 0.89 | 0.346\n```\n:::\n\n```{.r .cell-code}\npaste(\"AIC wth OSPAN IXN is lower than CONDITION only model?\", m.C$aic > m.C.O$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth OSPAN IXN is lower than CONDITION only model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.C,m.C.O) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.C   |   glm |  2 |         |      |      \nm.C.O |   glm |  4 |       2 | 4.08 | 0.130\n```\n:::\n:::\n\n**Adding OSPAN interaction does not improve model fit over condition-only model, or main effects only model.**\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model\nm <- m.C.O\n\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition * ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.918  -0.547  -0.500  -0.451   2.161  \n\nCoefficients:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.234      0.607   -3.68\npretty_conditionimpasse                           0.409      0.775    0.53\nospan_splithigh-memory                            0.219      0.808    0.27\npretty_conditionimpasse:ospan_splithigh-memory    0.959      1.011    0.95\n                                               Pr(>|z|)    \n(Intercept)                                     0.00024 ***\npretty_conditionimpasse                         0.59782    \nospan_splithigh-memory                          0.78656    \npretty_conditionimpasse:ospan_splithigh-memory  0.34295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 114.54  on 129  degrees of freedom\nAIC: 122.5\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nprint(\"SIGNIFIGANCE TEST\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGNIFIGANCE TEST\"\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m, type=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: accuracy\n                             LR Chisq Df Pr(>Chisq)\npretty_condition                0.284  1       0.59\nospan_split                     0.074  1       0.79\npretty_condition:ospan_split    0.887  1       0.35\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m, level = 0.90)) # get 90% for right side))\n# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval â€”- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients â€”- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients â€”- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m)), exp(confint(m)))) #exponentiated, not adjusted\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                      2.5 % 97.5 %\n(Intercept)                                    0.107 0.0256  0.302\npretty_conditionimpasse                        1.505 0.3380  7.881\nospan_splithigh-memory                         1.244 0.2528  6.786\npretty_conditionimpasse:ospan_splithigh-memory 2.610 0.3409 19.436\n```\n:::\n\n```{.r .cell-code}\n# (e <- cbind( exp(coef(m)), exp(dcint))) #exponentiated, adjusted\n\n#TODO INTERACTIONS & ESTIMATED MARGINAL MEANS \n# print(\"MODEL PREDICTIONS\")\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\n# pred.control <- predict(m,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\n# paste(\"Probability of success in control,\", pred.control)\n# pred.impasse <- predict(m,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\n# paste(\"Probability of success in impasse,\", pred.impasse)\n```\n:::\n\n##### Inference\n\nTODO double check chisqrs vs grouped_barstats. Why is the tests not the same. Otherwise report mm.C as ospan didn't improve fit\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-5.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m, type = \"eff\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-6.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/MODEL-VIS-Q1ACC-7.png){width=672}\n:::\n\n```{.r .cell-code}\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03&nbsp;&ndash;&nbsp;0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.34&nbsp;&ndash;&nbsp;7.88</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.598</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ospan split [high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.24</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.25&nbsp;&ndash;&nbsp;6.79</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.787</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse] * ospan split<br>[high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.61</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.34&nbsp;&ndash;&nbsp;19.44</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.343</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">133</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.066</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n# print(\"SANITY CHECK REPORTING\")\n# report::report(m)\n\n#print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/DIAG-MODEL-Q1ACC-1.png){width=672}\n:::\n:::\n\n\n## Q1 INTERPRETATION STATE\n\n**Do Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?**\n\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n-   **\"orthogonal\"** \\[reference category\\] includes orthogonal and satisficing responses ==\\> indicates a primarily *orthogonal* state of coordinate system understanding\n\n-   **\"other\"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular\n\n-   **\"angular\"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n-   **\"triangular\"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\\> indicates some degree of angular/triangular coordinate understanding\n\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |\n+=======================+===========================================================================================================================================================================================================================================================================================================================================================+\n| **Hypothesis**        | H1A \\| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |\n|                       | -   outcome: `state` ( 4 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |\n|                       | -   predictor: `condition` \\[between-subjects factor\\]                                                                                                                                                                                                                                                                                                    |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |\n|                       |                                                                                                                                                                                                                                                                                                                                                           |\n|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |\n|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |\n+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n#### Setup \n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q==1) %>% \n  dplyr::select(pretty_condition, ospan_split, state)\n```\n:::\n\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1STATE-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse    Sum\n  orthogonal  0.8154  0.2647 0.5338\n  other       0.0462  0.3824 0.2180\n  angular     0.0308  0.1176 0.0752\n  triangular  0.1077  0.2353 0.1729\n  Sum         1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, ,  = low-memory\n\n            \n             control impasse Sum\n  orthogonal      26      15  41\n  other            1      13  14\n  angular          1       3   4\n  triangular       3       5   8\n  Sum             31      36  67\n\n, ,  = high-memory\n\n            \n             control impasse Sum\n  orthogonal      27       3  30\n  other            2      13  15\n  angular          1       5   6\n  triangular       4      11  15\n  Sum             34      32  66\n```\n:::\n:::\n\n#### MULTINOMIAL REGRESSION\n\nTODO:: USE MBLOGIT VERSION WITH P VALUES IN MODEL\n\n*Does condition affect the response state of Q1?*\n\n*Fit a logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit CONDITION Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 184.377150 \niter  10 value 155.544397\nfinal  value 154.972366 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm.C <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 131.798993\nfinal  value 131.798569 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.C)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm.C$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm.C)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  3 |         |       |       \ncatm.C | multinom |  6 |       3 | 46.35 | < .001\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Fit OSPAN Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#FIT OSPAN only MODEL\n# print(\"OSPAN ONLY MODEL\")\ncatm.O <- multinom(state ~ ospan_split, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 152.820024\nfinal  value 152.819667 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.O) \n# car::Anova(catm.O) \nprint(\"OSPAN ONLY better than empty?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"OSPAN ONLY better than empty?\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm.O)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |     p\n-----------------------------------------------\ncatm.0 | multinom |  3 |         |      |      \ncatm.O | multinom |  6 |       3 | 4.31 | 0.230\n```\n:::\n\n```{.r .cell-code}\n#FIT OSPAN + CONDITION\n# print(\"OSPAN + CONDITION MODEL\")\ncatm.CO <- multinom(formula = state ~ pretty_condition + ospan_split, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  16 (9 variable)\ninitial  value 184.377150 \niter  10 value 128.125771\nfinal  value 128.076360 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.CO)\ncar::Anova(catm.CO) #MainEff condition, marginal ospan\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     49.5  3      1e-10 ***\nospan_split           7.4  3      0.059 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#COMPARE MODEL FIT\npaste(\"Adding OSPAN to CONDITION lowers AIC?\", catm.C$AIC > catm.CO$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Adding OSPAN to CONDITION lowers AIC? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.C, catm.CO)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\ncatm.C  | multinom |  6 |         |      |      \ncatm.CO | multinom |  9 |       3 | 7.44 | 0.059\n```\n:::\n:::\n_Adding (main effect) predictor of OSPAN decreases AIC and is a marginally better fit. In this model, there is still only a main effect of condition. OSPAN is not a significant main effect._\n\n::: {.cell}\n\n```{.r .cell-code}\n#FIT OSPAN * CONDITION\n# print(\"OSPAN * CONDITION MODEL\")\ncatm.C.O <- multinom(formula = state ~ pretty_condition * ospan_split, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  20 (12 variable)\ninitial  value 184.377150 \niter  10 value 126.168657\niter  20 value 125.962345\nfinal  value 125.962341 \nconverged\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(catm.C.O, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                             LR Chisq Df Pr(>Chisq)    \npretty_condition                16.37  3    0.00095 ***\nospan_split                      0.36  3    0.94767    \npretty_condition:ospan_split     4.23  3    0.23787    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.C.O)\n# car::Anova(catm.C.O) #MainEff condition, marginal ospan\n#COMPARE MODEL FIT\npaste(\"Adding INTERACTION lowers AIC?\", catm.CO$AIC > catm.C.O$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Adding INTERACTION lowers AIC? FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.CO, catm.C.O)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\ncatm.CO  | multinom |  9 |         |      |      \ncatm.C.O | multinom | 12 |       3 | 4.23 | 0.238\n```\n:::\n:::\n_Adding interaction of OSPAN does not improve fit and does not lower AIC. In the IXN model, only the main effect of condition is significant._\n\n::: {.cell}\n\n```{.r .cell-code}\n##compare bayesian version\n# library(brms)\n# b.cat <- brm( state ~ pretty_condition*ospan_split, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat) \n# plot(equivalence_test(b.cat))\n# plot(rope(b.cat))\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\nblm1 <- mblogit(state ~ pretty_condition *ospan_split , data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 253 - criterion = 0.272\nIteration 2 - deviance = 252 - criterion = 0.00566\nIteration 3 - deviance = 252 - criterion = 0.000157\nIteration 4 - deviance = 252 - criterion = 2.98e-07\nIteration 5 - deviance = 252 - criterion = 2.53e-12\nconverged\n```\n:::\n\n```{.r .cell-code}\nsummary(blm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmblogit(formula = state ~ pretty_condition * ospan_split, data = df)\n\nEquation for other vs orthogonal:\n                                               Estimate Std. Error z value\n(Intercept)                                      -3.258      1.019   -3.20\npretty_conditionimpasse                           3.115      1.087    2.87\nospan_splithigh-memory                            0.655      1.255    0.52\npretty_conditionimpasse:ospan_splithigh-memory    0.954      1.459    0.65\n                                               Pr(>|z|)   \n(Intercept)                                      0.0014 **\npretty_conditionimpasse                          0.0042 **\nospan_splithigh-memory                           0.6016   \npretty_conditionimpasse:ospan_splithigh-memory   0.5132   \n\nEquation for angular vs orthogonal:\n                                                  Estimate Std. Error z value\n(Intercept)                                        -3.2581     1.0190   -3.20\ntri(Intercept)                                     -2.1595     0.6097   -3.54\npretty_conditionimpasse                             1.6487     1.1994    1.37\ntripretty_conditionimpasse                          1.0609     0.7990    1.33\nospan_splithigh-memory                             -0.0377     1.4407   -0.03\ntriospan_splithigh-memory                           0.2499     0.8117    0.31\npretty_conditionimpasse:ospan_splithigh-memory      2.1580     1.7346    1.24\ntripretty_conditionimpasse:ospan_splithigh-memory   2.1480     1.1618    1.85\n                                                  Pr(>|z|)    \n(Intercept)                                         0.0014 ** \ntri(Intercept)                                      0.0004 ***\npretty_conditionimpasse                             0.1693    \ntripretty_conditionimpasse                          0.1843    \nospan_splithigh-memory                              0.9791    \ntriospan_splithigh-memory                           0.7581    \npretty_conditionimpasse:ospan_splithigh-memory      0.2135    \ntripretty_conditionimpasse:ospan_splithigh-memory   0.0645 .  \n\nEquation for triangular vs orthogonal:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.159      0.610   -3.54\npretty_conditionimpasse                           1.061      0.799    1.33\nospan_splithigh-memory                            0.250      0.812    0.31\npretty_conditionimpasse:ospan_splithigh-memory    2.148      1.162    1.85\n                                               Pr(>|z|)    \n(Intercept)                                      0.0004 ***\npretty_conditionimpasse                          0.1843    \nospan_splithigh-memory                           0.7581    \npretty_conditionimpasse:ospan_splithigh-memory   0.0645 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNull Deviance:     369 \nResidual Deviance: 252 \nNumber of Fisher Scoring iterations:  5 \nNumber of observations:  133 \n```\n:::\n\n```{.r .cell-code}\n# car::Anova(blm1) #todo need to separate by individual equation\n#identical to catm. super cool!\n```\n:::\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model\nm <- catm.C.O\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition * ospan_split, data = df, \n    model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother            -3.26                    3.11                 0.6553\nangular          -3.26                    1.65                -0.0377\ntriangular       -2.16                    1.06                 0.2500\n           pretty_conditionimpasse:ospan_splithigh-memory\nother                                               0.954\nangular                                             2.158\ntriangular                                          2.148\n\nStd. Errors:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother             1.02                   1.087                  1.255\nangular           1.02                   1.199                  1.441\ntriangular        0.61                   0.799                  0.812\n           pretty_conditionimpasse:ospan_splithigh-memory\nother                                                1.46\nangular                                              1.73\ntriangular                                           1.16\n\nResidual Deviance: 252 \nAIC: 276 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m, type =3) #always type 3 for ixns \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                             LR Chisq Df Pr(>Chisq)    \npretty_condition                16.37  3    0.00095 ***\nospan_split                      0.36  3    0.94767    \npretty_condition:ospan_split     4.23  3    0.23787    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           p..Intercept. p.pretty_conditionimpasse p.ospan_splithigh.memory\nother           0.001388                   0.00417                    0.602\nangular         0.001387                   0.16927                    0.979\ntriangular      0.000398                   0.18428                    0.758\n           p.pretty_conditionimpasse.ospan_splithigh.memory\nother                                                0.5132\nangular                                              0.2134\ntriangular                                           0.0645\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           OR..Intercept. OR.pretty_conditionimpasse OR.ospan_splithigh.memory\nother              0.0385                      22.53                     1.926\nangular            0.0385                       5.20                     0.963\ntriangular         0.1154                       2.89                     1.284\n           OR.pretty_conditionimpasse.ospan_splithigh.memory p..Intercept.\nother                                                   2.60      0.001388\nangular                                                 8.65      0.001387\ntriangular                                              8.57      0.000398\n           p.pretty_conditionimpasse p.ospan_splithigh.memory\nother                        0.00417                    0.602\nangular                      0.16927                    0.979\ntriangular                   0.18428                    0.758\n           p.pretty_conditionimpasse.ospan_splithigh.memory\nother                                                0.5132\nangular                                              0.2134\ntriangular                                           0.0645\n```\n:::\n:::\n\n##### Inference \n\nlooking at detailed p values \n\n\n... \nOTHER: only main effect of condition \nTRI-LIKE: no effects\nTRI: IXN condition * impasse\n\n\nTODO\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 45 (z = 3.81, p \\< 0.001) . **Participants in the impasse condition were 45x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 17.5 (z = 2.60, p \\< 0.001 ). **Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 4.8 (z = 3.30, p \\< 0.001 ). **Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n-   \\[need to to double check interpretation, but I *think* that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the control condition. which makes sense. I think.?\\]\n\n-   IF I change reference category for condition... then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) \\[Yup! this works!\\]\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"int\", ci.lvl = 0.95) \n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(m, type=\"eff\", ci.lvl = 0.95) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/VIS-Q1INTERPRETATION-LAB-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# +  ylim(0,1) +\n#   labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n#        subtitle = \"Impasse increases probability of more accurate response states Q1\",\n#        x = \"Condition\") + theme_clean()\n\n#TODO ESTIMAED MARGINALS AND IXN PLOTS \n# https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Response</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.01&nbsp;&ndash;&nbsp;0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.002</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">22.53</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.62&nbsp;&ndash;&nbsp;193.88</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.005</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ospan split [high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.93</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.16&nbsp;&ndash;&nbsp;23.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.603</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse] * ospan split<br>[high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.60</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.14&nbsp;&ndash;&nbsp;46.67</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.514</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">other</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.04</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.01&nbsp;&ndash;&nbsp;0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.002</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.48&nbsp;&ndash;&nbsp;55.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.172</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ospan split [high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.96</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.06&nbsp;&ndash;&nbsp;16.68</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.979</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse] * ospan split<br>[high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.28&nbsp;&ndash;&nbsp;268.24</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.216</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">angular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03&nbsp;&ndash;&nbsp;0.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.89</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.59&nbsp;&ndash;&nbsp;14.05</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.187</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ospan split [high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.28</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.26&nbsp;&ndash;&nbsp;6.40</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.759</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse] * ospan split<br>[high-memory]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.57</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.86&nbsp;&ndash;&nbsp;85.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.067</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">triangular</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">133</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.187 / 0.181</td>\n</tr>\n\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(m, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n275.925 | 310.609 | 0.187 |     0.181 | 0.354 | 1.443\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(m, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n     0.187      0.354      0.392 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\nchisq.test(df$state,predict(m)) #actual states VS predicted states\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(df$state, predict(m)): Chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  df$state and predict(m)\nX-squared = 33, df = 3, p-value = 3e-07\n```\n:::\n\n```{.r .cell-code}\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n\n\n\n## Q8 INTERPRETATION STATE\n\n\n#### Setup \n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q==8) %>% \n  dplyr::select(pretty_condition, ospan_split, state)\n```\n:::\n\n\n#### Describe \n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q8 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            \n             control impasse    Sum\n  orthogonal  0.6308  0.3971 0.5113\n  other       0.2769  0.3088 0.2932\n  angular     0.0462  0.0588 0.0526\n  triangular  0.0462  0.2353 0.1429\n  Sum         1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, ,  = low-memory\n\n            \n             control impasse Sum\n  orthogonal      19      16  35\n  other            9      15  24\n  angular          1       2   3\n  triangular       2       3   5\n  Sum             31      36  67\n\n, ,  = high-memory\n\n            \n             control impasse Sum\n  orthogonal      22      11  33\n  other            9       6  15\n  angular          2       2   4\n  triangular       1      13  14\n  Sum             34      32  66\n```\n:::\n:::\n\n#### MULTINOMIAL REGRESSION\n\nTODO:: USE MBLOGIT VERSION WITH P VALUES IN MODEL\n\n*Does condition affect the response state of Q?*\n\n\n##### Fit CONDITION Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (3 variable)\ninitial  value 184.377150 \niter  10 value 151.045297\niter  10 value 151.045297\niter  10 value 151.045296\nfinal  value 151.045296 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm.C <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 144.557718\nfinal  value 144.557713 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.C)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm.C$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm.C)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |     p\n------------------------------------------------\ncatm.0 | multinom |  3 |         |       |      \ncatm.C | multinom |  6 |       3 | 12.98 | 0.005\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n##### Fit OSPAN Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#FIT OSPAN only MODEL\n# print(\"OSPAN ONLY MODEL\")\ncatm.O <- multinom(state ~ ospan_split, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 147.680865\nfinal  value 147.680635 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.O) \n# car::Anova(catm.O) \nprint(\"OSPAN ONLY better than empty?\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"OSPAN ONLY better than empty?\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.0, catm.O)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |     p\n-----------------------------------------------\ncatm.0 | multinom |  3 |         |      |      \ncatm.O | multinom |  6 |       3 | 6.73 | 0.081\n```\n:::\n\n```{.r .cell-code}\n#FIT OSPAN + CONDITION\n# print(\"OSPAN + CONDITION MODEL\")\ncatm.CO <- multinom(formula = state ~ pretty_condition + ospan_split, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  16 (9 variable)\ninitial  value 184.377150 \niter  10 value 140.787130\nfinal  value 140.643485 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.CO)\ncar::Anova(catm.CO) #MainEff condition, marginal ospan\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)   \npretty_condition    14.07  3     0.0028 **\nospan_split          7.83  3     0.0497 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#COMPARE MODEL FIT\npaste(\"Adding OSPAN to CONDITION lowers AIC?\", catm.C$AIC > catm.CO$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Adding OSPAN to CONDITION lowers AIC? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.C, catm.CO)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\ncatm.C  | multinom |  6 |         |      |      \ncatm.CO | multinom |  9 |       3 | 7.83 | 0.050\n```\n:::\n:::\n_Adding (main effect) predictor of OSPAN decreases AIC and is a marginally better fit. In this model, there are main effects of condition and OSPAN._\n\n::: {.cell}\n\n```{.r .cell-code}\n#FIT OSPAN * CONDITION\n# print(\"OSPAN * CONDITION MODEL\")\ncatm.C.O <- multinom(formula = state ~ pretty_condition * ospan_split, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  20 (12 variable)\ninitial  value 184.377150 \niter  10 value 138.567549\niter  20 value 138.467842\niter  20 value 138.467842\niter  20 value 138.467842\nfinal  value 138.467842 \nconverged\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(catm.C.O, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                             LR Chisq Df Pr(>Chisq)\npretty_condition                 1.94  3       0.58\nospan_split                      0.76  3       0.86\npretty_condition:ospan_split     4.35  3       0.23\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.C.O)\n# car::Anova(catm.C.O) #MainEff condition, marginal ospan\n#COMPARE MODEL FIT\npaste(\"Adding INTERACTION lowers AIC?\", catm.CO$AIC > catm.C.O$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Adding INTERACTION lowers AIC? FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(catm.CO, catm.C.O)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\ncatm.CO  | multinom |  9 |         |      |      \ncatm.C.O | multinom | 12 |       3 | 4.35 | 0.226\n```\n:::\n:::\n_Adding interaction of OSPAN does not improve fit and does not lower AIC. In the IXN model, no effects are significant._ So we conclude that the main effects only model is the final model. \n\n::: {.cell}\n\n```{.r .cell-code}\n##compare bayesian version\n# library(brms)\n# b.cat <- brm( state ~ pretty_condition*ospan_split, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat) \n# plot(equivalence_test(b.cat))\n# plot(rope(b.cat))\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state ~ pretty_condition *ospan_split , data = df)\n# summary(blm1)\n# car::Anova(blm1) #todo need to separate by individual equation\n#identical to catm. super cool!\n```\n:::\n\n\n\n\n##### Describe\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model\nm <- catm.CO\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ pretty_condition + ospan_split, data = df, \n    model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother           -0.652                   0.533                 -0.352\nangular         -2.866                   0.754                  0.430\ntriangular      -3.494                   2.224                  1.297\n\nStd. Errors:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother            0.344                   0.409                  0.414\nangular          0.785                   0.809                  0.810\ntriangular       0.765                   0.689                  0.604\n\nResidual Deviance: 281 \nAIC: 299 \n```\n:::\n\n```{.r .cell-code}\ncar::Anova(m, type =2) #always type 3 for ixns \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)   \npretty_condition    14.07  3     0.0028 **\nospan_split          7.83  3     0.0497 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           p..Intercept. p.pretty_conditionimpasse p.ospan_splithigh.memory\nother         0.05779206                   0.19245                   0.3953\nangular       0.00026029                   0.35180                   0.5951\ntriangular    0.00000496                   0.00126                   0.0317\n```\n:::\n\n```{.r .cell-code}\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           OR..Intercept. OR.pretty_conditionimpasse OR.ospan_splithigh.memory\nother              0.5209                       1.70                     0.703\nangular            0.0569                       2.12                     1.538\ntriangular         0.0304                       9.24                     3.660\n           p..Intercept. p.pretty_conditionimpasse p.ospan_splithigh.memory\nother         0.05779206                   0.19245                   0.3953\nangular       0.00026029                   0.35180                   0.5951\ntriangular    0.00000496                   0.00126                   0.0317\n```\n:::\n:::\n\n##### Inference \n\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type = \"int\", ci.lvl = 0.95) \nplot_model(m, type=\"eff\", ci.lvl = 0.95) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-60-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n$ospan_split\n```\n:::\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-60-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# +  ylim(0,1) +\n#   labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n#        subtitle = \"Impasse increases probability of more accurate response states Q1\",\n#        x = \"Condition\") + theme_clean()\n\n#TODO ESTIMAED MARGINALS AND IXN PLOTS \n# https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(m, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n# DescTools::PseudoR2(m, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\nchisq.test(df$state,predict(m)) #actual states VS predicted states\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(df$state, predict(m)): Chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  df$state and predict(m)\nX-squared = 24, df = 3, p-value = 0.00002\n```\n:::\n\n```{.r .cell-code}\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations\n```\n:::\n\n\n\n\n\n## EXPLORE specific question \n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q==10)\ngrouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, grouping.var = ospan_split)\n```\n\n::: {.cell-output-display}\n![](4_sgc3A_ospan_hypotesting_files/figure-html/unnamed-chunk-63-1.png){width=672}\n:::\n:::",
    "supporting": [
      "4_sgc3A_ospan_hypotesting_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}