{
  "hash": "88f4e930ce449ae383435c06eb4beb51",
  "result": {
    "markdown": "---\nsubtitle: 'SGCX | Modelling Reference'\n---\n\n\\newpage\n\n# Modelling Reference {#modelling .unnumbered}\n\n**In this notebook we use data from study SGC3A to explore different modelling techniques and assess their suitability for the bimodal accuracy distributions in the SGC project data.**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc) # %nin% operator\nlibrary(jtools) #misc helpers \n\nlibrary(ggpubr) #arrange plots\nlibrary(cowplot) #arrange shift function plots\nlibrary(ggformula) #easy graphs\nlibrary(vcd) #mosaic plots\nlibrary(vcdExtra) #mosaic plots\nlibrary(kableExtra) #printing tables \nlibrary(sjPlot) #visualize model coefficients\nlibrary(ggeasy) #the way it should be\nlibrary(statsExpressions) #expressions to add to plots\nlibrary(ggstatsplot) #plots with expressions\nlibrary(ggdist) #uncertainty viz \nlibrary(ggeffects) #visualization log regr models\nlibrary(modelsummary) #tables\nlibrary(broom) #tidy models\nlibrary(broom.mixed) #tidy mixed and mixture models\n\n#misc utilities\nlibrary(broom)\nlibrary(modelr)\nlibrary(distributional)\nlibrary(report) #easystats reporting\nlibrary(see) #easystats visualization\nlibrary(performance) #easystats model diagnostics\nlibrary(parameters) #viz and compare models\nlibrary(equatiomatic) #extract model equation\nlibrary(pwr) #power analyses\n\n#modelling\nlibrary(rstatix) #helpful basic stats & non parametrics\nlibrary(WRS2) #robust and nonparametric tests \nlibrary(lmerTest) #for CIs in glmer \nlibrary(qqplotr) #confint on qq plot\nlibrary(gmodels) #contingency table and CHISQR\nlibrary(pscl) #zeroinfl / hurdle models \nlibrary(lme4) #mixed effects models \nlibrary(ordinal) #ordinal regression\nlibrary(MASS) # polyr ordinal regression\nlibrary(VGAM) #censored, zero infl, etc\nlibrary(brant) #brant test for ordinal regression\nlibrary(nnet) #multinomial logistic regression \nlibrary(mclogit) #multinomial logistic regression\nlibrary(bayestestR)\n\n#one package to rule them all\nlibrary(tidyverse) #ALL THE THINGS\n\n#OUTPUT OPTIONS\nlibrary(dplyr, warn.conflicts = FALSE)\noptions(dplyr.summarise.inform = FALSE)\noptions(ggplot2.summarise.inform = FALSE)\noptions(scipen=1, digits=3)\n\n#GRAPH THEMEING\ntheme_set(theme_minimal()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(mbp)\n\n#IMPORT DATA \ndf_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds')\ndf_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds')\n\n#PREP DATA \ndf_subjects <- df_subjects %>% mutate(\n  test_score = item_test_NABS,\n  raw_condition = condition,\n  condition = pretty_condition\n)\n\ndf_items <- df_items %>% mutate(\n  accuracy = as.factor(score_niceABS),\n  scaled = recode_factor(score_SCALED, \"-1\" = \"orth\", \"-0.5\"=\"unknown\",\"0\"=\"uncertain\",\"0.5\"=\"lines\",\"1\"=\"tri\"),\n  scaled = as.ordered(scaled),\n  raw_condition = condition,\n  condition = pretty_condition,\n  state = recode_factor(score_SCALED, #for ordinal\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  state = as.ordered(state)\n)\n# 3 group ordered STATE variable\n# 5 group ordered SCALED variable [matches high_interpretation]\n```\n:::\n\n\n-   test-equivalents of GLM models: https://rpubs.com/palday/glm-test\n-   models as test :https://lindeloev.github.io/tests-as-linear/\n-   GLM REFERENCE http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions\n\n# INDEPENDENT SAMPLES\n\n\n## CONTINUOUS OUTCOME\n\n**Does CONDITION have an effect on TEST PHASE ABSOLUTE SCORE?\\\n(# questions correct on test phase of task, \\[in lab\\] participants)**\n\n*(Can also be transformed to proportion or percentage).*\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::SETUP DATA\ndf = df_subjects %>% filter(mode == \"lab-synch\")\n\n#::::::::::::DESCRIPTIVES\nmosaic::favstats(test_score ~ condition, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition min Q1 median Q3 max mean   sd  n missing\n1   control   0  0      0  1   8 1.71 3.05 62       0\n2   impasse   0  0      2  7   8 3.33 3.40 64       0\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\n\n# #GGFORMULA | FACETED HISTOGRAM\n# stats = df %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS))\n# gf_props(~item_test_NABS, \n#          fill = ~pretty_condition, data = df) %>% \n#   gf_facet_grid(~pretty_condition) %>% \n#   gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n#   labs(x = \"# Correct\",\n#        y = \"proportion of subjects\",\n#        title = \"Test Phase Absolute Score (# Correct)\",\n#        subtitle = \"\") + theme(legend.position = \"blank\")\n\n##GGPUBR | HIST+DENSITY SCORE \np <- gghistogram(df, x = \"test_score\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"condition\")) +\n  labs( title = \"Distribution of TEST Absolute Score\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"Total Absolute Score (Test Phase)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-IND-TESTSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = condition, y = test_score,\n                        fill = condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=condition, y = test_score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=condition, y = test_score, color = condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of TEST Absolute Score \",\n    x = \"Condition\", y = \"Total Absolute Score (Test Phase)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-IND-TESTSCORE-2.png){width=672}\n:::\n:::\n\n### Independent Samples T-Test (Student's T)\n\n-   Tests null hypothesis that true difference in population mean is == 0\n-   Assumes normally distributed variables\n-   Assumes equal variance of samples (homogeneity of variance)\n-   **SGC accuracy data violate both homogeneity and normality**\\*\n\n::: {.cell}\n\n```{.r .cell-code}\n(t <- t.test( test_score ~ condition,data = df,\n              paired = FALSE, var.equal = TRUE, alternative = c(\"two.sided\"))) # less, greater for one sided tests\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  test_score by condition\nt = -3, df = 124, p-value = 0.006\nalternative hypothesis: true difference in means between group control and group impasse is not equal to 0\n95 percent confidence interval:\n -2.759 -0.478\nsample estimates:\nmean in group control mean in group impasse \n                 1.71                  3.33 \n```\n:::\n\n```{.r .cell-code}\nreport(t)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in .effectsize_t.test(model, type = type, verbose = verbose, ...):\nUnable to retrieve data from htest object. Using t_to_d() approximation.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Two Sample t-test testing the difference of test_score by condition (mean in group control = 1.71, mean in group impasse = 3.33) suggests that the effect is negative, statistically significant, and medium (difference = -1.62, 95% CI [-2.76, -0.48], t(124) = -2.81, p = 0.006; Cohen's d = -0.50, 95% CI [-0.86, -0.15])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#STATSPLOT | VIOLIN\n\n#one tailed tests must be done manually by extracting results expression and adding as subtitle\n#default is two tailed test\n# results <- two_sample_test( data = df, x = pretty_condition, \n#                             y = item_test_NABS,\n#                             alternative = \"g\")\n\nggbetweenstats(y = test_score, x = condition, data = df,\n               type = \"parametric\", var.equal = TRUE,\n               alternative  = \"g\",\n               pairwide.display = \"significant\", ) \n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# + labs(subtitle = results$expression[[1]])\n```\n:::\n\n### Independent Samples T-Test (Welch's T)\n\n-   Tests null hypothesis that true difference in population mean is == 0\n-   Assumes normally distributed variables\n-   **Does not** assumes equal variance of samples (homogeneity of variance)\n-   ***SGC accuracy data violates normality assumption***\n\n::: {.cell}\n\n```{.r .cell-code}\n(t <- t.test( test_score ~ condition,data = df,\n              paired = FALSE, var.equal = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  test_score by condition\nt = -3, df = 123, p-value = 0.006\nalternative hypothesis: true difference in means between group control and group impasse is not equal to 0\n95 percent confidence interval:\n -2.76 -0.48\nsample estimates:\nmean in group control mean in group impasse \n                 1.71                  3.33 \n```\n:::\n\n```{.r .cell-code}\nreport(t)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in .effectsize_t.test(model, type = type, verbose = verbose, ...):\nUnable to retrieve data from htest object. Using t_to_d() approximation.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference of test_score by condition (mean in group control = 1.71, mean in group impasse = 3.33) suggests that the effect is negative, statistically significant, and medium (difference = -1.62, 95% CI [-2.76, -0.48], t(123.25) = -2.81, p = 0.006; Cohen's d = -0.51, 95% CI [-0.86, -0.15])\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df,\n               type = \"parametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n### Yuen's T-Test (Trimmed Means)\n\n-   **Robust alternative to** to t-test is Yuen's t-test which uses trimmed means\n-   Trimmed means are not desireable for this research scenario because they trim data from the extremes, and in this study these are true, interesting values\n-   <https://garstats.wordpress.com/2017/11/28/trimmed-means/>\n\n::: {.cell}\n\n```{.r .cell-code}\n(y <- yuenbt( formula = test_score ~ condition, data = df,\n              side = TRUE, EQVAR = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nyuenbt(formula = test_score ~ condition, data = df, side = TRUE, \n    EQVAR = FALSE)\n\nTest statistic: -2.99 (df = NA), p-value = 0.00668\n\nTrimmed mean difference:  -2.53 \n95 percent confidence interval:\n-4.04     -1.02 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df,\n               type = \"robust\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n### Wilcoxon Rank Sum (Mann-Whitney Test)\n\n-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data\n-   Does not assume normality\n-   Does not assume equal variance of samples (homogeneity of variance)\n-   **Appropriate for SGC accuracy data**\n-   https://www.datanovia.com/en/lessons/wilcoxon-test-in-r/#two-sample-wilcoxon-test\n-   https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/\n\n::: {.cell}\n\n```{.r .cell-code}\n(w <- wilcox.test(df$test_score ~ df$condition,\n                 paired = FALSE, alternative = \"two.sided\")) #less, greater\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df$test_score by df$condition\nW = 1438, p-value = 0.003\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n\n```{.r .cell-code}\nreport(w)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df$test_score and df$condition suggests that the effect is negative, statistically significant, and medium (W = 1438.00, p = 0.003; r (rank biserial) = -0.28, 95% CI [-0.45, -0.08])\n```\n:::\n\n```{.r .cell-code}\n#effect size\ndf %>% wilcox_effsize(test_score ~ condition)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  .y.        group1  group2  effsize    n1    n2 magnitude\n* <chr>      <chr>   <chr>     <dbl> <int> <int> <ord>    \n1 test_score control impasse   0.263    62    64 small    \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#STATSPLOT | VIOLIN\nggbetweenstats(y = test_score, x = condition, data = df,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n### Floor/Ceiling Corrections + Wilcoxon Rank Sum\n\n-   The bimodal distribution of the subject-level score data do not meet the requirements for t-tests.\n-   However, a non-parametric alternative is available (Wilcoxon rank sum test / Man-Whitney test)\n-   Additional corrections are available for data with 'floor' and/or 'ceiling' effects via the 'DACR' package\n-   https://link.springer.com/article/10.3758/s13428-020-01407-2#Sec14 see also https://qmliu.shinyapps.io/DACFE/\n\nFor comparison we run a standard followed by a Wilcoxon rank-sum (Mann-Whitney) test that is a nonparametric alternative for non-normally distributed data.\n\n::: {.cell}\n\n```{.r .cell-code}\n(t <- wilcox.test(df$test_score ~ df$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  df$test_score by df$condition\nW = 1438, p-value = 0.003\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\nNext, we calculate the t-test and ANOVA (F-test) based on a series of corrections provided for data with floor and/or ceiling effects.\n\n-   <https://link.springer.com/article/10.3758/s13428-020-01407-2#Sec14>\n\nUsing properties from truncated normal distributions, the authors propose an easy-to-use method for the *t*-test and ANOVA with ceiling/floor data.\n\n*The proposed method calculates the degrees of freedom based on the after-truncation sample sizes (where l = number of floor observations, and r = number of ceiling observations). The rationale was that the proposed method utilizes full information only from data points of n − r − l participants and partial information from data points of r + l participants of a group for the mean and variance estimation. Specifically, the corrected mean and variance estimates (Eqs. 14 and 15) are functions of mean and variance estimates using after-truncation data (n − r − l participants) and the standardized floor and ceiling threshold estimates. The thresholds are estimated using the ceiling and floor percentage estimates based on data points of n − r and n − l participants, respectively. This is a relatively conservative approach for calculating the degrees of freedom, which can help control the type I error rate. This feature can be beneficial, especially given the \"replication crisis\" in psychological and behavioral research.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#FLOOR-CEILING ADJUSTED T TESTS\nlibrary(DACF) #tests for data with floor and ceiling \n# https://www.rdocumentation.org/packages/DACF/versions/1.0.0\n\n#prepare data [vector of scores for each group]\nscore_111 <- df %>% filter(condition == \"control\") %>% dplyr::select(test_score) %>% pull()\nscore_121 <- df %>% filter(condition == \"impasse\") %>% dplyr::select(test_score) %>% pull()\n\n# recover the mean and variance for ceiling/floor data\na <- rec.mean.var(score_111) %>% unlist()\n# recover the mean and variance for ceiling/floor data\nb <- rec.mean.var(score_121) %>% unlist()\nr <- as.data.frame(rbind(\"control\"=a ,\"impasse\"=b))\nr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        ceiling.percentage floor.percentage est.mean est.var\ncontrol              0.113            0.710    -7.70   207.4\nimpasse              0.172            0.422     2.39    51.8\n```\n:::\n\n```{.r .cell-code}\n# method \"a\" uses original sample size\n# method \"b\" uses after-truncation sample size\n\n# perform adjusted t test\nlw.t.test(score_111,score_121,\"b\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$statistic\n[1] -4.94\n\n$p.value\n[1] 0.000012\n\n$est.d\n[1] -0.887\n\n$conf.int\n[1] -14.22  -5.97\n```\n:::\n\n```{.r .cell-code}\n#FLOOR-CEILING ADJUSTED F* TEST ANOVA\nlw.f.star(df,test_score~condition,\"b\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$statistic\n[1] 5.85\n\n$p.value\n[1] 0.0321\n\n$est.f.squared\n[1] 0.158\n```\n:::\n\n```{.r .cell-code}\n# method \"a\" uses original sample size\n# method \"b\" uses after-truncation sample size\n```\n:::\n\n*The control condition has 11% of data at ceiling and 71% at floor, with corrected mean of -7 and variance of 207. The impasse condition has 17% at ceiling, and only 42% at floor, with with corrected mean of 2.39 and variance respectively as of 58.*\n\n*A corrected t-test t statistic is -4.94, p = 0.05. The estimated Cohen's d is -0.89 with a confidence interval 0f \\[-14.22, -5.97\\].*\n\n*A correct F-test (ANOVA) has a corrected F-statstic of 5.85, p \\< 0.05, and Fsquared effect size of 0.195*\n\n### Linear Regression\n\n-   Assumes homogeneity of variance\n-   Assumes normally distributed residuals\n-   when default dummy coding is used;\n    -   intercept = predicted mean of first group,\n    -   predictor coefficient = difference to mean of second group\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION\nlm.1 <- lm(test_score ~ condition, data = df)\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = test_score ~ condition, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3.33  -1.71  -1.71   3.67   6.29 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         1.710      0.411    4.16 0.000058 ***\nconditionimpasse    1.618      0.576    2.81   0.0058 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.23 on 124 degrees of freedom\nMultiple R-squared:  0.0598,\tAdjusted R-squared:  0.0522 \nF-statistic: 7.89 on 1 and 124 DF,  p-value: 0.00579\n```\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: test_score\n           Df Sum Sq Mean Sq F value Pr(>F)   \ncondition   1     82    82.5    7.89 0.0058 **\nResiduals 124   1297    10.5                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(lm.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 % 97.5 %\n(Intercept)      0.897   2.52\nconditionimpasse 0.478   2.76\n```\n:::\n\n```{.r .cell-code}\nreport(lm.1) #sanity check\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict test_score with condition (formula: test_score ~ condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.06, F(1, 124) = 7.89, p = 0.006, adj. R2 = 0.05). The model's intercept, corresponding to condition = control, is at 1.71 (95% CI [0.90, 2.52], t(124) = 4.16, p < .001). Within this model:\n\n  - The effect of condition [impasse] is statistically significant and positive (beta = 1.62, 95% CI [0.48, 2.76], t(124) = 2.81, p = 0.006; Std. beta = 0.49, 95% CI [0.14, 0.83])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\ncheck_model(lm.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MODEL ESTIMATES WITH UNCERTAINTY\n\n#setup references\nm <- lm.1\ndf <- df\ncall <- m$call %>% as.character()\n\n# uncertainty model visualization\ndf  %>%\n  modelr::data_grid(condition) %>%\n  augment(lm.1, newdata = ., se_fit = TRUE) %>%\n  ggplot(aes(y = condition, color = condition)) +\n  stat_halfeye( scale = .5,\n      aes(\n        xdist = dist_student_t(df = df.residual(m), mu = .fitted, sigma = .se.fit),\n        fill = stat(cut_cdf_qi(cdf,\n                .width = c(.90, .95),\n                labels = scales::percent_format())))) +\n  scale_fill_brewer(direction = -1) +\n  labs (title = \"(LAB) Test Phase Accuracy ~ Condition\",\n        x = \"model predicted mean (% correct)\", y = \"Condition\", fill = \"Interval\",\n        subtitle = paste(\"lm(\",call[2],\")\")\n  ) + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/PLOT-MODEL-COEFSS-GGDIST-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#sjPlot\np1 <- plot_model(lm.1,  type = \"eff\", \n           show.data = TRUE, jitter = TRUE,\n           show.p = TRUE) \n\n#BS TO MANUALLY ADD REGRESSION FORMULA AS SUBTITLE \n# library(equatiomatic)\n# library(latex2exp)\n# (x <- extract_eq(lm.1, use_coefs = TRUE, ital_vars=TRUE, coef_digits = 1, raw_tex = FALSE))\n# b = TeX(x)\n# p1[[\"condition\"]][[\"labels\"]][[\"subtitle\"]]= expression( paste(widehat(accuracy), \" = \", 1.7, \" + \", \"1.6\", \"*\", condition[impasse]) )\np1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/PLOT-MODEL-PRED-SJPLOT-1.png){width=672}\n:::\n:::\n\n### Censored (Tobit) Regression\n\n<https://stats.oarc.ucla.edu/r/dae/tobit-models/>\n\n**For censored data (i.e. truncated axis).** The tobit model, also called a censored regression model, is designed to estimate linear relationships between variables when there is either left- or right-censoring in the dependent variable (also known as censoring from below and above, respectively). Censoring from above takes place when cases with a value at or above some threshold, all take on the value of that threshold, so that the true value might be equal to the threshold, but it might also be higher. In the case of censoring from below, values those that fall at or below some threshold are censored.\n\n-   censored vs truncated : There is sometimes confusion about the difference between truncated data and censored data.\n-   With censored variables, all of the observations are in the dataset, but we don't know the \"true\" values of some of them.\n-   With truncation some of the observations are not included in the analysis because of the value of the variable.\n-   When a variable is censored, regression models for truncated data provide inconsistent estimates of the parameters. See Long (1997, chapter 7) for a more detailed discussion of problems of using regression models for truncated data to analyze censored data.\n\n::: {.cell}\n\n```{.r .cell-code}\n#set censoring values \nlo = 0\nhi = 8 \nrange(df$test_score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0 8\n```\n:::\n\n```{.r .cell-code}\nprint(\"Lo and Hi should equate to upper and lower bounds of the # Qs \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Lo and Hi should equate to upper and lower bounds of the # Qs \"\n```\n:::\n\n```{.r .cell-code}\nlibrary(VGAM)\n\n#FIT MODEL\nm1<- vglm(test_score ~ condition, tobit(Lower = lo, Upper =hi ), data = df)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nvglm(formula = test_score ~ condition, family = tobit(Lower = lo, \n    Upper = hi), data = df)\n\nCoefficients: \n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept):1      -4.185      1.483   -2.82   0.0048 ** \n(Intercept):2       2.203      0.127   17.38   <2e-16 ***\nconditionimpasse    5.577      1.982    2.81   0.0049 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: mu, loglink(sd)\n\nLog-likelihood: -196 on 249 degrees of freedom\n\nNumber of Fisher scoring iterations: 11 \n\nNo Hauck-Donner effect found in any of the estimates\n```\n:::\n\n```{.r .cell-code}\n#CONFIDENCE INTERVALS\nb <- coef(m1)\nse <- sqrt(diag(vcov(m1)))\ncbind(LL = b - qnorm(0.975) * se, UL = b + qnorm(0.975) * se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    LL    UL\n(Intercept):1    -7.09 -1.28\n(Intercept):2     1.95  2.45\nconditionimpasse  1.69  9.46\n```\n:::\n\n```{.r .cell-code}\n#TEST FIT\n#We can test the significance of condition overall by fitting an empty model and using a likelihood ratio test.\nm0 <- vglm(test_score ~ 1, tobit(Lower = lo, Upper = hi), data = df)\n(p <- pchisq(2 * (logLik(m1) - logLik(m0)), df = 2, lower.tail = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0134\n```\n:::\n\n```{.r .cell-code}\npaste(\"P value of likelihood ratio test less than alpha = 0.05? \", p <0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P value of likelihood ratio test less than alpha = 0.05?  TRUE\"\n```\n:::\n\n```{.r .cell-code}\ncompare_performance(m0,m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName | Model |     AIC | AIC weights |     BIC | BIC weights |  RMSE | Sigma\n----------------------------------------------------------------------------\nm0   |  vglm | 404.682 |       0.035 | 410.355 |       0.131 | 7.529 | 7.560\nm1   |  vglm | 398.060 |       0.965 | 406.569 |       0.869 | 7.101 | 7.144\n```\n:::\n\n```{.r .cell-code}\n#DIAGNOSTICS\nplot(m1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-17-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-17-4.png){width=672}\n:::\n\n```{.r .cell-code}\ndf$yhat <- fitted(m1)[,1]\ndf$rr <- resid(m1, type = \"response\")\ndf$rp <- resid(m1, type = \"pearson\")[,1]\n\npar(mfcol = c(2, 3))\n\nwith(df, {\n  plot(yhat, rr, main = \"Fitted vs Residuals\")\n  qqnorm(rr)\n  plot(yhat, rp, main = \"Fitted vs Pearson Residuals\")\n  qqnorm(rp)\n  plot(test_score, rp, main = \"Actual vs Pearson Residuals\")\n  plot(test_score, yhat, main = \"Actual vs Fitted\")\n})\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-17-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#VARIANCE ACCOUNTED FOR\nprint(\"VARIANCE ACCOUNTED FOR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"VARIANCE ACCOUNTED FOR\"\n```\n:::\n\n```{.r .cell-code}\n# correlation\n(r <- with(df, cor(yhat, test_score)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.245\n```\n:::\n\n```{.r .cell-code}\n# variance accounted for\nr^2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0598\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |  RMSE | Sigma\n---------------------------------\n398.060 | 406.569 | 7.101 | 7.144\n```\n:::\n\n```{.r .cell-code}\n#NOTE: censReg package also does Tobit regression [including mixed models]\n```\n:::\n\n-   The coefficient labeled \"(Intercept):1\" is the intercept or constant for the model.\n-   The coefficient labeled \"(Intercept):2\" is an ancillary statistic. If we exponentiate this value, we get a statistic that is analogous to the square root of the residual variance in OLS regression. logSigma is the variance of the model (logarithmized) (same as the second intercept in the VGAM output)\n-   The predicted value of test_phase_score is 5.75 points *higher* for students in the impasse condition than for students in the control condition. (72% improvement in score!)\n\n**Using censReg package** - https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(censReg) #censored regression\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: maxLik\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: miscTools\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nPlease cite the 'maxLik' package as:\nHenningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.\n\nIf you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:\nhttps://r-forge.r-project.org/projects/maxlik/\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nPlease cite the 'censReg' package as:\nHenningsen, Arne (2017). censReg: Censored Regression (Tobit) Models. R package version 0.5. http://CRAN.R-Project.org/package=censReg.\n\nIf you have questions, suggestions, or comments regarding the 'censReg' package, please use a forum or 'tracker' at the R-Forge site of the 'sampleSelection' project:\nhttps://r-forge.r-project.org/projects/sampleselection/\n```\n:::\n\n```{.r .cell-code}\n#FIT MODEL\nc1 <- censReg( test_score ~ condition, left=lo, right=hi, data = df )\nsummary(c1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\ncensReg(formula = test_score ~ condition, left = lo, right = hi, \n    data = df)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n           126             71             37             18 \n\nCoefficients:\n                 Estimate Std. error t value Pr(> t)    \n(Intercept)       -4.1854     1.7149  -2.441 0.01466 *  \nconditionimpasse   5.5775     1.9995   2.789 0.00528 ** \nlogSigma           2.2033     0.1424  15.471 < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNewton-Raphson maximisation, 5 iterations\nReturn code 1: gradient close to zero (gradtol)\nLog-likelihood: -196 on 3 Df\n```\n:::\n\n```{.r .cell-code}\n#CONFIDENCE INTERVALS\nb <- coef(c1)\nse <- sqrt(diag(vcov(c1)))\ncbind(LL = b - qnorm(0.975) * se, UL = b + qnorm(0.975) * se)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    LL     UL\n(Intercept)      -7.55 -0.824\nconditionimpasse  1.66  9.496\nlogSigma          1.92  2.482\n```\n:::\n\n```{.r .cell-code}\n#TEST FIT\n#We can test the significance of condition overall by fitting an empty model and using a likelihood ratio test.\n\nc0 <- censReg( test_score ~ 1, left=lo, right=hi, data = df )\n(p <- pchisq(2 * (logLik(c1) - logLik(c0)), df = 2, lower.tail = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'log Lik.' 0.0134 (df=3)\n```\n:::\n\n```{.r .cell-code}\npaste(\"P value of likelihood ratio test less than alpha = 0.05? \", p <0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P value of likelihood ratio test less than alpha = 0.05?  TRUE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(c1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in get_residuals.default(model, verbose = verbose, type = \"response\", :\nCan't extract residuals from model.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Response residuals not available to calculate mean square error. (R)MSE\n  is probably not reliable.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Models of class 'censReg' are not yet supported.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n:::\n\n-   logSigma is the variance of the model (logarithmized) (same as the second intercept in the VGAM output)\n-   output should match that of VGAM\n\n## COUNT OUTCOME\n\n**Does CONDITION have an effect on TEST PHASE ABSOLUTE SCORE?\\\n(# questions correct on test phase of task, \\[in lab\\] participants)**\n\nThe outcome variable absolute score is clearly not normal. As it represents the cumulative number of items a participant has answered correctly, we can try considering it a type of *count*, (i.e. count of the number of questions the participant got correct) and attempt to model it using a General Linear Model with the Poisson distribution (and the default log-link function). Note that the process of answering questions on a test do not seem to strictly match the assumptions of a Poisson process.\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::SETUP DATA\ndf = df_subjects %>% filter(mode == \"lab-synch\")\n\n#::::::::::::DESCRIPTIVES\nmosaic::favstats(test_score ~ condition, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition min Q1 median Q3 max mean   sd  n missing\n1   control   0  0      0  1   8 1.71 3.05 62       0\n2   impasse   0  0      2  7   8 3.33 3.40 64       0\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\n\n# #GGFORMULA | FACETED HISTOGRAM\n# stats = df %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS))\n# gf_props(~item_test_NABS, \n#          fill = ~pretty_condition, data = df) %>% \n#   gf_facet_grid(~pretty_condition) %>% \n#   gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n#   labs(x = \"# Correct\",\n#        y = \"proportion of subjects\",\n#        title = \"Test Phase Absolute Score (# Correct)\",\n#        subtitle = \"\") + theme(legend.position = \"blank\")\n\n##GGPUBR | HIST+DENSITY SCORE \np <- gghistogram(df, x = \"test_score\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"condition\")) +\n  labs( title = \"Distribution of TEST Absolute Score\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"Total Absolute Score (Test Phase)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-COUNT-TESTSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = condition, y = test_score,\n                        fill = condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=condition, y = test_score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=condition, y = test_score, color = condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of TEST Absolute Score \",\n    x = \"Condition\", y = \"Total Absolute Score (Test Phase)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-COUNT-TESTSCORE-2.png){width=672}\n:::\n:::\n\n### Poisson Regression\n\n<https://stats.oarc.ucla.edu/r/dae/poisson-regression/>\\\n*General Linear model using the Poisson distribution*\n\n::: {.cell}\n\n```{.r .cell-code}\n#SCORE predicted by CONDITION --> POISSON DISTRIBUTION\np.1 <- glm(test_score ~ condition, data = df, family = \"poisson\")\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsumm(p.1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 126 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> test_score </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> Generalized linear model </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Family </td>\n   <td style=\"text-align:right;\"> poisson </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Link </td>\n   <td style=\"text-align:right;\"> log </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> 𝛘²(1) </td>\n   <td style=\"text-align:right;\"> 33.28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-R² (Cragg-Uhler) </td>\n   <td style=\"text-align:right;\"> 0.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-R² (McFadden) </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> AIC </td>\n   <td style=\"text-align:right;\"> 764.95 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> BIC </td>\n   <td style=\"text-align:right;\"> 770.62 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> S.E. </th>\n   <th style=\"text-align:right;\"> z val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n   <td style=\"text-align:right;\"> 5.52 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> conditionimpasse </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n   <td style=\"text-align:right;\"> 0.12 </td>\n   <td style=\"text-align:right;\"> 5.60 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Standard errors: MLE</td></tr></tfoot>\n</table>\n`````\n:::\n\n```{.r .cell-code}\npaste(\"Partition Variance\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Partition Variance\"\n```\n:::\n\n```{.r .cell-code}\nanova(p.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: test_score\n\nTerms added sequentially (first to last)\n\n          Df Deviance Resid. Df Resid. Dev\nNULL                        125        604\ncondition  1     33.3       124        570\n```\n:::\n\n```{.r .cell-code}\npaste(\"Confidence Interval on Parameter Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Confidence Interval on Parameter Estimates\"\n```\n:::\n\n```{.r .cell-code}\nconfint(p.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 % 97.5 %\n(Intercept)      0.340  0.721\nconditionimpasse 0.436  0.902\n```\n:::\n\n```{.r .cell-code}\nreport(p.1) #sanity check\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a poisson model (estimated using ML) to predict test_score with condition (formula: test_score ~ condition). The model's explanatory power is moderate (Nagelkerke's R2 = 0.23). The model's intercept, corresponding to condition = control, is at 0.54 (95% CI [0.34, 0.72], p < .001). Within this model:\n\n  - The effect of condition [impasse] is statistically significant and positive (beta = 0.67, 95% CI [0.44, 0.90], p < .001; Std. beta = 0.67, 95% CI [0.44, 0.90])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\nplot_model(p.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_model(p.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n:::\n\n*The variable condition has a coefficient of 0.67, (p \\< 0.005). This means that for the impasse condition, the expected log count \\# of questions increases by 0.67. By exponentiating the estimate we see that \\# question correct rate for the impasse condition is 1.95x that of the control condition. However, model diagnostics suggest the residuals are not normally distributed.*\n\n### Negative Binomial Regression\n\n<https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/> -*overdispersed count data (variance much greater than mean)*\n\n-   similar to Poisson regression, but using the negative binomial distribution, which can better account for 'overdispersed' data where variance is much greater than the mean\n\n::: {.cell}\n\n```{.r .cell-code}\n#NEGATIVE BIONOMIAL REGRESSION\n\nlibrary(MASS)\n\n#fit model \nnb.1 <- glm.nb(test_score ~ condition, data = df)\n\n#check overdispersion need \n#assumes conditional means are not equal to conditional variances\n#conduct likelihood ration test to compare and test [need poisson]\nm.t <- glm(test_score ~ condition, family = \"poisson\", data = df)\n#pchisq(2 * (logLik(nb.1) - logLik(m.t)), df = 1, lower.tail = FALSE)\n#A large (+) log likelihood suggests that the negative binomial is more appropriate than the Poisson model\ntest_lrt(m.t, nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName |  Model | df | df_diff |   Chi2 |      p\n----------------------------------------------\nm.t  |    glm |  2 |         |        |       \nnb.1 | negbin |  3 |       1 | 277.71 | < .001\n```\n:::\n\n```{.r .cell-code}\n#EXPONENTIATE PARAMETER ESTIMATES\nest <- cbind(Estimate = coef(nb.1), confint(nb.1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n```{.r .cell-code}\n#exponentiate parameter estimates\nprint(\"Exponentiated Estimates\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Exponentiated Estimates\"\n```\n:::\n\n```{.r .cell-code}\nexp(est)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Estimate 2.5 % 97.5 %\n(Intercept)          1.71  1.07   2.89\nconditionimpasse     1.95  0.98   3.86\n```\n:::\n\n```{.r .cell-code}\nsummary(nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm.nb(formula = test_score ~ condition, data = df, init.theta = 0.2977734703, \n    link = log)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.220  -1.066  -1.066   0.447   1.067  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)  \n(Intercept)         0.536      0.252    2.13    0.033 *\nconditionimpasse    0.666      0.348    1.92    0.055 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.298) family taken to be 1)\n\n    Null deviance: 114.32  on 125  degrees of freedom\nResidual deviance: 110.70  on 124  degrees of freedom\nAIC: 489.2\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.2978 \n          Std. Err.:  0.0586 \n\n 2 x log-likelihood:  -483.2380 \n```\n:::\n\n```{.r .cell-code}\nreport(nb.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a negative-binomial model (estimated using ML) to predict test_score with condition (formula: test_score ~ condition). The model's explanatory power is weak (Nagelkerke's R2 = 0.05). The model's intercept, corresponding to condition = control, is at 0.54 (95% CI [0.07, 1.06], p = 0.033). Within this model:\n\n  - The effect of condition [impasse] is statistically non-significant and positive (beta = 0.67, 95% CI [-0.02, 1.35], p = 0.055; Std. beta = 0.67, 95% CI [-0.02, 1.35])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\nplot_model(nb.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_model(nb.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n*The variable condition has a coefficient of 0.67, (p \\< 0.005). This means that for the impasse condition, the expected log count \\# of questions increases by 0.67. By exponentiating the estimate we see that \\# question correct rate for the impasse condition is nearly 1.95x that of the control condition. However, model diagnostics suggest the residuals are not normally distributed.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#COMPARE POISSON AND NEGATIVE BINOMIAL\ncompare_performance(p.1, nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName |  Model |     AIC | AIC weights |     BIC | BIC weights | Nagelkerke's R2 |  RMSE | Sigma | Score_log | Score_spherical\n-----------------------------------------------------------------------------------------------------------------------------\np.1  |    glm | 764.945 |     < 0.001 | 770.618 |     < 0.001 |           0.234 | 3.208 | 2.145 |    -3.020 |           0.069\nnb.1 | negbin | 489.238 |        1.00 | 497.747 |        1.00 |           0.048 | 3.208 | 0.945 |    -2.213 |           0.074\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(p.1, nb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName |  Model | df | df_diff |   Chi2 |      p\n----------------------------------------------\np.1  |    glm |  2 |         |        |       \nnb.1 | negbin |  3 |       1 | 277.71 | < .001\n```\n:::\n:::\n\n*AIC, Pseudo-R2 and a likelihood ratio test indicate that the negative binomial regression model are a better fit for the distribution of test-phase scores.*\n\n## MIXTURE MODELS\n\n### Zero Inflated Poisson\n\n<https://stats.oarc.ucla.edu/r/dae/zip/>\\\n*A Poisson count process with excess zeros*\n\n-   The Zero-Inflated model allows specification of two models (a mixture) where *some* of the zeros are included in the DGP for the Poisson model, while only the 'excess' zeros are included in the DGP for the Binomial model \\[the zero-inflated part\\]\n-   The model includes:\n    -   A logistic model to model which of the two processes the zero outcome is associated with\n    -   A poisson model to model the count process\n-   Can specify different predictors for each part of the model\n-   predictors after the \\| are for the binomial zero-inflated part of the model, while those infront are for the poisson process\n\n::: {.cell}\n\n```{.r .cell-code}\n#ZERO INFLATED POISSON\n\nzinfp.1 <- zeroinfl(test_score ~  condition| condition , data = df)\nsummary(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nzeroinfl(formula = test_score ~ condition | condition, data = df)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.988 -0.575 -0.575  1.090  2.117 \n\nCount model coefficients (poisson with log link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.7702     0.0979   18.07   <2e-16 ***\nconditionimpasse  -0.0231     0.1199   -0.19     0.85    \n\nZero-inflation model coefficients (binomial with logit link):\n                 Estimate Std. Error z value Pr(>|z|)   \n(Intercept)         0.890      0.280    3.18   0.0015 **\nconditionimpasse   -1.213      0.378   -3.21   0.0013 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 7 \nLog-likelihood: -213 on 4 Df\n```\n:::\n\n```{.r .cell-code}\nreport(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a zero-inflated poisson model to predict test_score with condition (formula: test_score ~ condition). The model's explanatory power is substantial (R2 = 0.39, adj. R2 = 0.38). The model's intercept, corresponding to condition = control, is at 1.77 (95% CI [1.58, 1.96], p < .001). Within this model:\n\n  - The effect of condition [impasse] is statistically non-significant and negative (beta = -0.02, 95% CI [-0.26, 0.21], p = 0.847; Std. beta = -0.02, 95% CI [-0.26, 0.21])\n  - The effect of condition [impasse] is statistically significant and negative (beta = -1.21, 95% CI [-1.95, -0.47], p = 0.001; Std. beta = -1.21, 95% CI [-1.95, -0.47])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\n```\n:::\n\n```{.r .cell-code}\nperformance(zinfp.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n-----------------------------------------------------------------------------------\n434.837 | 446.183 | 0.391 |     0.381 | 3.208 | 3.260 |    -1.694 |           0.069\n```\n:::\n\n```{.r .cell-code}\n#check_model(zinfp.1)\n```\n:::\n\n*In the count model, the coefficient for the condition is not significant.*\n\n*In the zero-inflation model, the coefficient for the condition variable is -1.23 and statistically significant. This suggests that the log odds of being an excessive zero decrease by 1.23 if you are in the impasse condition*\n\n### Zero Inflated Negative Binomial Regression\n\n<https://stats.oarc.ucla.edu/r/dae/zinb/>\\\n*count data that are overdispersed and have excess zeros*\n\nZero-inflated negative binomial regression is for modelling count variables with excessive zeros, and especially when the count data are overdispersed (mean is much larger than variance). It can help account for situations where theory suggests that excess zeros are generated by 2 separate processes, one that includes the other count values, and the other that is just the zeros, and thus that the *excess* zeros can be modelled independently.\n\nTotal Absolute Score (# items correct) may fit this situation, as the data are overdispersed (variance much greater than the mean) and there are are very large number of zeros. It is theoretically plausible that these excess zeros (no answers correct) are the result of a different 'process' ... (i.e) little understanding and/or resistance to restructuring understanding of the coordinate system. However, I am not certain if it is plausible to suggest that the zeros themselves are the result of two different processes: (ie. perhaps trying to understand, and not trying to understand?) \\<- this could maybe be disentangled by first question latency?\n\nThe model includes:\n\n-   A logistic model to model which of the two processes the zero outcome is associated with\n-   A negative binomial model to model the count process\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl) #  for zeroinfl negbinomial\n\n#ZERO INFLATED NEGATIVE BINOMIAL\nzinb.1 <- zeroinfl(test_score ~ condition | condition , \n                   data = df, dist = \"negbin\")\n#before the | is the count part, after the | is the logit model\npaste(\"Model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Model\"\n```\n:::\n\n```{.r .cell-code}\nsummary(zinb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nzeroinfl(formula = test_score ~ condition | condition, data = df, dist = \"negbin\")\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.970 -0.568 -0.568  1.070  2.091 \n\nCount model coefficients (negbin with log link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.7689     0.1048   16.88   <2e-16 ***\nconditionimpasse  -0.0232     0.1282   -0.18    0.856    \nLog(theta)         3.7504     2.1488    1.75    0.081 .  \n\nZero-inflation model coefficients (binomial with logit link):\n                 Estimate Std. Error z value Pr(>|z|)   \n(Intercept)         0.888      0.280    3.17   0.0015 **\nconditionimpasse   -1.214      0.379   -3.21   0.0013 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta = 42.54 \nNumber of iterations in BFGS optimization: 7 \nLog-likelihood: -213 on 5 Df\n```\n:::\n\n```{.r .cell-code}\nreport(zinb.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a zero-inflated negative-binomial model to predict test_score with condition (formula: test_score ~ condition). The model's explanatory power is substantial (R2 = 0.40, adj. R2 = 0.39). The model's intercept, corresponding to condition = control, is at 1.77 (95% CI [1.56, 1.97], p < .001). Within this model:\n\n  - The effect of condition [impasse] is statistically non-significant and negative (beta = -0.02, 95% CI [-0.27, 0.23], p = 0.856; Std. beta = -0.02, 95% CI [-0.27, 0.23])\n  - The effect of condition [impasse] is statistically significant and negative (beta = -1.21, 95% CI [-1.96, -0.47], p = 0.001; Std. beta = -1.21, 95% CI [-1.96, -0.47])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset.\n```\n:::\n\n```{.r .cell-code}\nperformance(zinb.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n-----------------------------------------------------------------------------------\n436.585 | 450.766 | 0.398 |     0.388 | 3.208 | 3.274 |    -1.740 |           0.068\n```\n:::\n\n```{.r .cell-code}\n#   rootogram(zinb.1)\n\n\n\n# #EXPONENTIATE PARAMETER ESTIMATES\n# est <- cbind(Estimate = coef(zinb.1), confint(zinb.1))\n# #exponentiate parameter estimates\n# print(\"Exponentiated Estimates\")\n# exp(est)\n```\n:::\n\n*In the count model, the coefficient for the condition is very small, and not significant (suggesting it does not contribute to the count yielding process?).*\n\n*In the zero-inflation model, the coefficient for the condition variable is -1.056 and statistically significant. This suggests that the log odds of being an excessive zero decrease by 1.06 if you are in the impasse condition*\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_performance(zinfp.1, zinb.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName    |    Model |     AIC | AIC weights |     BIC | BIC weights |    R2 | R2 (adj.) |  RMSE | Sigma | Score_log | Score_spherical\n------------------------------------------------------------------------------------------------------------------------------------\nzinfp.1 | zeroinfl | 434.837 |       0.705 | 446.183 |       0.908 | 0.391 |     0.381 | 3.208 | 3.260 |    -1.694 |           0.069\nzinb.1  | zeroinfl | 436.585 |       0.295 | 450.766 |       0.092 | 0.398 |     0.388 | 3.208 | 3.274 |    -1.740 |           0.068\n```\n:::\n\n```{.r .cell-code}\ntest_likelihoodratio(zinfp.1, zinb.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nzinfp.1 | zeroinfl |  4 |         |      |      \nzinb.1  | zeroinfl |  5 |       1 | 0.25 | 0.615\n```\n:::\n:::\n\n**TODO come back to this and discuss further**\\\n\n### Hurdle Model\n\n-   <https://data.library.virginia.edu/getting-started-with-hurdle-models/>\n-   <https://en.wikipedia.org/wiki/Hurdle_model#:~:text=A%20hurdle%20model%20is%20a,of%20the%20non%2Dzero%20values.>\n\nclass of models for count data with both overdispersion and excess zeros;\\\ndifferent from zero-inflated models where the excess zeros are theorized to arise from two *different* processes; in the hurdle model, there is a separate model for P(x=0) and a separate model for P(x!=0)\n\nThe model includes:\n\n-   A binary logit model to model whether the observation takes a positive count or not. (1) Does the student get *any* questions right?\n\n-   a truncated Poisson or Negative binomial model that only fits positive counts (2) How many questions does the student get right?\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl) #zero-inf and hurdle models \nlibrary(countreg) #rootogram\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 methods overwritten by 'countreg':\n  method                 from\n  print.zeroinfl         pscl\n  print.summary.zeroinfl pscl\n  summary.zeroinfl       pscl\n  coef.zeroinfl          pscl\n  vcov.zeroinfl          pscl\n  logLik.zeroinfl        pscl\n  predict.zeroinfl       pscl\n  residuals.zeroinfl     pscl\n  fitted.zeroinfl        pscl\n  terms.zeroinfl         pscl\n  model.matrix.zeroinfl  pscl\n  extractAIC.zeroinfl    pscl\n  print.hurdle           pscl\n  print.summary.hurdle   pscl\n  summary.hurdle         pscl\n  coef.hurdle            pscl\n  vcov.hurdle            pscl\n  logLik.hurdle          pscl\n  predict.hurdle         pscl\n  residuals.hurdle       pscl\n  fitted.hurdle          pscl\n  terms.hurdle           pscl\n  model.matrix.hurdle    pscl\n  extractAIC.hurdle      pscl\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'countreg'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:VGAM':\n\n    dzipois, pzipois, qzipois, rzipois\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:pscl':\n\n    hurdle, hurdle.control, hurdletest, zeroinfl, zeroinfl.control\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcd':\n\n    rootogram\n```\n:::\n\n```{.r .cell-code}\n#install.packages(\"countreg\", repos=\"http://R-Forge.R-project.org\")\n\n#SYNTAX OUTCOME ~ count model predictor | hurdle predictor\n\nh.1 <- pscl::hurdle(test_score ~ condition | condition , data = df,\n              zero.dist = \"binomial\", dist = \"poisson\", size = 8)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = zeroDist, gr = zeroGrad, par = c(start$zero, if (zero.dist\n== : unknown names in control: size\n```\n:::\n\n```{.r .cell-code}\nh.2 <- pscl::hurdle(test_score ~ condition | condition , data = df,\n              zero.dist = \"binomial\", dist = \"negbin\", size = 8)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n\nWarning in optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist\n== : unknown names in control: size\n```\n:::\n\n```{.r .cell-code}\nsummary(h.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\npscl::hurdle(formula = test_score ~ condition | condition, data = df, \n    dist = \"poisson\", zero.dist = \"binomial\", size = 8)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.988 -0.575 -0.575  1.090  2.117 \n\nCount model coefficients (truncated poisson with log link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.7702     0.0979   18.07   <2e-16 ***\nconditionimpasse  -0.0231     0.1199   -0.19     0.85    \nZero hurdle model coefficients (binomial with logit link):\n                 Estimate Std. Error z value Pr(>|z|)   \n(Intercept)        -0.894      0.280   -3.19   0.0014 **\nconditionimpasse    1.209      0.377    3.20   0.0014 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 10 \nLog-likelihood: -213 on 4 Df\n```\n:::\n\n```{.r .cell-code}\nsummary(h.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\npscl::hurdle(formula = test_score ~ condition | condition, data = df, \n    dist = \"negbin\", zero.dist = \"binomial\", size = 8)\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-0.970 -0.568 -0.568  1.070  2.091 \n\nCount model coefficients (truncated negbin with log link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        1.7689     0.1048   16.88   <2e-16 ***\nconditionimpasse  -0.0232     0.1282   -0.18    0.856    \nLog(theta)         3.7506     2.1492    1.75    0.081 .  \nZero hurdle model coefficients (binomial with logit link):\n                 Estimate Std. Error z value Pr(>|z|)   \n(Intercept)        -0.894      0.280   -3.19   0.0014 **\nconditionimpasse    1.209      0.377    3.20   0.0014 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta: count = 42.546\nNumber of iterations in BFGS optimization: 19 \nLog-likelihood: -213 on 5 Df\n```\n:::\n\n```{.r .cell-code}\nrootogram(h.1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n```{.r .cell-code}\nrootogram(h.2)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-26-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(compare_performance(h.1,h.2))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-26-3.png){width=672}\n:::\n\n```{.r .cell-code}\ntest_lrt(h.1, h.2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName |  Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nh.1  | hurdle |  4 |         |      |      \nh.2  | hurdle |  5 |       1 | 0.25 | 0.615\n```\n:::\n:::\n\n## BETA REGRESSION\n\n### BETA Distribution\n\nBeta regression on % correct (with standard transformation for including \\[0,1\\])\n\n<https://stats.stackexchange.com/questions/63350/how-to-interpret-the-coefficients-from-a-beta-regression>\n\nhttps://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#2-fractional-logistic-regression\n\nIf a test score is conceptualized as correct (a) and b (incorrect) score = correct / (correct + incorrect) = a/ (a + b)\n\nIn the beta distribution, a and b are the shape parameters!\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(family = \"BarlowSemiCondensed-Bold\"),\n          axis.title = element_text(family = \"BarlowSemiCondensed-Medium\"),\n          strip.text = element_text(family = \"BarlowSemiCondensed-Bold\",\n                                    size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA))\n}\n\n\nggplot() +\n  geom_function(fun = dbeta, args = list(shape1 = 6, shape2 = 4),\n                aes(color = \"Beta(shape1 = 6, shape2 = 4)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")+ labs(\n    title = \"Beta a = 6, b = 4\"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dbeta, args = list(shape1 = 8, shape2 = 0.001),\n                aes(color = \"Beta(shape1 = 8, shape2 = 0.001)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"ALL CORRECT\"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-27-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dbeta, args = list(shape1 = 0.001, shape2 = 8),\n                aes(color = \"Beta(shape1 = 0.001, shape2 = 8)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"ALL WRONG\"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-27-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dbeta, args = list(shape1 = 4, shape2 = 4),\n                aes(color = \"Beta(shape1 = 4, shape2 = 4)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"FIGURED IT OUT HALFWAY \"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-27-4.png){width=672}\n:::\n:::\n\nALTERNATIVE conceptualization of a and b is as mean MU and precision PHI (same idea as variance).\n\na = mu \\* phi b = (1 - mu) \\* phi\n\nMU = a / (a+b) \\[the score\\] PHI = a + b \\[ the total \\# items \\]\n\nThe `extraDistr::dprop` function can also handle mu and phi parameters, named as mean and size\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(extraDistr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'extraDistr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:miscTools':\n\n    ddnorm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    rdunif\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:VGAM':\n\n    dfrechet, dgev, dgompertz, dgpd, dgumbel, dhuber, dkumar, dlaplace,\n    dlomax, dpareto, drayleigh, dskellam, dslash, pfrechet, pgev,\n    pgompertz, pgpd, pgumbel, phuber, pkumar, plaplace, plomax,\n    ppareto, prayleigh, pslash, qfrechet, qgev, qgompertz, qgpd,\n    qgumbel, qhuber, qkumar, qlaplace, qlomax, qpareto, qrayleigh,\n    rfrechet, rgev, rgompertz, rgpd, rgumbel, rhuber, rkumar, rlaplace,\n    rlomax, rpareto, rrayleigh, rskellam, rslash\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ordinal':\n\n    dgumbel, pgumbel, qgumbel, rgumbel\n```\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dprop, args = list(mean = 0.999, size = 8),\n                aes(color = \"Beta(mean = 0.99, size = 8)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"ALL CORRECT\"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dprop, args = list(mean = 0.001, size = 8),\n                aes(color = \"Beta(mean = 0.001, size = 8)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"ALL WRONG\"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-28-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dprop, args = list(mean = 0.5, size = 8),\n                aes(color = \"Beta(mean = 0.5, size = 8)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\") + labs(\n    \"FIGURED IT OUT HALFWAY \"\n  )\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-28-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = dbeta, args = list(shape1 = 0.001, shape2 = 1),\n                aes(color = \"Beta(shape1 = 6, shape2 = 4)\"),\n                size = 1) +\n  scale_color_viridis_d(option = \"plasma\", name = \"\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-28-4.png){width=672}\n:::\n:::\n\n**Note that in all cases, we have to slightly adjust the parameters because the distribution can't handle values at 0 or 1. So we scrunch the data in just a bit.**\n\n### BETA Regression\n\nhttps://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#2-fractional-logistic-regression\n\nThe syntax is just like all other formula-based regression functions, but with an added bit: the first part of the equation (x \\~ y) models the mean, or MU, while anything that comes after a \\| in the formula will explain variation in the precision, or PHI.\n\nThe link parameter determines the link function for the mu estimate?.\n\n#### Setup\n\n::: {.cell}\n\n```{.r .cell-code}\n# \nlibrary(betareg)\n\n#RESCLAE VARIABLE\n#beta reg can't handle 0s and 1s \nsub <- df_subjects %>% dplyr::select(condition, DV_percent_NABS)\nn = nrow(sub) %>% unlist()\nsub$dv_transformed = (sub$DV_percent_NABS * (n-1) + 0.5)/n\n \n#VISUALIZE VARIABLES\npaste(\"Slightly squished data\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Slightly squished data\"\n```\n:::\n\n```{.r .cell-code}\nhistogram(sub$dv_transformed)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#FIT MODEL\nmb1 <- betareg(dv_transformed ~ condition | condition, \n              data = sub)\n\nsummary(mb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nbetareg(formula = dv_transformed ~ condition | condition, data = sub)\n\nStandardized weighted residuals 2:\n   Min     1Q Median     3Q    Max \n-1.065 -0.450 -0.217  0.537  1.678 \n\nCoefficients (mean model with logit link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        -0.961      0.119   -8.06  7.6e-16 ***\nconditionimpasse    0.545      0.158    3.44  0.00057 ***\n\nPhi coefficients (precision model with log link):\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)       -0.4273     0.1001   -4.27    2e-05 ***\nconditionimpasse   0.0212     0.1307    0.16     0.87    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  506 on 4 Df\nPseudo R-squared: 0.0725\nNumber of iterations: 16 (BFGS) + 2 (Fisher scoring) \n```\n:::\n\n```{.r .cell-code}\nplot(mb1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-29-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-29-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-29-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-29-5.png){width=672}\n:::\n:::\n\n-   Which link function should be used for each? We now have two sets of coefficients, one set for each parameter (the mean and precision). The parameters for the mean are measured on the logit scale, just like with logistic regression previously, and we can calculate the marginal effect of having a quota by using plogis() and piecing together the coefficient and the intercept:\n\n#### Interpret\n\n::: {.cell}\n\n```{.r .cell-code}\nbeta_mu_intercept <- mb1 %>% \n  tidy() %>% \n  filter(component == \"mean\", term == \"(Intercept)\") %>% \n  pull(estimate)\n\nbeta_mu_condition <- mb1 %>% \n  tidy() %>% \n  filter(component == \"mean\", term == \"conditionimpasse\") %>% \n  pull(estimate)\n\n\nprint(\"Coefficients —- PROBABILITIES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- PROBABILITIES\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"[these should math pred plots]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"[these should math pred plots]\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Probability at reference level\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability at reference level\"\n```\n:::\n\n```{.r .cell-code}\nplogis(beta_mu_intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.277\n```\n:::\n\n```{.r .cell-code}\nprint(\"Probability at coefficient level\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability at coefficient level\"\n```\n:::\n\n```{.r .cell-code}\nplogis(beta_mu_intercept + beta_mu_condition)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.397\n```\n:::\n\n```{.r .cell-code}\nprint(\"CHANGE in probability by coefficient\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"CHANGE in probability by coefficient\"\n```\n:::\n\n```{.r .cell-code}\nplogis(beta_mu_intercept + beta_mu_condition) - plogis(beta_mu_intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.121\n```\n:::\n\n```{.r .cell-code}\nplot_model(mb1, type = \"pred\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\nImpasse increases the average of the distribution of accuracy by 12% percentage points, on average. This should match the value we get with fractional regression. (logistic regression with count variable instead of binomial)\n\n-   The intercept of MU indicates the average of the distribution of score proportion in the control condition\n-   The coefficient of MU indicates the change in the average distribution of score proportion in the impasse condition\n\nThe PHI parameter estimates are not measured on a logit scale. Instead, they're log values. We can invert them by exponentiating them with exp(). - The phi intercept indicates the precision of the distribution of score proportion in the control condition - The phi coefficient indicates the change in the precision of the distribution of score proportion in the impasse condition\n\n-   CONDITION is a significant predictor of MEAN (location) but not PHI (precision). Put another way, the shape of both distributions is similar, but the impasse condition distribution is shift to the right (higher) than the control distribution.\n\n\n\n#### Compare\n\n::: {.cell}\n\n```{.r .cell-code}\n# COMPARE MODELS\n\n\n#PREP DATA \ndf <- df_subjects %>% filter(mode == \"lab-synch\")\nn = nrow(df) %>% unlist()\ndf <- df %>%  mutate(\n    accuracy = item_test_NABS/8,\n    test_trans = (accuracy * (n-1) + 0.5)/n,\n    all_trans = (DV_percent_NABS * (n-1) + 0.5)/n\n  )\n\n# LINEAR REGRESSION\nlm1 <- lm( test_trans ~ pretty_condition    , data = df)\n# summary(lm1)\n\n# LINEAR REGRESSION on LOGTRANSFORMED\nqlm1 <- lm( qlogis(test_trans) ~ pretty_condition    , data = df)\n# summary(qlm1)\n\n# FRACTIONAL REGRESSION\n#uses quasibinomial [like binomial] on proportion \n#instead of binomial data. coeffs on logit scale\nflm1 <- glm( test_trans ~ pretty_condition, data = df, family = quasibinomial())\nsummary(flm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = test_trans ~ pretty_condition, family = quasibinomial(), \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.014  -0.667  -0.667   0.949   1.733  \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               -1.289      0.274   -4.71  6.6e-06 ***\npretty_conditionimpasse    0.953      0.354    2.69   0.0082 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 0.788)\n\n    Null deviance: 117.11  on 125  degrees of freedom\nResidual deviance: 111.18  on 124  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# BETA REGRESSION predictor phi\nbm1 <- betareg(test_trans ~ pretty_condition | pretty_condition, \n              data = df, link = \"logit\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, control):\nno valid starting value for precision parameter found, using 1 instead\n```\n:::\n\n```{.r .cell-code}\nsummary(bm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nbetareg(formula = test_trans ~ pretty_condition | pretty_condition, data = df, \n    link = \"logit\")\n\nStandardized weighted residuals 2:\n   Min     1Q Median     3Q    Max \n-0.867 -0.397 -0.397  0.619  1.525 \n\nCoefficients (mean model with logit link):\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -0.851      0.186   -4.58  4.7e-06 ***\npretty_conditionimpasse    0.530      0.252    2.10    0.036 *  \n\nPhi coefficients (precision model with log link):\n                        Estimate Std. Error z value Pr(>|z|)   \n(Intercept)              -0.4319     0.1545   -2.80   0.0052 **\npretty_conditionimpasse  -0.0629     0.2052   -0.31   0.7593   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nType of estimator: ML (maximum likelihood)\nLog-likelihood:  183 on 4 Df\nPseudo R-squared: 0.0608\nNumber of iterations: 17 (BFGS) + 2 (Fisher scoring) \n```\n:::\n\n```{.r .cell-code}\nmodels = list(\"LM\" = lm1, \n              \"LM log transform\" = qlm1, \n              \"GLM Quasibinomial\" = flm1, \n              \"beta\" = bm1)\nmodelsummary(models)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> LM </th>\n   <th style=\"text-align:center;\"> LM log transform </th>\n   <th style=\"text-align:center;\"> GLM Quasibinomial </th>\n   <th style=\"text-align:center;\"> beta </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 0.216 </td>\n   <td style=\"text-align:center;\"> −3.241 </td>\n   <td style=\"text-align:center;\"> −1.289 </td>\n   <td style=\"text-align:center;\"> −0.851 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.051) </td>\n   <td style=\"text-align:center;\"> (0.518) </td>\n   <td style=\"text-align:center;\"> (0.274) </td>\n   <td style=\"text-align:center;\"> (0.186) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pretty_conditionimpasse </td>\n   <td style=\"text-align:center;\"> 0.201 </td>\n   <td style=\"text-align:center;\"> 2.059 </td>\n   <td style=\"text-align:center;\"> 0.953 </td>\n   <td style=\"text-align:center;\"> 0.530 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.071) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.727) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.354) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> (0.252) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 126 </td>\n   <td style=\"text-align:center;\"> 126 </td>\n   <td style=\"text-align:center;\"> 126 </td>\n   <td style=\"text-align:center;\"> 126 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 </td>\n   <td style=\"text-align:center;\"> 0.060 </td>\n   <td style=\"text-align:center;\"> 0.061 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.061 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Adj. </td>\n   <td style=\"text-align:center;\"> 0.052 </td>\n   <td style=\"text-align:center;\"> 0.053 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 131.3 </td>\n   <td style=\"text-align:center;\"> 715.9 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −357.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 139.8 </td>\n   <td style=\"text-align:center;\"> 724.4 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −345.7 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Log.Lik. </td>\n   <td style=\"text-align:center;\"> −62.653 </td>\n   <td style=\"text-align:center;\"> −354.946 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> F </td>\n   <td style=\"text-align:center;\"> 7.887 </td>\n   <td style=\"text-align:center;\"> 8.022 </td>\n   <td style=\"text-align:center;\"> 7.225 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 0.40 </td>\n   <td style=\"text-align:center;\"> 4.05 </td>\n   <td style=\"text-align:center;\"> 0.40 </td>\n   <td style=\"text-align:center;\"> 0.40 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#GET ESTIMATES\nmodel_beta <- bm1\n\nbeta_mu_intercept <- model_beta %>% \n  tidy() %>% \n  filter(component == \"mean\", term == \"(Intercept)\") %>% \n  pull(estimate)\n\nbeta_mu_condition <- model_beta %>% \n  tidy() %>% \n  filter(component == \"mean\", term == \"pretty_conditionimpasse\") %>% \n  pull(estimate)\n\nbeta_phi_intercept <- model_beta %>% \n  tidy() %>% \n  filter(component == \"precision\", term == \"(Intercept)\") %>% \n  pull(estimate)\n\nbeta_phi_condition <- model_beta %>% \n  tidy() %>% \n  filter(component == \"precision\", term == \"pretty_conditionimpasse\") %>% \n  pull(estimate)\n\n\nmu_control = plogis(beta_mu_intercept)\nphi_control = plogis(beta_phi_intercept)\n#when you don’t explicitly model the precision, the resulting coefficient in the table isn’t on the log scale—it’s a regular non-logged number, so there’s no need to exponentiate\n\n#PLOT ESTIMATES\n\ncontrol_title <- paste0(\"dprop(mean = plogis(\", round(beta_mu_intercept, 2),\n                         \"), size = exp(\", round(beta_phi_intercept, 2), \"))\")\n\nimpasse_title <- paste0(\"dprop(mean = plogis(\", round(beta_mu_intercept, 2),\n                      \" + \", round(beta_mu_condition, 2), \n                      \"), size = exp(\", round(beta_phi_intercept, 2),\n                      \" + \", round(beta_phi_condition, 2), \"))\")\n\nggplot(data = tibble(x = 0:1), aes(x = x)) +\n  stat_function(fun = dprop, size = 1,\n                args = list(size = exp(beta_phi_intercept), \n                            mean = plogis(beta_mu_intercept)),\n                aes(color = control_title)) + \n  stat_function(fun = dprop, size = 1,\n                args = list(size = exp(beta_phi_intercept + beta_phi_condition), \n                            mean = plogis(beta_mu_intercept + beta_mu_condition)),\n                aes(color = impasse_title)) +\n  geom_density(data = df, \n               aes(x = test_trans, fill = pretty_condition), \n               alpha = 0.5, color = NA) +\n  labs(x = \"Beta Regression Predictions\") +\n  theme_clean() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\nWe can also convert the parameter estimates back to A and B. for the impasse condition, MU = 0.397 SIZE = 0.666\n\na = mu \\* phi = 0.397 \\* 0.66 = 0.264 b = (1 - mu) \\* phi = (1 - 0.397) \\* 0.666 = 0.402\n\nwe should expect it to look more like ... (for 50% ) a = correct = 3 b = incorrect = 10 a + b = total = 13\n\nMU = a / (a+b) \\[the score\\] = 3 / 13 = 0.23 PHI = a + b \\[ the total \\# items \\] = 13\n\nmu = 0.277 = a / (a + b) phi = 0.395 = a + b let b = 13\n\n::: {.cell}\n\n```{.r .cell-code}\n#RECOVER A AND B FROM MU AND PHI\nmuphi_to_shapes <- function(mu, phi) {\n  shape1 <- mu * phi\n  shape2 <- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\nshapes_to_muphi <- function(shape1, shape2) {\n  mu <- shape1 / (shape1 + shape2)\n  phi <- shape1 + shape2\n  return(list(mu = mu, phi = phi))\n}\n\npaste(\"model predicts control A and B \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"model predicts control A and B \"\n```\n:::\n\n```{.r .cell-code}\nmuphi_to_shapes(mu_control, phi_control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$shape1\n[1] 0.118\n\n$shape2\n[1] 0.276\n```\n:::\n\n```{.r .cell-code}\npaste(\"should be something like \")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"should be something like \"\n```\n:::\n\n```{.r .cell-code}\nshapes_to_muphi(5,13)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$mu\n[1] 0.278\n\n$phi\n[1] 18\n```\n:::\n:::\n\nIt seems like the although the (shrinkled) beta regression model is working, it is really messing up the estimate of the PHI parameter, such that we can't even recover the A and B. I expect whole numbers, and instead I'm geting values less than 1. I think this might be because the phi value is so low (note that phi = precision, so like inverse of variance. Lower values are more less precise (more variance)). Since I have so many values near 0 and near 1 (even though I've shrunk the estimates to be in the open interval (0,1) rather than \\[0,1\\], I think it causing problems with the estimation. )\n\n#### bayesian version\nhttps://www.bayesrulesbook.com/\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Rcpp\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading 'brms' package (version 2.17.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'brms'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:extraDistr':\n\n    ddirichlet, dfrechet, pfrechet, qfrechet, rdirichlet, rfrechet\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:VGAM':\n\n    acat, cratio, cumulative, dfrechet, dirichlet, exponential,\n    frechet, geometric, lognormal, multinomial, negbinomial, pfrechet,\n    qfrechet, rfrechet, s, sratio\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ordinal':\n\n    ranef, VarCorr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    ngrps\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ggdist':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:survival':\n\n    kidney\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    ar\n```\n:::\n\n```{.r .cell-code}\nmodel_beta_bayes <- brm(\n  bf(test_trans ~ pretty_condition,\n     phi ~ pretty_condition),\n  data = df,\n  family = Beta(),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  # Use the cmdstanr backend for Stan because it's faster and more modern than\n  # the default rstan You need to install the cmdstanr package first\n  # (https://mc-stan.org/cmdstanr/) and then run cmdstanr::install_cmdstan() to\n  # install cmdstan on your computer.\n  backend = \"cmdstanr\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 0.5 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_beta_bayes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: beta \n  Links: mu = logit; phi = log \nFormula: test_trans ~ pretty_condition \n         phi ~ pretty_condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                      -0.85      0.19    -1.22    -0.47 1.00     2740\nphi_Intercept                  -0.45      0.16    -0.77    -0.16 1.00     2846\npretty_conditionimpasse         0.53      0.25     0.02     1.01 1.00     3056\nphi_pretty_conditionimpasse    -0.06      0.20    -0.45     0.34 1.00     3452\n                            Tail_ESS\nIntercept                       2893\nphi_Intercept                   2889\npretty_conditionimpasse         3205\nphi_pretty_conditionimpasse     2805\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\npaste(\"Cool! parameters are almost identical to betareg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Cool! parameters are almost identical to betareg\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidybayes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'tidybayes'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:bayestestR':\n\n    hdi\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:parameters':\n\n    parameters\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:distributional':\n\n    parameters\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:gnm':\n\n    parameters\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ggridges':\n\n    scale_point_color_continuous, scale_point_color_discrete,\n    scale_point_colour_continuous, scale_point_colour_discrete,\n    scale_point_fill_continuous, scale_point_fill_discrete,\n    scale_point_size_continuous\n```\n:::\n\n```{.r .cell-code}\nposterior_beta <- model_beta_bayes %>% \n  gather_draws(`b_.*`, regex = TRUE) %>% \n  mutate(component = ifelse(str_detect(.variable, \"phi_\"), \"Precision\", \"Mean\"),\n         intercept = str_detect(.variable, \"Intercept\"))\n\nggplot(posterior_beta, aes(x = .value, y = fct_rev(.variable), fill = component)) +\n  geom_vline(xintercept = 0) +\n  stat_halfeye(aes(slab_alpha = intercept), \n               .width = c(0.8, 0.95), point_interval = \"median_hdi\") +\n  scale_fill_viridis_d(option = \"viridis\", end = 0.6) +\n  scale_slab_alpha_discrete(range = c(1, 0.4)) +\n  guides(fill = \"none\", slab_alpha = \"none\") +\n  labs(x = \"Coefficient\", y = \"Variable\",\n       caption = \"80% and 95% credible intervals shown in black; RAW COEFF\") +\n  facet_wrap(vars(component), ncol = 1, scales = \"free_y\") +\n  theme_clean()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n\n```{.r .cell-code}\n##GET USEFUL ESTIMATES\npaste(\"TRANSFORMED ESTIMATES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"TRANSFORMED ESTIMATES\"\n```\n:::\n\n```{.r .cell-code}\nmodel_beta_bayes %>% \n  spread_draws(`b_.*`, regex = TRUE) %>% \n  mutate(across(starts_with(\"b_phi\"), ~exp(.))) %>%\n  mutate(across((!starts_with(\".\") & !starts_with(\"b_phi\")), ~plogis(.))) %>%\n  gather_variables() %>% \n  median_hdi()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 7\n  .variable                     .value .lower .upper .width .point .interval\n  <chr>                          <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1 b_Intercept                    0.300  0.223  0.377   0.95 median hdi      \n2 b_phi_Intercept                0.643  0.451  0.843   0.95 median hdi      \n3 b_phi_pretty_conditionimpasse  0.944  0.613  1.36    0.95 median hdi      \n4 b_pretty_conditionimpasse      0.628  0.511  0.737   0.95 median hdi      \n```\n:::\n\n```{.r .cell-code}\n# now phi is a raw value indicating precision\n# now mu is an odds ratio for median? of the distribution\n```\n:::\n\n#### Bayesian predictions\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plug a dataset where quota is FALSE and TRUE into the model\nbeta_bayes_pred <- model_beta_bayes %>% \n  epred_draws(newdata = tibble(pretty_condition = c(\"control\", \"impasse\")))\n\nggplot(beta_bayes_pred, \n       aes(x = .epred, y = pretty_condition, fill = pretty_condition)) +\n  stat_halfeye(.width = c(0.8, 0.95), point_interval = \"median_hdi\") +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.8) +\n  guides(fill = \"none\") +\n  labs(x = \"Predicted Comprehension Task Score Percentage Correct\", y = NULL,\n       caption = \"80% and 95% credible intervals shown in black\") +\n  theme_clean()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\n#TODO POSTERIOR PREDICTIVE CHECKS \n\n# describe_posterior(model_beta_bayes, test = c(\"p_direction\", \"rope\", \"bayesfactor\"))\n\n# library(rstanarm)\n# pp_check(model_beta_bayes, plotfun = \"boxplot\", nreps = 10, notch = FALSE)\n# pp_check(model_beta_bayes, plotfun = \"stat_grouped\", stat = \"median\", group = \"pretty_condition\")\n```\n:::\n### ZERO INFLATED BETA \n\n1. logistic regression for zero inflated $\\alpha$ (logit scale)\n2. beta regression for proportion $\\mu$ (logit scale) and $\\phi$ (log scale)\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_subjects %>% dplyr::select(pretty_condition, DV_percent_NABS) %>% \n  mutate(\n    condition = pretty_condition,\n    accuracy = DV_percent_NABS\n  )\n#shrink accuracy just a tiny bit from 1 for testing purposes \nlibrary(tidyfst)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nLife's short, use R.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'tidyfst'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    between, cummean, nth\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:scales':\n\n    percent\n```\n:::\n\n```{.r .cell-code}\ndf <- df %>% mutate_when(accuracy == 1, accuracy = 0.99)\n\n#INTERCEPT ONLY model for alpha\nzinb <- brm(\n  bf(accuracy ~ condition, #mean of (0,1) values, mu\n     phi ~ condition, #precision of (0,1) values, phi\n     zi ~ condition), #zero inflated is extreme? alpha\n  data = df,\n  family = zero_inflated_beta(),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/zinb.rds\"\n)\n```\n:::\n::: {.cell}\n\n```{.r .cell-code}\nsummary(zinb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: zero_inflated_beta \n  Links: mu = logit; phi = log; zi = logit \nFormula: accuracy ~ condition \n         phi ~ condition\n         zi ~ condition\n   Data: df (Number of observations: 330) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                0.18      0.16    -0.14     0.51 1.00     4388\nphi_Intercept            0.04      0.15    -0.26     0.32 1.00     4447\nzi_Intercept             0.52      0.16     0.21     0.86 1.00     5364\nconditionimpasse         0.04      0.20    -0.36     0.43 1.00     4433\nphi_conditionimpasse     0.17      0.18    -0.17     0.53 1.00     4856\nzi_conditionimpasse     -1.36      0.24    -1.83    -0.90 1.00     4822\n                     Tail_ESS\nIntercept                2768\nphi_Intercept            3118\nzi_Intercept             3269\nconditionimpasse         3138\nphi_conditionimpasse     3267\nzi_conditionimpasse      2933\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nperformance(zinb)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Response residuals not available to calculate mean square error. (R)MSE\n  is probably not reliable.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nELPD     | ELPD_SE |   LOOIC | LOOIC_SE |    WAIC |    R2 |  RMSE | Sigma\n-------------------------------------------------------------------------\n-185.435 |   9.411 | 370.869 |   18.823 | 370.856 | 0.058 | 0.368 | 1.000\n```\n:::\n\n```{.r .cell-code}\n# plot(rope(zinb))\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(zinb, effects = \"fixed\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in tidy.brmsfit(zinb, effects = \"fixed\"): some parameter names contain\nunderscores: term naming may be unreliable!\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  effect component term                 estimate std.error conf.low conf.high\n  <chr>  <chr>     <chr>                   <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed  cond      (Intercept)            0.182      0.164   -0.142     0.506\n2 fixed  cond      phi_(Intercept)        0.0379     0.146   -0.256     0.317\n3 fixed  zi        (Intercept)            0.524      0.165    0.208     0.858\n4 fixed  cond      conditionimpasse       0.0375     0.202   -0.356     0.427\n5 fixed  cond      phi_conditionimpasse   0.173      0.178   -0.169     0.528\n6 fixed  zi        conditionimpasse      -1.36       0.236   -1.83     -0.899\n```\n:::\n\n```{.r .cell-code}\npaste(\"INTERPRET ALPHA\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"INTERPRET ALPHA\"\n```\n:::\n\n```{.r .cell-code}\nzi_intercept <- tidy(zinb, effects = \"fixed\") %>% \n  filter(component == \"zi\", term == \"(Intercept)\") %>% \n  pull(estimate)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in tidy.brmsfit(zinb, effects = \"fixed\"): some parameter names contain\nunderscores: term naming may be unreliable!\n```\n:::\n\n```{.r .cell-code}\n# Logit scale intercept\nzi_intercept\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb_zi_Intercept \n         0.524 \n```\n:::\n\n```{.r .cell-code}\n## b_zi_Intercept \n##          0.525\n\n# Transformed to a probability/proportion\nplogis(zi_intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb_zi_Intercept \n         0.628 \n```\n:::\n\n```{.r .cell-code}\n## b_zi_Intercept \n##         0.628\n\nnrow(df %>% filter(accuracy == 0 & condition == \"control\"))/nrow(df %>% filter(condition == \"control\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.627\n```\n:::\n:::\nThe value of the z_intercept should be the same as the proportion of 0s in the control condition. \n\nVISUALIZE ZERO INFLATED COMPONENT\n::: {.cell}\n\n```{.r .cell-code}\nbeta_zi_pred_int <- zinb %>% \n  predicted_draws(newdata = tibble(condition = c(\"control\", \"impasse\"))) %>% \n  mutate(is_zero = .prediction == 0,\n         .prediction = ifelse(is_zero, .prediction - 0.01, .prediction))\n\nggplot(beta_zi_pred_int, aes(x = .prediction)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 0.025, \n                 boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.5,\n                       guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Predicted proportion of Correct Responses\", \n       y = \"Count\", fill = \"Is zero?\") +\n  facet_wrap(vars(condition), ncol = 2,\n             labeller = labeller(condition = c(`control` = \"Control\", \n                                           `impasse` = \"Impasse\"))) + \n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n### ZERO-ONE INFLATED BETA Regression\n\nhttps://sometimesir.com/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/#zoib-regression\nhttps://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#2-fractional-logistic-regression\n\n**TODO** \n- explore priors\n- explore random effects\n- explore non-beta distribution; once the 1s and zeros are gone, do we need the beta? \n\nA zero-inflated beta regression allows us to model a separate data generating process for the 0s and 1s and the rest.\n\nA ZOINB is a mixture of:\n\n1.  A logistic regression model that predicts if an outcome is either 0 or 1 or not 0 or 1, defined by (or alternatively, a model that predicts if outcomes are extreme (0 or 1) or not (between 0 and 1); \"IS EXTREME\" model; defined by $\\alpha$\n\n2.  A logistic regression model that predicts if any of the 0 or 1 outcomes are actually 1s, defined by (or alternatively, a model that predicts if the extreme values are 1) \"WHICH EXTREME\" model defined by $\\gamma$\n\n3.  A beta regression model that predicts if an outcome is between 0 and 1 if it's not zero or not one, defined by and (or alternatively, a model that predicts the non-extreme (0 or 1) values) \"THE REST\" model $\\mu$ and $\\phi$\n\nCan also do mixed! (but no reason do this here, as the item level data is not beta reg )\n\n::: {.cell}\n\n```{.r .cell-code}\n#DATA SETUP\n# sub <- df_subjects %>% dplyr::select(condition, DV_percent_NABS) \n# don't need to transform anymore\ndf <- df_subjects %>% filter(mode == \"lab-synch\") %>% \n  mutate(\n    condition = pretty_condition,\n    scaled = (s_SCALED + 13)/26,  #transform scaled onto 0-1 scale\n    accuracy = item_test_NABS/8\n  ) %>% dplyr::select(condition, scaled, accuracy)\n\n\n#INTERCEPT ONLY model for alpha\nzoinb <- brm(\n  bf(accuracy ~ condition, #mean of (0,1) values, mu\n     phi ~ condition, #precision of (0,1) values, phi\n     zoi ~ condition, #is extreme? alpha\n     coi ~ condition), #is 1? gamma\n  data = df,\n  family = zero_one_inflated_beta(),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/zoinb.rds\"\n)\n\n\nzoinb_scaled <- brm(\n  bf(scaled ~ condition, #mean of (0,1) values, mu\n     phi ~ condition, #precision of (0,1) values, phi\n     zoi ~ condition, #is extreme? alpha\n     coi ~ condition), #is 1? gamma\n  data = df,\n  family = zero_one_inflated_beta(),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/zoinb_scaled.rds\"\n)\n```\n:::\n::: {.cell}\n\n```{.r .cell-code}\nsummary(zoinb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: zero_one_inflated_beta \n  Links: mu = logit; phi = log; zoi = logit; coi = logit \nFormula: accuracy ~ condition \n         phi ~ condition\n         zoi ~ condition\n         coi ~ condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                0.18      0.34    -0.50     0.83 1.00     4686\nphi_Intercept            0.64      0.37    -0.14     1.30 1.00     5921\nzoi_Intercept            1.54      0.33     0.90     2.21 1.00     6065\ncoi_Intercept           -1.86      0.42    -2.72    -1.10 1.00     6592\nconditionimpasse         0.15      0.40    -0.61     0.94 1.00     4866\nphi_conditionimpasse     0.28      0.44    -0.57     1.16 1.00     6320\nzoi_conditionimpasse    -1.18      0.43    -2.02    -0.36 1.00     5970\ncoi_conditionimpasse     0.98      0.55    -0.10     2.06 1.00     7590\n                     Tail_ESS\nIntercept                3068\nphi_Intercept            3140\nzoi_Intercept            3053\ncoi_Intercept            3007\nconditionimpasse         3428\nphi_conditionimpasse     3219\nzoi_conditionimpasse     3058\ncoi_conditionimpasse     2865\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nplot(rope(zoinb))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_phi_conditionimpasse and b_phi_Intercept (r = 0.83), b_zoi_conditionimpasse and b_zoi_Intercept (r = 0.8), b_coi_conditionimpasse and b_coi_Intercept (r = 0.76). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(zoinb)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-44-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(rope(zoinb_scaled))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_phi_conditionimpasse and b_phi_Intercept (r = 0.81). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-44-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(zoinb_scaled)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-44-4.png){width=672}\n:::\n:::\n\nMore plots \n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(zoinb, effects = \"fixed\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in tidy.brmsfit(zoinb, effects = \"fixed\"): some parameter names contain\nunderscores: term naming may be unreliable!\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 7\n  effect component term                 estimate std.error conf.low conf.high\n  <chr>  <chr>     <chr>                   <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed  cond      (Intercept)             0.184     0.337   -0.495     0.826\n2 fixed  cond      phi_(Intercept)         0.636     0.366   -0.143     1.30 \n3 fixed  cond      zoi_(Intercept)         1.54      0.332    0.904     2.21 \n4 fixed  cond      coi_(Intercept)        -1.86      0.418   -2.72     -1.10 \n5 fixed  cond      conditionimpasse        0.153     0.397   -0.609     0.940\n6 fixed  cond      phi_conditionimpasse    0.281     0.441   -0.573     1.16 \n7 fixed  cond      zoi_conditionimpasse   -1.18      0.425   -2.02     -0.358\n8 fixed  cond      coi_conditionimpasse    0.976     0.553   -0.103     2.06 \n```\n:::\n\n```{.r .cell-code}\npaste(\"INTERPRET ALPHA\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"INTERPRET ALPHA\"\n```\n:::\n\n```{.r .cell-code}\nzoi_intercept <- tidy(zoinb, effects = \"fixed\") %>% \n  filter(component == \"cond\", term == \"zoi_(Intercept)\") %>% \n  pull(estimate)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in tidy.brmsfit(zoinb, effects = \"fixed\"): some parameter names contain\nunderscores: term naming may be unreliable!\n```\n:::\n\n```{.r .cell-code}\n# Logit scale intercept\nzoi_intercept\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb_zoi_Intercept \n           1.54 \n```\n:::\n\n```{.r .cell-code}\n# Transformed to a probability/proportion\nplogis(zoi_intercept)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb_zoi_Intercept \n          0.824 \n```\n:::\n\n```{.r .cell-code}\nnrow(df %>% filter(accuracy %in% c(0,1) & condition == \"control\"))/nrow(df %>% filter(condition == \"control\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.823\n```\n:::\n:::\nThe value of the zoi_intercept should be the same as the proportion of 0s and 1s (vs non 0s and 1s) in the control condition... and it does!\n\nVISUALIZE ZERO INFLATED COMPONENT\n::: {.cell}\n\n```{.r .cell-code}\nbeta_zoi_pred_int <- zoinb %>% \n  predicted_draws(newdata = tibble(condition = c(\"control\", \"impasse\"))) %>% \n  mutate(is_extreme = .prediction %in% c(0,1),\n         is_one = .prediction ==1, \n         .prediction = ifelse(is_extreme & !is_one, .prediction - 0.01, .prediction),\n         .prediction = ifelse(is_one, .prediction + 0.01, .prediction))\n\nggplot(beta_zoi_pred_int, aes(x = .prediction)) +\n  geom_histogram(aes(fill = is_extreme), binwidth = 0.05, \n                 boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) +\n  geom_vline(xintercept = 1) +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.5,\n                       guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Predicted proportion of Correct Responses\", \n       y = \"Count\", fill = \"Is extreme?\") +\n  facet_wrap(vars(condition), ncol = 2,\n             labeller = labeller(condition = c(`control` = \"Control\", \n                                           `impasse` = \"Impasse\"))) + \n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\nbeta_zoi_pred_int <- zoinb_scaled %>% \n  predicted_draws(newdata = tibble(condition = c(\"control\", \"impasse\"))) %>% \n  mutate(is_extreme = .prediction %in% c(0,1),\n         is_one = .prediction ==1, \n         .prediction = ifelse(is_extreme & !is_one, .prediction - 0.01, .prediction),\n         .prediction = ifelse(is_one, .prediction + 0.01, .prediction))\n\nggplot(beta_zoi_pred_int, aes(x = .prediction)) +\n  geom_histogram(aes(fill = is_extreme), binwidth = 0.05, \n                 boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) +\n  geom_vline(xintercept = 1) +\n  scale_fill_viridis_d(option = \"plasma\", end = 0.5,\n                       guide = guide_legend(reverse = TRUE)) +\n  labs(x = \"Predicted proportion of Correct Responses\", \n       y = \"Count\", fill = \"Is extreme?\") +\n  facet_wrap(vars(condition), ncol = 2,\n             labeller = labeller(condition = c(`control` = \"Control\", \n                                           `impasse` = \"Impasse\"))) + \n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(zoinb, draws = 8000 )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The following arguments were unrecognized and ignored: draws\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n### HURDLE + NEG BINOM (bayesian)\n\nRather than transform score to a proportion correct, keep it in native count form, and model as negative binomial. \nhurdle model : \n\n(1) A logistic regression model that predicts if an outcome is 0 or not (this is the hurdle part)\n(2) A lognormal (hurdle_lognormal()), gamma (hurdle_gamma()), Poisson (hurdle_poisson()), or negative binomial (hurdle_negbinomial()) model for outcomes that are not zero\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA \ndf <- df_subjects %>% filter(mode == \"lab-synch\") %>% \n  mutate(\n    score = item_test_NABS,\n    condition = pretty_condition\n  )\n\n#PLOT\ngf_histogram(~score, fill = ~ condition, data = df) %>% gf_facet_wrap(~condition)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#FIT MODEL\nhln <- brm(\n  bf(score ~ condition,\n     hu ~ condition),\n  data = df,\n  family = hurdle_lognormal(),\n  chains = 4, iter = 2000, warmup = 1000, seed = 1234,\n  silent = 2, cores = 4, \n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/hln.rds\"\n)\n\nhnb <- brm(\n  bf(score ~ condition,\n     hu ~ condition),\n  data = df,\n  family = hurdle_negbinomial(),\n  chains = 4, iter = 2000, warmup = 1000, seed = 1234,\n  silent = 2, cores = 4, \n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/hnb.rds\"\n)\n\nhpoi <- brm(\n  bf(score ~ condition,\n     hu ~ condition),\n  data = df,\n  family = hurdle_poisson(),\n  chains = 4, iter = 2000, warmup = 1000, seed = 1234,\n  silent = 2, cores = 4, \n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/hpoi.rds\"\n)\n\n\nsummary(hln)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: hurdle_lognormal \n  Links: mu = identity; sigma = identity; hu = logit \nFormula: score ~ condition \n         hu ~ condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept               1.56      0.17     1.23     1.90 1.00     4165     2973\nhu_Intercept            0.90      0.28     0.38     1.46 1.00     3768     2802\nconditionimpasse        0.02      0.21    -0.39     0.42 1.00     4336     3019\nhu_conditionimpasse    -1.23      0.38    -1.99    -0.48 1.00     4061     2334\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.73      0.07     0.61     0.88 1.00     4271     2950\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nsummary(hnb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: hurdle_negbinomial \n  Links: mu = log; shape = identity; hu = logit \nFormula: score ~ condition \n         hu ~ condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept               1.76      0.11     1.54     1.97 1.00     3785     2780\nhu_Intercept            0.90      0.29     0.34     1.49 1.00     4271     2678\nconditionimpasse       -0.02      0.14    -0.29     0.25 1.00     3901     2831\nhu_conditionimpasse    -1.23      0.38    -2.00    -0.48 1.00     4206     2768\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape    42.90     51.27     5.69   184.18 1.00     3524     2681\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nsummary(hpoi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: hurdle_poisson \n  Links: mu = log; hu = logit \nFormula: score ~ condition \n         hu ~ condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept               1.76      0.10     1.57     1.95 1.00     3312     2732\nhu_Intercept            0.91      0.28     0.37     1.49 1.00     3524     2752\nconditionimpasse       -0.02      0.12    -0.25     0.22 1.00     3995     3309\nhu_conditionimpasse    -1.24      0.38    -2.00    -0.53 1.00     4350     3112\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nplot_model(hln)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(hnb)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(hpoi)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-4.png){width=672}\n:::\n\n```{.r .cell-code}\ncompare_performance(hln, hnb, hpoi)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome of the nested models seem to be identical\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Type 'pearson' is deprecated and will be removed in the future.\n\nWarning: Type 'pearson' is deprecated and will be removed in the future.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName |   Model |     ELPD | ELPD_SE |   LOOIC | LOOIC weights | LOOIC_SE |    WAIC | WAIC weights |    R2 |  RMSE | Sigma\n-------------------------------------------------------------------------------------------------------------------------\nhln  | brmsfit | -231.964 |  17.047 | 463.928 |       < 0.001 |   34.094 | 463.888 |      < 0.001 | 0.078 | 3.224 | 0.660\nhnb  | brmsfit | -218.127 |  15.993 | 436.255 |         0.256 |   31.987 | 436.257 |        0.393 | 0.061 | 3.208 | 1.000\nhpoi | brmsfit | -217.708 |  16.373 | 435.416 |         0.744 |   32.746 | 435.383 |        0.607 | 0.060 | 3.208 | 1.000\n```\n:::\n\n```{.r .cell-code}\n# Exponential\np1 <- pp_check(hpoi) + labs(title=\"Poisson Hurdle\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n:::\n\n```{.r .cell-code}\np2 <- pp_check(hnb) + labs(title=\"NegBinom Hurdle\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n:::\n\n```{.r .cell-code}\np3 <- pp_check(hln) + labs(title=\"LogNorm Hurdle\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n:::\n\n```{.r .cell-code}\ncowplot::plot_grid( p1 + p2 + p3)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# Logged\npred <- posterior_predict(hpoi)\nbayesplot::ppc_dens_overlay(y = log1p(df$score), \n                            yrep = log1p(pred[1:10,])) + \n  labs(title = \"Posterior Predictive Checks\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-49-6.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\npred_gdp_hurdle <- hpoi |> \n  predicted_draws(newdata = tibble(condition = c(\"control\",\"impasse\"))) |>\n  mutate(is_zero = .prediction == 0,\n         .prediction = ifelse(is_zero, .prediction - 0.1, .prediction))\n\nggplot(pred_gdp_hurdle, aes(x = .prediction)) +\n  geom_histogram(aes(fill = is_zero), binwidth = 1, \n                 boundary = 0, color = \"white\") +\n  geom_vline(xintercept = 0) +\n  labs(x = \"test phase correct\", y = \"Count\", fill = \"Is zero?\",\n       title = \"Predicted number correct from hurdle model\") +\n  # coord_cartesian(xlim = c(-2500, 75000)) +\n  theme_nice() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\nThis model is making predictions outside the bounds of the data (beyond 8)\n**TODO**\nhttps://jsdajournal.springeropen.com/articles/10.1186/s40488-021-00121-4\nconsider motivation of hurdle vs zero inflated \n\n### MIXED ZERO-ONE-INFLATED BETA Regression\n\nNext we'll explore doing a beta regression on a proportion transformed scaled score at the item level, as a zero one inflated mixed beta reg \n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(mode == \"lab-synch\") %>% \n  filter(q %nin% c(6,9)) %>% \n  mutate(scaled = (score_SCALED + 1)/2,\n         condition = pretty_condition) %>% \n  dplyr::select(subject, scaled, condition)\n\n\nzoinb_scaled <- brm(\n  bf(scaled ~ condition + (1|subject) , #mean of (0,1) values, mu\n     phi ~ condition , #precision of (0,1) values, phi\n     zoi ~ condition , #is extreme? alpha\n     coi ~ condition ), #is 1? gamma\n  data = df,\n  family = zero_one_inflated_beta(),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file =\"analysis/utils/models/zoinb_scaled_2.rds\"\n)\n\nsummary(zoinb_scaled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: zero_one_inflated_beta \n  Links: mu = logit; phi = log; zoi = logit; coi = logit \nFormula: scaled ~ condition + (1 | subject) \n         phi ~ condition\n         zoi ~ condition\n         coi ~ condition\n   Data: df (Number of observations: 1638) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~subject (Number of levels: 126) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.21      0.09     0.02     0.38 1.01      686      999\n\nPopulation-Level Effects: \n                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept               -0.56      0.10    -0.75    -0.37 1.00     3621\nphi_Intercept            2.09      0.18     1.74     2.43 1.00     3764\nzoi_Intercept            2.41      0.13     2.17     2.66 1.00     4732\ncoi_Intercept           -1.16      0.09    -1.33    -0.99 1.00     6594\nconditionimpasse         0.25      0.12     0.02     0.47 1.00     3722\nphi_conditionimpasse    -0.09      0.20    -0.49     0.30 1.00     4326\nzoi_conditionimpasse    -1.20      0.15    -1.50    -0.92 1.00     5779\ncoi_conditionimpasse     1.46      0.12     1.23     1.69 1.00     6619\n                     Tail_ESS\nIntercept                2831\nphi_Intercept            3016\nzoi_Intercept            2525\ncoi_Intercept            2578\nconditionimpasse         2872\nphi_conditionimpasse     3305\nzoi_conditionimpasse     3425\ncoi_conditionimpasse     2759\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nplot_model(zoinb_scaled)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\n### BETA HURDLE Regression (Frequentist)\n\n<https://github.com/markhwhiteii/beta_hurdle/blob/master/manuscript/beta_hurdle.pdf>\n\n-   MU tells if mean is different by condition\n-   SIGMA tells if variance is different by condition\n-   NU coefficient tells if condition yields different probability at floor\n-   TAU coefficient tells if condition yields different probability at ceiling\n\n::: {.cell}\n\n```{.r .cell-code}\n#BETA HURDLE REGRESSION EXAMPLE\nlibrary(gamlss)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: gamlss.data\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'gamlss.data'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:datasets':\n\n    sleep\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: gamlss.dist\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: nlme\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'nlme'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    collapse\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:ordinal':\n\n    ranef, VarCorr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    lmList\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: parallel\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n **********   GAMLSS Version 5.4-3  ********** \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nFor more on GAMLSS look at https://www.gamlss.com/\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nType gamlssNews() to see new features/changes/bug fixes.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'gamlss'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:brms':\n\n    cs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:extraDistr':\n\n    pcat\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    refit\n```\n:::\n\n```{.r .cell-code}\n#CREATE SAMPLE DATA \nn <- 5000 \nmu <- 0.40 \nsigma <- 0.60 \np0 <- 0.13 \np1 <- 0.17 \np2 <- 1- p0- p1\na <- mu * (1- sigma ^ 2) / (sigma ^ 2) \nb <- a * (1- mu) / mu\n\n#CREATE DIST\nset.seed(1839) \ny <- rbeta(n, a, b) \ncat <- sample(1:3, n, prob = c(p0, p2, p1), replace = TRUE) \ny[cat == 1] <- 0 \ny[cat == 3] <- 1\n\n#VISUALIZE DISTRIBUTION\nx <- as.data.frame(y)\ngf_histogram(~x$y)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#this looks not unlike my distribution! \n\n#CREATE AN EMPTY MODEL\nfit <- gamlss( formula = y ~ 1, # formula for mu \n               formula.sigma = ~ 1, # formula for sigma \n               formula.nu = ~ 1, # formula for nu \n               formula.tau = ~ 1, # formula for tau \n               family = BEINF() )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = 7799 \nGAMLSS-RS iteration 2: Global Deviance = 7778 \nGAMLSS-RS iteration 3: Global Deviance = 7778 \nGAMLSS-RS iteration 4: Global Deviance = 7778 \n```\n:::\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"BEINF\", \"Beta Inflated\") \n\nCall:  gamlss(formula = y ~ 1, family = BEINF(), formula.sigma = ~1,  \n    formula.nu = ~1, formula.tau = ~1) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.3796     0.0196   -19.4   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.3951     0.0162    24.5   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNu link function:  log \nNu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -1.632      0.042   -38.9   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nTau link function:  log \nTau Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -1.4014     0.0382   -36.7   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  5000 \nDegrees of Freedom for the fit:  4\n      Residual Deg. of Freedom:  4996 \n                      at cycle:  4 \n \nGlobal Deviance:     7778 \n            AIC:     7786 \n            SBC:     7812 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\nplot(fit)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-52-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\n\t Summary of the Randomised Quantile Residuals\n                           mean   =  0.000571 \n                       variance   =  1 \n               coef. of skewness  =  0.0294 \n               coef. of kurtosis  =  2.95 \nFilliben correlation coefficient  =  1 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\n#TRANSFORM PARAMETRS BACK \ninv_logit <- function(x) exp(x) / (1 + exp(x)) # inverse of link function\nfit_mu <- inv_logit(fit$mu.coefficients) \npaste(\"MU: \",fit_mu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MU:  0.406229902102452\"\n```\n:::\n\n```{.r .cell-code}\nfit_sigma <- inv_logit(fit$sigma.coefficients) \npaste(\"SIGMA: \",fit_sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGMA:  0.597499259410111\"\n```\n:::\n\n```{.r .cell-code}\nfit_nu <- exp(fit$nu.coefficients) \nfit_tau <- exp(fit$tau.coefficients) \nfit_p0 <- fit_nu / (1 + fit_nu + fit_tau) \npaste(\"P0: \",fit_p0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P0:  0.135600165493784\"\n```\n:::\n\n```{.r .cell-code}\nfit_p1 <- fit_tau / (1 + fit_nu + fit_tau)\npaste(\"P1: \",fit_p1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P1:  0.170800000002391\"\n```\n:::\n:::\n\n**BETA HURDLE INTERPRETATION** - beta component\\\n- MU \"location\" (mean)\\\n- SIGMA \"scale\" (positively related to variance; variance = sigma.squared *mean* (1-mean)\\\n- Rigby, Stasinopoulos, Heller, and De Bastiani (2017) \"reparameterized\" the beta distribution so that the two parameters determining the shape of the distribution would be more useful in a regression framework (see Ferrari & Cribari-Neto, 2004 for a different parameterization)\n\n**ZERO-ONE HURDLE COMPONENT**\\\n- The two additional parameters, ν NU and τTAU , are related to p0 and p1, respectively.\\\n- p0 is the probability that a case equals 0,\\\n- p1 is the probability that a case equals 1,\\\n- p2 (i.e., 1 −p0 −p1) is the probability that the case comes from the beta distribution\n\n::: {.cell}\n\n```{.r .cell-code}\n#MY DATA\n#SETUP DATA \n\nmin = 0 #min possible value of scale\nmax = 13 #max possible value of scale\n\nlibrary(mosaic) #for shuffling\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mosaic'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:brms':\n\n    mm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    cross\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:VGAM':\n\n    chisq, logit\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lmerTest':\n\n    rand\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lme4':\n\n    factorize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:Matrix':\n\n    mean\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:rstatix':\n\n    cor_test, prop_test, t_test\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:modelr':\n\n    resample\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:modelsummary':\n\n    msummary\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:vcd':\n\n    mplot\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:scales':\n\n    rescale\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:cowplot':\n\n    theme_map\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggplot2':\n\n    stat\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n```\n:::\n\n```{.r .cell-code}\n#1. Rescale accuracy using \n# recommended adjustment \n#rescaled = value-min/(max-min)\ndf <- df_subjects %>% mutate(\n  accuracy = s_NABS,\n  R_acc = (accuracy-min)/(max-min), #as %\n  T_acc = (accuracy * (nrow(df)-1) + 0.5)/nrow(df)/max, #transform for no 0 and 1\n  # perm = shuffle(condition),\n  scaffold_rt = item_scaffold_rt\n) %>% dplyr::select(accuracy,R_acc, T_acc, condition,scaffold_rt)\n\n#VISUALIZE DISTRIBUTION\ngf_histogram(~R_acc, fill = ~condition, data = df) %>% gf_facet_wrap(~condition) + labs(title = \"Histogram of accuracy\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#VISUALIZE DISTRIBUTION\ngf_histogram(~T_acc, fill = ~condition, data = df) %>% gf_facet_wrap(~condition) + labs(title = \"Histogram of [rescaled] accuracy\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-53-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# gf_histogram(~R_acc, fill = ~perm, data = df) %>% gf_facet_wrap(~perm) + labs(title = \"Histogram of shuffled accuracy\")\n\n#SUMMARIZE SAMPLE\npaste(\"Grand mean\", mean(df$R_acc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Grand mean 0.288344988344988\"\n```\n:::\n\n```{.r .cell-code}\nlibrary(mosaic)\nstats = favstats(df$R_acc ~ df$condition)\nstats$mean <- mean(df$R_acc ~ df$condition)\nstats$var <- var(df$R_acc ~ df$condition)\nprint(\"Grand stats\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Grand stats\"\n```\n:::\n\n```{.r .cell-code}\nstats \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  df$condition min Q1 median    Q3 max  mean    sd   n missing   var\n1      control   0  0  0.000 0.154   1 0.190 0.343 158       0 0.118\n2      impasse   0  0  0.154 0.788   1 0.379 0.395 172       0 0.156\n```\n:::\n\n```{.r .cell-code}\nprint(\"P0\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P0\"\n```\n:::\n\n```{.r .cell-code}\nnrow(df %>% filter(R_acc ==0))/nrow(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.458\n```\n:::\n\n```{.r .cell-code}\nprint(\"P1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P1\"\n```\n:::\n\n```{.r .cell-code}\nnrow(df %>% filter(R_acc ==1))/nrow(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0939\n```\n:::\n\n```{.r .cell-code}\n#CREATE MODEL\n\n#CREATE AN EMPTY MODEL\nm0 <- gamlss( formula = R_acc ~ 1, # formula for mu \n              formula.sigma =  ~ 1, # formula for sigma \n              formula.nu =  ~ 1, # formula for nu \n              formula.tau =  ~ 1, # formula for tau \n              family = BEINF(), data = df )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = 611 \nGAMLSS-RS iteration 2: Global Deviance = 610 \nGAMLSS-RS iteration 3: Global Deviance = 610 \nGAMLSS-RS iteration 4: Global Deviance = 610 \n```\n:::\n\n```{.r .cell-code}\nm0 <- gamlss(R_acc ~ 1, ~ 1, ~ 1, ~ 1, \n            data = df, family = BEINF())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = 611 \nGAMLSS-RS iteration 2: Global Deviance = 610 \nGAMLSS-RS iteration 3: Global Deviance = 610 \nGAMLSS-RS iteration 4: Global Deviance = 610 \n```\n:::\n\n```{.r .cell-code}\npaste(\"THE EMPTY MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"THE EMPTY MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"BEINF\", \"Beta Inflated\") \n\nCall:  gamlss(formula = R_acc ~ 1, sigma.formula = ~1, nu.formula = ~1,  \n    tau.formula = ~1, family = BEINF(), data = df) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -0.2304     0.0947   -2.43    0.015 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.4262     0.0775     5.5  7.7e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNu link function:  log \nNu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.0201     0.1157    0.17     0.86\n\n------------------------------------------------------------------\nTau link function:  log \nTau Coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -1.563      0.198   -7.91  3.9e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  330 \nDegrees of Freedom for the fit:  4\n      Residual Deg. of Freedom:  326 \n                      at cycle:  4 \n \nGlobal Deviance:     610 \n            AIC:     618 \n            SBC:     634 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\nplot(m0)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-53-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\n\t Summary of the Randomised Quantile Residuals\n                           mean   =  -0.00445 \n                       variance   =  1.03 \n               coef. of skewness  =  0.0264 \n               coef. of kurtosis  =  3.03 \nFilliben correlation coefficient  =  0.996 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\n#TRANSFORM PARAMETRS BACK \ninv_logit <- function(x) exp(x) / (1 + exp(x)) # inverse of link function\nm0_mu <- inv_logit(m0$mu.coefficients) \npaste(\"MU: \",m0_mu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MU:  0.442655135079248\"\n```\n:::\n\n```{.r .cell-code}\nm0_sigma <- inv_logit(m0$sigma.coefficients) \npaste(\"SIGMA: \",m0_sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGMA:  0.604970105601303\"\n```\n:::\n\n```{.r .cell-code}\nm0_nu <- exp(m0$nu.coefficients) \npaste(\"NU: \",m0_nu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"NU:  1.02032203257766\"\n```\n:::\n\n```{.r .cell-code}\nm0_tau <- exp(m0$tau.coefficients) \npaste(\"TAU: \",m0_tau)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"TAU:  0.209464832192797\"\n```\n:::\n\n```{.r .cell-code}\nm0_p0 <- fit_nu / (1 + fit_nu + fit_tau) \npaste(\"P0: \",m0_p0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P0:  0.135600165493784\"\n```\n:::\n\n```{.r .cell-code}\nm0_p1 <- fit_tau / (1 + fit_nu + fit_tau)\npaste(\"P1: \",m0_p1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"P1:  0.170800000002391\"\n```\n:::\n\n```{.r .cell-code}\n#CREATE PREDICTOR MODEL\nm1 <- gamlss(R_acc ~ condition, \n             ~ condition, \n             ~ condition, \n             ~ condition, \n            data = df, family = BEINF())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = 573 \nGAMLSS-RS iteration 2: Global Deviance = 572 \nGAMLSS-RS iteration 3: Global Deviance = 572 \nGAMLSS-RS iteration 4: Global Deviance = 572 \n```\n:::\n\n```{.r .cell-code}\npaste(\"THE PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"THE PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"BEINF\", \"Beta Inflated\") \n\nCall:  gamlss(formula = R_acc ~ condition, sigma.formula = ~condition,  \n    nu.formula = ~condition, tau.formula = ~condition,  \n    family = BEINF(), data = df) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)  \n(Intercept)        -0.421      0.171   -2.46    0.014 *\nconditionimpasse    0.274      0.205    1.33    0.183  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)   \n(Intercept)        0.3949     0.1407    2.81   0.0053 **\nconditionimpasse   0.0309     0.1687    0.18   0.8549   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNu link function:  log \nNu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.767      0.178    4.30  2.3e-05 ***\nconditionimpasse   -1.440      0.247   -5.84  1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nTau link function:  log \nTau Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        -1.264      0.314   -4.02 0.000072 ***\nconditionimpasse   -0.471      0.405   -1.16     0.25    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  330 \nDegrees of Freedom for the fit:  8\n      Residual Deg. of Freedom:  322 \n                      at cycle:  4 \n \nGlobal Deviance:     572 \n            AIC:     588 \n            SBC:     618 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\n#LOOKING PREDICTOR MODEL\nm <- gamlss(R_acc ~ condition , \n            ~ condition , \n            ~ condition , \n            ~ condition , \n            data = df, family = BEINF())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = 573 \nGAMLSS-RS iteration 2: Global Deviance = 572 \nGAMLSS-RS iteration 3: Global Deviance = 572 \nGAMLSS-RS iteration 4: Global Deviance = 572 \n```\n:::\n\n```{.r .cell-code}\npaste(\"THE PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"THE PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"BEINF\", \"Beta Inflated\") \n\nCall:  gamlss(formula = R_acc ~ condition, sigma.formula = ~condition,  \n    nu.formula = ~condition, tau.formula = ~condition,  \n    family = BEINF(), data = df) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)  \n(Intercept)        -0.421      0.171   -2.46    0.014 *\nconditionimpasse    0.274      0.205    1.33    0.183  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)   \n(Intercept)        0.3949     0.1407    2.81   0.0053 **\nconditionimpasse   0.0309     0.1687    0.18   0.8549   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNu link function:  log \nNu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.767      0.178    4.30  2.3e-05 ***\nconditionimpasse   -1.440      0.247   -5.84  1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nTau link function:  log \nTau Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        -1.264      0.314   -4.02 0.000072 ***\nconditionimpasse   -0.471      0.405   -1.16     0.25    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  330 \nDegrees of Freedom for the fit:  8\n      Residual Deg. of Freedom:  322 \n                      at cycle:  4 \n \nGlobal Deviance:     572 \n            AIC:     588 \n            SBC:     618 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\n#CREATE PREDICTOR MODEL ON SHUFFLED [PERMUTATION TEST]\n# mperm <- gamlss(R_acc ~ perm, ~ perm, ~ perm, ~ perm, \n#             data = df, family = BEINF())\n# summary(mperm)\n\n#sanity check with scaled outcome, no zeros ones\n# m3 <- gamlss(T_acc ~ condition, ~ condition, ~ condition, ~ condition, \n#             data = df, family = BEINF())\n# summary(m3)\n#m3 shouldn't show condition as significant for nu and tau, because T_acc was scaled to not include any 0s and 1s\n\n#investigate beta negative binomial distribution\n#https://en.wikipedia.org/wiki/Beta_negative_binomial_distribution\n\n#TRANSFORM PARAMETRS BACK \ninv_logit <- function(x) exp(x) / (1 + exp(x)) # inverse of link function\nm1_mu <- inv_logit(m1$mu.coefficients) \npaste(\"MU: \",m1_mu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MU:  0.396369901111619\" \"MU:  0.568036956954873\"\n```\n:::\n\n```{.r .cell-code}\nm1_sigma <- inv_logit(m0$sigma.coefficients) \npaste(\"SIGMA: \",m1_sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SIGMA:  0.604970105601303\"\n```\n:::\n\n```{.r .cell-code}\nm1_nu <- exp(m1$nu.coefficients) \npaste(\"NU: \",m1_nu)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"NU:  2.15227350452983\"  \"NU:  0.236870904856183\"\n```\n:::\n\n```{.r .cell-code}\nm1_tau <- exp(m1$tau.coefficients) \npaste(\"TAU: \",m1_tau)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"TAU:  0.282617628302748\" \"TAU:  0.624417570712948\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"BEINF\", \"Beta Inflated\") \n\nCall:  gamlss(formula = R_acc ~ condition, sigma.formula = ~condition,  \n    nu.formula = ~condition, tau.formula = ~condition,  \n    family = BEINF(), data = df) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)  \n(Intercept)        -0.421      0.171   -2.46    0.014 *\nconditionimpasse    0.274      0.205    1.33    0.183  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)   \n(Intercept)        0.3949     0.1407    2.81   0.0053 **\nconditionimpasse   0.0309     0.1687    0.18   0.8549   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNu link function:  log \nNu Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.767      0.178    4.30  2.3e-05 ***\nconditionimpasse   -1.440      0.247   -5.84  1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nTau link function:  log \nTau Coefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        -1.264      0.314   -4.02 0.000072 ***\nconditionimpasse   -0.471      0.405   -1.16     0.25    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  330 \nDegrees of Freedom for the fit:  8\n      Residual Deg. of Freedom:  322 \n                      at cycle:  4 \n \nGlobal Deviance:     572 \n            AIC:     588 \n            SBC:     618 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\nplot(m)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-53-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\n\t Summary of the Randomised Quantile Residuals\n                           mean   =  0.0127 \n                       variance   =  0.938 \n               coef. of skewness  =  0.11 \n               coef. of kurtosis  =  2.76 \nFilliben correlation coefficient  =  0.997 \n******************************************************************\n```\n:::\n:::\n\n-   MU tells if mean is different by condition\n-   SIGMA tells if variance is different by condition\n-   NU coefficient tells if condition yields different probability at floor\n-   TAU coefficient tells if condition yields different probability at ceiling\n\n## BINOMIAL OUTCOME\n\n::: {.cell}\n\n```{.r .cell-code}\n#PREPARE DATA \ndf <- df_items %>% filter(q ==1) %>% filter(mode == \"lab-synch\")\n# %>% mutate(\n#   accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n#   scaled = as.ordered(score_SCALED),\n#   q = as.factor(q),\n#   high_interpretation = as.factor(high_interpretation)\n# )\n\n#GROUPED PROPORTIONAL BAR CHART\ngf_props(~accuracy, fill = ~pretty_condition, x =~pretty_condition,\n       position = position_dodge(), data = df) %>%\n  gf_facet_grid(~pretty_mode) +\n   labs(x = \"Question 1 Accuracy\",\n       title = \"Accuracy on Q1\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-Q1-ACCURACY-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n   labs(#y = \"\",\n       title = \"Accuracy on Test Phase\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-Q1-ACCURACY-2.png){width=672}\n:::\n:::\n\n#### CHI SQUARE\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::CROSSTABLE\n# CrossTable( x = df$condition, y = df$accuracy, \n#              fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n\n#::::::::::::MOSAIC PLOT\n# note: blue indicates cell count higher than expected, \n# red indicates cell count less than expected; under null hypothesis\n# mosaicplot(main=\"Accuracy on First Question by Condition\",\n#             data = df, pretty_condition ~ accuracy, \n#             shade = T)\n\n#::::::::::::TABLE\ndf %>% sjtab( fun = \"xtab\", var.labels=c(\"accuracy\", \"pretty_condition\"),\n        show.row.prc=F, show.col.prc=T, show.summary=T, show.exp=T, show.legend=T,\n        statistics = c(\"auto\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n <tr>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal; border-bottom:1px solid;\" rowspan=\"2\">accuracy</th>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal;\" colspan=\"2\">pretty_condition</th>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal; font-weight:bolder; font-style:italic; border-bottom:1px solid; \" rowspan=\"2\">Total</th>\n </tr>\n \n<tr>\n <td style=\"border-bottom:1px solid; text-align:center; padding:0.2cm;\">control</td>\n <td style=\"border-bottom:1px solid; text-align:center; padding:0.2cm;\">impasse</td>\n </tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">0</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">52</span><br><span style=\"color:#339999;\">48</span><br><span style=\"color:#339933;\">83.9&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">45</span><br><span style=\"color:#339999;\">49</span><br><span style=\"color:#339933;\">70.3&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">97</span><br><span style=\"color:#339999;\">97</span><br><span style=\"color:#339933;\">77&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">1</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">10</span><br><span style=\"color:#339999;\">14</span><br><span style=\"color:#339933;\">16.1&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">19</span><br><span style=\"color:#339999;\">15</span><br><span style=\"color:#339933;\">29.7&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">29</span><br><span style=\"color:#339999;\">29</span><br><span style=\"color:#339933;\">23&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  border-bottom:double; font-weight:bolder; font-style:italic; text-align:left; vertical-align:middle;\">Total</td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">62</span><br><span style=\"color:#339999;\">62</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">64</span><br><span style=\"color:#339999;\">64</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">126</span><br><span style=\"color:#339999;\">126</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td> \n</tr>\n<td style=\"text-align:right; font-size:0.9em; font-style:italic; padding:0.2cm;\" colspan=\"4\">&chi;<sup>2</sup>=2.547 &middot; df=1 &middot; &phi;=0.161 &middot; p=0.111</td> \n</tr>\n \n</table> <p>\n <span style=\"color:black;\">observed values</span><br>\n <span style=\"color:#339999;\">expected values</span><br>\n <span style=\"color:#339933;\">&#37; within pretty_condition</span><br>\n </p>\n\n`````\n:::\n\n```{.r .cell-code}\n#::::::::::::BAR PLOT\nggbarstats(data = df, x = accuracy, y = condition,\n           type = \"nonparametric\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - CHISQR-Q1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#::::::::::::CHISQR TEST\n(x <- stats::chisq.test(x = df$accuracy, y = df$condition, simulate.p.value = T))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test with simulated p-value (based on 2000\n\treplicates)\n\ndata:  df$accuracy and df$condition\nX-squared = 3, df = NA, p-value = 0.09\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::POWER ANALYSIS\n(po <- pwr.chisq.test( w = 0.1, df=(2-1), N = nrow(df), sig.level = 0.05))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Chi squared power calculation \n\n              w = 0.1\n              N = 126\n             df = 1\n      sig.level = 0.05\n          power = 0.202\n\nNOTE: N is the number of observations\n```\n:::\n:::\n\n**A Chi-Square test of independence of Q1 accuracy \\[correct,incorrect\\] by condition indicates the question accuracy is not dependent on condition. *However, this test may be underpowered, as with the given sample size it has only 20% power to detect a small effect (w = 0.1)***\n\n### LOGISTIC REGRESSION\n\n-   http://post8000.svmiller.com/lab-scripts/logistic-regression-lab.html\n\n*Fit a logistic regression (at the subject-item level), predicting Q1 accuracy (absolute score) by condition.*\\\n*note: this example uses the combined dataset rather than lab-only, as learning notes were done with the combined and I don't want to recalcualte all the marginal probabilities by hand for learning purposes.*\n\n-   Fit a logistic regression predicting accuracy (absolute score) (n = r nrow(df)) by condition. (k = 2).\n-   Parameter estimate: $\\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition\n    -   $e^{\\beta_{0}}$ = ODDS of correct response in CONTROL condition\n-   Parameter estimate: $\\beta_{1}$ = $\\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \\[log scale\\])\n    -   $e^{\\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\n-   Null hypothesis:$\\beta_{impasse} \\le 0$ the odds for a correct response does not change, or decreases\n-   Alternative hypothesis: $\\beta_{impasse} \\gt 0$ the odds of a correct response increases\n\n#### Fit Model\n\n*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*\n\n::: {.cell}\n\n```{.r .cell-code}\n#combined dataset, not lab only\ndf <- df_items %>% filter(q==1) %>% mutate(\n  accuracy = as.factor(score_niceABS)\n)\n\n# FREQUENCY TABLE\n# my.table <- table(df$accuracy, df$pretty_condition)\n# addmargins(my.table) #counts\n# addmargins(prop.table(my.table)) #props\n\n# MODEL FITTING:::::::::::::::::::::::::::::::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\nprint(\"EMPTY MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"EMPTY MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ 1, family = \"binomial\", data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.696  -0.696  -0.696  -0.696   1.753  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.294      0.134   -9.66   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 343.66  on 329  degrees of freedom\nResidual deviance: 343.66  on 329  degrees of freedom\nAIC: 345.7\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.819  -0.819  -0.548  -0.548   1.986  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.822      0.230   -7.93  2.2e-15 ***\npretty_conditionimpasse    0.901      0.285    3.16   0.0016 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 343.66  on 329  degrees of freedom\nResidual deviance: 333.07  on 328  degrees of freedom\nAIC: 337.1\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff |  Chi2 |     p\n-------------------------------------------\nm0   |   glm |  1 |         |       |      \nm1   |   glm |  2 |       1 | 10.59 | 0.001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0.00113745235691825\"\n```\n:::\n:::\n\n*The Condition predictor significantly improves model fit.*\n\n#### Learning Notes\n\n::: {.cell}\n\n```{.r .cell-code}\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.819  -0.819  -0.548  -0.548   1.986  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.822      0.230   -7.93  2.2e-15 ***\npretty_conditionimpasse    0.901      0.285    3.16   0.0016 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 343.66  on 329  degrees of freedom\nResidual deviance: 333.07  on 328  degrees of freedom\nAIC: 337.1\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n#: INTERPRET COEFFICIENTS\nprint(\"Coefficients —- LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\nconfint(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                         2.5 % 97.5 %\n(Intercept)             -2.299  -1.39\npretty_conditionimpasse  0.353   1.48\n```\n:::\n\n```{.r .cell-code}\nprint(\"Coefficients —- ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiate)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                              2.5 % 97.5 %\n(Intercept)             0.162  0.10  0.248\npretty_conditionimpasse 2.463  1.42  4.374\n```\n:::\n\n```{.r .cell-code}\nprint(\"Coefficients —- PROBABILITIES\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Coefficients —- PROBABILITIES\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"[these should math pred plots]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"[these should math pred plots]\"\n```\n:::\n\n```{.r .cell-code}\nprint(\"Probability at reference level\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability at reference level\"\n```\n:::\n\n```{.r .cell-code}\nplogis(m1$coefficients[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.139\n```\n:::\n\n```{.r .cell-code}\nprint(\"Probability at coefficient level\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability at coefficient level\"\n```\n:::\n\n```{.r .cell-code}\nplogis(m1$coefficients[[1]] + m1$coefficients[[2]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.285\n```\n:::\n\n```{.r .cell-code}\nprint(\"CHANGE in probability by coefficient\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"CHANGE in probability by coefficient\"\n```\n:::\n\n```{.r .cell-code}\nplogis(m1$coefficients[[1]] + m1$coefficients[[2]]) - plogis(m1$coefficients[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.146\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PREDICTIONS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PREDICTIONS\"\n```\n:::\n\n```{.r .cell-code}\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\npaste(\"Probability of success in control,\", pred.control)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in control, 0.139240506329147\"\n```\n:::\n\n```{.r .cell-code}\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\npaste(\"Probability of success in impasse,\", pred.impasse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Probability of success in impasse, 0.284883720930631\"\n```\n:::\n\n```{.r .cell-code}\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"p value for two-tailed test, null B = 0 :  0.002\"\n```\n:::\n\n```{.r .cell-code}\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.001\"\n```\n:::\n\n```{.r .cell-code}\npaste(\"adjusted confint for directional hypothesis\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"adjusted confint for directional hypothesis\"\n```\n:::\n\n```{.r .cell-code}\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                          5 %  95 %\n(Intercept)             -2.22 -1.46\npretty_conditionimpasse  0.44  1.38\n```\n:::\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n\n#:::::::: INTERPRET COEFFICIENTS [directional]\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\n# print(\"Coefficients —- ODDS RATIOS\")\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n# (e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n```\n:::\n\n**Understanding the logistic regression model**\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES\n\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     \n      control impasse   Sum\n  0     0.861   0.715 0.785\n  1     0.139   0.285 0.215\n  Sum   1.000   1.000 1.000\n```\n:::\n\n```{.r .cell-code}\ntable(df$accuracy, df$condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     \n      control impasse Sum\n  0       136     123 259\n  1        22      49  71\n  Sum     158     172 330\n```\n:::\n:::\n\n*The logistic regression intercept gives the log odds of the outcome for the reference level of the predictor variable*\n\n*The logistic regression coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable.*\n\n**\\[the empty model**\n\n-   The intercept of an empty model (glm(accuracy \\~ 1) is equal to log(p/(1-p)), where p = the overall probability of a correct response (df\\$accuracy ==1 ).\n-   In SGC3A Q1 accuracy this = 71 correct / 330 = 0.215 -\\> log(0.215 / (1-0.215)) = -1.29.\n-   In other words, the intercept from the model with no predictor variables is the estimated log odds of a correct response for the whole sample.\n-   We can also transform the log of the odds back to a probability: p = ODDS/ (1+ODDS) = exp(-1.29)/(1+exp(-1.29)) = 0.215. This should matched the prediction of the empty model\n\n**\\[a dichotomous predictor\\]**\n\nnatural log (odds of +) = -1.822 + 0.901(x1) ; x1 = 0 for control, 1 for impasse - b0 intercept is ODDS OF CORRECT RESPONSE IN REFERENCE (control) - b1 intercept is ODDS RATIO (difference in odds) FOR CORRECT RESPONSE IN IMPASSE\n\n-   INTERCEPT: log odds of (+ response) in control condition\n    -   log odds of (+) in control : -1.822 + 0.9(0) = -1.822\n    -   convert to odds by exponentiating the coefficients\\\n        log odds of (+) in control = exp(-1.822) = 0.162 odds\n    -   convert to probability by formula =\\>\\\n        p(+) = odds / (1+odds) = 0.162 / (1 + 0.162) = 0.139\\\n        probability of (+) in control = \\~14%\n-   B1 COEFFICIENT: DIFFERENCE in log odds of (+) in impasse vs. control\n    -   log odds of (+) in impasse: -1.822 + 0.901 = -0.921\n    -   convert to odds by exponentiating log odds\\\n        log odds (+) in impasse = exp(-0.921) = 0.398\n    -   convert to probability by formula =\\>\\\n        p(+) = odds / (1 + odds) = 0.398 / (1+0.398) = 0.285\\\n        probaility of (+) in impasse = \\~ 29%\n-   ODDS RATIO : exponentiated B1 COEFFICIENT\n    -   B1 = (slope of logit model = difference in log odds = log odds ratio\n    -   B1 = 0.901 is log odds ratio of (+) in impasse vs control\n    -   exp(b1) = exp(0.901) = 2.46\n    -   Ratio of odds in impasse are 2.46 times higher than in control. Bein in the impasse condition yields odds athat are 2.46 X higher than in control.\n\n+:----------------------------------------------------------------------+\n| MARGINAL\\                                                             |\n| total = 330 success : 71, failure : 259\\                              |\n| p(+) = 71 / 330 = 0.215 = 22%\\                                        |\n| odds(+) = 71 / 259 = 0.274                                            |\n+-----------------------------------------------------------------------+\n| CONTROL total = 158 success = 22; failure = 136\\                      |\n| p(+) = 22/158 = 0.139 = 14%\\                                          |\n| odds(+) = 22/136 = 0.162                                              |\n+-----------------------------------------------------------------------+\n| IMPASSE total = 172 success = 49; failure = 123\\                      |\n| p(+) = 49/172 = 0.285 = 29%\\                                          |\n| odds(+) = 49/123 = 0.398                                              |\n+-----------------------------------------------------------------------+\n\n#### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \nggcoefstats(m1, output = \"plot\", \n              conf.level = 0.90) + \n  labs(x = \"Log Odds Estimate\", \n       subtitle = \"p is for two tailed test\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m1, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-59-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m1, type=\"eff\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-59-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | TABLE\n# tab_model(m1)\n\n#MODELSUMMARY | MODEL | PROBABILITIES\n# modelsummary(m1, exponentiate = TRUE)\n\n#MARGINALEFFECTS | MODEL | PROBABILITIES\nlibrary(marginaleffects)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'marginaleffects'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:modelr':\n\n    typical\n```\n:::\n\n```{.r .cell-code}\n#plot adjusted predictions, conditional on the CONDITION variable using the plot_cap\n#interactions plot_cap(mod, condition = c(\"length\", \"style\"))\nplot_cap(m1, condition = \"pretty_condition\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-59-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# The plot_cme function can be used to draw “Conditional Marginal Effects.” \n#use for ixns \n# plot_cme(m1, effect = \"var1\", condition = \"pretty_condition\")\n```\n:::\n\n#### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic model (estimated using ML) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model's explanatory power is weak (Tjur's R2 = 0.03). The model's intercept, corresponding to pretty_condition = control, is at -1.82 (95% CI [-2.30, -1.39], p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 0.90, 95% CI [0.35, 1.48], p = 0.002; Std. beta = 0.90, 95% CI [0.35, 1.48])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using \n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n----------------------------------------------------------------------------------------------\n337.074 | 344.673 |     0.031 | 0.404 | 1.008 |    0.505 |   -16.847 |           0.021 | 0.673\n```\n:::\n\n```{.r .cell-code}\nprint(\"MODEL DIAGNOSTICS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL DIAGNOSTICS\"\n```\n:::\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOk: About 100% of the residuals are inside the error bounds.\n```\n:::\n\n```{.r .cell-code}\n# logitgof(df$accuracy, m1$fitted.values, ord=FALSE)\n# hoslem.test(x = df$accuracy, y = fitted(m1), g =  2)\n# p should be non significant\n```\n:::\n\n#### Inference\n\nWe fit a logistic regression model to analyze the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 3.16, p = 0.0016). The model predicts that the odds of a correct response on the first question in the *impasse condition* increase by 146% ($e^{beta_1}$ = 2.46, 95% CI \\[1.42, 4.37\\]) over the *control condition*.\n\n*Equivalent statements:*\n\n-   being in impasse condition increases log odds of correct response by 0.901 (over control)\n-   being in impasse increases odds of correct response in impasse over control increases by factor of 2.46\n-   probability of correct response in control predicted as 28.5%, vs only 14% in control condition\n\n::: {.cell}\n\n```{.r .cell-code}\n#PRETTY TABLE SJPLOT\ntab_model(m1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10&nbsp;&ndash;&nbsp;0.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.46</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.42&nbsp;&ndash;&nbsp;4.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.002</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">330</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Tjur</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.031</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n## ORDINAL OUTCOME\n\n**Does CONDITION affect the Q1 \\[ordered\\] type of response given?**\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA\ndf <- df_items %>% filter(q==1)  %>% filter(mode == \"lab-synch\") \n#scaled has already been set as an ordered factor of score_SCALED\n\n#::::::::::::DESCRIPTIVES\nprop.table(table(df$scaled, df$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse\n  orth      0.39683 0.15873\n  unknown   0.00794 0.00000\n  uncertain 0.00000 0.14286\n  lines     0.00794 0.05556\n  tri       0.07937 0.15079\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\ngf_props(~scaled, fill= ~condition, data = df) %>% \n  gf_facet_grid(condition ~ .) + easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - SETUP-INDEPENDENT-ORDINAL-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = condition,\n                       fill = scaled)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - SETUP-INDEPENDENT-ORDINAL-2.png){width=672}\n:::\n:::\n\n**Does CONDITION affect the Q1 \\[ordered\\] state of understanding?**\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA\ndf <- df_items %>% filter(q==1)  %>% filter(mode == \"lab-synch\") \n#scaled has already been set as an ordered factor of score_SCALED\n\n#::::::::::::DESCRIPTIVES\nprop.table(table(df$state, df$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse\n  orth-like 0.39683 0.15873\n  unknown   0.00794 0.14286\n  tri-like  0.08730 0.20635\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\ngf_props(~state, fill= ~condition, data = df) %>% \n  gf_facet_grid(condition ~ .) + easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - SETUP-INDEPENDENT-ORDINAL-STATE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"\",\n       title = \"Q1 State\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - SETUP-INDEPENDENT-ORDINAL-STATE-2.png){width=672}\n:::\n:::\n\n### ORDINAL REGRESSION --- Cumulative Link; Proportional Odds\n\n*Fit an ordinal logistic regression (at the subject level), predicting Q1 interpretation by condition.*\n\n-   <https://stats.oarc.ucla.edu/r/faq/ologit-coefficients/>\n-   <https://journals.sagepub.com/doi/full/10.1177/2515245918823199>\n-   todo see ordinal regression video: <https://www.youtube.com/watch?v=rPcMcW25PPA&ab_channel=NCRMUK>\n-   <https://peopleanalytics-regression-book.org/ord-reg.html>\n-   <https://medium.com/evangelinelee/brant-test-for-proportional-odds-in-r-b0b373a93aa2>\n-   <https://github.com/runehaubo/ordinal/blob/master/old_vignettes/clm_tutorial.pdf>\n\n**Learning Notes**\n\n-   proportional odds regression models effectively act as a series of stratified binomial models under the assumption that the 'slope' of the logistic function of each stratified model is the same.\n-   thus need to verify proportional odds assumption - ordinal regression requires an **proportional odds assumption** (the same slope holds for each equation)\n-   this is required because the model simultaneously estimates k-1 equations, but each equation has the same *slope*, with different intercepts.\n-   conversely, a multinomial (categorical) model will have different slopes as well as intercepts - the intercepts are always ordered in size alpha 1 \\< alpha 2 \\< alpha k-1...\n-   **TODO** - see difference between the three types of ordinal models (adjacent category (vs) cumulative proportions; check Agresti book\n\n#### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::ORDINAL REGRESSION MODELS\n\n#EMPTY MODEL\npaste(\"EMPTY Ordinal regression of q1 SCALED score (ordered interpretation)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"EMPTY Ordinal regression of q1 SCALED score (ordered interpretation)\"\n```\n:::\n\n```{.r .cell-code}\nom.0 <- clm(state ~ 1 , data = df)\n# summary(om.0)\n\n#PREDICTOR MODEL\npaste(\"Ordinal regression of q1 SCALED score (ordered interpretation)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Ordinal regression of q1 SCALED score (ordered interpretation)\"\n```\n:::\n\n```{.r .cell-code}\nom <- clm(state ~ condition, data = df)\n# summary(om)\n\n#COMPARE EMPTY AND PREDICTOR\ntest_lrt(om.0, om)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff |  Chi2 |      p\n--------------------------------------------\nom.0 |   clm |  2 |         |       |       \nom   |   clm |  3 |       1 | 25.77 | < .001\n```\n:::\n\n```{.r .cell-code}\n#::::::::: EQUIVALENT APPROACH USING POLYR \n\n# #MODEL\nm <- polr(state ~ condition , data = df, Hess=TRUE)\n# summary(m)\n\n#exponentiate coefficients and CIs\n# (ctable <- coef(summary(m)))\n# (p <- pnorm(abs(ctable[, \"t value\"]), lower.tail = FALSE) * 2)\n# (ctable <- cbind(ctable, \"p value\" = p))\n# (ci <- confint(m))\n# (e <- coef(m))\n```\n:::\n\n*Likelihood ratio test suggests the predictor model is a better fit than the empty (intercept only) model.*\n\n#### Inference\n\n::: {.cell}\n\n```{.r .cell-code}\npaste(\"SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(om)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nformula: state ~ condition\ndata:    df\n\n link  threshold nobs logLik  AIC    niter max.grad cond.H \n logit flexible  126  -109.55 225.09 6(0)  2.18e-10 2.5e+01\n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \nconditionimpasse      1.9        0.4    4.74  2.1e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n                  Estimate Std. Error z value\north-like|unknown    1.326      0.323    4.10\nunknown|tri-like     2.109      0.355    5.94\n```\n:::\n\n```{.r .cell-code}\n#LOG ODDS\npaste(\"IN LOG ODDS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"IN LOG ODDS\"\n```\n:::\n\n```{.r .cell-code}\n(ctable <- coef(summary(om)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Estimate Std. Error z value Pr(>|z|)\north-like|unknown     1.33      0.323    4.10 4.07e-05\nunknown|tri-like      2.11      0.355    5.94 2.80e-09\nconditionimpasse      1.90      0.400    4.74 2.10e-06\n```\n:::\n\n```{.r .cell-code}\n(ci <- confint(om)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 % 97.5 %\nconditionimpasse  1.14   2.72\n```\n:::\n\n```{.r .cell-code}\npaste(\"IN ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"IN ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\n#ODDS RATIOS\nexp(coef(om))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\north-like|unknown  unknown|tri-like  conditionimpasse \n             3.77              8.24              6.68 \n```\n:::\n\n```{.r .cell-code}\nexp(ci)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 % 97.5 %\nconditionimpasse  3.12   15.1\n```\n:::\n:::\n\n**Overall, participants in the impasse condition had higher odds (6.68 X as likely) to offer *more correct* interpretations than those in the control condition (z = 4.74, p \\< 0.001).**\n\n-   we see the estimates for the 2 intercepts, which are sometimes called cutpoints.\n-   The intercepts indicate where the latent variable is cut to make the three groups that we observe in our data.\n-   Note that this latent variable is continuous. In general, these are not used in the interpretation of the results.\n-   The cutpoints are closely related to thresholds, which are reported by other statistical packages.\n-   for k groups there will be k-1 intercepts (cutpoints)\n-   confirm that the CI does not include 0 (the units are ordered logits \\[ordered log odds\\])\n-   as with logistic regression we exponentiate the coefficients and confints to get odds ratio\n\n#### Visualize Model\n\n::: {.cell}\n\n```{.r .cell-code}\n# sjPlot::tab_model(om)\nsjPlot::plot_model(om)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-66-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsjPlot::plot_model(om, type = \"eff\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-66-2.png){width=672}\n:::\n\n```{.r .cell-code}\n                   # show.data = TRUE, jitter = TRUE)\n```\n:::\n\n#### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#:: ASSESS FIT\nperformance(om)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC | Nagelkerke's R2 |  RMSE | Sigma\n---------------------------------------------------\n225.090 | 233.599 |           0.216 | 1.629 | 1.648\n```\n:::\n\n```{.r .cell-code}\n# #test proporitional odds assumption \nbrant(m) #only works for polyr type model not clm type model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n---------------------------------------------------- \nTest for\t\tX2\tdf\tprobability \n---------------------------------------------------- \nOmnibus\t\t\t15.6\t1\t0\nconditionimpasse\t15.6\t1\t0\n---------------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n```\n:::\n\n```{.r .cell-code}\n# # A p-value of less than 0.05 on this test—particularly on the Omnibus plus at least one of the variables—should be interpreted as a failure of the proportional odds assumption.\n\n#test proportional odds assumption\nlibrary(pomcheckr)\n# https://cran.r-project.org/web/packages/pomcheckr/pomcheckr.pdf\n(p <- pomcheck( scaled ~ condition , data = df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 2 × 6\n# Groups:   condition [2]\n  condition `scaled_>=1` `scaled_>=2` `scaled_>=4` `scaled_>=5` `scaled_>=3`\n  <fct>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl>\n1 control            Inf        -1.43       -1.53        -1.65        NA    \n2 impasse            Inf        NA          -0.379       -0.862        0.788\n\nattr(,\"class\")\n[1] \"pomcheck\" \"list\"    \n```\n:::\n\n```{.r .cell-code}\nplot(p)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-67-1.png){width=672}\n:::\n:::\n\n**The output of the graphical test for proportional odds assumption suggests that the proportional odds assumption may be unreasonable for this dataset. Also, inspecting the output table, we see the coefficients for each level of the scaled variable are quite different.**\n\nThus, an alternative approach may be more appropriate:\n\n-   Baseline logistic model. This model is the same as the multinomial regression model covered in the previous chapter, using the lowest ordinal value as the reference.\n\n-   Adjacent-category logistic model. This model compares each level of the ordinal variable to the next highest level, and it is a constrained version of the baseline logistic model. The brglm2 package in R offers a function bracl() for calculating an adjacent category logistic model.\n\n-   Continuation-ratio logistic model. This model compares each level of the ordinal variable to all lower levels. This can be modeled using binary logistic regression techniques, but new variables need to be constructed from the data set to allow this. The R package rms has a function cr.setup() which is a utility for preparing an outcome variable for a continuation ratio model.\n\n\\*Note: for multiple regression, the ordinal package offers a parameter (nominal = \\~predictors) that allow you to designate some predictors as nominal rather than ordinal. But this is not appropriate for this use case.\\_\n\n## CATEGORICAL OUTCOME\n\n**Does CONDITION affect the Q1 \\[ordered\\] type of response given?**\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA\ndf <- df_items %>% filter(q==1)  %>% filter(mode == \"lab-synch\") \n#scaled has already been set as an ordered factor of score_SCALED\n\n#::::::::::::DESCRIPTIVES\nprop.table(table(df$scaled, df$condition))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse\n  orth      0.39683 0.15873\n  unknown   0.00794 0.00000\n  uncertain 0.00000 0.14286\n  lines     0.00794 0.05556\n  tri       0.07937 0.15079\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\ngf_props(~scaled, fill= ~condition, data = df) %>% \n  gf_facet_grid(condition ~ .) + easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-68-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = condition,\n                       fill = scaled)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-68-2.png){width=672}\n:::\n:::\n\n**Does CONDITION affect the Q1 \\[ordered\\] state of understanding?**\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA\ndf <- df_items %>% filter(q==1)  %>% filter(mode == \"lab-synch\") \n#scaled has already been set as an ordered factor of score_SCALED\n\n#::::::::::::DESCRIPTIVES\ntable(df$state, df$condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.8065  0.3125 0.5556\n  unknown    0.0161  0.2812 0.1508\n  tri-like   0.1774  0.4062 0.2937\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n#::::::::::::VISUALIZE DISTRIBUTIONS\ngf_props(~state, fill= ~condition, data = df) %>% \n  gf_facet_grid(condition ~ .) + easy_remove_legend()\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-69-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"\",\n       title = \"Q1 State\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-69-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGSTATSPLOT\nggbarstats(df, state, condition)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-69-3.png){width=672}\n:::\n:::\n\n### CHI SQUARE\n\n**Does CONDITION affect the Q1 \\[categorical\\] type of response given?**\n\n::: {.cell}\n\n```{.r .cell-code}\nCrossTable( x = df$condition, y = df$scaled, \n             fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(t, correct = FALSE, ...): Chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$scaled \ndf$condition |      orth |   unknown | uncertain |     lines |       tri | Row Total | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n     control |        50 |         1 |         0 |         1 |        10 |        62 | \n             |    34.444 |     0.492 |     8.857 |     3.937 |    14.270 |           | \n             |     7.025 |     0.524 |     8.857 |     2.191 |     1.278 |           | \n             |     0.806 |     0.016 |     0.000 |     0.016 |     0.161 |     0.492 | \n             |     0.714 |     1.000 |     0.000 |     0.125 |     0.345 |           | \n             |     0.397 |     0.008 |     0.000 |     0.008 |     0.079 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n     impasse |        20 |         0 |        18 |         7 |        19 |        64 | \n             |    35.556 |     0.508 |     9.143 |     4.063 |    14.730 |           | \n             |     6.806 |     0.508 |     8.580 |     2.122 |     1.238 |           | \n             |     0.312 |     0.000 |     0.281 |     0.109 |     0.297 |     0.508 | \n             |     0.286 |     0.000 |     1.000 |     0.875 |     0.655 |           | \n             |     0.159 |     0.000 |     0.143 |     0.056 |     0.151 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\nColumn Total |        70 |         1 |        18 |         8 |        29 |       126 | \n             |     0.556 |     0.008 |     0.143 |     0.063 |     0.230 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  39.1     d.f. =  4     p =  6.55e-08 \n\n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nAlternative hypothesis: two.sided\np =  1.01e-09 \n\n \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MOSAIC PLOT\n#note: blue indicates cell count higher than expected, red indicates cell count less than expected; under null hypothesis\nmosaicplot(main=\"Interpretation on First Question by Condition\",\n            data = df, condition ~ scaled, \n            shade = T)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-71-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#::::::::::::WITH STATISTICS\nggbarstats(data = df, x = condition, y = scaled,\n           type = \"nonparametric\") \n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-71-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#MOSAIC PLOT\n#note: blue indicates cell count higher than expected, red indicates cell count less than expected; under null hypothesis\nmosaicplot(main=\"Response Type on First Question by Condition\",\n            data = df, condition ~ scaled, \n            shade = T)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/label - CHISQR-interpreation-1.png){width=672}\n:::\n\n```{.r .cell-code}\nCrossTable( x = df$condition, y = df$scaled, \n            fisher = TRUE, chisq=TRUE, expected = TRUE, sresid = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(t, correct = FALSE, ...): Chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|              Expected N |\n| Chi-square contribution |\n|           N / Row Total |\n|           N / Col Total |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  126 \n\n \n             | df$scaled \ndf$condition |      orth |   unknown | uncertain |     lines |       tri | Row Total | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n     control |        50 |         1 |         0 |         1 |        10 |        62 | \n             |    34.444 |     0.492 |     8.857 |     3.937 |    14.270 |           | \n             |     7.025 |     0.524 |     8.857 |     2.191 |     1.278 |           | \n             |     0.806 |     0.016 |     0.000 |     0.016 |     0.161 |     0.492 | \n             |     0.714 |     1.000 |     0.000 |     0.125 |     0.345 |           | \n             |     0.397 |     0.008 |     0.000 |     0.008 |     0.079 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n     impasse |        20 |         0 |        18 |         7 |        19 |        64 | \n             |    35.556 |     0.508 |     9.143 |     4.063 |    14.730 |           | \n             |     6.806 |     0.508 |     8.580 |     2.122 |     1.238 |           | \n             |     0.312 |     0.000 |     0.281 |     0.109 |     0.297 |     0.508 | \n             |     0.286 |     0.000 |     1.000 |     0.875 |     0.655 |           | \n             |     0.159 |     0.000 |     0.143 |     0.056 |     0.151 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\nColumn Total |        70 |         1 |        18 |         8 |        29 |       126 | \n             |     0.556 |     0.008 |     0.143 |     0.063 |     0.230 |           | \n-------------|-----------|-----------|-----------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  39.1     d.f. =  4     p =  6.55e-08 \n\n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nAlternative hypothesis: two.sided\np =  1.01e-09 \n\n \n```\n:::\n\n```{.r .cell-code}\ndf %>%\n  sjtab(fun = \"xtab\", var.labels=c(\"scaled\", \"pretty_condition\"),\n        show.row.prc=T, show.col.prc=T, show.summary=T, show.exp=T, show.legend=T,\n        statistics = \"fisher\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n <tr>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal; border-bottom:1px solid;\" rowspan=\"2\">scaled</th>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal;\" colspan=\"2\">pretty_condition</th>\n <th style=\"border-top:double; text-align:center; font-style:italic; font-weight:normal; font-weight:bolder; font-style:italic; border-bottom:1px solid; \" rowspan=\"2\">Total</th>\n </tr>\n \n<tr>\n <td style=\"border-bottom:1px solid; text-align:center; padding:0.2cm;\">control</td>\n <td style=\"border-bottom:1px solid; text-align:center; padding:0.2cm;\">impasse</td>\n </tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">orth</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">50</span><br><span style=\"color:#339999;\">34</span><br><span style=\"color:#333399;\">71.4&nbsp;&#37;</span><br><span style=\"color:#339933;\">80.6&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">20</span><br><span style=\"color:#339999;\">36</span><br><span style=\"color:#333399;\">28.6&nbsp;&#37;</span><br><span style=\"color:#339933;\">31.2&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">70</span><br><span style=\"color:#339999;\">70</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">55.6&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">unknown</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">1</span><br><span style=\"color:#339999;\">0</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">1.6&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">0</span><br><span style=\"color:#339999;\">1</span><br><span style=\"color:#333399;\">0&nbsp;&#37;</span><br><span style=\"color:#339933;\">0&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">1</span><br><span style=\"color:#339999;\">1</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">0.8&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">uncertain</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">0</span><br><span style=\"color:#339999;\">9</span><br><span style=\"color:#333399;\">0&nbsp;&#37;</span><br><span style=\"color:#339933;\">0&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">18</span><br><span style=\"color:#339999;\">9</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">28.1&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">18</span><br><span style=\"color:#339999;\">18</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">14.3&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">lines</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">1</span><br><span style=\"color:#339999;\">4</span><br><span style=\"color:#333399;\">12.5&nbsp;&#37;</span><br><span style=\"color:#339933;\">1.6&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">7</span><br><span style=\"color:#339999;\">4</span><br><span style=\"color:#333399;\">87.5&nbsp;&#37;</span><br><span style=\"color:#339933;\">10.9&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">8</span><br><span style=\"color:#339999;\">8</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">6.3&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  text-align:left; vertical-align:middle;\">tri</td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">10</span><br><span style=\"color:#339999;\">14</span><br><span style=\"color:#333399;\">34.5&nbsp;&#37;</span><br><span style=\"color:#339933;\">16.1&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center; \"><span style=\"color:black;\">19</span><br><span style=\"color:#339999;\">15</span><br><span style=\"color:#333399;\">65.5&nbsp;&#37;</span><br><span style=\"color:#339933;\">29.7&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;  \"><span style=\"color:black;\">29</span><br><span style=\"color:#339999;\">29</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">23&nbsp;&#37;</span></td> \n</tr>\n \n<tr> \n<td style=\"padding:0.2cm;  border-bottom:double; font-weight:bolder; font-style:italic; text-align:left; vertical-align:middle;\">Total</td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">62</span><br><span style=\"color:#339999;\">62</span><br><span style=\"color:#333399;\">49.2&nbsp;&#37;</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">64</span><br><span style=\"color:#339999;\">64</span><br><span style=\"color:#333399;\">50.8&nbsp;&#37;</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td>\n<td style=\"padding:0.2cm; text-align:center;   border-bottom:double;\"><span style=\"color:black;\">126</span><br><span style=\"color:#339999;\">126</span><br><span style=\"color:#333399;\">100&nbsp;&#37;</span><br><span style=\"color:#339933;\">100&nbsp;&#37;</span></td> \n</tr>\n<td style=\"text-align:right; font-size:0.9em; font-style:italic; padding:0.2cm;\" colspan=\"4\">&chi;<sup>2</sup>=39.128 &middot; df=4 &middot; Cramer's V=0.557 &middot; Fisher's p=0.000</td> \n</tr>\n \n</table> <p>\n <span style=\"color:black;\">observed values</span><br>\n <span style=\"color:#339999;\">expected values</span><br>\n <span style=\"color:#333399;\">&#37; within scaled</span><br>\n <span style=\"color:#339933;\">&#37; within pretty_condition</span><br>\n </p>\n\n`````\n:::\n:::\n\n**TODO INFERENCE**\n\n### MULTINOMIAL REGRESSION\n\non interpreting coefficients (marginal probability)\n- https://data.princeton.edu/wws509/stata/mlogit\n\n**TODO** RECONCILE actual predictions with coefficients and visualization of predictions\n\n*Does condition affect the response state of Q1?*\n\n-   <https://peopleanalytics-regression-book.org/multinomial-logistic-regression-for-nominal-category-outcomes.html#running-a-multinomial-regression-model>\n-   <https://bookdown.org/chua/ber642_advanced_regression/multinomial-logistic-regression.html>\n-   <https://www.youtube.com/watch?v=JcCBIPqcwFo&list=PLzv58M2GAfm50X_Twskr1aXaV5qMuIszx&ab_channel=NCRMUK>\n-   Can use nnet package multinom() or mclogit package mblogit() \\[\"baseline logit model\"\\] or brms with family = \"categorical\"\n\n*Fit a logistic regression predicting interpretation (k=#response categories) by condition. (k = 2).*\n\n-   2 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer)\n\n-   (from experience, seems) Each cell must have at least one observation (if one cell is blank, then it seems to be incorrectly estimated, see predicting high_interpretation vs. state. suggests nonsignificant OR for 'unknown' category, when infact that difference drives the effect\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n\n        -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n\n    -   *Null hypothesis:* $\\beta_{impasse} \\le 0$ *the odds for \\[this category of response vs. reference\\] does not change, or decreases*\n\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\gt 0$ *the odds of \\[this category of response vs. reference\\] increases*\n\n    -   \n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::::::DESCRIPTIVES RESPONSE STATE\n\ntable(df$state, df$condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse    Sum\n  orth-like  0.8065  0.3125 0.5556\n  unknown    0.0161  0.2812 0.1508\n  tri-like   0.1774  0.4062 0.2937\n  Sum        1.0000  1.0000 1.0000\n```\n:::\n\n```{.r .cell-code}\n(t <- table(df$state, df$condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           \n            control impasse Sum\n  orth-like      50      20  70\n  unknown         1      18  19\n  tri-like       11      26  37\n  Sum            62      64 126\n```\n:::\n:::\n\n#### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nnet)\n\n#check reference level \nlevels(df$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\ncatm.0 <- multinom(state ~ 1, data = df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  6 (2 variable)\ninitial  value 138.425148 \nfinal  value 122.428550 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\ncatm <- multinom(formula = state ~ condition, data = df, model = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  9 (4 variable)\ninitial  value 138.425148 \niter  10 value 103.421004\niter  10 value 103.421004\nfinal  value 103.421004 \nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(catm)\n\n#COMPARE MODEL FIT\ntest_lrt(catm.0, catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  2 |         |       |       \ncatm   | multinom |  4 |       2 | 38.02 | < .001\n```\n:::\n\n```{.r .cell-code}\n##compare bayesian version\n#library(brms)\n# bm1 <- brm( state ~ pretty_condition, data = df, family = \"categorical\")\n# summary(bm1)\n# plot_model(bm1)\n# report(bm1)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n```\n:::\n\n*Likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*\n\n#### Interpretation\n\n::: {.cell}\n\n```{.r .cell-code}\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL SUMMARY\"\n```\n:::\n\n```{.r .cell-code}\nsummary(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = state ~ condition, data = df, model = TRUE)\n\nCoefficients:\n         (Intercept) conditionimpasse\nunknown        -3.91             3.81\ntri-like       -1.51             1.78\n\nStd. Errors:\n         (Intercept) conditionimpasse\nunknown        1.010            1.061\ntri-like       0.333            0.447\n\nResidual Deviance: 207 \nAIC: 215 \n```\n:::\n\n```{.r .cell-code}\n# calculate z-statistics of coefficients\n(z_stats <- summary(catm)$coefficients/summary(catm)$standard.errors)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         (Intercept) conditionimpasse\nunknown        -3.87             3.59\ntri-like       -4.55             3.98\n```\n:::\n\n```{.r .cell-code}\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\np_values <- data.frame(p = (p_values))\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIOS\"\n```\n:::\n\n```{.r .cell-code}\nodds_ratios <- data.frame(OR = exp(summary(catm)$coefficients))\n\n# options(scipen = 3)\n(results <- cbind(odds_ratios, p_values))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         OR..Intercept. OR.conditionimpasse p..Intercept. p.conditionimpasse\nunknown            0.02               44.99      1.07e-04          0.0003330\ntri-like           0.22                5.91      5.45e-06          0.0000692\n```\n:::\n:::\n\n**Learning Notes**\n\n-   Model estimates encompass two equations:\n-   effect of predictor on log odds of being in \\[unknown\\] instead of reference category \\[orth-like\\]\n-   effect of predictor on log odds of being in \\[tri-like\\] instead of reference category \\[orth-like\\]\n-   \\[need to to double check interpretation, but I *think* that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the \\[reference\\] control condition. which makes sense. I think\\]\n-   IF I change reference category for condition... then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) \\[Yup! this works!\\]\n\n#### Inference\n\n-   Being in the IMPASSE condition increases the odds of giving 'unknown/uncertain' response rather than an orthogonal (or satisficing) response by a factor of 50 (z = 3.59, p \\< 0.001 ).\n-   Being in the IMPASSE condition increases the odds of giving an 'triangular or line-driven' response rather than an orthogonal (or satisficing) response by a factor of 6 (z = 3.98, p \\<0.001 )\n\n#### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(catm, vline.color = 'red')\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-76-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_model(catm, type = \"eff\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-76-2.png){width=672}\n:::\n:::\n\n#### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\n#EXAMINE PREDICTIONS\n#create sample data frame\ntest <- data.frame(condition = c(\"control\", \"impasse\"))\npred <- predict(catm, newdata = test, \"probs\")\npaste(\"Predicted Probability of Being in Each State\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Predicted Probability of Being in Each State\"\n```\n:::\n\n```{.r .cell-code}\n(cbind(test, pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  condition orth-like unknown tri-like\n1   control     0.806  0.0161    0.177\n2   impasse     0.312  0.2812    0.406\n```\n:::\n\n```{.r .cell-code}\n#performance\nperformance(catm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n214.842 | 226.187 | 0.155 |     0.147 | 0.404 | 1.302\n```\n:::\n\n```{.r .cell-code}\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'DescTools':\n  method         from \n  reorder.factor gdata\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n  McFadden   CoxSnell Nagelkerke \n     0.155      0.260      0.304 \n```\n:::\n\n```{.r .cell-code}\n#General Goodness of Fit\n# library(generalhoslem)\n# logitgof(df$state, catm$fitted.values, g = 3)\n# hoslem.test(x = df$state, y = catm$fitted.values, g =  10)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\n```\n:::\n\n# MIXED (Repeated Measures)\n\n::: {.cell}\n\n```{.r .cell-code}\n#PREPARE DATA \nn_items = 8 #number of items in test\n\n#item level\ndf = df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = recode_factor(score_niceABS, \"0\" =\"incorrect\",\"1\"=\"correct\"),\n  q = as.factor(q)\n)\n\n#FACETED HISTOGRAM\nstats = df_subjects %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(item_test_NABS))\ngf_props(~item_test_NABS, \n         fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_grid(pretty_condition ~ pretty_mode) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"# Correct\",\n       y = \"proportion of subjects\",\n       title = \"Test Phase Absolute Score (# Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-TEST-ACC-ITEM-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#GROUPED PROPORTIONAL BAR CHART\ngf_props(~accuracy, fill = ~pretty_condition, x =~pretty_condition,\n       position = position_dodge(), data = df) %>%\n  gf_facet_grid(~pretty_mode) +\n   labs(x = \"Correct Responses in Test Phase\",\n       title = \"Accuracy on Task by Condition\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-TEST-ACC-ITEM-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#STACKED PROPORTIONAL BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n   labs(#y = \"\",\n       title = \"Accuracy on Test Phase\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/SETUP-TEST-ACC-ITEM-3.png){width=672}\n:::\n:::\n\n## MIXED --- CONTINUOUS\n\n## MIXED --- BINOMIAL\n\n#### Mixed Logistic Regression\n\n*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on test phase questions by condition; accounting for random effects of subject.*\n\n##### Fit Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#SETUP DATA \nn_items = 8 #number of items in test\n\n#item level\ndf = df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% mutate(\n  accuracy = as.factor(score_niceABS),\n  q = as.factor(q)\n) %>% filter(mode ==\"lab-synch\")\n\nlibrary(lmerTest) #for CIs in glmer \n\n## 1 | SETUP RANDOM EFFECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df) \n\n#:: RANDOM INTERCEPT SUBJECT\nmm.rS <- glmer(accuracy ~ (1|subject), data = df,family = \"binomial\")\n\n#:: RANDOM INTERCEPT SUBJECT ITEM\nmm.rS <- glmer(accuracy ~ (1|subject) + (1|q), data = df,family = \"binomial\")\n\n# :: TEST random effect\npaste(\"AIC with random effect is lower than glm empty model?\", m0$aic > AIC(logLik(mm.rS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC with random effect is lower than glm empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  3 |       2 | 691.72 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  6.23684317028986e-151\"\n```\n:::\n\n```{.r .cell-code}\n## 2 | ADD FIXED EFFECT\n\n# SUBJECT INTERCEPT | FIXED CONDITION \nmm.CrS <- glmer(accuracy ~ pretty_condition + (1|subject), \n                data = df,family = \"binomial\")\n\n# SUBJECT INTERCEPT | FIXED CONDITION \nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q), \n                data = df,family = \"binomial\")\n\n# :: TEST fixed factor \npaste(\"AIC with fixed effect is lower than random intercept only model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.CrS)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC with fixed effect is lower than random intercept only model? FALSE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(mm.rS,mm.CrS) #same as anova(m0, m1, test = \"Chi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |      p\n------------------------------------------------\nmm.rS  | glmerMod |  3 |         |      |       \nmm.CrS | glmerMod |  3 |       0 | 9.40 | < .001\n```\n:::\n\n```{.r .cell-code}\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS,mm.CrS))$p[2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Likelihood Ratio test is significant? p =  0\"\n```\n:::\n:::\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#: PRINT MODEL \nprint(\"PREDICTOR MODEL\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PREDICTOR MODEL\"\n```\n:::\n\n```{.r .cell-code}\nsumm(mm.CrS)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Observations </td>\n   <td style=\"text-align:right;\"> 1008 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Dependent variable </td>\n   <td style=\"text-align:right;\"> accuracy </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Type </td>\n   <td style=\"text-align:right;\"> Mixed effects generalized linear model </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Family </td>\n   <td style=\"text-align:right;\"> binomial </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Link </td>\n   <td style=\"text-align:right;\"> logit </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> AIC </td>\n   <td style=\"text-align:right;\"> 582.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> BIC </td>\n   <td style=\"text-align:right;\"> 596.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-R² (fixed effects) </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Pseudo-R² (total) </td>\n   <td style=\"text-align:right;\"> 0.95 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"5\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Fixed Effects</div></th></tr>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Est. </th>\n   <th style=\"text-align:right;\"> S.E. </th>\n   <th style=\"text-align:right;\"> z val. </th>\n   <th style=\"text-align:right;\"> p </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -7.46 </td>\n   <td style=\"text-align:right;\"> 1.20 </td>\n   <td style=\"text-align:right;\"> -6.21 </td>\n   <td style=\"text-align:right;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> pretty_conditionimpasse </td>\n   <td style=\"text-align:right;\"> 4.03 </td>\n   <td style=\"text-align:right;\"> 1.67 </td>\n   <td style=\"text-align:right;\"> 2.42 </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Random Effects</div></th></tr>\n  <tr>\n   <th> Group </th>\n   <th> Parameter </th>\n   <th> Std. Dev. </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td> subject </td>\n   <td> (Intercept) </td>\n   <td> 7.36 </td>\n  </tr>\n</tbody>\n</table> <table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr><th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Grouping Variables</div></th></tr>\n  <tr>\n   <th> Group </th>\n   <th> # groups </th>\n   <th> ICC </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td> subject </td>\n   <td> 126 </td>\n   <td> 0.94 </td>\n  </tr>\n</tbody>\n</table>\n`````\n:::\n\n```{.r .cell-code}\n#: INTERPRET COEFFICIENTS\n\nprint(\"MODEL PERFORMANCE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"MODEL PERFORMANCE\"\n```\n:::\n\n```{.r .cell-code}\nperformance(mm.CrS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC     |    AICc |     BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma | Log_loss | Score_log | Score_spherical\n----------------------------------------------------------------------------------------------------------------------\n582.024 | 582.048 | 596.771 |      0.946 |      0.066 | 0.943 | 0.213 | 1.000 |    0.145 |      -Inf |           0.021\n```\n:::\n\n```{.r .cell-code}\nprint(\"SANITY CHECK REPORTING\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"SANITY CHECK REPORTING\"\n```\n:::\n\n```{.r .cell-code}\nreport(mm.CrS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a logistic mixed model (estimated using ML and Nelder-Mead optimizer) to predict accuracy with pretty_condition (formula: accuracy ~ pretty_condition). The model included subject as random effect (formula: ~1 | subject). The model's total explanatory power is substantial (conditional R2 = 0.95) and the part related to the fixed effects alone (marginal R2) is of 0.07. The model's intercept, corresponding to pretty_condition = control, is at -7.46 (95% CI [-9.81, -5.11], p < .001). Within this model:\n\n  - The effect of pretty condition [impasse] is statistically significant and positive (beta = 4.03, 95% CI [0.76, 7.29], p = 0.016; Std. beta = 4.03, 95% CI [0.76, 7.29])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n\n```{.r .cell-code}\n# se <- sqrt(diag(stats::vcov(m1)))\n# # table of estimates with 95% CI\n# (tab <- cbind(Est = fixef(m1), LL = fixef(m1) - 1.96 * se, UL = fixef(m1) + 1.96 *\n#     se))\n# (e <- exp(tab))\n\n#: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(mm.CrS, type=\"std2\", vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE) +  \n  labs(title = \"Model Predicted Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-80-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(mm.CrS, type=\"pred\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Predicted Probability of Accuracy\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pretty_condition\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-80-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#GGEFFECTS | MODEL | PROBABILITIES\n# library(ggeffects)\n# ggeffect(model = mm.CrS) %>% plot()\n\n#SANITY CHECK SJPLOT\n# library(effects)\n# plot(allEffects(mm.CrS))\n```\n:::\n\n##### Diagnostics\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(mm.CrS)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-81-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbinned_residuals(mm.CrS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Probably bad model fit. Only about 64% of the residuals are inside the error bounds.\n```\n:::\n:::\n\n##### Inference\n\nWe fit a mixed-effect binomial logistic regression model with random intercepts for subjects to investigate the effect of condition on test phase item accuracy. The model including a fixed effect of condition performed significantly better than an intercept-only baseline model (χ2(3): 4.98, p \\< 0.05). Consistent with the pattern of results for the first question only, across all test-phase items, being in the impasse condition increases the odds of a correct response by a factor of 5 over the control condition $e^{\\beta_1}$ = 5.11, 95% CI \\[1.17,22,36\\], p \\< 0.05.\n\n::: {.cell}\n\n```{.r .cell-code}\n# PRETTY TABLE SJPLOT\ntab_model(mm.CrS)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">accuracy</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Odds Ratios</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00&nbsp;&ndash;&nbsp;0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">pretty condition<br>[impasse]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">56.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.14&nbsp;&ndash;&nbsp;1472.88</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.016</strong></td>\n</tr>\n<tr>\n<td colspan=\"4\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">54.11</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.94</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">126</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">1008</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.066 / 0.946</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n#### BAYESIAN Mixed Lostistic Regression\n\n**Sanity Check** Compare frequentist model with bayesian alternative\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_i = df_items %>% filter(q %nin% c(6,9)) \n\n\n##:::::::: FLAT PRIORS\n#fit matching bayesian model [flat priors]\nFLAT_B.mm.CrSQ <-  brm(\n  bf(accuracy ~ pretty_condition + (1|subject) + (1|q)),\n  data = df_i,\n  family = bernoulli(link = \"logit\"),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file = \"analysis/utils/models/FLAT_B.mm.CrSQ.rds\"\n)\n\n#describe model\nsummary(FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 4290) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.93      0.23     0.58     1.47 1.00     1163     1843\n\n~subject (Number of levels: 330) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.68      0.35     4.05     5.39 1.00      852     1424\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  -4.63      0.58    -5.80    -3.52 1.01      495\npretty_conditionimpasse     3.11      0.61     1.98     4.34 1.00      331\n                        Tail_ESS\nIntercept                   1081\npretty_conditionimpasse      786\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n#compare to frequentist model\npaste(\"COMPARE TO FREQUENTIST\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"COMPARE TO FREQUENTIST\"\n```\n:::\n\n```{.r .cell-code}\ncompare_models(mm.CrSQ, FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                  |               mm.CrSQ |       FLAT_B.mm.CrSQ\n-------------------------------------------------------------------------\n(Intercept)                | -9.35 (-11.68, -7.03) | -4.62 (-5.80, -3.52)\npretty condition (impasse) |  2.18 ( -0.84,  5.19) |                     \npretty_conditionimpasse    |                       |  3.09 ( 1.98,  4.34)\n-------------------------------------------------------------------------\nObservations               |                  1008 |                 4290\n```\n:::\n\n```{.r .cell-code}\n#_Here we see that the model with default priors yields estimates comparable to the frequentist mixed model, though slightly smaller for fixed effects condition, with tighter credible intervals._\n\n\n##:::::::: INFORMATIVE PRIORS\n\n#describe priors that were used\npaste(\"DEFAULT PRIORS\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"DEFAULT PRIORS\"\n```\n:::\n\n```{.r .cell-code}\nprior_summary(FLAT_B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                prior     class                    coef   group resp dpar nlpar\n               (flat)         b                                                \n               (flat)         b pretty_conditionimpasse                        \n student_t(3, 0, 2.5) Intercept                                                \n student_t(3, 0, 2.5)        sd                                                \n student_t(3, 0, 2.5)        sd                               q                \n student_t(3, 0, 2.5)        sd               Intercept       q                \n student_t(3, 0, 2.5)        sd                         subject                \n student_t(3, 0, 2.5)        sd               Intercept subject                \n lb ub       source\n            default\n       (vectorized)\n            default\n  0         default\n  0    (vectorized)\n  0    (vectorized)\n  0    (vectorized)\n  0    (vectorized)\n```\n:::\n\n```{.r .cell-code}\n#set informative priors for fixed effects\n#parameters normally distributed around the mean of the expected log coefficient\n#we expect low probability of accuracy in control [intercept] and in impasse, but higher variance in impasse\npriors <- c(\n  prior(normal(-1, 2), class = b),\n  prior(normal(-1, 4), class = b, coef=\"pretty_conditionimpasse\")\n)\n\n#fit model with informative priors\nB.mm.CrSQ <-  brm(\n  accuracy ~ pretty_condition + (1|subject) + (1|q),\n  prior = priors,\n  data = df_i,\n  family = bernoulli(link = \"logit\"),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 1234,\n  backend = \"cmdstanr\",\n  file = \"analysis/utils/models/B.mm.CrSQ.rds\"\n)\n\n#describe model\nsummary(B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 4290) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.93      0.23     0.59     1.46 1.00     1270     2257\n\n~subject (Number of levels: 330) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.64      0.33     4.06     5.32 1.01     1010     1894\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  -4.48      0.57    -5.61    -3.38 1.01      485\npretty_conditionimpasse     2.93      0.60     1.76     4.11 1.01      379\n                        Tail_ESS\nIntercept                   1292\npretty_conditionimpasse      832\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n#compare to frequentist model\npaste(\"COMPARE TO UNFINFORMATIVE PRIOR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"COMPARE TO UNFINFORMATIVE PRIOR\"\n```\n:::\n\n```{.r .cell-code}\ncompare_models(FLAT_B.mm.CrSQ, B.mm.CrSQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter               |       FLAT_B.mm.CrSQ |            B.mm.CrSQ\n---------------------------------------------------------------------\n(Intercept)             | -4.62 (-5.80, -3.52) | -4.48 (-5.61, -3.38)\npretty_conditionimpasse |  3.09 ( 1.98,  4.34) |  2.92 ( 1.76,  4.11)\n---------------------------------------------------------------------\nObservations            |                 4290 |                 4290\n```\n:::\n:::\n_Here we see tha the model with the informative prior makes predictions similar to the uninformative prior model_. \n\n::: {.cell}\n\n```{.r .cell-code}\n#DIAGNOSTICS\n\n#set model \nm <- B.mm.CrSQ\n\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 4290) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.93      0.23     0.59     1.46 1.00     1270     2257\n\n~subject (Number of levels: 330) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.64      0.33     4.06     5.32 1.01     1010     1894\n\nPopulation-Level Effects: \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  -4.48      0.57    -5.61    -3.38 1.01      485\npretty_conditionimpasse     2.93      0.60     1.76     4.11 1.01      379\n                        Tail_ESS\nIntercept                   1292\npretty_conditionimpasse      832\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n#POSTERIOR CHECKS\nlibrary(bayestestR)\ndiagnostic_posterior(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Parameter Rhat ESS   MCSE\n1               b_Intercept 1.01 484 0.0257\n2 b_pretty_conditionimpasse 1.01 382 0.0308\n```\n:::\n\n```{.r .cell-code}\npp_check(m, ndraws = 500)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(m)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#INTERPRET\ndescribe_posterior(m, test = c(\"p_direction\", \"rope\", \"bayesfactor\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSampling priors, please wait...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nSummary of Posterior Distribution\n\nParameter               | Median |         95% CI |   pd |          ROPE | % in ROPE |  Rhat |    ESS |     BF\n--------------------------------------------------------------------------------------------------------------\n(Intercept)             |  -4.48 | [-5.61, -3.38] | 100% | [-0.18, 0.18] |        0% | 1.006 | 484.00 | > 1000\npretty_conditionimpasse |   2.92 | [ 1.76,  4.11] | 100% | [-0.18, 0.18] |        0% | 1.010 | 382.00 | > 1000\n```\n:::\n\n```{.r .cell-code}\n#set working model\nm <- B.mm.CrSQ\n\n\n#equivalence test \nresult <- equivalence_test(m, rule = \"cet\")\nplot(result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPicking joint bandwidth of 0.0912\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 200 rows containing non-finite values (stat_density_ridges).\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#rope \nresult <- rope(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#direction of effect \nresult <- pd(m)\nplot(result)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# all parameters\nm %>% \n  posterior_samples() %>% \n  select(-c(lp__, contains(\"[\"))) %>%\n  pivot_longer(cols = everything(),\n               names_to = \"variable\",\n               values_to = \"value\") %>% \n  ggplot(data = .,\n         mapping = aes(x = value)) +\n  stat_halfeye(point_interval = mode_hdi,\n               fill = \"lightblue\") + \n  facet_wrap(~ variable,\n             ncol = 2,\n             scales = \"free\") +\n  theme(text = element_text(size = 12))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#plot parameters\nstanplot(m, \n         type = \"areas\",\n         prob = 0.95) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Method 'stanplot' is deprecated. Please use 'mcmc_plot' instead.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#plot model\nplot_model(m)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-8.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT PARAMETERS\nresult <- model_parameters(m, exponentiate = TRUE, \n                           component = \"all\")\nplot(result) + \n  labs(\n  title = \"Accuracy ~ Condition + (1 | subject) + (1 | question)\",\n  subtitle = \"Logistic Mixed Effects Model\"\n)  + theme_clean() +  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-9.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")[[1]] + \n  ylim(0,1) + labs(\n    title = \"Model Prediction | Probability of Accurate Response\",\n    subtitle = \"Impasse increases Probability of Correct Response\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/MODEL-DESC-ACC-10.png){width=672}\n:::\n:::\n::: {.cell}\n\n```{.r .cell-code}\n#report(m)\n```\n:::\n\n\n\n\n## MIXED --- ORDINAL\n\n## MIXED --- CATEGORICAL \n### Mixed Multinomial Regression\n\n\n*Does condition affect the response state of of items across the task?*\n\n*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*\n\n-   Can use mclogit mblogit() with random effect *or* bayesian brms package b/c nlme, lme4 don't support random effects on multinomial (ie no categorical family on glmer())\n\n-   Alternative would be to manually run [k-1] X binomial mixed models \\[should compare outcomes\\]\n\n-   [k-1] equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \\[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \\[reference category\\] vs \\[this category\\])\n\n-   For *each* equation:\n\n    -   $\\beta_{0}$ *= Log Odds of \\[this category type vs. reference category type) response in CONTROL condition*\n    -   $e^{\\beta_{0}}$ *= ODDS of \\[this category type vs. reference category type\\] response in CONTROL condition*\n    -   $\\beta_{1}$ *=* $\\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \\[this category\\] type response in impasse (vs) control \\[log scale\\])*\n    -   $e^{\\beta_{1}}$ *= ODDS RATIO of \\[this. vs reference category type\\] response in IMPASSE (vs) CONTROL*\n    -   Two-tailed NHST *Null hypothesis:* $\\beta_{impasse} = 0$ *the odds for \\[this category of response vs. reference\\] are not different for IMPASSE condition*\n    -   *Alternative hypothesis:* $\\beta_{impasse} \\ne 0$ *the odds of \\[this category of response vs. reference\\] increases or decreases for IMPASSE condition*\n\n##### Fit Model \\[MANUAL INDIVIDUAL BINOMIALS\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n#VERIFY RESULTS BELOW VIA MULTIPLE INDIVIDUAL MODELS\n\npaste(\"ORTH vs. UNKNOWN\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. UNKNOWN\"\n```\n:::\n\n```{.r .cell-code}\nd1 <- df_i %>% filter(state %nin% c(\"tri-like\")) %>% droplevels()\ntable(d1$pretty_condition, d1$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         \n          orth-like unknown\n  control      1358     237\n  impasse       719     510\n```\n:::\n\n```{.r .cell-code}\nplot(d1$pretty_condition, d1$state)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-86-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.unknown <- glmer(state ~ pretty_condition + ( 1 | subject) + (1 | q), family = \"binomial\", data = d1)\nsummary(m.unknown)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: d1\n\n     AIC      BIC   logLik deviance df.resid \n    2478     2502    -1235     2470     2820 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.840 -0.464 -0.212  0.361  4.430 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 1.67     1.29    \n q       (Intercept) 2.16     1.47    \nNumber of obs: 2824, groups:  subject, 292; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.554      0.435   -5.87  4.2e-09 ***\npretty_conditionimpasse    2.218      0.204   10.89  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.257\n```\n:::\n:::\n\n*Being in the IMPASSE condition increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 19 ( logodds = 2.92, z = 6.89, p \\< 0.001) . Participants in the impasse condition were 19x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.67, marginal R2 = 0.21; SD(subject) = 1.55, SD(question) = 2.22)\n\n::: {.cell}\n\n```{.r .cell-code}\npaste(\"ORTH vs. TRIANGULAR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ORTH vs. TRIANGULAR\"\n```\n:::\n\n```{.r .cell-code}\nd2 <- df_i %>% filter(state %nin% c(\"unknown\")) %>% droplevels()\ntable(d2$pretty_condition, d2$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         \n          orth-like tri-like\n  control      1358      459\n  impasse       719     1007\n```\n:::\n\n```{.r .cell-code}\nplot(d2$pretty_condition, d2$state)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-87-1.png){width=672}\n:::\n\n```{.r .cell-code}\nm.tri <- glmer(state ~ pretty_condition + ( 1 | subject) + (1 | q), family = \"binomial\", data = d2)\nsummary(m.tri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: state ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: d2\n\n     AIC      BIC   logLik deviance df.resid \n    2113     2138    -1052     2105     3539 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-10.465  -0.189  -0.051   0.152   6.603 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 19.99    4.47    \n q       (Intercept)  1.28    1.13    \nNumber of obs: 3543, groups:  subject, 330; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -3.571      0.573   -6.24  4.5e-10 ***\npretty_conditionimpasse    4.350      0.631    6.90  5.4e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.661\n```\n:::\n:::\n\n*Being in the IMPASSE condition increases* the odds of giving an triangle-like response by a factor of 305 ( logodds = 5.72, z = 4.14, p \\< 0.001) . Participants in the impasse condition were 305 times as likely to give an triangle-like response rather than an orthogonal response compared to participants in control. (Conditional R2 = 0.91, marginal R2 = 0.21; SD(subject) = 5.05, SD(q) = 1.09)\n\n##### Fit Model \\[mblogit\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://www.elff.eu/software/mclogit/manual/mblogit/\n#\"baseline category logit\" model matches multinom()\n\n#check reference level \nprint(\"Categories (first is reference)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Categories (first is reference)\"\n```\n:::\n\n```{.r .cell-code}\nlevels(df_i$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"orth-like\" \"unknown\"   \"tri-like\" \n```\n:::\n\n```{.r .cell-code}\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nm.mbl0 <- mblogit(state ~ pretty_condition ,  #no random intercepts; fixed only model \n                  data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 8288 - criterion = 0.471\nIteration 2 - deviance = 8269 - criterion = 0.00228\nIteration 3 - deviance = 8269 - criterion = 6.61e-06\nIteration 4 - deviance = 8269 - criterion = 7.44e-11\nconverged\n```\n:::\n\n```{.r .cell-code}\n#summary(m.mbl0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nm.mbl1 <- mblogit(state ~ pretty_condition , \n                  random = list( ~ 1|subject, ~1|q), \n                  data = df_i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIteration 1 - deviance = 5845 - criterion = 0.772\nIteration 2 - deviance = 5237 - criterion = 0.0926\nIteration 3 - deviance = 5038 - criterion = 0.0186\nIteration 4 - deviance = 4957 - criterion = 0.00278\nIteration 5 - deviance = 4907 - criterion = 0.000674\nIteration 6 - deviance = 4884 - criterion = 0.00015\nIteration 7 - deviance = 4874 - criterion = 0.0000316\nIteration 8 - deviance = 4871 - criterion = 6.67e-06\nIteration 9 - deviance = 4869 - criterion = 1.44e-06\nIteration 10 - deviance = 4868 - criterion = 3.16e-07\nIteration 11 - deviance = 4868 - criterion = 6.99e-08\nIteration 12 - deviance = 4868 - criterion = 1.55e-08\nIteration 13 - deviance = 4868 - criterion = 3.38e-09\nconverged\n```\n:::\n\n```{.r .cell-code}\n# summary(m.mbl1)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(m.mbl0) > AIC(m.mbl1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n```\n:::\n\n```{.r .cell-code}\ntest_lrt(m.mbl0, m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |    Chi2 |      p\n---------------------------------------------------\nm.mbl0 |  mblogit |  4 |         |         |       \nm.mbl1 | mmblogit | 10 |       6 | 4981.16 | < .001\n```\n:::\n\n```{.r .cell-code}\n#DESCRIBE MODEL\nsummary(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df_i, random = list(~1 | \n    subject, ~1 | q))\n\nEquation for unknown vs orth-like:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.068      0.484   -4.27 0.000019 ***\npretty_conditionimpasse    2.080      0.212    9.83  < 2e-16 ***\n\nEquation for tri-like vs orth-like:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.387      0.538   -4.44  9.0e-06 ***\npretty_conditionimpasse    2.989      0.423    7.06  1.7e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Co-)Variances:\nGrouping level: subject \n           Estimate      Std.Err.   \nunknown~1   2.36         0.187      \ntri-like~1  3.90 12.15   1.553 4.802\n\nGrouping level: q \n           Estimate    Std.Err. \nunknown~1  2.72        25.8     \ntri-like~1 1.90 2.47   24.1 22.5\n\nNull Deviance:     9430 \nResidual Deviance: 4870 \nNumber of Fisher Scoring iterations:  13\nNumber of observations\n  Groups by subject: 330\n  Groups by q: 13\n  Individual observations:  4290\n```\n:::\n\n```{.r .cell-code}\n#INTERPRET COEFFICIENTS\ncint <- confint(m.mbl1, level = 0.95)\nprint(\"ODDS RATIO\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"ODDS RATIO\"\n```\n:::\n\n```{.r .cell-code}\n(e <- cbind( exp(coef(m.mbl1)), exp(cint))) #exponentiated, adjusted\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                         2.5 % 97.5 %\nunknown~(Intercept)               0.1264 0.049  0.326\ntri-like~(Intercept)              0.0919 0.032  0.264\nunknown~pretty_conditionimpasse   8.0025 5.285 12.118\ntri-like~pretty_conditionimpasse 19.8582 8.660 45.538\n```\n:::\n\n```{.r .cell-code}\n#PERFORMANCE\nperformance(m.mbl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Indices of model performance\n\nAIC       |       BIC |  RMSE | Sigma\n-------------------------------------\n36798.535 | 36862.176 | 0.293 | 1.066\n```\n:::\n\n```{.r .cell-code}\n#TABLE\ntab_model(m.mbl1, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Model Predicted Odds Ratio</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.05&nbsp;&ndash;&nbsp;0.33</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.09</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.03&nbsp;&ndash;&nbsp;0.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty_conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">5.28&nbsp;&ndash;&nbsp;12.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty_conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">19.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">8.66&nbsp;&ndash;&nbsp;45.54</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">330</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">4290</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 12 (z = 6.48, p \\< 0.001) . **Participants in the impasse condition were 12x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 29 (z = 4.63, p \\< 0.001 ). **Participants in the impasse condition were more than 29x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.\n\n-   As with the (binary) logistic regression on accuracy \\~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n#set model \nm <- m.mbl1\n\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, vline.color = \"red\", \n           transform = \"exp\", #for some reason have to manually add for mixed?\n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #can manually adjust to account for directional test\n           ci.lvl = 0.95) +  #can manually adjusted for directional test   \n  labs(title = \"ODDS RATIO | State ~ condition\",\n       subtitle = \"(p for  two-tailed test)\")\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-89-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(parameters)\n\n#PLOT PARAMETER ESTIMATES\nresult <- simulate_parameters(m)\nplot(result, stack = FALSE)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-89-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresult <- equivalence_test(m, rule = \"cet\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Could not estimate a good default ROPE range. Using 'c(-0.1, 0.1)'.\n```\n:::\n\n```{.r .cell-code}\nplot(result)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-89-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#raw coefficients\nplot_model(m)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-89-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#PLOT PARAMETERS\nresult <- model_parameters(m, exponentiate = TRUE, \n                           component = \"all\")\nplot(result) + \n  labs(\n  title = \"Accuracy ~ Condition + (1 | subject) + (1 | question)\",\n  subtitle = \"Logistic Mixed Effects Model\"\n)  + theme_clean() +  theme(legend.position = \"blank\") \n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-89-5.png){width=672}\n:::\n\n```{.r .cell-code}\ns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (...) \n{\n    mgcv::s(...)\n}\n<bytecode: 0x7f849707a900>\n<environment: namespace:brms>\n```\n:::\n\n```{.r .cell-code}\n#TODO CAN'T SEEM TO COMPUTE MARGINAL EFFECTS PLOT FOR THE MIXED MODEL\n# pr <- ggpredict(m, \"pretty_condition\", type = \"fixed\")\n# plot(pr)\n#PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")\n# plot_model(m, type = \"eff\")\n\n# TERNARY PLOT\n# library(plot3logit)\n# field3logit(ggpredict(m))\n#https://cran.r-project.org/web/packages/plot3logit/vignettes/plot3logit-overview.html\n\n\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">state</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.02&nbsp;&ndash;&nbsp;-1.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;3.44&nbsp;&ndash;&nbsp;-1.33</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">unknown~pretty_conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.66&nbsp;&ndash;&nbsp;2.49</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">tri-like~pretty_conditionimpasse</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.99</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.16&nbsp;&ndash;&nbsp;3.82</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>subject</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">330</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>q</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">13</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">4290</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n##### Diagnostics\n\n**COMPARE TO MANUAL MODELS**\n::: {.cell}\n\n```{.r .cell-code}\ncompare_models(m, m.unknown, m.tri)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter                        |                    m |            m.unknown |                m.tri\n-----------------------------------------------------------------------------------------------------\n(Intercept)                      |                      | -2.55 (-3.41, -1.70) | -3.57 (-4.69, -2.45)\nunknown~(Intercept)              | -2.07 (-3.02, -1.12) |                      |                     \ntri-like~(Intercept)             | -2.39 (-3.44, -1.33) |                      |                     \nunknown~pretty conditionimpasse  |  2.08 ( 1.66,  2.49) |                      |                     \ntri-like~pretty conditionimpasse |  2.99 ( 2.16,  3.82) |                      |                     \npretty condition (impasse)       |                      |  2.22 ( 1.82,  2.62) |  4.35 ( 3.11,  5.59)\n-----------------------------------------------------------------------------------------------------\nObservations                     |                 4290 |                 2824 |                 3543\n```\n:::\n:::\n\n##### Fit Model \\[brms\\]\n\n::: {.cell}\n\n```{.r .cell-code}\n#BAYESIAN MIXED VERSION\nmixcat.1 <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 backend = \"cmdstanr\",\n                 file =\"analysis/utils/models/mixcat1.rds\")\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- mixcat.1\n\n#DESCRIBE MODEL\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: muunknown = logit; mutrilike = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 4290) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muunknown_Intercept)     1.54      0.35     1.01     2.36 1.00     1571\nsd(mutrilike_Intercept)     1.22      0.29     0.80     1.93 1.00     1588\n                        Tail_ESS\nsd(muunknown_Intercept)     2624\nsd(mutrilike_Intercept)     2353\n\n~subject (Number of levels: 330) \n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muunknown_Intercept)     1.20      0.10     1.02     1.40 1.00     1570\nsd(mutrilike_Intercept)     4.09      0.27     3.59     4.67 1.00     1271\n                        Tail_ESS\nsd(muunknown_Intercept)     2708\nsd(mutrilike_Intercept)     2159\n\nPopulation-Level Effects: \n                                  Estimate Est.Error l-95% CI u-95% CI Rhat\nmuunknown_Intercept                  -2.43      0.45    -3.29    -1.52 1.00\nmutrilike_Intercept                  -3.16      0.52    -4.19    -2.12 1.00\nmuunknown_pretty_conditionimpasse     2.04      0.19     1.67     2.41 1.00\nmutrilike_pretty_conditionimpasse     3.52      0.51     2.56     4.54 1.00\n                                  Bulk_ESS Tail_ESS\nmuunknown_Intercept                   1166     1903\nmutrilike_Intercept                   1006     1533\nmuunknown_pretty_conditionimpasse     2775     3303\nmutrilike_pretty_conditionimpasse      772     1479\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# report(mixcat.1)\n\n#TABLE\n# tab_model(m,\n          # show.r2 = FALSE) #, transform = \"exp\", title = \"Model Predicted Odds Ratio\")\n\n\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n```\n:::\n\n##### Inference\n\n-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 43.86.\n\n-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 6.64.\n\n\n##### Visualize\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# #:::::::: PLOT\n# \n# #SJPLOT | MODEL | ODDS RATIO\n# #library(sjPlot)\n# plot_model(m, vline.color = \"red\", \n#            show.intercept = TRUE, \n#            show.values = TRUE,\n#            p.threshold = 0.05, #can manually adjust to account for directional test\n#            ci.lvl = 0.95 ) +  #can manually adjusted for directional test   \n#   labs(title = \"ODDS RATIO | State ~ condition\",\n#        subtitle = \"(p for one two test)\")\n# \n# \n# result <- estimate_density(m)\n# plot(result, stack = FALSE, priors = TRUE)\n# \n# result <- describe_posterior(m)\n# plot(result, stack = FALSE, priors = TRUE)\n# \n# result <- p_direction(m)\n# plot(result, stack = FALSE)\n# \n# #ROPE\n# result <- rope(m, ci = 0.89)\n# plot(result) + theme_clean()\n# \n# result <- equivalence_test(m)\n# plot(result)\n# \n# #ERROR incompatible arguments to calculate multivariate normal distribution\n# # result <- simulate_parameters(m)\n# # plot(result)\n# \n# #check posterior\n# pp_check(m, ndraws=1000)\n# \n# #PERFORMANCE\n# # performance(m)\n# \n# #Plot parameters\n# plot(model_parameters(m, exponentiate = TRUE))\n# \n# #plot marginal predictions of model\n# plot_model(m, type = \"pred\")[[1]] + \n#   labs(\n#     title = \"Model Predicted Marginal Probabilities\",\n#     x = \"Condition\", \n#     y = \"probability of being in each state\"\n#   ) + theme_clean() \n```\n:::\n\n##### COMPARE\n\n::: {.cell}\n\n```{.r .cell-code}\n# compare_models(m.unknown, m.tri, m.mbl1, mixcat.1)\n```\n:::\nThe predictions of the manual, frequentist mixed multinomial and bayesian mixed multinomial models are comparable. \n\nDECISION: Report bayesian model, because for some reason the visualization of the marginal predictions is actually working?\n\n##### TODO\n\n-   priors? used default flat priors... ok?\n-   posterior predictive checks\n-   diagnostics on random effects\n-   reconcilliation of mblogit() vs brms versions of the model; seems like they should yield similar estimates\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#BAYESIAN MIXED VERSION\n#df <- df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% filter(term==\"spring18\")\n# mm1 <- brm( state ~ condition + (1|subject), data = df, family = \"categorical\", \n# file = \"analysis/models/sgc3a_brms_mixedcat_teststate.rds\" # cache model (can be removed)))\n# summary(mm1)\n# performance(mm1)\n# plot(mm1)\n# #report(mm1)\n# #check_posterior_predictions(mm1, draws=100)\n# # library(bayesplot)\n# library(bayestestR)\n# plot(rope(mm1))\n```\n:::\n\n## WIP UNKNOWN\n\n### Cummulative Ordinal (Bayesian) --- Equal Variance\n\nhttps://journals.sagepub.com/doi/full/10.1177/2515245918823199\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\n\n\n#DEFINE DATA \ndf <- df_items %>% filter(q==1) %>% filter(mode ==\"lab-synch\")\n  \n#TODO: why is this probit instead of logit?\ncumord <- brm( formula = state ~ condition,\n               data = df,\n               family = cumulative(\"probit\"),\n               file = \"analysis/utils/models/sgc3a_brms_cumord_q1state.rds\" # cache model (can be removed)\n)\n\nsummary(cumord)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: cumulative \n  Links: mu = probit; disc = identity \nFormula: state ~ condition \n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]         0.76      0.19     0.40     1.14 1.00     2783     2309\nIntercept[2]         1.22      0.20     0.84     1.62 1.00     3000     2548\nconditionimpasse     1.11      0.24     0.66     1.58 1.00     2746     2646\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nconditional_effects(cumord, \"condition\", categorical = TRUE)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-96-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT\nplot_model(cumord)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-96-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(cumord)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-96-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(rope(cumord))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_conditionimpasse and b_Intercept[2] (r = 0.77). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-96-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#REPORT\nreport(cumord)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_conditionimpasse and b_Intercept[2] (r = 0.77). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_conditionimpasse and b_Intercept[2] (r = 0.77). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL '3a68d5685b54180e73711b90f350310a' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.104655 seconds (Warm-up)\nChain 1:                0.116506 seconds (Sampling)\nChain 1:                0.221161 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL '3a68d5685b54180e73711b90f350310a' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.110988 seconds (Warm-up)\nChain 2:                0.116263 seconds (Sampling)\nChain 2:                0.227251 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL '3a68d5685b54180e73711b90f350310a' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.2e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.105778 seconds (Warm-up)\nChain 3:                0.099159 seconds (Sampling)\nChain 3:                0.204937 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL '3a68d5685b54180e73711b90f350310a' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.105963 seconds (Warm-up)\nChain 4:                0.110911 seconds (Sampling)\nChain 4:                0.216874 seconds (Total)\nChain 4: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between b_conditionimpasse and b_Intercept[2] (r = 0.76). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is likely invalid for ordinal families.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a Bayesian probit model (estimated using MCMC sampling with 4 chains of 2000 iterations and a warmup of 1000) to predict state with condition (formula: state ~ condition). Priors over parameters were set as uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50) and uniform (location = , scale = ) distributions. The model's explanatory power is moderate (R2 = 0.18, 95% CI [0.07, 0.28]).  Within this model:\n\n  - The effect of b Intercept[1] (Median = 0.75, 95% CI [0.40, 1.14]) has a 100.00% probability of being positive (> 0), 99.98% of being significant (> 0.05), and 99.35% of being large (> 0.30). The estimation successfully converged (Rhat = 0.999) and the indices are reliable (ESS = 2725)\n  - The effect of b Intercept[2] (Median = 1.22, 95% CI [0.84, 1.62]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 100.00% of being large (> 0.30). The estimation successfully converged (Rhat = 1.000) and the indices are reliable (ESS = 2723)\n  - The effect of b conditionimpasse (Median = 1.11, 95% CI [0.66, 1.58]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 99.92% of being large (> 0.30). The estimation successfully converged (Rhat = 1.000) and the indices are reliable (ESS = 3047)\n\nFollowing the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.05| and |0.30|. Convergence and stability of the Bayesian sampling has been assessed using R-hat, which should be below 1.01 (Vehtari et al., 2019), and Effective Sample Size (ESS), which should be greater than 1000 (Burkner, 2017).\n```\n:::\n\n```{.r .cell-code}\n# ord_cum %>%\n#   spread_draws(b_Intercept, r_condition[condition,]) %>%\n#   mutate(condition_mean = b_Intercept + r_condition) %>%\n#   ggplot(aes(y = condition, x = condition_mean)) +\n#   stat_halfeye()\n\n# performance(cumord)\n# plot(cumord)\n```\n:::\n\n### Cummulative Ordinal (Bayesian) --- Unequal Variance\n\nhttps://journals.sagepub.com/doi/full/10.1177/2515245918823199\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\n\n\n#DEFINE DATA \ndf <- df_items %>% filter(q==1) %>% filter(mode ==\"lab-synch\")\n  \n#TODO: why is this probit instead of logit?\nu.cumord <- brm( \n  formula = bf(state ~ condition) +\n               lf(disc ~ 0 + condition, cmc = FALSE),\n               data = df,\n               family = cumulative(\"probit\"),\n               file = \"analysis/utils/models/sgc3a_brms_ucumord_q1state.rds\" # cache model (can be removed)\n)\n\nsummary(u.cumord)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There were 76 divergent transitions after warmup. Increasing\nadapt_delta above 0.8 may help. See http://mc-stan.org/misc/\nwarnings.html#divergent-transitions-after-warmup\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: cumulative \n  Links: mu = probit; disc = log \nFormula: state ~ condition \n         disc ~ 0 + condition\n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept[1]              0.83      0.18     0.48     1.19 1.00     1294\nIntercept[2]              1.00      0.19     0.66     1.38 1.01     1236\nconditionimpasse          0.95      0.19     0.60     1.32 1.01     1325\ndisc_conditionimpasse     1.48      0.56     0.41     2.64 1.01      302\n                      Tail_ESS\nIntercept[1]              1484\nIntercept[2]              1540\nconditionimpasse          1717\ndisc_conditionimpasse      142\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nconditional_effects(u.cumord, \"condition\", categorical = TRUE)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-97-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#SJPLOT\nplot_model(u.cumord)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-97-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(u.cumord)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-97-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(rope(u.cumord))\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-97-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#REPORT\nreport(u.cumord)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL '8051b427c5dbb5a865c588f34a9e215a' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.453928 seconds (Warm-up)\nChain 1:                0.262774 seconds (Sampling)\nChain 1:                0.716702 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL '8051b427c5dbb5a865c588f34a9e215a' NOW (CHAIN 2).\nChain 2: Rejecting initial value:\nChain 2:   Log probability evaluates to log(0), i.e. negative infinity.\nChain 2:   Stan can't start sampling from this initial value.\nChain 2: \nChain 2: Gradient evaluation took 2.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.443154 seconds (Warm-up)\nChain 2:                0.386187 seconds (Sampling)\nChain 2:                0.829341 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL '8051b427c5dbb5a865c588f34a9e215a' NOW (CHAIN 3).\nChain 3: Rejecting initial value:\nChain 3:   Log probability evaluates to log(0), i.e. negative infinity.\nChain 3:   Stan can't start sampling from this initial value.\nChain 3: Rejecting initial value:\nChain 3:   Log probability evaluates to log(0), i.e. negative infinity.\nChain 3:   Stan can't start sampling from this initial value.\nChain 3: \nChain 3: Gradient evaluation took 2.9e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.385624 seconds (Warm-up)\nChain 3:                0.474365 seconds (Sampling)\nChain 3:                0.859989 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL '8051b427c5dbb5a865c588f34a9e215a' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.6e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.357993 seconds (Warm-up)\nChain 4:                0.305731 seconds (Sampling)\nChain 4:                0.663724 seconds (Total)\nChain 4: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is likely invalid for ordinal families.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a Bayesian probit model (estimated using MCMC sampling with 4 chains of 2000 iterations and a warmup of 1000) to predict state with condition (formula: state ~ condition). Priors over parameters were set as uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), uniform (location = , scale = ) and uniform (location = , scale = ) distributions. The model's explanatory power is moderate (R2 = 0.17, 95% CI [0.06, 0.26]).  Within this model:\n\n  - The effect of b Intercept[1] (Median = 0.83, 95% CI [0.48, 1.19]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 99.92% of being large (> 0.30). The estimation successfully converged (Rhat = 1.006) and the indices are reliable (ESS = 1320)\n  - The effect of b Intercept[2] (Median = 1.00, 95% CI [0.66, 1.38]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 100.00% of being large (> 0.30). The estimation successfully converged (Rhat = 1.006) but the indices are unreliable (ESS = 312)\n  - The effect of b conditionimpasse (Median = 0.94, 95% CI [0.60, 1.32]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 100.00% of being large (> 0.30). The estimation successfully converged (Rhat = 1.003) and the indices are reliable (ESS = 1284)\n  - The effect of b disc conditionimpasse (Median = 1.45, 95% CI [0.41, 2.64]) has a 99.78% probability of being positive (> 0), 99.72% of being significant (> 0.05), and 98.45% of being large (> 0.30). The estimation successfully converged (Rhat = 1.006) and the indices are reliable (ESS = 1238)\n\nFollowing the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.05| and |0.30|. Convergence and stability of the Bayesian sampling has been assessed using R-hat, which should be below 1.01 (Vehtari et al., 2019), and Effective Sample Size (ESS), which should be greater than 1000 (Burkner, 2017).\n```\n:::\n\n```{.r .cell-code}\n# ord_cum %>%\n#   spread_draws(b_Intercept, r_condition[condition,]) %>%\n#   mutate(condition_mean = b_Intercept + r_condition) %>%\n#   ggplot(aes(y = condition, x = condition_mean)) +\n#   stat_halfeye()\n\n# performance(cumord)\n# plot(cumord)\n```\n:::\n\nIn brms, the parameter related to latent variances is called disc (short for \"discrimination\"), following conventions in item response theory. Note that disc is not the variance itself, but the inverse of the standard deviation, s. That is, s = 1/disc. Further, because disc must be strictly positive, it is by default modeled on the log scale.\n\n### Adjacent-Category Ordinal (Bayesian)\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df_items %>% filter(q==1) %>% filter(mode ==\"lab-synch\")\n\n\n# # To specify an adjacent-category model, we use family = acat() instead of family = cumulative() as an argument to the brm() function. Then, to model condition with possible category-specific effects, we wrap this variable in cs() in the model’s formula:\n\nadjcat <- brm( formula = state ~ cs(condition),\n               data = df,\n               family = acat(\"probit\"),\n               file = \"analysis/utils/models/sgc3a_brms_adjcat_q1state.rds\" # cache model (can be removed)\n)\n \nsummary(adjcat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: acat \n  Links: mu = probit; disc = identity \nFormula: state ~ cs(condition) \n   Data: df (Number of observations: 126) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept[1]            2.01      0.38     1.36     2.88 1.00      639      551\nIntercept[2]           -1.29      0.49    -2.36    -0.41 1.00      614      579\nconditionimpasse[1]     1.95      0.43     1.16     2.90 1.00      674      589\nconditionimpasse[2]    -1.06      0.53    -2.20    -0.11 1.00      586      604\n\nFamily Specific Parameters: \n     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndisc     1.00      0.00     1.00     1.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\nconditional_effects(cumord, \"condition\", categorical = TRUE)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-98-1.png){width=672}\n:::\n\n```{.r .cell-code}\nconditional_effects(adjcat, \"condition\", categorical = TRUE)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-98-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#WHICH IS BETTER? cumulative or adjacent?\nplot(compare_performance(cumord, adjcat))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: A `range` must be provided for data with only one unique value.\n```\n:::\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-98-3.png){width=672}\n:::\n\n```{.r .cell-code}\ncompare_performance(cumord, adjcat)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# Comparison of Model Performance Indices\n\nName   |   Model |     ELPD | ELPD_SE |   LOOIC | LOOIC weights | LOOIC_SE |    WAIC | WAIC weights |    R2 | Sigma\n-------------------------------------------------------------------------------------------------------------------\ncumord | brmsfit | -113.736 |   7.542 | 227.471 |         0.071 |   15.085 | 227.450 |        0.002 | 0.178 | 1.000\nadjcat | brmsfit | -107.521 |   7.199 | 215.042 |         0.929 |   14.397 | 214.897 |        0.998 | 0.171 | 1.000\n```\n:::\n\n```{.r .cell-code}\n# #TIDYBAYES VISUALIZATION\n# library(tidybayes)\n# adjcat %>%\n#   spread_draws(b_Intercept, r_condition[condition,]) %>%\n#   mutate(condition_mean = b_Intercept + r_condition) %>%\n#   ggplot(aes(y = condition, x = condition_mean)) +\n#   stat_halfeye()\n\nplot(cumord)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-98-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(adjcat)\n```\n\n::: {.cell-output-display}\n![](modelling_ref_files/figure-html/unnamed-chunk-98-5.png){width=672}\n:::\n\n```{.r .cell-code}\nreport(adjcat)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between bcs_conditionimpasse[1] and b_Intercept[2] (r = 0.83), bcs_conditionimpasse[2] and bcs_conditionimpasse[1] (r = 0.86). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is\nlikely invalid for ordinal families.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between bcs_conditionimpasse[1] and b_Intercept[2] (r = 0.83), bcs_conditionimpasse[2] and bcs_conditionimpasse[1] (r = 0.86). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStart sampling\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'ebf0c4c0e51ade2b00ca4594e215d3ad' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000125 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.25 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.35813 seconds (Warm-up)\nChain 1:                1.74949 seconds (Sampling)\nChain 1:                3.10762 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'ebf0c4c0e51ade2b00ca4594e215d3ad' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 0.000101 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.01 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.48609 seconds (Warm-up)\nChain 2:                1.56339 seconds (Sampling)\nChain 2:                3.04949 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'ebf0c4c0e51ade2b00ca4594e215d3ad' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 0.000106 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.46677 seconds (Warm-up)\nChain 3:                1.43753 seconds (Sampling)\nChain 3:                2.9043 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'ebf0c4c0e51ade2b00ca4594e215d3ad' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 0.000102 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 1.02 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.41558 seconds (Warm-up)\nChain 4:                1.46047 seconds (Sampling)\nChain 4:                2.87605 seconds (Total)\nChain 4: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPossible multicollinearity between bcs_conditionimpasse[1] and b_Intercept[2] (r = 0.82), bcs_conditionimpasse[2] and bcs_conditionimpasse[1] (r = 0.86). This might lead to inappropriate results. See 'Details' in '?rope'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions are treated as continuous variables in 'bayes_R2' which is likely invalid for ordinal families.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a Bayesian probit model (estimated using MCMC sampling with 4 chains of 2000 iterations and a warmup of 1000) to predict state with condition (formula: state ~ cs(condition)). Priors over parameters were set as uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), uniform (location = , scale = ), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), student_t (location = 0.00, scale = 2.50), NA (NA) and NA (NA) distributions. The model's explanatory power is moderate (R2 = 0.17, 95% CI [0.07, 0.27]).  Within this model:\n\n  - The effect of b Intercept[1] (Median = 1.97, 95% CI [1.36, 2.88]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 100.00% of being large (> 0.30). The estimation successfully converged (Rhat = 1.005) but the indices are unreliable (ESS = 580)\n  - The effect of b Intercept[2] (Median = -1.25, 95% CI [-2.36, -0.41]) has a 99.85% probability of being negative (< 0), 99.83% of being significant (< -0.05), and 98.78% of being large (< -0.30). The estimation successfully converged (Rhat = 1.005) but the indices are unreliable (ESS = 577)\n  - The effect of bcs conditionimpasse[1] (Median = 1.92, 95% CI [1.16, 2.90]) has a 100.00% probability of being positive (> 0), 100.00% of being significant (> 0.05), and 100.00% of being large (> 0.30). The estimation successfully converged (Rhat = 1.004) but the indices are unreliable (ESS = 629)\n  - The effect of bcs conditionimpasse[2] (Median = -1.02, 95% CI [-2.20, -0.11]) has a 98.40% probability of being negative (< 0), 98.05% of being significant (< -0.05), and 93.62% of being large (< -0.30). The estimation successfully converged (Rhat = 1.005) but the indices are unreliable (ESS = 560)\n\nFollowing the Sequential Effect eXistence and sIgnificance Testing (SEXIT) framework, we report the median of the posterior distribution and its 95% CI (Highest Density Interval), along the probability of direction (pd), the probability of significance and the probability of being large. The thresholds beyond which the effect is considered as significant (i.e., non-negligible) and large are |0.05| and |0.30|. Convergence and stability of the Bayesian sampling has been assessed using R-hat, which should be below 1.01 (Vehtari et al., 2019), and Effective Sample Size (ESS), which should be greater than 1000 (Burkner, 2017).\n```\n:::\n:::\n\n*Converges, but estimates are unreliable?*\n\n\n## HELPERS\n\n### Odds and Probabilities \n::: {.cell}\n\n```{.r .cell-code}\n# t <- table( df$pretty_condition, df$accuracy)\n# \n# print(\"AS FREQUENCY\")\n# t %>% addmargins()\n# \n# print(\"AS PROBABILITY\")\n# prop.table(t) %>% addmargins()\n# \n# print(\"GRAND PROBABILITY\")\n# (p_grand <-  sum(t[,2]) / sum(t))\n# print(\"GRAND ODDS\")\n# (odds_grand <- sum(t[,2]) / sum(t[,1]))\n# \n# print(\"P_control\")\n# (p_control <- t[1,2]/sum(t[1,]))\n# print(\"ODDS_control\") # correct:incorrect\n# (odds_control <- t[1,2] / t[1,1])\n# \n# print(\"P_impasse\")\n# (p_impasse <- t[2,2] / sum(t[2,]))\n# print(\"ODDS_impasse\") # correct:incorrect\n# (odds_impasse <- t[2,2] / t[2,1])\n# # \n# paste(\"ODDS RATIO FOR IMPASSE\", odds_impasse-odds_control)\n\n# to calculate odds from odds ratio ... ODDS = OR * [denominator of ratio]\n#eg.  ODDS [impasse] = OR[impasse] * ODDS[control] = [b_impasse] * [intercept] #for dummy coding \n```\n:::\n\n## GGDist bayesian posterior vis\n\n::: {.cell}\n\n```{.r .cell-code}\n# df <- df_i %>% filter(q %nin% c(6,9)) %>% droplevels()\n# \n# #WORKING visualize post dist of prediction\n# #create df of 'draws' from the \n# draws <- df %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_predicted_draws(Bmm.CrSQ) \n# \n# #visualize the predictions\n# x <- draws %>% \n#   ggplot(aes(x = .prediction, y = pretty_condition)) +\n#   stat_slab() + labs(title = \"Posterior Predictions??\")\n\n# \n# #WORKING visualize parameter distribution?\n# #create df of 'draws' from the \n# draws2 <- df %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_linpred_draws(Bmm.CrSQ,\n#                       re_formula = NA) %>%     # zero out random effects (condition on average subj avg q)) %>% \n#   ungroup() \n#   # filter(!duplicated(.)) \n#   # mutate(probs = exp(.prediction)/(1+ exp(.prediction)))\n# \n# #visualize the predictions\n# draws2 %>% \n#   ggplot(aes(x = .linpred, y = pretty_condition)) +\n#   stat_slab()\n# \n# \n# #WORKING visualize posterior distribution as probabilities?\n# #create df of 'draws' from the \n# draws2 <- df %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_epred_draws(Bmm.CrSQ,\n#                    re_formula = NA)\n#                 \n# #visualize the predictions\n# draws2 %>% \n#   ggplot(aes(x = .epred, y = pretty_condition)) +\n#   stat_slab()\n# \n# \n# \n# #WORKING visualize posterior distribution as probabilities?\n# #create df of 'draws' from the \n# draws3 <- df %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.CrSQ,\n#                    # scale = \"linear\", without scale linear, .value is probability of %\n#                    re_formula = NA) %>% \n#   ungroup() \n#   # filter(!duplicated(.)) \n#   # mutate(probs = exp(.value)/(1+ exp(.value))) #same as scale = linear and doing the transformation manually\n# \n# #visualize the predictions\n# draws3 %>% \n#   ggplot(aes(x = .value, y = pretty_condition)) +\n#   stat_slab() \n# #x = .value plots the distribution of the ODDS ratios?\n# #without the scale = linear... gives probabilities of correct response?\n# \n# \n# THE GOOD ONE\n\n##WORKING\n## VIS probability of correct response\n# draws <- df %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_linpred_draws(Bmm.CrSQ,\n#                    transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA) \n# \n# #visualize the predictions\n# #TODO adjust bandwidth/smoothing? + put on same line + \n# draws %>%  \n#   ggplot(aes(x = .linpred,  y = 0, fill = pretty_condition)) +\n#   stat_halfeye(width = c(.95), alpha = 0.5) + \n#   xlim(0,1) + labs(\n#     title = \"Model Predicted Probability of Correct Response\",\n#     x = \"probability of correct response\",\n#     y = \"condition\"\n#   ) +  theme_clean() + ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# \n# #equivalent to...this! \n# # plot_model(Bmm.CrSQ, type  = \"pred\")[[1]]+ylim(0,1) + coord_flip()\n```\n:::",
    "supporting": [
      "modelling_ref_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}