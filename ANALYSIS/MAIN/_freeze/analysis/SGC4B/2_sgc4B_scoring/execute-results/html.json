{
  "hash": "4a48585a5d4aa33a68cb1b9787646508",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC4B | 2 Response Scoring'\n---\n\n\\newpage\n\n# Response Scoring {#sec-SGC4B-scoring}\n\n*The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC4B study. This is required because the question type on the graph comprehension task used a 'Multiple Response' (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.)* To review the strategy behind Multiple Response scoring for the SGC project, refer to section @sec-scoring.\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=1, digits=3)\n\nlibrary(kableExtra) #printing tables \nlibrary(ggformula) #quick graphs\nlibrary(pbapply) #progress bar and time estimate for *apply fns\nlibrary(Hmisc) # %nin% operator\nlibrary(tidyverse) #ALL THE THINGS\n```\n:::\n\n## SCORE SGC DATA \n\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section @sec-scoring.\n\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The **graph comprehension task** asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant's performance, for each question (q=15) we will calculate the following scores:\n\n*An overall, strict score:*\\\n1. **Absolute Score** : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\n\n*Sub-scores, for each alternative graph interpretation*\\\n2. **Triangular Score** : using partial scoring \\[-1/q, +1/p\\] referencing true (Triangular) answer key.\n\n3\\. **Orthogonal Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect Orthogonal) answer key.\n\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n\n4\\. **Tversky Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect connecting-lines strategy) answer key. 5. **Satisficing Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect satisficing strategy) answer key.\n\n### Prepare Answer Keys {#sec-SGC4B-keys}\n\nWe start by importing three answer keys: (1) Q1 - Q5 \\[control condition\\], (2) Q1-Q5 \\[impasse condition\\], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n```\n:::\n\n### Calculate Subscores {#sec-SGC4B-subscores}\n\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response `df_items$response` with the answer keys in each interpretation (e.g. `keys_orth`, `keys_tri`, etc...), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial\\[-1/q, +1/p\\] scores for each interpretation. The resulting scores are then stored on each item in `df_items`, and can be used to determine which graph interpretation the subject held.\n\nSpecifically, the following scores are calculated for each item:\n\n**Interpretation Subscores**\n\n-   `score_TRI` How consistent is the response with the **triangular**interpretation?\n-   `score_ORTH` How consistent is the response with the **orthogonal**interpretation?\n-   `score_SATISFICE` is calculated by taking the maximum value of :\n    -   `score_SAT_left` How consistent is the response with the **(left side) Satisficing** interpretation?\n    -   `score_SAT_right` How consistent is the response with the **(right side) Satisficing** interpretation\n-   `score_TVERSKY` is calculated by taking the maximum value of:\n    -   `score_TV_max` How consistent is the response with the **(maximal) Tversky** interpretation?\n    -   `score_TV_start` How consistent is the response with the **(start-time) Tversky** interpretation?\n    -   `score_TV_end` How consistent is the response with the **(end-time) Tversky** interpretation?\n    -   `score_TV_duration` How consistent is the response with the **(duration) Tversky** interpretation?\n-   `score_REF` Did the response select only the **reference point**?\n-   `score_BOTH` How consistent is the response with **both** the orthogonal and triangular interpretations?\n\n**Absolute Scores**\n\n-   `score_ABS` Is the response strictly correct? (triangular interpretation)\n-   `score_niceABS` Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer *in addition to* they also select the data point referenced in the question.\n\n::: {.cell}\n\n```{.r .cell-code}\n#HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#backup <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_items.rds')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n```\n:::\n\n*note: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records*\n\n::: {.cell hash='2_sgc4B_scoring_cache/html/CALCULATE-SCORES-MAPPLY_089fe1953136007003b179f2c2c94cfc'}\n\n```{.r .cell-code}\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tri))\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_orth))\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\ndf_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n```\n:::\n\n### Derive Interpretation {#sec-SGC4B-interpretation}\n\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more 'special' situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn't match a special situation, it compares the individual subscores, and subscores and decides if they are *discriminant* (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as \"?\", indicating it cannot be classified, and is of an unknown interpretation.\n\nThe final output is called `interpretation`.\n\n::: {.cell hash='2_sgc4B_scoring_cache/html/DERIVE-INTERPRETATION_ae75160af5d95cffb90b32b3cf734c0c'}\n\n```{.r .cell-code}\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items \ntemp <- derive_interpretation(temp)\ndf_items <- temp \n```\n:::\n\n\n### Derive Scaled Score {#sec-SGC4B-scaledScore}\n\nThe `interpretation` response variable gives us the finest grain indication of the reader's understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a *scaled_score* that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\n\nSpecifically, we assign the following values to each interpretation:\n\n-   (-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n-   (-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n-   (0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n-   (+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they \"see\" a triangular response, but lack certainty and also select the ORTHOGONAL response)\n-   (+1) TRIANGULAR +1\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n```\n:::\n\n## SUMMARIZE BY SUBJECT\n\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\ndf_subjects <- test_subs\n```\n:::\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task. \n\n::: {.cell}\n\n```{.r .cell-code}\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)\n```\n:::\n\n\n## EXPLORE DISTRIBUTIONS\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  pretty_condition = pretty_condition,\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n```\n:::\n\n### Absolute Score\n\n::: {.cell}\n\n```{.r .cell-code}\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-ABSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>%\n  gf_facet_grid(pretty_condition~q) +\n  labs( x = \"Absolute Score\",\n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-ABSCORE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-ABSCORE-3.png){width=672}\n:::\n:::\n\n### Scaled Score\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-SCALEDSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>%\n  gf_facet_grid(q~pretty_condition) +\n  labs( x = \"Scaled Score\",\n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) +\n  theme_minimal() + theme(legend.position=\"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-SCALEDSCORE-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>%\n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\",\n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-SCALEDSCORE-3.png){width=672}\n:::\n:::\n### Interpretations\n\n::: {.cell}\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-INTERPRETATIONS-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-INTERPRETATIONS-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DISTR-INTERPRETATIONS-3.png){width=672}\n:::\n:::\n\n### Progress over Task\n\n::: {.cell}\n\n```{.r .cell-code}\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/VIZ-PROGRESS-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/VIZ-PROGRESS-2.png){width=672}\n:::\n:::\n\n### Interpretation Subscores\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DIST-SUBSCORES-1.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DIST-SUBSCORES-2.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DIST-SUBSCORES-3.png){width=672}\n:::\n\n```{.r .cell-code}\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4B_scoring_files/figure-html/DIST-SUBSCORES-4.png){width=672}\n:::\n:::\n## PEEKING\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\nlibrary(report)\nm1 <- lm(s_SCALED ~ pretty_condition, data = df_subjects)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = s_SCALED ~ pretty_condition, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -8.55  -5.55  -3.72   1.78  20.62 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             -7.621      0.891   -8.55  9.2e-16 ***\npretty_conditionarrow    3.172      1.237    2.56    0.011 *  \npretty_conditioncross    1.344      1.290    1.04    0.299    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.5 on 269 degrees of freedom\nMultiple R-squared:  0.0241,\tAdjusted R-squared:  0.0168 \nF-statistic: 3.32 on 2 and 269 DF,  p-value: 0.0376\n```\n:::\n\n```{.r .cell-code}\nanova(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: s_SCALED\n                  Df Sum Sq Mean Sq F value Pr(>F)  \npretty_condition   2    480   240.0    3.32  0.038 *\nResiduals        269  19434    72.2                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nreport(m1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with pretty_condition (formula: s_SCALED ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.02, F(2, 269) = 3.32, p = 0.038, adj. R2 = 0.02). The model's intercept, corresponding to pretty_condition = point, is at -7.62 (95% CI [-9.38, -5.87], t(269) = -8.55, p < .001). Within this model:\n\n  - The effect of pretty condition [arrow] is statistically significant and positive (beta = 3.17, 95% CI [0.74, 5.61], t(269) = 2.56, p = 0.011; Std. beta = 0.37, 95% CI [0.09, 0.65])\n  - The effect of pretty condition [cross] is statistically non-significant and positive (beta = 1.34, 95% CI [-1.20, 3.88], t(269) = 1.04, p = 0.299; Std. beta = 0.16, 95% CI [-0.14, 0.45])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation.\n```\n:::\n:::\n## EXPORT\n\nFinally, we export the scores for each item (`df_items`) and summarized over subjects (`df_subjects`), as well as cumulative progress dataframes (`df_absolute_progress`, `df_scaled_progress`)\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4B/data/2-scored-data/sgc4b_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4B/data/2-scored-data/sgc4b_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4B/data/2-scored-data/sgc4b_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4B/data/2-scored-data/sgc4b_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4B/data/2-scored-data/sgc4b_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4B/data/2-scored-data/sgc4b_scored_items.rds\") # to R data structure file\n```\n:::\n\n## RESOURCES\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      performance_0.9.1 forcats_0.5.1     stringr_1.4.0    \n [5] dplyr_1.0.9       purrr_0.3.4       readr_2.1.2       tidyr_1.2.0      \n [9] tibble_3.1.7      tidyverse_1.3.1   Hmisc_4.7-0       Formula_1.2-4    \n[13] survival_3.3-1    lattice_0.20-45   pbapply_1.5-0     ggformula_0.10.1 \n[17] ggridges_0.5.3    scales_1.2.0      ggstance_0.3.5    ggplot2_3.3.6    \n[21] kableExtra_1.3.4 \n\nloaded via a namespace (and not attached):\n [1] fs_1.5.2            bit64_4.0.5         lubridate_1.8.0    \n [4] insight_0.17.1      webshot_0.5.3       RColorBrewer_1.1-3 \n [7] httr_1.4.3          tools_4.2.1         backports_1.4.1    \n[10] utf8_1.2.2          R6_2.5.1            rpart_4.1.16       \n[13] DBI_1.1.3           colorspace_2.0-3    nnet_7.3-17        \n[16] withr_2.5.0         tidyselect_1.1.2    gridExtra_2.3      \n[19] curl_4.3.2          bit_4.0.4           compiler_4.2.1     \n[22] cli_3.3.0           rvest_1.0.2         htmlTable_2.4.0    \n[25] xml2_1.3.3          bayestestR_0.12.1   labeling_0.4.2     \n[28] mosaicCore_0.9.0    checkmate_2.1.0     systemfonts_1.0.4  \n[31] digest_0.6.29       foreign_0.8-82      rmarkdown_2.14     \n[34] svglite_2.1.0       rio_0.5.29          base64enc_0.1-3    \n[37] jpeg_0.1-9          pkgconfig_2.0.3     htmltools_0.5.2    \n[40] labelled_2.9.1      dbplyr_2.2.1        fastmap_1.1.0      \n[43] readxl_1.4.0        htmlwidgets_1.5.4   rlang_1.0.3        \n[46] rstudioapi_0.13     farver_2.1.0        generics_0.1.2     \n[49] jsonlite_1.8.0      vroom_1.5.7         zip_2.2.0          \n[52] magrittr_2.0.3      parameters_0.18.1   Matrix_1.4-1       \n[55] Rcpp_1.0.8.3        munsell_0.5.0       fansi_1.0.3        \n[58] lifecycle_1.0.1     stringi_1.7.6       yaml_2.3.5         \n[61] MASS_7.3-57         plyr_1.8.7          grid_4.2.1         \n[64] parallel_4.2.1      crayon_1.5.1        haven_2.5.0        \n[67] splines_4.2.1       hms_1.1.1           knitr_1.39         \n[70] pillar_1.7.0        effectsize_0.7.0    reprex_2.0.1       \n[73] glue_1.6.2          evaluate_0.15       latticeExtra_0.6-29\n[76] data.table_1.14.2   modelr_0.1.8        tzdb_0.3.0         \n[79] png_0.1-7           vctrs_0.4.1         tweenr_1.0.2       \n[82] cellranger_1.1.0    gtable_0.3.0        polyclip_1.10-0    \n[85] datawizard_0.4.1    assertthat_0.2.1    openxlsx_4.2.5     \n[88] xfun_0.31           ggforce_0.3.3       broom_0.8.0        \n[91] viridisLite_0.4.0   cluster_2.1.3       ellipsis_0.3.2     \n```\n:::\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}