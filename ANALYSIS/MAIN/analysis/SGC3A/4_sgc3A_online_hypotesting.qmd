---
subtitle: 'Study SGC3A | (Online) Hypothesis Testing'
# YAML FOR generating modelsummary tables
# uncomment to run those  cells only 
# \usepackage{booktabs}
# \usepackage{siunitx}
# \newcolumntype{d}{S[input-symbols = ()]}
---

\newpage

# (Online) Hypothesis Testing {#sec-SGC3A-online-hypotesting}

*The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study ONLINE REPLICATION WITH OSPAN.*

```{r}
#| label: SETUP
#| warning : false
#| message : false

#UTILITIES
library(Hmisc) # %nin% operator
library(broom) #tidy model output
library(mosaic) #favstats
# library(modelr)
library(distributional)
# library(jtools)
# library(pwr) #power analysis

#VISUALIZATION
# library(ggpubr) #arrange plots
# library(cowplot) #arrange shift function plots
library(ggformula) #easy graphs
# # library(vcd) #mosaic plots
# # library(vcdExtra) #mosaic plots
library(kableExtra) #printing tables
library(sjPlot) #visualize model coefficients
library(ggdist) #uncertainty viz
library(gghalves) # plots. in half
library(ggbeeswarm) # violin plot stuffs
library(statsExpressions)
library(ggstatsplot) #plots with stats
library(modelsummary) #latex tables for models!

#MODELLING
# library(rstatix) #helpful testing functions incl wilcoxon, etc
library(report) #easystats reporting
library(see) #easystats visualization
library(performance) #easystats model diagnostics
library(parameters) #easystats model summary and vis
# library(qqplotr) #confint on qq plot
# library(gmodels) #contingency table and CHISQR
# library(equatiomatic) #extract model equation
# library(pscl) #zeroinfl / hurdle models 
library(lme4) #mixed effects models
library(lmerTest) #for CIs in glmer
# library(ggeffects) #visualization log regr models
#MULTINOMIAL 
library(nnet) #multinomial logistic regression [not mixed] #no p values
library(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values
#BAYESIAN
library(cmdstanr) #executing stan
library(brms) #bayesian mixed multinomials [+ other bayesian reg models]
library(bayestestR) 

library(tidyverse) #ALL THE THINGS

#OUTPUT OPTIONS
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
options(ggplot2.summarise.inform = FALSE)
options(scipen=1, digits=3)

#GRAPH THEMEING
# theme_set(theme_minimal()) 

# Custom ggplot theme to make pretty plots
# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed
theme_clean <- function() {
  theme_minimal(base_family = "Barlow Semi Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "BarlowSemiCondensed-Bold"),
          axis.title = element_text(family = "BarlowSemiCondensed-Medium"),
          strip.text = element_text(family = "BarlowSemiCondensed-Bold",
                                    size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA))
}

set_theme(base = theme_clean())

```

**TODO UPDATE Research Questions**

In SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task?

**Experimental Hypothesis**\
*Learners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.*

-   H1A \| Learners in the IMPASSE condition will score higher overall than learners in CONTROL.
-   H1B \| Learners in the IMPASSE condition will be more likely to correctly answer the first question than learners in CONTROL.

**Null Hypothesis**\
*No significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions.*

```{r}
#| label: IMPORT-DATA
#| warning : false
#| message : false

#IMPORT DATA 

df_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_ospan.rds') %>% mutate(
  task_percent = DV_percent_NABS
) %>% droplevels()

df_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_ospan.rds') %>% 
   mutate (
    q = as.factor(q), 
    subject = as.factor(subject),
    accuracy = recode_factor(score_niceABS, "0" ="incorrect","1"="correct"),
    # CODES TVERSKY AS TRI-LIKE
    # state = recode_factor(score_SCALED, #for ordinal
    #                      "-1" = "orth-like",
    #                      "-0.5" = "unknown",
    #                      "0" = "unknown",
    #                      "0.5" = "tri-like",
    #                      "1" = "tri-like"),
    # CODES TVERSKY AS OTHER
    state = recode_factor(score_SCALED, #for ordinal
                         "-1" = "orthogonal",
                         "-0.5" = "other",
                         "0" = "other",
                         "0.5" = "tri-like",
                         "1" = "triangular"),
    state = as.ordered(state)) 

```

## SAMPLE

### Data Collection

Data was collected (online, via SONA) in Fall 2021. TODO ADDITIONAL SUMMER 2022? Note that approximately 200 subjects were run in Fall 2021, but only 133 of them completed the OSPAN task. Therefore subjects who did not complete the task are discarded from analysis.

```{r}
#| label : DESC-DATA-COLLECTION

title = "Participants by Condition and Data Collection Period"
cols = c("Control Condition","Impasse Condition","Total for Period")
cont <- table(df_subjects$term, df_subjects$condition)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

```

### Participants

```{r}
#| label: DESC-PARTICIPANTS

#Describe participants
subject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()
subject.stats$percent.male <- ((df_subjects %>% filter(gender=="Male") %>% count())/count(df_subjects))$n
subject.stats$percent.female <- ((df_subjects %>% filter(gender=="Female") %>% count())/count(df_subjects))$n
subject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c("Female","Male")) %>% count())/count(df_subjects))$n


title = "Descriptive Statistics of Participant Age and Gender"
subject.stats %>% kbl (caption = title) %>% kable_classic()%>% 
  footnote(general = "Age in Years", 
           general_title = "Note: ",footnote_as_chunk = T) 
```



**Overall** `r subject.stats$n` participants (`r round((subject.stats$percent.male),2) * 100` % male, `r round((subject.stats$percent.female),2) * 100` % female, `r round((subject.stats$percent.other),2) * 100` % other)  undergraduate STEM majors at a public American University participated in exchange for course credit (age: `r (subject.stats$min)` - `r (subject.stats$max)` years).





### OSPAN



```{r}
#| label: DESC-SUBJ-OSPAN
 
title = "Descriptive Statistics of OSPAN Task Accuracy"
ospan.stats <- rbind(
  "MATH" = df_subjects %>% dplyr::select(OSPAN.math_acc) %>% unlist() %>% favstats(),
  "ORDER" = df_subjects %>%  dplyr::select(OSPAN.order_acc) %>% unlist() %>% favstats(),
  "WEIGHTED" = df_subjects %>% dplyr::select(OSPAN.weighted) %>% unlist() %>% favstats()

)
ospan.stats %>% kbl (caption = title) %>% kable_classic() %>%
  footnote(general = "MATH = %correct of all math questions;
           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct", general_title = "Note: ",footnote_as_chunk = T)

```


```{r}
#| label: VIS-SUBJ-OSPAN

# #GGFORMULA | DENSITY HISTOGRAM 
 med = median(df_subjects$OSPAN.weighted)
  gf_dhistogram(~OSPAN.weighted, data = df_subjects) %>% 
  gf_vline(xintercept = ~med, color = "red") +
  labs(x = "OSPAN (weighted) score",
       y = "% of subjects",
       title = "Distribution of OSPAN SCORE",
       subtitle = "line indicates median split")


#:::::::: STACKED PROPORTIONAL BAR CHART
df_subjects %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = ospan_split)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  # facet_wrap(~ospan_split) + 
   labs(title = "OSPAN SPLIT",
       x = "Condition",
       fill = "",
       subtitle="After taking a median split, comparable high(vs) low in each condition")

```








## H1A \| OVERALL ACCURACY

+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Do Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?                                                                                                                                                                                |
+=======================+====================================================================================================================================================================================================================================================================================+
| **Hypothesis**        | (H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.                                                                                                                                               |
+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | **data**: `df_items` where `q nin 6,9` (the 13 discriminating Qs ), `df_subjects`                                                                                                                                                                                                  |
|                       |                                                                                                                                                                                                                                                                                    |
|                       | **outcome**:                                                                                                                                                                                                                                                                       |
|                       |                                                                                                                                                                                                                                                                                    |
|                       | -   \[at item level\] : *accuracy* ( factor(incorrect/correct) from `score_niceABS` \[absolute score\]                                                                                                                                                                             |
|                       | -   \[subject level\]: accuracy (number of test phase qs correct from total `s_NABS`)                                                                                                                                                                                              |
|                       |                                                                                                                                                                                                                                                                                    |
|                       | **predictor**: `condition` \[between-subjects factor\]                                                                                                                                                                                                                             |
+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  Wilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (`s_NABS`)                                                                                                                                                                                 |
|                       | 2.  Mixed Logistic Regression\                                                                                                                                                                                                                                                     |
|                       |     `accuracy` \~ `condition` + (1 \| `subject` ) + (1 \| `question`)\                                                                                                                                                                                                             |
|                       |     model effect of condition on probability of correct response \[during test phase\] while accounting for subject (and item-level?) effects                                                                                                                                      |
+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Alternatives**      | -   Ordinal Mixed Logistic Regression on `scaled_score`                                                                                                                                                                                                                            |
|                       | -   OLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals |
+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Notes**             | **Also exploring:**                                                                                                                                                                                                                                                                |
|                       |                                                                                                                                                                                                                                                                                    |
|                       | -   Hurdle model (mixture model w/ binomial + \[poisson or negbinom count; 0s from 1 DGP)                                                                                                                                                                                          |
|                       | -   Zero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)                                                                                                                                                                                    |
|                       | -   Beta regression hurdle model? (mixture with location and scale parameters \[mean, variance\] and hurdles for floor and ceiling effects)                                                                                                                                        |
|                       | -   Other way to account for the severe bimodality?                                                                                                                                                                                                                                |
+-----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup
```{r}
#| label: SETUP-ACC


df_i = df_items %>% filter(q %nin% c(6,9)) %>% 
  dplyr::select(pretty_condition, accuracy, subject,q, ospan_split)

df_s <- df_subjects %>% 
  dplyr::select(pretty_condition, ospan_split, task_percent)

```

#### Describe
```{r}
#| label: DESC-ACC

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~ospan_split) + 
   labs(title = "Overall Accuracy",
       x = "Condition",
       fill = "",
       subtitle="Impasse Condition yields a greater proportion of correct responses for HIGH WM")

#:::::::: STACKED BAR CHART BY QUESTION
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap( q ~ ospan_split) +
   labs(title = "Accuracy by Question",
       x = "Condition",
       fill = "",
       subtitle="Q6 and Q9 are non-discriminative")

#:::::::: FACETED HISTOGRAM
stats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))
gf_props(~task_percent,
         fill = ~pretty_condition, data = df_s) %>%
  gf_facet_grid(pretty_condition ~ ospan_split) %>%
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
  labs(x = "% Correct",
       y = "proportion of subjects",
       title = "Overall Absolute Score (% Correct)",
       subtitle = "") + theme(legend.position = "blank")

```



```{r}
#| label: DESC2-ACC

title = "Descriptive Statistics of Response Accuracy (Total % Correct)"
tbl1 <- mosaic::favstats(~task_percent, data = df_s) 
tbl1 %>% kbl (caption = title) %>% kable_classic()


title = "Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION"
tbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) 
tbl2 %>% kbl (caption = title) %>% kable_classic()

```

Across both conditions, overall accuracy on the task ranges from `r tbl1$min *100` to `r tbl1$max *100` with a mean of `r tbl1$mean * 100`. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.

A score of 100% indicates that the participant correctly interpreted the interval-coordinate system throughout the task, *starting at the first question*. A score of 0% indicates the individual *never* correctly interpreted the coordinate system. A score somewhere inbetween indicates that an individual deciphered the coordinate system *sometime over the course the task*.


#### WILCOXON RANK SUM (Mann-Whitney Test) 

-   **Non parametric alternative** to t-test; compares median rather than mean by ranking data
-   Does not assume normality
-   Does not assume equal variance of samples (homogeneity of variance)


##### Test

```{r}
#| label: TEST-ACC


#WILCOXON ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY
df_low <- df_s %>% filter(ospan_split == "low-memory")
(w <- wilcox.test(df_low$task_percent ~ df_low$pretty_condition,
                 paired = FALSE, alternative = "less")) #less, greater

#WILCOXON ON ACCURACY X OSPAN-SPLIT in HIGH
df_high <- df_s %>% filter(ospan_split == "high-memory")
(w <- wilcox.test(df_high$task_percent ~ df_high$pretty_condition,
                 paired = FALSE, alternative = "less")) #less, greater


grouped_ggbetweenstats( data = df_s, type = "nonparametric",
                        y = task_percent, x = pretty_condition, grouping.var = ospan_split)
                    

```


##### Inference

A Wilcoxon-Rank sum test on task accuracy x condition for the low-memory participants indicate that impasse is not significantly higher. A Wilcoxon rank sum test on task accuracy x condition for high-memory participants indicate that impasse IS higher. Taken together, this indiates there may be an interaction between working memory and condition. 

##### Visualize

```{r}

#TODO   
grouped_ggbetweenstats(data = df_s,
                       y = task_percent, x = pretty_condition, grouping.var = ospan_split,
               plot.type = "box", type = "nonparametric", var.equal = FALSE,
               centrality.type = "parametric",
               package = "RColorBrewer",
               palette = "PRGn",
               centrality.point.args = list(color="black", size = 3, shape = 1),
               # point.args = list(alpha=0), #suppress points
               ggplot.component = ## modify further with `{ggplot2}` functions
                list(
                  aes(color = pretty_condition, fill = pretty_condition),
                  scale_colour_manual(values = paletteer::paletteer_c("viridis::viridis", 3)),
                  scale_fill_manual(values = paletteer::paletteer_c("viridis::viridis", 3))
                  # theme(axis.text.x = element_text(angle = 90)
                )) 

# # ggplot(data = df_s, aes( x = pretty_condition, y = task_percent)) + 
#   ggdist::stat_halfeye(
#     alpha = 0.7,
#     point_colour = NA,
#     adjust = .5,
#     width = .5, .width = 0,
#     justification = -.5) +
#   geom_boxplot(
#     alpha = 0.1,
#     width = .2,
#     outlier.shape = NA
#   ) +
#   geom_point(
#     size = 2,
#     alpha = .5,
#     position = position_jitter(
#       seed = 1, width = .05, height = .02
#     )
#   ) 
# coord_flip() + theme_clean() + theme(legend.position = "blank")
# p$layers[[3]]=NULL #remove default boxplot
# e <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df_s,
#                                 type = "nonparametric", alternative = "less",
#                                 var.equal = FALSE)
# #labels are layer 4
# p + labs(title = "Distribution of Total Accuracy",
#          y = "Proportion of correct responses across task", x = "",
#          subtitle = "Impasse condition yields higher scores and greater variance",
#          caption=e$expression[[1]])

```


#### MIXED LOGISTIC REGRESSION [IXN!!]

*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*

##### Fit Model

```{r}
#| label: MODEL-FIT-ACC

## 0 | SETUP
#confirm 13 items [all discriminating items]
nrow(df_i) / nrow(df_s) == 13
#confirm all factors 
is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy) && is.factor(df_i$ospan_split)


## 1 | SETUP RANDOM INTERCEPT SUBJECT

#:: EMPTY MODEL (baseline, no random effect)
print("Empty fixed model")
m0 = glm(accuracy ~ 1, family = "binomial", data = df_i) 
# summary(m0)

#:: RANDOM INTERCEPT SUBJECT
print("Subject intercept random model")
mm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = "binomial")
# summary(mm.rS)

# :: TEST random effect
paste("AIC decreases w/ new model?", m0$aic > AIC(logLik(mm.rS)))
test_lrt(m0,mm.rS) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(m0,mm.rS))$p[2])

#:: RANDOM INTERCEPT SUBJECT + ITEM
print("Subject Intercept + Item intercept random model")
mm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = "binomial")
#summary(mm.rSQ)

# :: TEST random effect
paste("AIC decreases w/ new model?", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))
test_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(mm.rS, mm.rSQ))$p[2])


## 2 | ADD FIXED EFFECT CONDITION

print("FIXED Condition + Subject & Item random intercepts")
mm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,
                data = df_i, family = "binomial")
#summary(mm.CrSQ)

paste("AIC decreases w/ new model", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )
test_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])


## 3 | ADD INTERACTION OSPAN

print("FIXED Condition * FIXED OSPAN + Subject & Item random intercepts")
mm.COrSQ <- glmer(accuracy ~ pretty_condition *ospan_split + (1|subject) + (1|q) ,
                data = df_i, family = "binomial")
summary(mm.COrSQ)
car::Anova(mm.COrSQ)

paste("AIC decreases w/ new model", AIC(logLik(mm.CrSQ)) > AIC(logLik(mm.COrSQ)) )
test_lrt(mm.CrSQ,mm.COrSQ) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(mm.CrSQ,mm.COrSQ))$p[2])


```

*A likelihood ratio test indicates adding OSPAN as a fixed effect to a logistic regression model including a fixed effect for CONDITION and random intercepts for SUBJECT and QUESTION explains more variance in the data than the CONDITION + random-effects only model.*

##### Describe

```{r}
#| label: MODEL-DESC-ACC

# best model
m <- mm.COrSQ

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)
print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type=3) #TYPE 3 SS FOR IXNS

#:::::::: MANUAL ONE-SIDED SIGTEST 
#note: anova and chi square are always one-tailed, but that is independent of being one-sided
#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half

# one-sided (right tail) z test for B COEFFICIENT
#SANITY CHECK 2-tailed test should match the model output
#NOTE ... NEED TO DO THIS FOR _EACH_ COEFFICIENT
# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("p value for two-tailed test, null B = 0 : ",round(tt,5))
# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("BUT we want a one  directional, null: B <= 0: ",round(ot,5))

#:::::::: INTERPRET COEFFICIENTS

se <- sqrt(diag(stats::vcov(m)))
# table of estimates with 95% CI
paste("LOG ODDS")
(tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *
    se))
paste("ODDS RATIOS")
(e <- exp(tab))

```

##### Inference

***(TODO Dissertation)***

To quantify the effect of CONDITION and OSPAN on ACCURACY, we fit a mixed-effect binomial logistic regression model with random intercepts for subjects and questions. The structure of this model allows us to differentiate between random variance introduced by individual subjects and questions, versus the expected systematic variance of CONDITION and OSPAN. A likelihood ratio test indicates that a model including a fixed effect of CONDITION is explains significantly more variance in the data than an intercepts-only baseline model ($\chi^2 (3,4) = 17.84, p < 0.001$). The final model including main effect and interaction term of OSPAN is a significantly better fit than the CONDITION-only model ($\chi^2 (4,6) = 8.84, p < 0.05$).

The explanatory power of the entire model is substantial ($conditional \ R^2 = 0/93$) and the part related to the fixed effects CONDITION and OSPAN ($marginal \ R^2$) explains 18% of variance. There were no significant main effects of condition or impasse, but a rather a significant interaction between condition and ospan, ($e^{\beta_1} = 266.00 p < 0.05 \ 95 \% \  CI [2.48, 28700] $)). 

TODO INTERPRETING INTERACTIONS IN REGRESSION

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",
# 
# 
# 

```

##### Visualize

```{r}
#| label: MODEL-VIS-ACC

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

## | PLOT TESTS
result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

#ONLY FOR BAYESIAN VERSION
# result <- rope(m)
# plot(result)
# 
# result <- pd(m)
# plot(result)


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="int",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response",
           axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
plot_model(m, type = "pred")  
plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

#TODO EMMEANS for the estimated marginal means OR USE IXN PLOT


```

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
```

##### Diagnostics

```{r}
#| label: MODEL-DIAG-ACC
#| warning: false
#| message: false

# print("SANITY CHECK REPORTING")
# report(m)

# print("MODEL PERFORMANCE")
# performance(m)

print("DIAGNOSTICS")
check_model(m)

```

## H1A \| OVERALL INTERPRETATION STATE

**Do Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?**

While absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:

-   **"orthogonal"** \[reference category\] includes orthogonal and satisficing responses ==\> indicates a primarily *orthogonal* state of coordinate system understanding

-   **"other"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular

-   **"angular"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

-   **"triangular"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions?                                          |
+=======================+=================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q nin 6,9` (13 discriminant test phase items)                                                              |
|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                          |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |
|                       |                                                                                                                                                 |
|                       | Alternative:                                                                                                                                    |
|                       |                                                                                                                                                 |
|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |
|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+


#### Setup

```{r}
#| label: SETUP-STATE

#:::::::: PREP DATA
df_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition, ospan_split)
```

```{r}
#:::::::: STACKED BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~ospan_split) +
   labs(title = "Interpretation across all Questions",
       x = "Condition",
       fill = "",
       subtitle="")


#:::::::: STACKED BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(q ~ ospan_split) +
   labs(title = "Interpretation by Question",
       x = "Condition",
       fill = "",
       subtitle="")

```


```{r}

#::::::::::::DESCRIPTIVES

table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns


(t <- table(df_i$state, df_i$pretty_condition, df_i$ospan_split) %>% addmargins(2) %>% #display sum for row
      addmargins(1)) #sanity check sum of columns

```

#### MIXED MULTINOMIAL REGRESSION


*Does condition affect the response state of of items across the task?*

*Fit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).*

-   mblogit version wouldn't coverge, so using brms

##### Fit Model \[brms\]

```{r}
#| label: FIT-BRMS-STATE

# CONDITION ONLY MODEL
mm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), 
                 data = df_i, 
                 family = "categorical",
                 chains = 4, iter = 2000, warmup = 1000,
                 cores = 4, seed = 1234,
                 backend = "cmdstanr",
                 file ="analysis/SGC3A/models/sgc3a_brms_mixedcat.condition._state_ONLINE.rds")

summary(mm.cat.CrSQ)

# CONDITION + OSPAN MODEL
mm.cat.COrSQ <- brm( state ~ pretty_condition*ospan_split + (1|subject) + (1|q), 
                 data = df_i, 
                 family = "categorical",
                 chains = 4, iter = 2000, warmup = 1000,
                 cores = 4, seed = 1234,
                 backend = "cmdstanr",
                 file ="analysis/SGC3A/models/sgc3a_brms_mixedcat.conditionospan._state_ONLINE.rds")
summary(mm.cat.COrSQ)

#which model is better?
compare_models(mm.cat.CrSQ, mm.cat.COrSQ)
compare_performance(mm.cat.CrSQ, mm.cat.COrSQ)
# test_lrt(mm.cat.CrSQ, mm.cat.COrSQ) #doesn't run?
# car::Anova(mm.cat.CrSQ, mm.cat.COrSQ)
# car::Anova(mm.cat.COrSQ)
```

##### Describe

```{r}
#| label: VIS-PD

plot(pd(mm.cat.CrSQ))
plot(pd(mm.cat.COrSQ))
```

```{r}
#| label: VIS-BRMS-STATE

#set model 
m <- mm.cat.COrSQ
summary(m)

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

result <- rope(m)
plot(result)

result <- pd(m) 
plot(result)

## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="int",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response",
           axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
# plot_model(m, type = "pred")  
# plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

```
```{r}
#| label: TBL-BRMS-STATE

#DISPLAY MODEL AS TABLE
tab_model(mm.cat.CrSQ)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
#TODO OUTPUT TABLE 

#https://arelbundock.com/posts/modelsummary_multinomial_logit/
# modelsummary(m)



```

## H1B \| Q1 ACCURACY

**Do Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?**

The graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.

+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \[Is response accuracy independent of condition?\]                                                                                   |
+=======================+========================================================================================================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                    |
|                       | -   outcome: *accuracy* ( factor(incorrect/correct) from `score_niceABS` \[absolute score\]                                                                                                                                            |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                                                                                                                 |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |
|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |
|                       |                                                                                                                                                                                                                                        |
|                       | Alternatives:                                                                                                                                                                                                                          |
|                       |                                                                                                                                                                                                                                        |
|                       | -   Chi-Square test of independence on outcome `accuracy` by `condition`                                                                                                                                                               |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \~ continuous; though with regression we can quantify the size of the effect and overall model fit |
|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |
|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup
```{r}
#| label: SETUP-Q1ACC

#:::::::: PREP DATA
df <- df_items %>% filter(q==1) 
# %>% dplyr::select(accuracy, pretty_condition, ospan_split)

```

#### Describe 
```{r}
#| label: VIS-Q1ACC

#:::::::: STACKED BAR CHART
df %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~ospan_split) +
   labs(#y = "Correct Response on Q 1",
       title = "Q1 Accuracy",
       x = "Condition",
       fill = "",
       subtitle="Impasse Condition yields a greater proportion of correct responses")

```

TODO DESCRIPTIONS

```{r}
#| label: DESC-Q1ACC

#::::::::::::DESCRIPTIVES

paste("Proportions of Correct Responses by Condition")
table(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns

paste("Number of Correct Responses by Condition")
table(df$accuracy, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row
      addmargins(1) #sanity check sum of columns
```

#### CHI SQUARE [YES]

```{r}
#| label: TESTS-Q1ACC

#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY
df_low <- df %>% filter(ospan_split == "low-memory")
# table(df_low$pretty_condition, df_low$accuracy)
chisq.test( x = df_low$pretty_condition, y = df_low$accuracy, correct = TRUE)

#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in HIGH WORKING MEMORY
df_high <- df %>% filter(ospan_split == "high-memory")
#table(df_high$pretty_condition, df_high$accuracy)
chisq.test( x = df_high$pretty_condition, y = df_high$accuracy,correct = TRUE)
#significant if correct = FALSE
```
TODO why do these chisqrs not match the grouped bar stats?
```{r}

# INTERACTION (OSPAN X CONDITION)
grouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, 
                    grouping.var = ospan_split,
                    type = "parametric")

# MAIN EFFECT CONDITION (yes)
# ggbarstats( data = df, x = accuracy, y = pretty_condition, 
#                     type = "nonparametric")

# MAIN EFFECT OSPAN (none)
# ggbarstats( data = df, x = accuracy, y = ospan_split, 
#                     type = "nonparametric")

```


There is no non-parametric version of two-way ANOVA, so we perform individual CHI-SQR tests. We split the data into two groups (low memory, and high memory, based on the median split). For each, we run a CHI SQR test of independence testing the null hypothesis that Q1 ACCURACY is independent of CONDITION.  In the low-working memory group, we cannot reject the null hypothesis, suggesting that accuracy does not differ by condition. But in the HIGH working memory group we do reject the null hypothesis.  The proportion of correct responses in IMPASSE is much higher than in CONTROL, but only in the HIGH WORKING MEMORY group. 


#### LOGISTIC REGRESSION (MAIN EFFECT CONDITION)

TODO:: consider weighted(centered) continuous vs ospan split

Fit a logistic regression predicting accuracy (absolute score) (n = `r nrow(df)`) by condition (k = 2).\

-   Parameter estimate: $\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition
-   $e^{\beta_{0}}$ = ODDS of correct response in CONTROL condition
-   Parameter estimate: $\beta_{1}$ = $\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \[log scale\])
-   $e^{\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL
-   **Null hypothesis**:$\beta_{impasse} \le 0$ the odds for a correct response does not change, or decreases
-   **Alternative hypothesis:** $\beta_{impasse} \gt 0$ the odds of a correct response increases

##### Fit CONDITION Model

*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*

```{r}
#| label: FIT-MODEL-Q1ACC
#| warning: false
#| message: false

# MODEL FITTING ::::::::

#: 1 EMPTY MODEL baseline glm model intercept only
m.0 = glm(accuracy ~ 1, data = df, family = "binomial")
# print("EMPTY MODEL")
# summary(m0)

#: 2 CONDITION model
m.C <- glm( accuracy ~ pretty_condition, data = df, family = "binomial")
# print("PREDICTOR MODEL")
# summary(m1)

#: 2 TEST SUPERIOR FIT
paste("AIC wth predictor is lower than empty model?", m.0$aic > m.C$aic)
test_lrt(m.0,m.C) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(m.0,m.C))$p[2])

summary(m.C)


##### Fit OSPAN Models

#: 3 OSPAN ONLY MODEL 
m.O = glm(accuracy ~ ospan_split, data = df, family = "binomial")
# print("EMPTY MODEL")
# summary(m0)

#: 3 TEST SUPERIOR FIT
paste("AIC OSPAN predictor is lower than CONDITION model?", m.C$aic > m.O$aic)
```

**ADD OSPAN**
```{r}
#: 4 OSPAN + CONDITION model
m.CO <- glm( accuracy ~ pretty_condition + ospan_split, data = df, family = "binomial")
# print("PREDICTOR MODEL")
summary(m.CO)
car::Anova(m.CO, type=3)

#: 4 TEST SUPERIOR FIT
paste("AIC wth OSPAN is lower than CONDITION only model?", m.C$aic > m.CO$aic)
test_lrt(m.C,m.CO) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(m.C,m.CO))$p[2])

```
Adding OSPAN as a predictor (no interaction) decreases AIC, but does not improve fit (LRT)

**INTERACTION MODEL**
```{r}
#: 5 OSPAN + CONDITION INTERACTION model
m.C.O <- glm( accuracy ~ pretty_condition * ospan_split, data = df, family = "binomial")
x <- glm( accuracy ~ pretty_condition + ospan_split + pretty_condition*ospan_split, data = df, family = "binomial")
# print("PREDICTOR MODEL")
summary(m.C.O)
car::Anova(m.C.O, type =3)

#: 5 TEST SUPERIOR FIT
paste("AIC wth OSPAN IXN lower than CONDITION + OSPAN only model?", m.CO$aic > m.C.O$aic)
test_lrt(m.CO,m.C.O) 


paste("AIC wth OSPAN IXN is lower than CONDITION only model?", m.C$aic > m.C.O$aic)
test_lrt(m.C,m.C.O) 
```

Adding OSPAN interaction does not improve model fit over condition-only model, or main effects only model. 

##### Describe

```{r}
#| label: DESC-MODEL-Q1ACC

#set model
m <- m.C.O

# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: 

print("PREDICTOR MODEL [default two-tailed sig test]")
summary(m)
car::Anova(m, type=3)

# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: 

# one-sided (right tail) z test for B COEFFICIENT
#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients

#SANITY CHECK 2-tailed test should match the model output
# tt <- 2*pnorm(summary(m)$coefficients[2:4], lower.tail = F)
# paste("p value for two-tailed test, null B = 0 : ",round(tt,3))
# ot <- pnorm(summary(m)$coefficients[2:4], lower.tail = F)
# paste("BUT we want a one tailed directional, null: B <= 0: ",round(ot,3))
# paste("adjusted confint for directional hypothesis")
# (dcint <- confint(m, level = 0.90)) # get 90% for right side))
# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte

#:::::::: INTERPRET COEFFICIENTS

# print("Confidence Interval - LOG ODDS")
# confint(m1) #not adjusted for 1-tailed
print("Coefficients - ODDS RATIOS")
(e <- cbind( exp(coef(m)), exp(confint(m)))) #exponentiated, not adjusted
# (e <- cbind( exp(coef(m)), exp(dcint))) #exponentiated, adjusted

#TODO INTERACTIONS & ESTIMATED MARGINAL MEANS 
# print("MODEL PREDICTIONS")
# Retrieve predictions as probabilities 
# (for each level of the predictor)
# pred.control <- predict(m,data.frame(pretty_condition="control"),type="response")
#this should match : plogis(intercept coefficient)
# paste("Probability of success in control,", pred.control)
# pred.impasse <- predict(m,data.frame(pretty_condition="impasse"),type="response")
#this should match : plogis(intercept coefficient + predictor coeff)
# paste("Probability of success in impasse,", pred.impasse)
```

##### Inference

TODO double check chisqrs vs grouped_barstats. Why is the tests not the same. Otherwise report mm.C as ospan didn't improve fit

##### Visualize

```{r}
#| label: MODEL-VIS-Q1ACC
#| message: false
#| warning : false


## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)



## | PLOT TESTS
result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

#ONLY FOR BAYESIAN VERSION
# result <- rope(m)
# plot(result)
# 
# result <- pd(m)
# plot(result)


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="int",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response",
           axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
plot_model(m, type = "pred")  
plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )


```

```{r}
#| label: TBL-MODEL-Q1ACC

#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",

```

##### Diagnostics

```{r}
#| label: DIAG-MODEL-Q1ACC
#| message: false
#| warning: false

# print("SANITY CHECK REPORTING")
# report::report(m)

#print("MODEL PERFORMANCE")
# performance(m)

print("MODEL DIAGNOSTICS")
check_model(m)
```


## H1B \| Q1 INTERPRETATION STATE

**Do Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?**

While absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:

-   **"orthogonal"** \[reference category\] includes orthogonal and satisficing responses ==\> indicates a primarily *orthogonal* state of coordinate system understanding

-   **"other"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular

-   **"angular"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

-   **"triangular"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |
+=======================+===========================================================================================================================================================================================================================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |
|                       | -   outcome: `state` ( 4 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                                                                                                                                                                                                                                    |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |
|                       |                                                                                                                                                                                                                                                                                                                                                           |
|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |
|                       |                                                                                                                                                                                                                                                                                                                                                           |
|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |
|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup 
```{r}
#| label: SETUP-Q1-STATE

#:::::::: PREP DATA
df <- df_items %>% filter(q==1) %>% 
  dplyr::select(pretty_condition, ospan_split, state)

```


#### Describe 
```{r}
#| label: VIS-Q1STATE

#:::::::: STACKED BAR CHART
df %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~ospan_split) +
   labs(#y = "Correct Response on Q 1",
       title = "Q1 Interpretation",
       x = "Condition",
       fill = "",
       subtitle="")

```


```{r}
#| label: DESC-Q1STATE

#::::::::::::DESCRIPTIVES

table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns


(t <- table(df$state, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row
      addmargins(1)) #sanity check sum of columns

```

#### MULTINOMIAL REGRESSION

TODO:: USE MBLOGIT VERSION WITH P VALUES IN MODEL

*Does condition affect the response state of Q1?*

*Fit a logistic regression predicting interpretation state (k=3) by condition(k = 2).*

-   3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) \[essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing \[reference category\] vs \[this category\])

-   For *each* equation:

    -   $\beta_{0}$ *= Log Odds of \[this category type vs. reference category type) response in CONTROL condition*
    -   $e^{\beta_{0}}$ *= ODDS of \[this category type vs. reference category type\] response in CONTROL condition*
    -   $\beta_{1}$ *=* $\beta_{1impasse}$ *Log Odds (Log OR; change in odds for \[this category\] type response in impasse (vs) control \[log scale\])*
    -   $e^{\beta_{1}}$ *= ODDS RATIO of \[this. vs reference category type\] response in IMPASSE (vs) CONTROL*
    -   Two-tailed NHST *Null hypothesis:* $\beta_{impasse} = 0$ *the odds for \[this category of response vs. reference\] are not different for IMPASSE condition*
    -   *Alternative hypothesis:* $\beta_{impasse} \ne 0$ *the odds of \[this category of response vs. reference\] increases or decreases for IMPASSE condition*

##### Fit CONDITION Model

```{r}
#| label: FIT-Q1-INTERPRETATION

#check reference level 
print("Categories (first is reference)")
levels(df$state)

#FIT EMPTY MODEL
# print("EMPTY MODEL")
catm.0 <- multinom(state ~ 1, data = df)
# summary(catm.0)

#FIT PREDICTOR MODEL
# print("PREDICTOR MODEL")
catm.C <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)
# summary(catm.C)

#COMPARE MODEL FIT
paste("AIC wth predictor is lower than empty model?", catm.0$AIC > catm.C$AIC)
test_lrt(catm.0, catm.C)

##compare bayesian version
#library(brms)
# b.cat <- brm( state2 ~ pretty_condition, data = df, family = "categorical", backend = "cmdstanr")
# summary(b.cat)
# plot_model(b.cat)
# report(b.cat)
# coefficient estimates are very simliar to catm. super cool!

##compare mclogit version
#"baseline-category logit model
# https://www.elff.eu/software/mclogit/manual/mblogit/
# blm1 <- mblogit(state2 ~ pretty_condition , data = df)
# summary(blm1)
#identical to catm. super cool!

```

*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*

##### Fit OSPAN Model

```{r}

#FIT OSPAN only MODEL
# print("OSPAN ONLY MODEL")
catm.O <- multinom(state ~ ospan_split, data = df)
# summary(catm.O) 
# car::Anova(catm.O) 
print("OSPAN ONLY better than empty?")
test_lrt(catm.0, catm.O)


#FIT OSPAN + CONDITION
# print("OSPAN + CONDITION MODEL")
catm.CO <- multinom(formula = state ~ pretty_condition + ospan_split, data = df, model = TRUE)
# summary(catm.CO)
car::Anova(catm.CO) #MainEff condition, marginal ospan

#COMPARE MODEL FIT
paste("Adding OSPAN to CONDITION lowers AIC?", catm.C$AIC > catm.CO$AIC)
test_lrt(catm.C, catm.CO)

```
_Adding (main effect) predictor of OSPAN decreases AIC and is a marginally better fit. In this model, there is still only a main effect of condition. OSPAN is not a significant main effect._

```{r}

#FIT OSPAN * CONDITION
# print("OSPAN * CONDITION MODEL")
catm.C.O <- multinom(formula = state ~ pretty_condition * ospan_split, data = df, model = TRUE)
car::Anova(catm.C.O, type = 3)
# summary(catm.C.O)
# car::Anova(catm.C.O) #MainEff condition, marginal ospan
#COMPARE MODEL FIT
paste("Adding INTERACTION lowers AIC?", catm.CO$AIC > catm.C.O$AIC)
test_lrt(catm.CO, catm.C.O)

```
_Adding interaction of OSPAN does not improve fit and does not lower AIC. In the IXN model, only the main effect of condition is significant._

```{r}
##compare bayesian version
# library(brms)
# b.cat <- brm( state ~ pretty_condition*ospan_split, data = df, family = "categorical", backend = "cmdstanr")
# summary(b.cat)
# plot_model(b.cat) 
# plot(equivalence_test(b.cat))
# plot(rope(b.cat))
# report(b.cat)
# coefficient estimates are very simliar to catm. super cool!

##compare mclogit version
#"baseline-category logit model
# https://www.elff.eu/software/mclogit/manual/mblogit/
blm1 <- mblogit(state ~ pretty_condition *ospan_split , data = df)
summary(blm1)
# car::Anova(blm1) #todo need to separate by individual equation
#identical to catm. super cool!

```

*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*



##### Describe

```{r}
#| label: DESC-Q1-INTERPRETATION

#set model
m <- catm.C.O

#::::::::INTERPRETATION
paste("MODEL SUMMARY")
summary(m)
car::Anova(m, type =3) #always type 3 for ixns 

# calculate z-statistics of coefficients
z_stats <- summary(m)$coefficients/summary(m)$standard.errors
# convert to p-values
p_values <- (1 - pnorm(abs(z_stats)))*2
# display p-values in transposed data frame
(p_values <- data.frame(p = (p_values)))
# display odds ratios in transposed data frame

paste("ODDS RATIOS")
odds_ratios <- data.frame(OR = exp(summary(m)$coefficients))
options(scipen = 2)
(results <- cbind(odds_ratios, p_values))
```

##### Inference 

looking at detailed p values 


... 
OTHER: only main effect of condition 
TRI-LIKE: no effects
TRI: IXN condition * impasse


TODO

-   Being in the IMPASSE condition *increases* the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 45 (z = 3.81, p \< 0.001) . **Participants in the impasse condition were 45x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control**.

-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 17.5 (z = 2.60, p \< 0.001 ). **Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.


-   Being in the IMPASSE condition *increases* the odds of giving 'triangle-like' response rather than an orthogonal (or satisficing) response by a factor of 4.8 (z = 3.30, p \< 0.001 ). **Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control**.


-   As with the (binary) logistic regression on accuracy \~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 *in the control condition.* (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)

-   \[need to to double check interpretation, but I *think* that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the control condition. which makes sense. I think.?\]

-   IF I change reference category for condition... then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) \[Yup! this works!\]

##### Visualize

```{r}
#| label: VIS-Q1INTERPRETATION-LAB

#:::::::: PLOT

#SJPLOT | MODEL | ODDS RATIO
#library(sjPlot)
plot_model(m, type = "est",
           vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) +  #manually adjusted for directional test   
  # scale_y_continuous() + #remove to put on log scale x axis 
  # scale_x_discrete(labels=c("control","impasse"))+
  labs(title = "MODEL ESTIMATE  | Q1 Accuracy ~ condition",
       subtitle = "Impasse increases odds of correct response on Q1",
       x = "Condition") + theme_clean()

  
#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type = "int", ci.lvl = 0.95) 
plot_model(m, type="eff", ci.lvl = 0.95) 
# +  ylim(0,1) +
#   labs(title = "MODEL PREDICTION  | Q1 State ~ condition",
#        subtitle = "Impasse increases probability of more accurate response states Q1",
#        x = "Condition") + theme_clean()

#TODO ESTIMAED MARGINALS AND IXN PLOTS 
# https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html


```

```{r}

#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",

# modelsummary(mixcat.1, s)
#TODO OUTPUT TABLE 
#https://arelbundock.com/posts/modelsummary_multinomial_logit/


```

##### Diagnostics

```{r}

#EXAMINE PREDICTIONS
#create sample data frame
# test <- data.frame(pretty_condition = c("control", "impasse"))
# pred <- predict(m, newdata = test, "probs")
# paste("Predicted Probability of Being in Each State")
# ( x <- cbind(test, pred))

print("MODEL PERFORMANCE")
performance(m)
DescTools::PseudoR2(m, which = c("McFadden", "CoxSnell", "Nagelkerke"))

#General Goodness of Fit
#library(generalhoslem)
#logitgof(df$state, catm$fitted.values, g = 3)
#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).
#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables
chisq.test(df$state,predict(m)) #actual states VS predicted states
# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model

# print("MODEL DIAGNOSTICS")
# check_model(m) can't do overall diagnostics, have to do them on individual model equations

```

## EXPLORE specific question 

```{r}

df <- df_items %>% filter(q==10)
grouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, grouping.var = ospan_split)

```