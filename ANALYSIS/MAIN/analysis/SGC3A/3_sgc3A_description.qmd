---
subtitle: 'Study SGC3A | 3 Description'
---

\newpage

# Description {#sec-SGC3A-description}

**TODO**

-   refactor titles to match hypo testing
-   add first question latency and accuracy 
-   describe response consistency
-   finish description of latency

*The purpose of this notebook is describe the distributions of dependent variables for Study SGC3A.*

+------------------------+
| Pre-Requisite          |
+========================+
| 1_sgc3A_harmonize.qmd\ |
| 2_sgc3A_scoring.qmd    |
+------------------------+

```{r}
#| label: SETUP
#| warning : false
#| message : false

library(tidyverse) #ALL THE THINGS
library(kableExtra) #printing tables 
library(mosaic) #simple descriptives [favstats]
library(Hmisc) # %nin% operator
library(ggpubr) #arrange plots
library(report) #easystats reporting
library(vcd) #mosaicplots

#OUTPUT OPTIONS
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
options(ggplot2.summarise.inform = FALSE)
options(scipen=1, digits=3)
```

```{r}
#| label: IMPORT-DATA
#| warning : false
#| message : false

#IMPORT DATA 
df_items <- read_rds('data/2-scored-data/sgc3a_scored_items.rds')
df_subjects <- read_rds('data/2-scored-data/sgc3a_scored_participants.rds')

#SEPARATE ITEM DATA BY QUESTION TYPE
df_scaffold <- df_items %>% filter(q < 6)
df_test <- df_items %>% filter(q > 6) %>% filter (q %nin% c(6,9))
df_nondiscrim <- df_items %>% filter (q %in% c(6,9))
```

## SAMPLE

### Data Collection

Data was initially collected (in person, SONA groups in computer lab) in Fall 2017. In Spring 2018, additional data were collected after small modifications were made to the experimental platform to increase the size of multiple-choice input buttons, and to add an additional free-response question following the main task block. In Fall 2021, the study was replicated using asynchronous, online SONA pool, with additional participants collected in Winter 2022.

```{r}
#| label : INSPECT-DATA-COLLECTION

title = "Participants by Condition and Data Collection Period"
cols = c("Control Condition","Impasse Condition","Total for Period")
cont <- table(df_subjects$term, df_subjects$condition)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

```

### Participants

```{r}
#| label: DESC-PARTICIPANTS

#Describe participants
subject.stats <- rbind(
  "lab"= df_subjects %>% filter(mode == 'lab-synch') %>% select(age) %>% unlist() %>% favstats(),
  "online" = df_subjects %>% filter(mode == "asynch") %>% select(age) %>% unlist() %>% favstats()
) 
subject.stats$female <- c(
  (df_subjects %>% filter(mode == 'lab-synch') %>%  filter(gender=="Female") %>% count())$n,
  (df_subjects %>% filter(mode == "asynch") %>% filter(gender=="Female") %>% count())$n
)

title = "Descriptive Statistics of Participant Age and Gender"
subject.stats %>% kbl (caption = title) %>% kable_classic()
```

For **in-person** collection, `r subject.stats["lab",]$n` participants (`r round(subject.stats["lab",]$female/subject.stats["lab",]$n,1) * 100` % female ) undergraduate STEM majors at a public American University participated *in person* in exchange for course credit (age: `r (subject.stats['lab','min'])` - `r (subject.stats['lab','max'])` years). Participants were randomly assigned to one of two experimental groups.

For **online replication** `r subject.stats["online",]$n` participants (`r round(subject.stats["online",]$female/subject.stats["online",]$n,1) * 100` % female ) undergraduate STEM majors at a public American University participated *online, asynchronously* in exchange for course credit (age: `r (subject.stats['online','min'])` - `r (subject.stats['online','max'])` years). Participants were randomly assigned to one of two experimental groups.

```{r}
#| label: REPORT-PARTICIPANTS
report_participants(df_subjects, education = "schoolyear", sex = "gender", group = "mode")
```

## RESPONSE ACCURACY

### Cumulative Scores

Cumulative scores indicate the response accuracy by a particular participant across all discriminant items (n=13) in the graph comprehension task.

#### Cumulative Absolute Score

Recall from [Section -@sec-absolute-scoring] that the absolute score (following the dichotomous scoring approach) `s_ABS` indicates if the subject's response for a particular item was *perfectly* correct: whether they selected all correct answer options and no others (excluding certain allowed exceptions, such as also selecting the data point referenced in the question). The absolute score for an individual item is either 0 or 1. When summarized across the entire set of discriminant items, the cumulative absolute score for an individual subject ranges from \[0,13\].

```{r}
#| label: DESC-SUBJ-ABS
title = "Descriptive Statistics of Response Accuracy (Cumulative Item Absolute Score)"
abs.stats <- rbind(
  "lab"= df_subjects %>% filter(mode == 'lab-synch') %>% select(s_ABS) %>% unlist() %>% favstats(),
  "online" = df_subjects %>% filter(mode == "asynch") %>% select(s_ABS) %>% unlist() %>% favstats()
) 
abs.stats %>% kbl (caption = title) %>% kable_classic()

```

For *in person* collection, cumulative absolute scores (n = `r abs.stats["lab",]$n`) range from `r round(abs.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(abs.stats["lab",]$mean,2)`, SD = `r round(abs.stats["lab",]$sd,2)`).

For *online replication*, (online) cumulative accuracy scores (n = `r abs.stats["online",]$n`) range from `r round(abs.stats["online",]$min,2)` to `r round(abs.stats["online",]$max,2)` with a slighly lower mean score of (M = `r round(abs.stats["online",]$mean,2)`, SD = `r round(abs.stats["online",]$sd,2)`).

```{r}
#| label: VIS-SUBJ-ABS
 
#VISUALIZE distribution of response accuracy across SUBJECTS

#HISTOGRAM
stats = df_subjects %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(s_ABS))
gf_density(~s_ABS, data = df_subjects) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) %>% 
  gf_lims(x = c(0, 13)) %>% 
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
  labs(x = "Cumulative Absolute Score",
       y = "proportion of subjects",
       title = "Subject Cumulative Score (Absolute)",
       subtitle = "Score distributions are comparable across modalities and different across conditions") + 
  theme_minimal()
  

#RIDGEPLOT
# ggplot(data = df_subjects, aes(x = s_NABS, y = mode)) +
#   geom_density_ridges() + xlim(0,13)+
#   facet_wrap(~condition, labeller = label_both) +
#  labs(x = "Cumulative Absolute Score",
#       y = "proportion of subjects",
#        title = "Subject Cumulative Score (Absolute)",
#        subtitle = "Score distributions are comparable across modalities and different across conditions") + 
#   theme_minimal()

```

::: callout-decision
**Condition appears to exert a positive influence on Cumulative Absolute Score across data collection modalities.**
:::

#### Cumulative Scaled Scores

The Cumulative Scaled score `s_SCALED` summarizes the scaled score on the 13 strategy-discriminant questions, for each subject The range is from -13 (all orthogonal) to 13 (all triangular). Recall that the s_SCALED score for an item is a numeric representation of the strategy-consistent response, scaled from -1 to +1, where "Orthogonal" = -1, "Satisfice" = -1, "Triangular" = 1, "Tversky" = 0.5, "both tri + orth" = 0.5, "reference" = 0, "blank" = 0, "frenzy" = 0, "?" = 0.

Most importantly, the Scaled score gives us a way of quantitatively examining how correctly a participant interpreted the coordinate system across the entire set of items. It offers a more nuanced look into performance than absolute score

```{r}
#| label: DESC-SUBJ-SCALED

title = "Descriptive Statistics of Response Accuracy (Cumulative Scaled Score)"
scaled.stats <- rbind(
  "lab"= df_subjects %>% filter(mode == 'lab-synch') %>% select(s_SCALED) %>% unlist() %>% favstats(),
  "online" = df_subjects %>% filter(mode == "asynch") %>% select(s_SCALED) %>% unlist() %>% favstats()
) 
scaled.stats %>% kbl (caption = title) %>% kable_classic()

```

For in person collection, cumulative absolute scores (n = `r scaled.stats["lab",]$n`) range from `r round(scaled.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(scaled.stats["lab",]$mean,2)`, SD = `r round(scaled.stats["lab",]$sd,2)`).

For online replication, (online) cumulative accuracy scores (n = `r scaled.stats["online",]$n`) range from `r round(scaled.stats["online",]$min,2)` to `r round(scaled.stats["online",]$max,2)` with a slighly lower mean score of (M = `r round(scaled.stats["online",]$mean,2)`, SD = `r round(scaled.stats["online",]$sd,2)`).

```{r}
#| label: VIS-SUBJ-SCALED
 
#VISUALIZE distribution of response accuracy across SUBJECTS

#HISTOGRAM
stats = df_subjects %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(s_SCALED))
gf_density(~s_SCALED, data = df_subjects, binwidth = 1) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) %>% 
  gf_lims(x = c(-13, 13)) %>%
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
   labs(x = "Cumulative Scaled Score",
       y = "proportion of subjects",
       title = "Subject Cumulative Score (Scaled)",
       subtitle = "Score distributions are comparable across modalities and different across conditions") + 
  theme_minimal()
  
```

::: callout-decision
**Condition appears to exert a positive influence on Scaled Score across data collection modalities.**
:::

### Item Scores

Item scores indicate the response accuracy by a participant on each individual question discriminant question (n=13) in the graph comprehension task.

#### Item Absolute Score

```{r}
#| label: DESC-ITEM-ABS

x <- df_items %>% mutate(score = as.logical(score_ABS))

title = "Proportion of Correct Items By Condition (Lab)"

item.contingency <- df_items %>% filter(mode == "lab-synch") %>% select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Correct Items By Condition (Online)"
item.contingency <- df_items %>% filter(mode == "asynch") %>% select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

```

Across both data collection modalities, the proportion of correct answers is greater in the impasse vs. control condition.

```{r}
#| label: VIS-ITEM-ABS

#VISUALIZE distribution of response accuracy across ITEMS

#HISTOGRAM
stats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_niceABS))
gf_props(~score_niceABS, data = df_items) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) +
  labs(x = "Item Absolute Score",
       title = "Item Absolute Score",
       subtitle="Across modalities, the impasse condition yielded more correct responses")+
  theme_minimal()

```

#### Item Scaled Score

At the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1.

```{r}
#| label: DESC-ITEM-SCALED

title = "Descriptive Statistics of Item Response Accuracy (Scaled Score)"
scaled.stats.items <- rbind(
  "lab"= df_items %>% filter(mode == 'lab-synch') %>% select(score_SCALED) %>% unlist() %>% favstats(),
  "online" = df_items %>% filter(mode == "asynch") %>% select(score_SCALED) %>% unlist() %>% favstats()
) 
scaled.stats.items %>% kbl (caption = title) %>% kable_classic()

```

```{r}
#| label: VIS-ITEM-SCALED

#VISUALIZE distribution of response accuracy across ITEMS

#HISTOGRAM
stats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_SCALED))
gf_density(~score_SCALED, data = df_items) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) %>% 
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
  labs(x = "Scaled Score for Item",
       y = "Proportion of Items",
       title = "Distribution of Accuracy per Item (Scale Score)",
       subtitle="The impasse condition shifts density toward the positive score")+
  theme_minimal()

```

#### Item Interpretation Scores

```{r}
#| label: DESC-ITEM-INTEPRETATION

#VISUALIZE distribution of interpretations across all ITEMS


#REORDER INTERPRETATION LEVELS
df_items$interpretation <- factor(df_items$interpretation, levels = c("Triangular", "Tversky", "both tri + orth", "blank", "?", "frenzy","reference","Satisfice", "Orthogonal"))            


title = "Proportion of Interpretations Across Items Items By Condition (Lab)"
item.contingency <- df_items %>% filter(mode == "lab-synch") %>% select(interpretation, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Interpretations Across Items Items By Condition (Online)"
item.contingency <- df_items %>% filter(mode == "asynch") %>% select(interpretation, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()



```

```{r}
#| label: VIS-ITEM-INTERPRETATION


#PROPORTIONAL BAR CHART
gf_propsh(~interpretation, data = df_items, fill = ~mode) %>% 
  gf_facet_grid(mode~condition, labeller = label_both) +
  labs(x = "Interpretation for Item",
       title = "Proportion of Interpretations Across Items",
       subtitle="Impasse Condition yields shift from Orthogonal to alternative interpretations")+
  theme_minimal()+ theme(legend.position = "none")


#MOSAIC PLOT
vcd::mosaic(main="Proportion of Item Interpretation across Conditions",
            data = df_items, condition ~ interpretation, rot_labels=c(0,90,0,0), 
            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = "right",
            spacing = spacing_dimequal(unit(1:2, "lines"))) 


```

## RESPONSE LATENCY

-   [TODO: Investigate super high and super low response times.]{style="color: red;"}.

-   [TODO: Investigate appropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/)]{style="color: red;"}.

-   Especially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data

### Time on Study

```{r DESCRIBE-TOTALTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_subjects %>% filter(mode == 'lab-synch') %>% select(totaltime_m) %>% unlist() %>% favstats(),
  "online"= df_subjects %>% filter(mode == 'asynch') %>% select(totaltime_m) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of Response Latency (Time on Study)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Total time on study for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Total time on study for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

```{r}
#| label : VIS-TOTALTIME
#| message : false
#| warning : false

#VISUALIZE distribution of response time
plab <- gf_dhistogram(~totaltime_m, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Lab", x = "Total Time (mins)", y = "% subjects") +  theme_minimal()

ponline <- gf_dhistogram(~totaltime_m, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["online",]$mean, color = "black") %>% 
  gf_fitdistr(dist = "gamma", color="red")+
  labs(title="Online", x = "Total Time (mins)", y = "% subjects") +  theme_minimal()

plot <-ggarrange(plab, ponline, common.legend = TRUE, nrow = 1, ncol =2)

annotate_figure(plot, 
                top = text_grob("Total Time by Study Mode",color = "black", face = "bold", size = 14),
                bottom = text_grob("fit by Gamma distribution", face = "italic", size = 10))
                
```

**TODO consider log transform of response latency data** *see* archive sgc3A_participants.Rmd

### Time on Question

**TODO time on question**

## RESPONSE CONSISTENCY

**TODO**

## DUE DILIGENCE

### Data Collection Mode on Absolute Score

**Does Mode Change Effect of Condition on Score?**

To verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of ABSOLUTE SCORE for each condition, and examine whether data collection modality is a significant predictor of variance in absolute score

```{r}
#| label : MODEL-ABSCORE-BY-MODALITY

paste("Two Sample T-Test for S_ABS LAB vs. ONLINE control condition")
t.test(data = df_subjects %>% filter(condition == 111), s_ABS ~ mode )

paste("Two Sample T-Test for S_ABS LAB vs. ONLINE impasse condition")
t.test(data = df_subjects %>% filter(condition == 121), s_ABS ~ mode )

paste("OLS Linear Regression Predicting Absolute Score by Data Collection Mode")
summary(lm(data = df_subjects, formula = s_ABS ~ mode ))

```

Both t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative absolute score indicates that data collection mode is not a significant predictor, explaining only 0.01% of variance in absolute score, F(1,328) = 1.03, p \> 0.05.

::: callout-decision
**It is reasonable to infer that data from both in-person and remote studies arise from the same data generating process.**
:::

### Data Collection Mode on Cumulative Score

**Are the by-condition group means significantly different by data collection modality?**

To verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of SCALED SCORE for each condition.

```{r}
#| label : MODEL-SCALEDSCORE-BY-MODALITY

paste("Two Sample T-Test for s_SCALED LAB vs. ONLINE control condition")
t.test(data = df_subjects %>% filter(condition == 111), s_SCALED ~ mode )

paste("Two Sample T-Test for s_SCALED LAB vs. ONLINE impasse condition")
t.test(data = df_subjects %>% filter(condition == 121), s_SCALED ~ mode )

paste("OLS Linear Regression Predicting Scaled Score by Data Collection Mode")
summary(lm(data = df_subjects, formula = s_SCALED ~ mode ))

```

Both t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative scaled score indicates that data collection mode is not a significant predictor, explaining less than 0.001% of variance in absolute score, F(1,328) = 0.0078, p \> 0.05.

::: callout-decision
**It is reasonable to infer that data from both in-person and remote studies arise from the same data generating process.**
:::

## RESOURCES

-   https://rpkgs.datanovia.com/ggpubr/reference/index.html
