---
subtitle: 'Study SGC2 | Hypothesis Testing'
---

\newpage

# Hypothesis Testing {#sec-SGC2-hypotesting}

## TODO

Q3 looks nondiscriminant perhaps remove this from analysis

*The purpose of this notebook is test the hypotheses that determined the design of the SGC2 study.*

1.  **The Need for Scaffolding:** Learners without scaffolding (control) will perform better with the LM than TM\
2.  **The Effectiveness of Scaffolding:** Learners with (any form of) scaffolding will perform better with the TM than LM (replication of \[12\]).\
3.  **Graph-Order as Scaffolding:** Based on observations in Study One we expect that graph-order will act as a scaffold. Learners who solve problems with the LM graph first will perform better on the TM (relative to TM-first learners) as their attention will be drawn to the salient differences between the graphs.\
    <br>
    
  

```{r}
#| label: SETUP
#| warning : false
#| message : false


#UTILITIES
library(Hmisc) # %nin% operator
library(broom) #tidy model output
library(broom.mixed) #tidy mixed  models
library(mosaic) #favstats
library(svglite) #saving plots as svg
library(distributional)

#VISUALIZATION
# library(ggpubr) #arrange plots
# library(cowplot) #arrange shift function plots
library(ggformula) #easy graphs
# # library(vcd) #mosaic plots
# # library(vcdExtra) #mosaic plots
library(kableExtra) #printing tables
library(sjPlot) #visualize model coefficients
library(ggdist) #uncertainty viz
library(modelr) #needed for ggdist
library(gghalves) # plots. in half
library(ggbeeswarm) # violin plot stuffs
library(statsExpressions)
library(ggstatsplot) #plots with stats
library(modelsummary) #latex tables for models!
library(ggeasy) #shortcuts 

#MODELLING
# library(rstatix) #helpful testing functions incl wilcoxon, etc
library(report) #easystats reporting
library(see) #easystats visualization
library(performance) #easystats model diagnostics
library(parameters) #easystats model summary and vis
# library(qqplotr) #confint on qq plot
# library(gmodels) #contingency table and CHISQR
# library(equatiomatic) #extract model equation
# library(pscl) #zeroinfl / hurdle models 
library(lme4) #mixed effects models
library(lmerTest) #for CIs in glmer
library(merTools) #predictInterval
# library(ggeffects) #visualization log regr models
#MULTINOMIAL 
library(nnet) #multinomial logistic regression [not mixed] #no p values
library(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values
#BAYESIAN
library(cmdstanr) #executing stan
library(brms) #bayesian mixed multinomials [+ other bayesian reg models]
library(bayestestR) 
library(tidybayes)
library(posterior)

library(tidyverse) #ALL THE THINGS

#OUTPUT OPTIONS
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
options(ggplot2.summarise.inform = FALSE)
options(scipen=1, digits=3)

#GRAPH THEMEING
# theme_set(theme_minimal()) 

# Custom ggplot theme to make pretty plots
# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed
theme_clean <- function() {
  theme_minimal(base_family = "Barlow Semi Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "BarlowSemiCondensed-Bold"),
          axis.title = element_text(family = "BarlowSemiCondensed-Medium"),
          strip.text = element_text(family = "BarlowSemiCondensed-Bold",
                                    size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA))
}

set_theme(base = theme_clean())

```

**Research Questions**

In SGC2 we compare learner performance on the linear and triangular model graphs by testing the effectiveness of 4 scaffolds and by seeking to replicate the Qiang et.al (2014) finding that after 20 minutes of video training, students perform faster and more accurately with the unconventional TM than the conventional Linear Model (LM). Will our participants show similar performance on the TM with scaffolds rather than formal instruction? Further, will engagement with the TM in a reading task be sufficient for students to reproduce the graph in a subsequent drawing task?

**Hypotheses**

1.  Learners without scaffolding (control) will perform better with the LM than TM
2.  Learners with (any form of) scaffolding will perform better with the TM than LM (replication of \[12\]).
3.  Based on observations in Study One we expect that graph-order will act as a scaffold. Learners who solve problems with the LM graph first will perform better on the TM (relative to TM-first learners) as their attention will be drawn to the salient differences between the graphs.

```{r}
#| label: IMPORT-DATA
#| warning : false
#| message : false

# HACK WD FOR LOCAL RUNNING?
# imac = "/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN"
# mbp = "/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN"
# setwd(mbp)

#IMPORT DATA 
df_items <- read_rds('analysis/SGC2/data/2-scored-data/sgc2_items.rds') %>% dplyr::select(
  subject,
  pretty_condition,
  order,
  scenario,
  graph,
  rt_sec,
  block,
  q_order, 
  q,
  score
) %>% 
  mutate( subject = as.factor(subject),
          accuracy = as.factor(score)) %>% 
  filter(block %nin% c("drawingTest")) #discard drawing task questions (only two, not analyzing)


df_subjects <- read_rds('analysis/SGC2/data/2-scored-data/sgc2_participants.rds') %>% dplyr::select(
  AGE, GENDER, 
  subject,
  pretty_condition,
  order, #order of graphs counterbalanced
  lm_scenarios, #scenario for lm graph
  tm_scenarios, #scenario for tm graph — counterbalanced with graphs
  linear_score,
  triangular_score,
  score_diff, #triangular - linear 
  time_diff, #triangular time  - linear time
  LM_T_M, #linear model time
  TM_T_M, #traingular model time
  DT_T_M, #drawing task time
  draw_type,
  ls_n, #linear scaffold phase score
  lt_n, #linear test phase score
  ts_n, #tri scaffold phase score
  tt_n  #tri test phase score
) %>%  mutate( subject = as.factor(subject)) 


```

## SAMPLE

### Data Collection

Data was collected in Spring 2017.

```{r}
#| label : DESC-DATA-COLLECTION

title = "Participants by Condition and Data Collection Period"
cols = c("Control","Text:What", "Text:How", "Img:Static", "Img:Ixv")
table(df_subjects$pretty_condition) 

```

### Participants

```{r}
#| label: DESC-PARTICIPANTS

#Describe participants
subject.stats <-df_subjects %>% dplyr::select(AGE) %>% unlist() %>% favstats()
subject.stats$percent.male <- ((df_subjects %>% filter(GENDER=="Male") %>% count())/count(df_subjects))$n
subject.stats$percent.female <- ((df_subjects %>% filter(GENDER=="Female") %>% count())/count(df_subjects))$n
subject.stats$percent.other <- ((df_subjects %>% filter(GENDER %nin% c("Female","Male")) %>% count())/count(df_subjects))$n


title = "Descriptive Statistics of Participant Age and Gender"
subject.stats %>% kbl (caption = title) %>% kable_classic()%>% 
  footnote(general = "Age in Years", 
           general_title = "Note: ",footnote_as_chunk = T) 
```

**Overall** `r subject.stats$n` participants (`r round((subject.stats$percent.male),2) * 100` % male, `r round((subject.stats$percent.female),2) * 100` % female, `r round((subject.stats$percent.other),2) * 100` % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: `r (subject.stats$min)` - `r (subject.stats$max)` years).


### Accuracy


## H1 \| The Utility of Scaffolding (aka, Linear Graph x Condition)

Does ACCURACY differ between *scaffold conditions* for the *linear graph*? 

**Hypothesis:**
Scaffolding does not improve performance overall, rather, it is only necessary to facilitate discovery of the triangular coordinate system. Thus, performance with the LM graph won't differ by condition. 

#### Setup

```{r}
#| label: SETUP-H1

#FILTER THE DATASET
#only control condition 
df_s <- df_subjects 

df_i <- df_items %>% filter(graph == "linear") 
```

#### Visualize

```{r}
#| label: VIS-H1

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(order~graph) + 
   labs(title = "Linear Graph Accuracy by Condition and Order",
       x = "Condition",
       subtitle="Across graph orders, Accuracy is comparable across conditions.")

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(scenario ~ graph) + 
   labs(title = "Accuracy by Graph and Scenario",
       x = "Condition",
       subtitle="Across graph scenarios, Accuracy is comparable across conditions.")


#:::::::: STACKED BAR CHART BY QUESTION
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = score)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap( graph ~ q) +
   labs(title = "Accuracy by Question",
       x = "Condition",
       fill = "",
       subtitle="Accuracy differs by question, but is comparable across conditions")

#:::::::: FACETED HISTOGRAM
gf_props(~linear_score,
         fill = ~pretty_condition, data = df_subjects) %>%
  gf_facet_grid(pretty_condition ~ order) +
  labs(x = "# Correct",
       y = "proportion of subjects",
       title = "Linear Graph Score by Condition and Order",
       subtitle = "comprable across factors") + 
  theme(legend.position = "blank")


#:::::::: FACETED HISTOGRAM
gf_props(~linear_score,
         fill = ~pretty_condition, data = df_subjects) %>%
  gf_facet_grid(pretty_condition~tm_scenarios) +
  labs(x = "# Correct",
       y = "proportion of subjects",
       title = "Linear Graph Score by Condition and Scenario",
       subtitle = "comparable across factors") + 
  theme(legend.position = "blank")

# ##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = linear_score,
                        fill = pretty_condition) ) +
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.1,
    width = 1,
    point_colour = NA
   ) +
  geom_boxplot(
    inherit.aes = TRUE, #supress fill
    # mapping = aes(x=pretty_condition, y = score),
    width = .15,
    outlier.shape = NA
  ) +
  geom_point(
    inherit.aes = TRUE, #supress fill
    # mapping = aes(x=graph, y = score, color = graph),
    size = 1.3,
    alpha = .3,
    position = position_jitter(
      seed = 1, width = .05
  )) + labs(
    title = "Distribution of scores on LINEAR graph",
    x = "Condition", y = "Score (# correct)") +
  theme(legend.position = "blank") +
  coord_cartesian(xlim = c(0.5, NA), clip = "off")

```

*Visualizations indicate it is likely that scores in the LM graph scores are stable across conditions (and orders and scenarios)*

#### Describe

```{r}

favstats (linear_score ~ pretty_condition, data = df_subjects)
```

#### Test


```{r}

#PLOT PAIRED DATA
ggbetweenstats(
  data = df_subjects,
  x    = pretty_condition,
  y    = linear_score, 
  type  = "parametric", #parametric, robust, bayes
  annotation.args = list(title = "Linear score is consistent across conditions")
) 

#PLOT PAIRED DATA
grouped_ggbetweenstats(
  data = df_subjects,
  grouping.var = order,
  x    = pretty_condition,
  y    = linear_score, 
  type  = "parametric", #parametric, robust, bayes
  annotation.args = list(title = "Linear score is consistent across conditions and graph order"),
)

#PLOT PAIRED DATA
grouped_ggbetweenstats(
  data = df_subjects,
  grouping.var = tm_scenarios,
  x    = pretty_condition,
  y    = linear_score, 
  type  = "parametric", #parametric, robust, bayes
  annotation.args = list(title = "Linear score is consistent across conditions and graph order"),
)

```

Analysis of Variance implies that it is likely that LINEAR GRAPH score is not affected by condition, across graph orders or scenarios. 

### Logistic Regression

##### Visualize

```{r}
#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
   labs(title = "Linear Graph Accuracy by Condition",
       x = "Condition",
       subtitle="Probability of correct response consistent across conditions")

```

##### Fit Model
```{r}

#empty model
m.0 <- glm(accuracy ~ 1, family = "binomial", data = df_i)

#condition model
m.C <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q), family = "binomial", data = df_i)
# summary(m.C)
# car::Anova(m.C)
```


##### Describe

```{r}
#| label: MODEL-DESC-CACC

# best model
m <- m.C

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)

print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type=2) #TYPE 3 SS FOR IXNS

#:::::::: INTERPRET COEFFICIENTS

paste("LOG ODDS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")

paste("ODDS RATIOS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald", exponentiate = TRUE)

paste("PROBABILITIES")
#probability control = plogis(intercept)
#probability impasse = plogis(intercept + coefficient)

#FROM predict()
newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)
preds <- predict(m, newdata = newdata, type = "response")
preds <- cbind(newdata, preds)
(p <- preds %>% 
  dplyr::select(pretty_condition, preds) %>%
  group_by(pretty_condition) %>%
  summarise(
    median = median(preds),
    se = sd(preds)/sqrt(n()),
    lwr = median - 1.96*se,
    upr = median + 1.96*se))
    
```

##### INFERENCE

A Mixed Logistic Regression model including CONDITION as a fixed effect and SUBJECT and QUESTION as random effects indicates that the odds of a correct response in the linear graph task does not differ by scaffold condition, $\chi(4) = 0.35, p > 0.1$.


##### Visualize

```{r}
#| label: MODEL-VIS-CACC

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = FALSE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)


#ONLY FOR BAYESIAN VERSION
# result <- rope(m)
# plot(result)
# 
# result <- pd(m)
# plot(result)


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
# plot_model(m, type="int",
#            show.intercept = TRUE,
#            show.values = TRUE,
#            title = "Model Prediction | Probability of Accurate Response",
#            axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
plot_model(m, type = "pred")  
# plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

```

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
```

##### Diagnostics

```{r}
#| label: MODEL-DIAG-ACC
#| warning: false
#| message: false

# print("SANITY CHECK REPORTING")
# report(m)

# print("MODEL PERFORMANCE")
# performance(m)

print("DIAGNOSTICS")
check_model(m)

```


## H2 \| The Need for Scaffolding (aka, Linear VS Triangular in CONTROL)

Does ACCURACY differ between *linear* and *triangular* graphs in the control condition?

**Hypothesis** The TM graph is not *discoverable* and requires scaffolding for correct interpretation. We predict that learners without scaffolding (the control condition) will perform better with the LM than TM

#### Setup

```{r}
#| label: SETUP-H1

#FILTER THE DATASET
#only control condition 
df_s <- df_subjects %>% filter(pretty_condition == "control")

df_long <- df_s %>% dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios,linear_score, triangular_score) %>% pivot_longer(
  cols = ends_with("score"),
  names_to = "graph",
  values_to = "score"
)

df_i <- df_items %>% filter(pretty_condition == "control") %>% filter(q %nin% c(3))
```

#### Visualize

```{r}
#| label: VIS-H1

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(order~graph) + 
   labs(title = "Accuracy by Graph and Order",
       x = "Condition",
       subtitle="Across graph orders, Accuracy is higher on the LINEAR than TRIANGULAR graph.")

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(scenario ~ graph) + 
   labs(title = "Accuracy by Graph and Scenario",
       x = "Condition",
       subtitle="Accuracy is higher on the LINEAR than TRIANGULAR graph; much lower for TM = AXIS scenario.")



#:::::::: STACKED BAR CHART BY QUESTION
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = score)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap( graph ~ q) +
   labs(title = "Accuracy by Question",
       x = "Condition",
       fill = "",
       subtitle="")

#:::::::: FACETED HISTOGRAM
gf_props(~score,
         fill = ~graph, data = df_long) %>%
  gf_facet_grid(order ~ graph) +
  labs(x = "# Correct",
       y = "proportion of subjects",
       title = "Overall Absolute Score by Graph and Order",
       subtitle = "") + 
  theme(legend.position = "blank")


#:::::::: FACETED HISTOGRAM
gf_props(~score,
         fill = ~graph, data = df_long) %>%
  gf_facet_grid(tm_scenarios ~ graph) +
  labs(x = "# Correct",
       y = "proportion of subjects",
       title = "Overall Absolute Score by Graph and TM Scenario",
       subtitle = "TM Scores are different by Scenario") + 
  theme(legend.position = "blank")

# ##VERTICAL RAINCLOUD USING GGDISTR
# ggplot(df_long, aes(x = graph, y = score,
#                         fill = graph) ) + 
#   ggdist::stat_halfeye(
#     side = "left",
#     justification = 1.1,
#     width = 1, 
#     point_colour = NA
#    ) + 
#   geom_boxplot(
#     inherit.aes = FALSE, #supress fill
#     mapping = aes(x=graph, y = score),
#     width = .15, 
#     outlier.shape = NA
#   ) + 
#   geom_point(
#     inherit.aes = FALSE, #supress fill
#     mapping = aes(x=graph, y = score, color = graph),
#     size = 1.3,
#     alpha = .3,
#     position = position_jitter( 
#       seed = 1, width = .05
#   )) + labs( 
#     title = "Distribution of scores in CONTROL condition", 
#     x = "Condition", y = "Score (# correct)") +
#   theme(legend.position = "blank") + 
#   coord_cartesian(xlim = c(0.5, NA), clip = "off")


#DISTRIBUTION OF SCORE
gf_dhistogram(~score_diff, data = df_s) %>% 
  gf_facet_grid(tm_scenarios ~ order) +
  xlim(-13,5) + 
  labs(title = "Distribution of paired score differences in CONTROL condition") + 
  easy_remove_legend() 

```

*Visualizations indicate it is likely that scores in the LM are infact higher than the TM in the control condition.*

#### Describe

```{r}


title = "Descriptive Statistics of Response Accuracy by Block (CONTROL Condition)"
abs.stats <- rbind(
  "linear.block"= df_s %>% dplyr::select(linear_score) %>% unlist() %>% favstats(),
  "triangular.block" = df_s %>% dplyr::select(triangular_score) %>% unlist() %>% favstats(),
  "block.differences" = df_s %>% dplyr::select(score_diff) %>% unlist() %>% favstats()
)

abs.stats %>% kbl (caption = title) %>% kable_classic() %>%
  footnote(general = "block # questions correct [0,15]; DIFF = triangular - linear",
           general_title = "Note: ",footnote_as_chunk = T)
```

For participants in the CONTROL condition, total absolute scores for the LINEAR graph (n = `r abs.stats["linear.block",]$n`) range from `r round(abs.stats["linear.block",]$min,2)` to `r round(abs.stats["linear.block",]$max,2)` with a mean score of (M = `r round(abs.stats["linear.block",]$mean,2)`, SD = `r round(abs.stats["linear.block",]$sd,2)`).

For participants in the CONTROL condition, total absolute scores for the TRIANGULAR graph (n = `r abs.stats["triangular.block",]$n`) range from `r round(abs.stats["triangular.block",]$min,2)` to `r round(abs.stats["triangular.block",]$max,2)` with a mean score of (M = `r round(abs.stats["triangular.block",]$mean,2)`, SD = `r round(abs.stats["triangular.block",]$sd,2)`).

Visual inspection of the distribution of scores for each block reveal that scores in on the triangular task were more variant than those in the linear graph. On average, scores on the triangular block were lower than those on the linear block.

#### Test

-   WILCOXON RANK SUM (Mann-Whitney Test) **Non parametric alternative** to t-test; compares median rather than mean by ranking data
-   Does not assume normality
-   Does not assume equal variance of samples (homogeneity of variance)

```{r}

#WILCOXON RANK SUM PAIRED T-TEST
w <- wilcox.test(df_s$linear_score, df_s$triangular_score, 
            paired = TRUE, alternative = "greater", conf.int = TRUE)
w
report(w)
```

```{r}

#PLOT PAIRED DATA
grouped_ggwithinstats(
  grouping.var = order,
  data = df_long,
  x    = graph,
  y    = score, 
  annotation.args = list(title = "Linear is better than Triangular regardless of Order"),
  type  = "nonparametric" #parametric, robust, bayes
) 

#PLOT PAIRED DATA
grouped_ggwithinstats(
  grouping.var = tm_scenarios,
  data = df_long,
  x    = graph,
  y    = score, 
  type  = "nonparametric", #parametric, robust, bayes
  annotation.args = list(title = "Linear is better than Triangular regardless of [triangle model] Scenario"),
)

```

The Wilcoxon signed rank test confirms that (for subjects in the control condition) scores on the **triangle graph** were significantly lower than those in the **linear graph** block. This provides evidence in support of our hypothesis that the Triangular model graph (though computationally efficient) is in fact unconventional and lacking in discoverablility. It needs to be augmented with scaffolding in order to be correctly interpreted by novice readers.

#### MIXED EFFECTS LOGISTIC REGRESSION

*Fit mixed effects logistic regression model to test effect of GRAPH, ORDER, and SCENARIO on probability of correct response \[just in the control condition\]*

##### Fit Model

```{r}
#| label: MODEL-FIT-CACC

## 0 | SETUP
#confirm 13 items [all discriminating items]
nrow(df_i) / nrow(df_s) == 28 #removed nondiscrim Q3
#confirm all factors 
is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$graph) && is.factor(df_i$score) && is.factor(df_i$order) && is.factor(df_i$scenario)


#RECODE TRIANGULAR AS REFERENCE LEVEL 
df_i <- df_i %>% mutate(
  graph = recode_factor(graph, "triangular"="triangular","linear"="linear")
) 

## 1 | SETUP RANDOM INTERCEPT SUBJECT

#:: EMPTY MODEL (baseline, no random effect)
print("Empty fixed model")
m0 = glm(accuracy ~ 1, family = "binomial", data = df_i) 
# summary(m0)

#:: RANDOM INTERCEPT SUBJECT
print("Subject intercept random model")
mm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = "binomial")
# summary(mm.rS)

# :: TEST random effect
paste("AIC decreases w/ new model?", m0$aic > AIC(logLik(mm.rS)))
test_lrt(m0,mm.rS) #same as anova(m0, m1, test = "Chi")


#:: RANDOM INTERCEPT SUBJECT + ITEM
print("Subject Intercept + Item intercept random model")
mm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = "binomial")
#summary(mm.rSQ)

# :: TEST random effect
paste("AIC decreases w/ new model?", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))
test_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = "Chi")

## 2 | ADD FIXED EFFECT GRAPH

print("FIXED Condition + Subject & Item random intercepts")
mm.GrSQ <- glmer(accuracy ~ graph + (1|subject) + (1|q) ,
                data = df_i, family = "binomial")
# car::Anova(mm.GrSQ) #main effect graph

paste("AIC decreases w/ new model", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.GrSQ)) )
test_lrt(mm.rSQ,mm.GrSQ) #same as anova(m0, m1, test = "Chi")


# NOT RELEVANT TO HYPOTHESIS 
# 
# ## 2 | ADD IXN GRAPH & ORDER EFFECT GRAPH ++ ORDER
# 
# print("FIXED Graph + ORDER + Subject & Item random intercepts")
# mm.GOrSQ <- glmer(accuracy ~ graph * order + (1|subject) + (1|q) ,
#                 data = df_i, family = "binomial")
# # summary(mm.GOrSQ)
# # car::Anova(mm.GOrSQ)
# 
# paste("AIC decreases w/ new model", AIC(logLik(mm.GrSQ)) > AIC(logLik(mm.GOrSQ)) )
# test_lrt(mm.GrSQ,mm.GOrSQ) #same as anova(m0, m1, test = "Chi")
# 
# 
# ## 2 | ADD FIXED EFFECT GRAPH + ORDER+ SCENARIO
# 
# print("FIXED Graph * SCENARIO * ORDER + Subject & Item random intercepts")
# mm.GSOrSQ <- glmer(accuracy ~ graph*scenario*order + (1|subject) + (1|q) ,
#                 data = df_i, family = "binomial",
#                 control=glmerControl(optimizer="bobyqa",
#                                  optCtrl=list(maxfun=2e5)))
# # summary(mm.GSOrSQ)
# #car::Anova(mm.GSOrSQ)
# 
# paste("AIC decreases w/ new model", AIC(logLik(mm.GOrSQ)) > AIC(logLik(mm.GSOrSQ)) )
# test_lrt(mm.GOrSQ,mm.GSOrSQ) #same as anova(m0, m1, test = "Chi")


```


##### Describe

```{r}
#| label: MODEL-DESC-CACC

# best model
m <- mm.GrSQ

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)

print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type=2) #TYPE 3 SS FOR IXNS

#:::::::: INTERPRET COEFFICIENTS

paste("LOG ODDS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")

paste("ODDS RATIOS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald", exponentiate = TRUE)

paste("PROBABILITIES")
#probability control = plogis(intercept)
#probability impasse = plogis(intercept + coefficient)

#FROM predict()
newdata <- df_i %>% dplyr::select(graph, subject, q)
preds <- predict(m, newdata = newdata, type = "response")
preds <- cbind(newdata, preds)
(p <- preds %>%
  dplyr::select(graph, preds) %>%
  group_by(graph) %>%
  summarise(
    median = median(preds),
    se = sd(preds)/sqrt(n()),
    lwr = median - 1.96*se,
    upr = median + 1.96*se))
    
  
# #FROM merTools
# #setup df 
# newdata <- df_i %>% dplyr::select(graph, order, scenario, subject, q)
# #make predictions
# preds <- predictInterval(m, newdata = newdata,
#                               which = "fixed", #full, fixed or random for those only
#                               type = "probability", #linear.prediction
#                               stat = "median",
#                               n.sims = 1000,
#                               level = 0.80) #width of prediction interval
# #join predictions to the new dataframe
# preds <- cbind(newdata, preds)
# #summarize
# (summ_preds <- preds %>% 
#   dplyr::select(graph, scenario, order, fit, lwr, upr) %>% 
#   group_by(graph, scenario, order) %>% 
#   dplyr::summarise(
#     median = median(fit),
#     lower = median(lwr),
#     upper = median(upr)
#   )) 

```

##### Inference TODO UPDATE

We fit a mixed logistic regression model predicting question-level accuracy by graph for only participants in the control condition (n = 61). The model included random intercepts for subject and question, and a fixed effect of GRAPH. The model implies that (with no scaffolding; in the control condition) the odds of a correct response on a linear-graph question are more than 4 times higher than the triangle graph, ($e^\beta_1 = 4.34, 95 \% CI [3.47, 5.44], p < 0.001$) 

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",
# 
# 
# 

```

##### Visualize

```{r}
#| label: MODEL-VIS-CACC

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)


#ONLY FOR BAYESIAN VERSION
# result <- rope(m)
# plot(result)
# 
# result <- pd(m)
# plot(result)


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
# plot_model(m, type="int",
#            show.intercept = TRUE,
#            show.values = TRUE,
#            title = "Model Prediction | Probability of Accurate Response",
#            axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
plot_model(m, type = "pred")  
plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

#TODO EMMEANS for the estimated marginal means OR USE IXN PLOT


```

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
```

##### Diagnostics

```{r}
#| label: MODEL-DIAG-ACC
#| warning: false
#| message: false

# print("SANITY CHECK REPORTING")
# report(m)

# print("MODEL PERFORMANCE")
# performance(m)

print("DIAGNOSTICS")
check_model(m)

```






## H3 \| Computational Efficiency

**Hypothesis** Qiang et. al found that the TM graph was more computationally efficient than the LM graph. We expect that for learners that *do* correctly interpret the graph, they will have lower response times for the TM vs. LM graph.

### H2 \| Realizing Computational Efficiency -- SCORE DIFFERENCE

#### Setup

```{r}
#| label: SETUP-ACC

#FILTER THE DATASET
#only control condition 
df_s <- df_subjects %>% dplyr::select(score_diff, time_diff, subject, order, tm_scenarios, pretty_condition)

df_i <- df_items %>% filter(q %nin% c(3))
```

#### Visualize

```{r}

# Box plots
# ++++++++++++++++++++
# Plot weight by group and color by group
library("ggpubr")
ggboxplot(df_s, x = "pretty_condition", y = "score_diff", 
          color = "pretty_condition", 
          # palette = c("#00AFBB", "#E7B800", "#FC4E07"),
          # order = c("ctrl", "trt1", "trt2"),
          title = "DIFFERENCE IN GRAPH scores by Condition",
          ylab = "TRI - LINEAR Score [-15,15]", xlab = "Condition") +
  geom_hline(yintercept = 0, color = "black") + 
  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +
  ylim(-15,15) + 
  # facet_wrap(order~ tm_scenarios) +
  easy_remove_legend() + theme_clean()

```

```{r}

favstats(score_diff ~ pretty_condition, data = df_s)

```

### TEST

```{r}

df_what <- df_s %>% filter(pretty_condition=="text:what")
df_how <- df_s %>% filter(pretty_condition=="text:how")
df_img <- df_s %>% filter(pretty_condition=="img:static")
df_ixn <- df_s %>% filter(pretty_condition=="img:ixv")

t.test(x = df_what$score_diff, mu = 0, alternative = 'less')
t.test(x = df_how$score_diff, mu = 0,  alternative = 'less')
t.test(x = df_img$score_diff, mu = 0,  alternative = 'less')
t.test(x = df_ixn$score_diff, mu = 0,  alternative = 'less')

```
To test the hypothesis that each scaffold condition will improve performance on the triangular graph to a level that matches or exceeds that of the linear graph, we first calculated a difference score for each participant (triangular-linear score). We then performed a one-sample t-test for each scaffold condition, testing the null hypothesis that the mean difference score for that condition is greater than or equal to 0. The t-statistics and resulting p-values indicating the need to reject the null hypothesis for the what-text, how-text and static-img conditions, indicating that while they the scaffolds do seem to improve performance, accuracy does not match or exceed that of the linear graph.  Only for the interactive image condition did we fail to reject the null hypothesis, indicating that the interactive image may infact improve performance to at least match that of the linear graph. 

### LINEAR REGRESSION [ SCORE diff ~ condition]

#### Fit Model

```{r}

#empty model
m.0 <- lm( data = df_s, score_diff ~ 1)

#predictor model
m.C <- lm(data = df_s, score_diff ~ pretty_condition)
car::Anova(m.C)
test_lrt(m.0, m.C)
```

### H2 \| Realizing Computational Efficiency ------ TIME EFFICIENCY

#### Visualize

```{r}

ggboxplot(df_s, x = "pretty_condition", y = "time_diff", 
          color = "pretty_condition", 
          # palette = c("#00AFBB", "#E7B800", "#FC4E07"),
          # order = c("ctrl", "trt1", "trt2"),
          title = "DIFFERENCE IN TIME by Condition",
          ylab = "TRI - LINEAR TIME (seconds)", xlab = "Condition") +
  geom_hline(yintercept = 0, color = "black") + 
  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +
  # facet_wrap(order~ tm_scenarios) +
  easy_remove_legend() + theme_clean()

```

#### Model Response time for CORRECT answers

**Is the TRIANGULAR graph FASTER for correct answers? (i.e. computational efficiency)**

```{r}

#GET ONLY CORRECT ITEMS in TEST phase 
df <- df_items %>% filter(q %nin% c(1,2,3,4,5)) %>% filter(score == 1)

table (df$pretty_condition)

# Box plots
# ++++++++++++++++++++
ggplot( data = df, aes( x = pretty_condition, y = rt_sec, color = graph )) + 
  geom_boxplot(position = position_dodge()) 
  # geom_point( alpha = 0.2, position = position_dodge(width = 2))


## Does GRAPH predict rt_sec for correct items?
m <- lmer( log(rt_sec) ~ graph + (1|q), data = df)
summary(m)
car::Anova(m)

plot_model(m, type = "pred")


```

A mixed log-linear model predicting response time by GRAPH for only CORRECT items in the test phase (i.e. without scaffolding text or images) indicates that there is not a significant difference between response times for linear and orthogonal graphs.

#### Model Response time for by ACCURACY on TRIANGLE graph (Test Phase)

**Are *correct* answers FASTER than *incorrect* answers for the TRIANGULAR graph? (i.e. computational inefficiency of mental projection/transformation)**

```{r}

#GET ONLY CORRECT ITEMS in TEST phase 
df <- df_items %>% filter(q %nin% c(1,2,3,4,5)) %>% filter(graph=="triangular")

table (df$pretty_condition)

# ++++++++++++++++++++
ggplot( data = df, aes( x = pretty_condition, y = rt_sec, color = score )) + 
  geom_boxplot(position = position_dodge()) 
  # geom_point( alpha = 0.2, position = position_dodge(width = 2))


gf_histogram(~log(rt_sec), data = df) %>% 
  gf_facet_grid(score ~ .)



## Does ACCURACY predict rt_sec for correct items?
m <- lmer( log(rt_sec) ~ accuracy + (1|q), data = df)
summary(m)
car::Anova(m)

plot_model(m, type = "pred")



```

A mixed log-linear model predicting response time by GRAPH for only CORRECT items in the test phase (i.e. without scaffolding text or images) indicates that there is not a significant difference between response times for linear and orthogonal graphs.

## H3 \| The Effectiveness of Scaffolding

**Hypothesis** All of the designs offered by participants in Study 1 are promising. We expect that only a small amount of scaffolding (a little nudge) will be required to help readers correctly interpret the graph. We predict that learners with (any form of) scaffolding will perform better with the TM than readers in the CONTROL condition.

#### Setup

```{r}

#FILTER THE DATASET
#only control condition 
df_s <- df_subjects 

df_long <- df_s %>% dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios,linear_score, triangular_score) %>% pivot_longer(
  cols = ends_with("score"),
  names_to = "graph",
  values_to = "score"
)

df_i <- df_items %>% filter(q %nin% c(3))
```

#### Visualize

```{r}

## HISTOGRAM
gf_histogram( ~ triangular_score, fill = ~pretty_condition, binwidth = 1, data = df_s) %>%
  gf_facet_grid(pretty_condition ~ .)

## MEDIANS
ggbetweenstats( y = triangular_score, x = pretty_condition, data = df_s, 
                type = "nonparametric",   var.equal = FALSE,
                pairwise.comparisons = TRUE,
                pairwise.display = "significant",
                p.adjust.method = "none"
)

```

```{r}

# Box plots
# ++++++++++++++++++++
# Plot weight by group and color by group
library("ggpubr")
ggboxplot(df_s, x = "pretty_condition", y = "linear_score", 
          color = "pretty_condition", 
          # palette = c("#00AFBB", "#E7B800", "#FC4E07"),
          # order = c("ctrl", "trt1", "trt2"),
          title = "LINEAR Graph Scores by Condition",
          subtitle = "No effect of condition, order or scenario",
          ylab = "Linear Score [0,15]", xlab = "Condition") +
  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +
  facet_wrap(order~ tm_scenarios)+
  easy_remove_legend() + theme_clean()

```

```{r}

# Box plots
# ++++++++++++++++++++
# Plot weight by group and color by group
library("ggpubr")
ggboxplot(df_s, x = "pretty_condition", y = "triangular_score", 
          color = "pretty_condition", 
          # palette = c("#00AFBB", "#E7B800", "#FC4E07"),
          # order = c("ctrl", "trt1", "trt2"),
          title = "TRIANGULE Graph Scores by Condition",
          subtitle = "Clear effect of condition, possible ixn scenario",
          ylab = "Triangular Score [0,15]", xlab = "Condition") +
  geom_jitter( aes(color = pretty_condition), width = 0.15, alpha = 0.5) +
  facet_wrap(order~ tm_scenarios)+
  easy_remove_legend() + theme_clean()

```

```{r}
#| label: VIS-acc

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(order~graph) + 
   labs(title = "Accuracy by Graph and Order",
       x = "Condition",
       subtitle="Across graph orders, Accuracy is higher on the LINEAR than TRIANGULAR graph.")

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(scenario ~ graph) + 
   labs(title = "Accuracy by Graph and Scenario",
       x = "Condition",
       subtitle="Accuracy is higher on the LINEAR than TRIANGULAR graph; much lower for TM = AXIS scenario.")



# ##VERTICAL RAINCLOUD USING GGDISTR
# ggplot(df_long, aes(x = graph, y = score,
#                         fill = graph) ) + 
#   ggdist::stat_halfeye(
#     side = "left",
#     justification = 1.1,
#     width = 1, 
#     point_colour = NA
#    ) + 
#   geom_boxplot(
#     inherit.aes = FALSE, #supress fill
#     mapping = aes(x=graph, y = score),
#     width = .15, 
#     outlier.shape = NA
#   ) + 
#   geom_point(
#     inherit.aes = FALSE, #supress fill
#     mapping = aes(x=graph, y = score, color = graph),
#     size = 1.3,
#     alpha = .3,
#     position = position_jitter( 
#       seed = 1, width = .05
#   )) + labs( 
#     title = "Distribution of scores in CONTROL condition", 
#     x = "Condition", y = "Score (# correct)") +
#   theme(legend.position = "blank") + 
#   coord_cartesian(xlim = c(0.5, NA), clip = "off")


#DISTRIBUTION OF SCORE DIFFERENCE
gf_dhistogram(~score_diff, fill = ~pretty_condition, data = df_s) %>% 
  gf_facet_grid(pretty_condition ~ order) +
  xlim(-13,5) + 
  labs(title = "Distribution of paired score differences by CONDITION and ORDER") + 
  easy_remove_legend() 


#DISTRIBUTION OF SCORE DIFFERENCE
gf_dhistogram(~score_diff, fill = ~pretty_condition, data = df_s) %>% 
  gf_facet_grid(pretty_condition ~ tm_scenarios) +
  xlim(-13,5) + 
  labs(title = "Distribution of paired score differences by CONDITION and TM SCENARIO") + 
  easy_remove_legend() 

```

#### Describe

```{r}
#| label: DESCR-H1
#| 
title = "Descriptive Statistics of Response Accuracy by Block (CONTROL Condition)"
abs.stats <- rbind(
  "linear.block"= df_s %>% dplyr::select(linear_score) %>% unlist() %>% favstats(),
  "triangular.block" = df_s %>% dplyr::select(triangular_score) %>% unlist() %>% favstats(),
  "block.differences" = df_s %>% dplyr::select(score_diff) %>% unlist() %>% favstats()
)

abs.stats %>% kbl (caption = title) %>% kable_classic() %>%
  footnote(general = "block # questions correct [0,15]; DIFF = triangular - linear",
           general_title = "Note: ",footnote_as_chunk = T)
```

For participants in the CONTROL condition, total absolute scores for the LINEAR graph (n = `r abs.stats["linear.block",]$n`) range from `r round(abs.stats["linear.block",]$min,2)` to `r round(abs.stats["linear.block",]$max,2)` with a mean score of (M = `r round(abs.stats["linear.block",]$mean,2)`, SD = `r round(abs.stats["linear.block",]$sd,2)`).

For participants in the CONTROL condition, total absolute scores for the TRIANGULAR graph (n = `r abs.stats["triangular.block",]$n`) range from `r round(abs.stats["triangular.block",]$min,2)` to `r round(abs.stats["triangular.block",]$max,2)` with a mean score of (M = `r round(abs.stats["triangular.block",]$mean,2)`, SD = `r round(abs.stats["triangular.block",]$sd,2)`).

```{r}

#PLOT PAIRED DATA
grouped_ggwithinstats(
  grouping.var = pretty_condition,
  data = df_long,
  x    = graph,
  y    = score, 
  type  = "nonparametric", #parametric, robust, bayes
  annotation.args = list(title = "Effect of Condition"),
)

```

#### LINEAR REGRESSION --\> SCORE DIFF

Predict difference score by condition, order and tm_scenario

##### Fit Model

```{r}

# empty model 
m0 <- lm( score_diff ~ 1, data = df_s)

# CONDITION model 
m.C <- lm( score_diff ~ pretty_condition, data = df_s)
paste("Condition model better fit than empty?")
test_lrt(m0,m.C)
car::Anova(m.C) #main effects condition, order

# CONDITION + ORDER model 
m.C.O <- lm( score_diff ~ pretty_condition + order, data = df_s)
paste("Condition + Order model better fit than CONDITION?")
test_lrt(m.C.O,m.C)
# car::Anova(m.CO) #main effects condition, order

# CONDITION + ORDER + SCENARIO model 
m.C.O.S <- lm( score_diff ~ pretty_condition + order + tm_scenarios, data = df_s)
paste("Condition*Order + Scenario model better fit than interactions model?")
test_lrt(m.C.O.S,m.C.O)
# car::Anova(m.C.O.S) #main effects condition, order scenario, scenario

# CONDITION*ORDER*SCENARIO model 
m.COS <- lm( score_diff ~ pretty_condition*order*tm_scenarios, data = df_s)
paste("Condition*Order*Scenario model better fit than CONDITION*ORDER + SCENARIO?")
test_lrt(m.C.O.S,m.COS)
# car::Anova(m.COS, type = 3) #main effects condition, order scenario, IXN condition & order
#interaction model is not a better fit than main effects only 

```

*The best fitting model is one with condition + order + scenario.*

##### Describe

```{r}

# best model
m <- m.C.O.S

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)

print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type=2) #TYPE 3 SS FOR IXNS

#:::::::: MANUAL ONE-SIDED SIGTEST 
#note: anova and chi square are always one-tailed, but that is independent of being one-sided
#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half

# one-sided (right tail) z test for B COEFFICIENT
#SANITY CHECK 2-tailed test should match the model output
#NOTE ... NEED TO DO THIS FOR _EACH_ COEFFICIENT
# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("p value for two-tailed test, null B = 0 : ",round(tt,5))
# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("BUT we want a one  directional, null: B <= 0: ",round(ot,5))

#:::::::: INTERPRET COEFFICIENTS
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")

paste("PROBABILITIES")
#probability control = plogis(intercept)
#probability impasse = plogis(intercept + coefficient)

#FROM predict()
newdata <- df_s %>% dplyr::select(pretty_condition, order, tm_scenarios, subject)
preds <- predict(m, newdata = newdata, type = "response")
preds <- cbind(newdata, preds)
(p <- preds %>%
  group_by(pretty_condition, order, tm_scenarios) %>%
  dplyr::summarise(
    median = median(preds),
    se = sd(preds)/sqrt(n()),
    lwr = median - 1.96*se,
    upr = median + 1.96*se))
    
```

##### Visualize

```{r}


## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Score Difference (TRI - LIN)",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="eff",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response")

#PLOT MODEL PREDICTION
# plot_model(m, type = "pred")  
# plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

#TODO EMMEANS for the estimated marginal means OR USE IXN PLOT


```

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
```

#### MIXED EFFECTS LOGISTIC REGRESSION --\> RAW SCORE

*Fit mixed effects logistic regression model to test effect of GRAPH, ORDER, and SCENARIO on probability of correct response \[just in the control condition\]*

##### Fit Model

```{r}
#| label: MODEL-FIT-ACC

## 0 | SETUP
#confirm 13 items [all discriminating items]
nrow(df_i) / nrow(df_s)  #removed nondiscrim Q3

#confirm all factors 
is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$graph) && is.factor(df_i$score) && is.factor(df_i$order) && is.factor(df_i$scenario)

## 1 | SETUP RANDOM INTERCEPT SUBJECT

#:: EMPTY MODEL (baseline, no random effect)
print("Empty fixed model")
m0 = glm(accuracy ~ 1, family = "binomial", data = df_i) 
# summary(m0)

#:: RANDOM INTERCEPT SUBJECT + ITEM
print("Subject Intercept + Item intercept random model")
mm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = "binomial")
#summary(mm.rSQ)

## 2 | ADD FIXED EFFECT GRAPH

print("FIXED GRAPH + Subject & Item random intercepts")
mm.GrSQ <- glmer(accuracy ~ graph + (1|subject) + (1|q) ,
                data = df_i, family = "binomial")
# car::Anova(mm.GrSQ) #main effect graph

paste("AIC decreases w/ new model", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.GrSQ)) )
test_lrt(mm.rSQ,mm.GrSQ) #same as anova(m0, m1, test = "Chi")


## 2 | ADD FIXED EFFECT CONDITION

print("IXN GRAPH*Condition + Subject & Item random intercepts")
mm.GCrSQ <- glmer(accuracy ~ graph*pretty_condition + (1|subject) + (1|q) ,
                data = df_i, family = "binomial", 
                control=glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
#car::Anova(mm.GCrSQ) #main effects graph + IXN graph*condition

paste("AIC decreases w/ new model", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.GCrSQ)) )
test_lrt(mm.rSQ,mm.GCrSQ) #same as anova(m0, m1, test = "Chi")


# 2 | ADD IXN ORDER
print("FIXED Graph + ORDER + Subject & Item random intercepts")
mm.GC.COrSQ <- glmer(accuracy ~ graph*pretty_condition + graph*order + (1|subject) + (1|q),
                   data = df_i, family = "binomial", 
                   control=glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
# summary(mm.GC.COrSQ)
car::Anova(mm.GC.COrSQ, type = 3) #IXN graphX condition, GRAPH*order

#x <-  mm.GCOrSQ <- glmer(accuracy ~ graph*pretty_condition*order + (1|subject) + (1|q),
#                    data = df_i, family = "binomial", 
#                    control=glmerControl(optimizer="bobyqa",
#                                  optCtrl=list(maxfun=2e5)))
# car::Anova(x) # 3 way ixn graph,condition,order??


paste("AIC decreases w/ new model", AIC(logLik(mm.GCrSQ)) > AIC(logLik(mm.GC.COrSQ)) )
test_lrt(mm.GCrSQ,mm.GC.COrSQ) 


# 3 | ADD FIXED EFFECT SCENARIO

print("FIXED Graph * SCENARIO * ORDER + Subject & Item random intercepts")
mm.GC.CO.GSrSQ <- glmer(accuracy ~ graph*pretty_condition + graph*order + graph*scenario +  (1|subject) + (1|q) ,
                data = df_i, family = "binomial",
                control=glmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
summary(mm.GC.CO.GSrSQ)
car::Anova(mm.GC.CO.GSrSQ, type = 3) #IXN graphXscenario, graphXorder, graphXcondition, 

paste("AIC decreases w/ new model", AIC(logLik(mm.GC.COrSQ)) > AIC(logLik(mm.GC.CO.GSrSQ)) )
test_lrt(mm.GC.COrSQ,mm.GC.CO.GSrSQ) #same as anova(m0, m1, test = "Chi")


```

The best fitting model included interactions for graph X condition, graph X order, and graph X scenario

##### Describe

```{r}

# best model
m <- mm.GC.CO.GSrSQ

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)

print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type=3) #TYPE 3 SS FOR IXNS

#:::::::: INTERPRET COEFFICIENTS

paste("LOG ODDS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")

paste("ODDS RATIOS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald", exponentiate = TRUE)

paste("PROBABILITIES")
#probability control = plogis(intercept)
#probability impasse = plogis(intercept + coefficient)

#FROM merTools
#setup empty df 
newdata <- df_i %>% dplyr::select(graph, pretty_condition, order, scenario, subject, q)
#make predictions
preds <- predictInterval(m, newdata = newdata,
                              which = "fixed", #full, fixed or random for those only
                              type = "probability", #linear.prediction
                              stat = "median",
                              n.sims = 1000,
                              level = 0.80) #width of prediction interval
#join predictions to the new dataframe
preds <- cbind(newdata, preds)
#summarize
(summ_preds <- preds %>% 
  dplyr::select(graph, pretty_condition, scenario, order, fit, lwr, upr) %>% 
  group_by(graph, pretty_condition, scenario, order) %>% 
  dplyr::summarise(
    median = median(fit),
    lower = median(lwr),
    upper = median(upr)
  )) 

```

##### Inference TODO UPDATE

##### Visualize

```{r}

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
# result <- model_parameters(m, exponentiate = TRUE, component = "all")
# plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="int",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response")

#PLOT MODEL PREDICTION
# plot_model(m, type = "pred")  
# plot_model(m, type = "eff")  
  # ylim(0,1) + 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

#TODO EMMEANS for the estimated marginal means OR USE IXN PLOT


```

```{r}
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
```

##### Diagnostics

```{r}
#| warning: false
#| message: false

# print("SANITY CHECK REPORTING")
# report(m)

# print("MODEL PERFORMANCE")
# performance(m)

print("DIAGNOSTICS")
check_model(m)

```

## DRAWING TASK

### Setup

```{r}
 
df_s <- df_subjects

```

### Visualize

```{r}

ggbarstats( x = draw_type, y =pretty_condition , data = df_s,
            title = "Drawing Type by Condition")


#drawing type by order 
grouped_ggbarstats( x = draw_type, y =pretty_condition , 
                    grouping.var = order, data = df_s,
                    annotation.args = list(
                      title = "Drawing type BY ORDER"
                    ))

#drawing type by tm-scenario 
grouped_ggbarstats( x = draw_type, y =pretty_condition , 
                    grouping.var = tm_scenarios, data = df_s,
                    annotation.args = list(
                      title = "Drawing type BY tm-scenario"
                    ))
```

### MULTINOMIAL REGRESSION

*Does condition affect the type of drawing produced?*

##### Fit Model \[multinom\]

```{r}
#| label: FIT-MBLOGIT-STATE

#https://www.elff.eu/software/mclogit/manual/mblogit/
#"baseline category logit" model matches multinom()

#check reference level 
print("Categories (first is reference)")
levels(df_s$draw_type)

#FIT EMPTY MODEL
# print("EMPTY MODEL")
mm.cat.rSQ <- multinom(draw_type ~ 1 , data = df_s)
# summary(mm.cat.rSQ)

#FIT PREDICTOR MODEL
# print("PREDICTOR MODEL")
mm.cat.CrSQ <- multinom(draw_type ~ pretty_condition , data = df_s)
mb <- mblogit(draw_type ~ pretty_condition , data = df_s)


#COMPARE MODEL FIT
paste("AIC wth predictor is lower than empty model?", AIC(mm.cat.rSQ) > AIC(mm.cat.CrSQ))
test_lrt(mm.cat.rSQ, mm.cat.CrSQ)
```

##### Describe

```{r}
#| label: DESC-BRMS-STATE

# best model
m <- mm.cat.CrSQ

#DESCRIBE MODEL
summary(mb) #use mblogit version to see estimate level p values

#INTERPRET COEFFICIENTS
paste("LOG ODDS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")
paste("ODDS RATIOS")
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald", exponentiate = TRUE)


#PERFORMANCE
performance(m)


paste("PROBABILITIES")

#PREDICT METHOD
newdata <- df_i %>% dplyr::select(pretty_condition, subject)
preds <- predict(m, newdata = newdata, type = "probs")
preds <- cbind(newdata, preds)
#lengthen data frame to handle multinomial
preds <- preds %>%
  dplyr::select(-subject) %>% #marginalize over subject and q
  pivot_longer(
  cols = !pretty_condition,
  values_to = "preds",
  names_to = "drawing_type",
)

(p <- preds %>%
  group_by(pretty_condition, drawing_type ) %>%
  dplyr::summarise(
    median = median(preds),
    se = sd(preds)/sqrt(n()),
    lwr = median - 1.96*se,
    upr = median + 1.96*se))

##DRAWS METHOD
# GENERATE draws from model
# draws <- df_i %>%
#   data_grid(pretty_condition, subject, q) %>% 
#   add_fitted_draws(Bmm.cat.CrSQ,
#                    # n = 100,
#                    # dpar = TRUE,
#                    # transform = TRUE, #gives prob%, otherwise OR
#                    re_formula = NA)
# # draws %>% write_rds(file = "analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds")
# 
# #OR load from file
# # draws <- read_rds(file = "analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds")
# 
# # SUMMARIZE draws from model
# (k <- kable(draws %>%
#   dplyr::select(pretty_condition, .category, .value) %>%
#   group_by(pretty_condition, .category) %>%
#   median_hdci(.value), digits = 4, col.names =
#     c("Condition","Category", "Probability","Lower Cred.I","Upper Cred.I", "CI Width", "Point Type", "Interval Type")) %>%
#   kable_styling())

```

##### INFERENCE

##### Visualize

```{r}
#| label: VIS-BRMS-STATE



## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
# plot_model(m, vline.color = "red", 
#            show.intercept = TRUE, 
#            show.values = TRUE,
#            p.threshold = 0.1, #manually adjust to account for directional test
#            ci.lvl = 0.90 ) + #manually adjusted for directional test   
#   labs(title = "Model Estimate | Odds Ratio",
#        subtitle = "",
#        x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
result <- model_parameters(m, exponentiate = TRUE, component = "all")
plot(result, show_intercept = TRUE, show_labels = TRUE) 
# + theme_clean()


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="eff",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Drawing Type",
           axis.title = c("Condition","Probability of Drawing Type"))



```

```{r}
#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE
##WORKING
# https://mjskay.github.io/ggdist/reference/stat_slab.html
## VIS probability of correct response
#TAKES A REALLY LONG TIME

#1 | get draws
# draws <- df_i %>%
#   data_grid(pretty_condition, ospan_split, subject, q) %>%
#   add_epred_draws(m,
#                    # ndraws = 100, # n = 100,
#                    # dpar = TRUE,
#                    transform = TRUE, #gives prob%, otherwise OR
#                    re_formula = NA)
# # draws %>% write_rds(file = "analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds")
# 
# #OR load from file
# # draws <- read_rds(file = "analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds")
# 
# #2| VISUALIZE PREDICTIONS | GGDIST
# ##TODO figure out height normalization.
# ##do it with much smaller number of draws 
# #TODO adjust bandwidth/smoothing? + put on same line + 
# #TAKES A REAAALY LONG TIME
# # d <- 
# 
# d <- draws %>% sample_n(10) %>% 
#   ggplot(aes(x = .epred,  y = pretty_condition, fill = ospan_split)) +
#   stat_slab(width = c(.95), alpha = 0.5, normalize="xy") +
#   facet_wrap(~.category) +
#   #   #normalize = all, panels, xy, groups, none
#   xlim(0,1) + labs(
#     title = "Model Predicted Probability of Correct Response",
#     x = "probability of correct response",
#     y = "Interpretation"
#   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()
# # # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()
# # # 
# # # ggsave(d, filename = "figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg", width = 6, height =4)
# d
```

```{r}
#| label: TBL-BRMS-STATE

#DISPLAY MODEL AS TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m, "(log odds)" = m)
# notes = list('"* p < 0.05, ** p < 0.01, *** p < 0.001"',
#                'N(subject) = 133 $\tau_{00}$(subject) = 34.85',
#              'N(question) = 13 $\tau_{00}$(question) = 1.14')
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex")
# # #              # coef_omit = "Intercept",
#TODO OUTPUT TABLE 

#https://arelbundock.com/posts/modelsummary_multinomial_logit/
# modelsummary(m)



```

## HO \| Diagrams 2018 Replication

#### Setup

```{r}
#| label: SETUP-ALL

#FILTER THE DATASET
#only control condition 
df_s <- df_subjects 

df_long <- df_s %>% 
  dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios,linear_score, triangular_score) %>% 
  pivot_longer(
  cols = ends_with("score"),
  names_to = "graph",
  values_to = "score"
)

# df_i <- df_items %>% filter(pretty_condition == "control") %>% filter(q %nin% c(3))
```

#### Visualize
```{r}

ggplot( data = df_long, aes( x = pretty_condition, y = score, fill = graph)) + 
  geom_boxplot(position = position_dodge()) + 
  facet_wrap(~order) + theme_clean()

```

#### Model

To explore the potential influence of graph, scaffold, and graph-order on scores, we performed a mixed effects ANOVA on score with graph as the within-subjects factor, and scaffold, graph-order and scenario as between-subjects factors 

```{r}

# m <- lm (  diff_score ~ pretty_condition + (1|subject), data = df_subjects )
# 
# plot_model(m)
```

