---
subtitle: 'Study SGC4A | Hypothesis Testing'
---

\newpage

# Hypothesis Testing {#sec-SGC4A-hypotesting}


*The purpose of this notebook is test the hypotheses that determined the designs of the SGC4A study.*

```{r}
#| label: SETUP
#| warning : false
#| message : false

#UTILITIES
library(Hmisc) # %nin% operator
library(broom) #tidy model output
library(broom.mixed) #tidy model output
library(mosaic) #favstats
# library(modelr)
library(distributional)
# library(jtools)
# library(pwr) #power analysis

#VISUALIZATION
library(scales)
# library(ggpubr) #arrange plots
# library(cowplot) #arrange shift function plots
library(ggformula) #easy graphs
# # library(vcd) #mosaic plots
# # library(vcdExtra) #mosaic plots
library(kableExtra) #printing tables
library(sjPlot) #visualize model coefficients
library(ggdist) #uncertainty viz
library(gghalves) # plots. in half
library(ggbeeswarm) # violin plot stuffs
library(statsExpressions)
library(ggstatsplot) #plots with stats
library(modelsummary) #latex tables for models!

#MODELLING
library(ARTool) #nonparametric anova
# library(rstatix) #helpful testing functions incl wilcoxon, etc
library(report) #easystats reporting
library(see) #easystats visualization
library(performance) #easystats model diagnostics
library(parameters) #easystats model summary and vis
# library(qqplotr) #confint on qq plot
# library(gmodels) #contingency table and CHISQR
# library(equatiomatic) #extract model equation
# library(pscl) #zeroinfl / hurdle models 
library(lme4) #mixed effects models
library(lmerTest) #for CIs in glmer
library(merTools)
# library(ggeffects) #visualization log regr models
#MULTINOMIAL 
library(nnet) #multinomial logistic regression [not mixed] #no p values
library(mclogit) #frequentist mixed multinomial logistic regression [mblogit] #gives p values
#BAYESIAN
library(cmdstanr) #executing stan
library(brms) #bayesian mixed multinomials [+ other bayesian reg models]
library(bayestestR) 

library(tidyverse) #ALL THE THINGS

#OUTPUT OPTIONS
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
options(ggplot2.summarise.inform = FALSE)
options(scipen=1, digits=3)

#GRAPH THEMEING
# theme_set(theme_minimal()) 

# Custom ggplot theme to make pretty plots
# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed
theme_clean <- function() {
  theme_minimal(base_family = "Barlow Semi Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "BarlowSemiCondensed-Bold"),
          axis.title = element_text(family = "BarlowSemiCondensed-Medium"),
          strip.text = element_text(family = "BarlowSemiCondensed-Bold",
                                    size = rel(1), hjust = 0),
          strip.background = element_rect(fill = "grey80", color = NA))
}

set_theme(base = theme_clean())

##IMPORT CUSTOM COLOR PALETTES
source("analysis/utils/foxy_palettes.R")

set.seed(1234)
```


```{r}
#| label: IMPORT-DATA
#| warning : false
#| message : false

# #HACK WD FOR LOCAL RUNNING?
imac = "/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN"
setwd(imac)

#IMPORT DATA 
df_subjects <- read_rds('analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.rds') %>% 
  mutate(
    task_percent = DV_percent_NABS
  ) %>% mutate(
    pretty_condition = recode_factor(pretty_condition, 
                                     "Orth-Full" = "regular",
                                     "Orth-Sparse" = "sparse",
                                     "Orth-Grid" = "grid"))%>% droplevels()


df_items <- read_rds('analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.rds') %>% 
   mutate (
    q = as.factor(q), 
    subject = as.factor(subject),
    accuracy = recode_factor(score_niceABS, "0" ="incorrect","1"="correct"),
    # CODES TVERSKY AS TRI-LIKE
    # state = recode_factor(score_SCALED, #for ordinal
    #                      "-1" = "orth-like",
    #                      "-0.5" = "unknown",
    #                      "0" = "unknown",
    #                      "0.5" = "tri-like",
    #                      "1" = "tri-like"),
    # CODES TVERSKY AS OTHER
    state = recode_factor(score_SCALED, #for ordinal
                         "-1" = "orthogonal",
                         "-0.5" = "other",
                         "0" = "other",
                         "0.5" = "angular",
                         "1" = "triangular"),
    state = as.ordered(state)) %>% mutate(
    pretty_condition = recode_factor(pretty_condition, 
                                     "Orth-Full" = "regular",
                                     "Orth-Sparse" = "sparse",
                                     "Orth-Grid" = "grid"))%>% droplevels()

```


## SAMPLE

### Data Collection


```{r}
#| label : DESC-DATA-COLLECTION

title = "Participants by Condition and Data Collection Period"
cols = c("Orth-Full","Orth-Sparse","Orth-Grid","Total for Period")
cont <- table(df_subjects$term, df_subjects$condition)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

```

### Participants

```{r}
#| label: DESC-PARTICIPANTS

#Describe participants
subject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()
subject.stats$percent.male <- ((df_subjects %>% filter(gender=="Male") %>% count())/count(df_subjects))$n
subject.stats$percent.female <- ((df_subjects %>% filter(gender=="Female") %>% count())/count(df_subjects))$n
subject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c("Female","Male")) %>% count())/count(df_subjects))$n


title = "Descriptive Statistics of Participant Age and Gender"
subject.stats %>% kbl (caption = title) %>% kable_classic()%>% 
  footnote(general = "Age in Years", 
           general_title = "Note: ",footnote_as_chunk = T) 
```

**Reported**

**Overall** `r subject.stats$n` participants (`r round((subject.stats$percent.male),2) * 100` % male, `r round((subject.stats$percent.female),2) * 100` % female, `r round((subject.stats$percent.other),2) * 100` % other)  undergraduate STEM majors at a public American University participated in exchange for course credit (age: `r (subject.stats$min)` - `r (subject.stats$max)` years).

## H1 â€”  OVERALL TASK  ACCURACY

#### Setup
```{r}
#| label: SETUP-ACC

df_s <- df_subjects %>% 
   dplyr::select(pretty_condition, task_percent)


df_i = df_items %>% filter(q %nin% c(6,9)) %>% 
  dplyr::select(pretty_condition, accuracy, subject,q)

```


#### Visualize
```{r}
#| label: DESC-ACC

#:::::::: STACKED PROPORTIONAL BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  # facet_wrap(~pretty_mode) + 
   labs(title = "Overall Accuracy",
       x = "Condition",
       fill = "",
       subtitle="The full grid decreases performance")

#:::::::: STACKED BAR CHART BY QUESTION
df_items %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~q) +
   labs(title = "Accuracy by Question",
       x = "Condition",
       fill = "",
       subtitle="Q6 and Q9 are non-discriminative")

#:::::::: FACETED HISTOGRAM
stats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))
gf_props(~task_percent,
         fill = ~pretty_condition, data = df_s) %>%
  # gf_facet_grid(pretty_condition ~ pretty_mode) %>%
  gf_facet_grid(~pretty_condition) %>%
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
  labs(x = "% Correct",
       y = "proportion of subjects",
       title = "Overall Absolute Score (% Correct)",
       subtitle = "") + theme(legend.position = "blank")

```

#### Present

```{r}
#:::::::: RAINCLOUD WITH STATS
  
df <- df_s %>% mutate(task_percent = task_percent*100,
                      condition = fct_rev(pretty_condition))

p <-   ggbetweenstats(data = df, x = condition, y = task_percent,
               plot.type = "box", 
               # centrality.type = "parametric",
               results.subtitle = FALSE,
               subtitle = NULL,
               # package = "RColorBrewer",
               # palette = "PRGn",
               centrality.point.args = list(color="black", size = 3, shape = 1),
               point.args = list(alpha=0), #suppress points
               ggplot.component = ## modify further with `{ggplot2}` functions
                list(
                  # aes(color = pretty_condition, fill = pretty_condition),
                  # scale_colour_manual(values = paletteer::paletteer_c("viridis::viridis", 3)),
                  # scale_fill_manual(values = paletteer::paletteer_c("viridis::viridis", 3)),
                  theme(axis.text.x = element_text(angle = 90)))
               ) +
  # ggdist::stat_halfeye(
  #   alpha = 0.7, 
  #   point_colour = NA,
  #   adjust = .5, 
  #   width = .5, .width = 0, 
  #   justification = -.5) +
  geom_boxplot(
    alpha = 0.1,
    width = .2, 
    outlier.shape = NA
  ) +
  geom_point(
    size = 2,
    alpha = .5,
    position = position_jitter(
      seed = 1, width = .08, height = 1.5
    )
  )  +
coord_flip() + theme_clean() + theme(legend.position = "blank")
p$layers[[3]]=NULL #remove default boxplot

# e <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df,
                                # type = "nonparametric", alternative = "less",
                                # var.equal = FALSE)
#labels are layer 4
p <- p + labs(title = "STUDY 4A | Distribution of Total Score",
         y = "Percentage of correct responses across task", x = "",
         subtitle = "Impasse condition yields greater variance and more high scores")

p
# ggsave(p, filename = "figures/SGC4A_GRID_totalscore.png", width = 6, height =4)
# ggsave(p, filename = "figures/SGC3A_LAB_totalscore.svg", width = 6, height =4)



```

```{r}

#:::::::: LABELLED 

# temp <- df_i %>% mutate(
#   accuracy = fct_rev(accuracy)
# )  
# 
# p <-  
# ggbarstats(data = temp, x = accuracy, y = pretty_condition,
#                results.subtitle = FALSE,
#                ggplot.component = ## modify further with `{ggplot2}` functions
#                 list(
#                   scale_fill_foxy(discrete = TRUE, "accuracy")
#                   # scale_fill_manual(values = paletteer::paletteer_d("lisa::FridaKahlo", 2))
#                   # scale_fill_manual(values = paletteer::paletteer_d("lisa::FridaKahlo", 2))
#                   # theme(axis.text.x = element_text(angle = 90)))
#                ))  + theme_clean() + theme(legend.position = "bottom")
# 
# p <- p + labs(title = "DISTRIBUTION | Question Accuracy",
#          y = "Proportion of Questions", x = "Condition",
#          subtitle = "")
# 
# p 


p <- df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill", width = 0.5 ) + #,color = "black") +
  scale_fill_foxy(discrete = TRUE, "accuracy")  +
  # scale_fill_manual(values = paletteer::paletteer_d("lisa::FridaKahlo", 2))+
  # facet_wrap(~pretty_mode) + 
  # coord_flip() +
  theme(legend.position="bottom")+
   labs(title = "DISTRIBUTION | Question Accuracy",
       x = "Condition",
       y = "Proportion of Questions",
       fill = "",
       subtitle="")
p
# ggsave(p, filename = "figures/SGC4A_GRID_accuracy.png", width = 6, height =4)


```


#### Describe

```{r}
#| label: DESC2-ACC

title = "Descriptive Statistics of Response Accuracy (Total % Correct)"
tbl1 <- mosaic::favstats(~task_percent, data = df_s) 
tbl1 %>% kbl (caption = title) %>% kable_classic()


title = "Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION"
tbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) 
tbl2 %>% kbl (caption = title) %>% kable_classic()

```


**REPORTED**

Across all conditions, overall accuracy on the task ranges from `r tbl1$min *100` to `r tbl1$max *100` with a mean of `r tbl1$mean * 100`. 

To explore the effect of \textbf{gridlines} on TM graph reading performance, we start by describing the distribution of \textsc{total score}. Across all conditions, \textsc{total score} ranged from 0 to 100 with a mean of 15\%.  In Figure \ref{fig_4A_GRID_totalscore} we see that across all gridline conditions, participant level accuracy on the interval graph comprehension task is low (less than 50\%).  The full grid condition has the lowest mean score (10\%) and the smallest variance. 

#### TESTS

##### Aligned Ranks Transformation
<!-- https://rcompanion.org/handbook/F_16.html -->
```{r}


m.art = art(task_percent ~ pretty_condition, data = df_s)
anova(m.art)

```

##### Kruskal Wallis Test
```{r}
#| label: TEST-ACC

(k <- kruskal.test(df_s$task_percent ~ df_s$pretty_condition))

```

##### Visualize

```{r}
#| label: TEST-VIZ-ACC

(results <- statsExpressions::oneway_anova(data = df_s, 
          x = pretty_condition, y = task_percent,
          type = "nonparametric", alternative = "less"))

#:::::::: STATSPLOT | VIOLIN
ggbetweenstats(y = task_percent, x = pretty_condition, 
               data = df_s, type = "nonparametric")

```




#### MIXED LOGISTIC REGRESSION

*Fit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.*

##### Fit Model


```{r}
#| label: MODEL-FIT-ACC

## 0 | SETUP
#confirm 13 items [all discriminating items]
nrow(df_i) / nrow(df_s) == 13
#confirm all factors 
is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)

## 1 | SETUP RANDOM INTERCEPT SUBJECT

#:: EMPTY MODEL (baseline, no random effect)
print("Empty fixed model")
m0 = glm(accuracy ~ 1, family = "binomial", data = df_i) 
# summary(m0)

#:: RANDOM INTERCEPT SUBJECT + ITEM
print("Subject Intercept + Item intercept random model")
mm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = "binomial",
                control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)))
#summary(mm.rSQ)


## 2 | ADD FIXED EFFECT CONDITION

print("FIXED Condition + Subject & Item random intercepts")
mm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,
                data = df_i, family = binomial,
                control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5)))
# summary(mm.CrSQ)
# car::Anova(mm.CrSQ)

test_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])
```

**Reported**

To explore the effect of gridlines on accuracy, we fit a mixed effects logistic regression model with random intercepts for subjects and questions, with gridline design as a fixed effect. A likelihood ratio test indicates that a model including these main effects does not significantly more variance in the data than an intercepts-only baseline model ($\chi^2 (3,5) = 0.82, p = 0.66$). 


##### Describe

```{r}
#| label: MODEL-DESC-ACC

# best model
m <- mm.CrSQ
m %>% write_rds(file = "analysis/SGC4A/models/sgc4a_glmer_acc_mm.CrSQ.rds")

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)
print("SIGNIFICANCE TEST [non directional]")
car::Anova(m, type = 2)

#:::::::: MANUAL ONE-SIDED SIGTEST 
#note: anova and chi square are always one-tailed, but that is independent of being one-sided
#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half
# one-sided (right tail) z test for B COEFFICIENT
#SANITY CHECK 2-tailed test should match the model output
# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("p value for two-tailed test, null B = 0 : ",round(tt,5))
# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)
# paste("BUT we want a one  directional, null: B <= 0: ",round(ot,5))


#:::::::: INTERPRET COEFFICIENTS

paste("LOG ODDS")
# se <- sqrt(diag(stats::vcov(m)))
# (tab <- cbind(Est = fixef(m),
#               LL = fixef(m) - 1.96 * se,
#               UL = fixef(m) + 1.96 * se))
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald")

paste("ODDS RATIOS")
# (e <- exp(tab))
tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = "Wald", exponentiate = TRUE)

paste("PROBABILITIES")
#probability control = plogis(intercept)
#probability impasse = plogis(intercept + coefficient)

#FROM predict()
# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)
# preds <- predict(m, newdata = newdata, type = "response")
# preds <- cbind(newdata, preds)
# p <- preds %>% 
#   dplyr::select(pretty_condition, preds) %>% 
#   group_by(pretty_condition) %>% 
#   summarise(
#     median = median(preds),
#     se = sd(preds)/sqrt(n()),
#     lwr = median - 1.96*se,
#     upr = median + 1.96*se)
    
  
#FROM merTools
#setup df 
newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)
#make predictions
preds <- predictInterval(m, newdata = newdata,
                              which = "fixed", #full, fixed or random for those only
                              type = "probability", #linear.prediction
                              stat = "median",
                              n.sims = 1000,
                              level = 0.80) #width of prediction interval
#join predictions to the new dataframe
preds <- cbind(newdata, preds)
#summarize
(summ_preds <- preds %>% 
  dplyr::select(pretty_condition, fit, lwr, upr) %>% 
  group_by(pretty_condition) %>% 
  summarise(
    median = median(fit),
    lower = median(lwr),
    upper = median(upr)
  )) 


```


#####  Inference

**Reported**

A Wald Chi-Square tests confirms no main effect of gridline design ($\chi^2 (2) = 0.84, p = 0.66$). 

\textbf{Counter to our (H1) hypothesis, altering the design of the gridlines to emphasize the triangular portion of the graph space did not significantly improve accuracy.} Model coefficients indicate that relative to the full y-axis grid condition, removing gridlines outside the eligible data area does not increase the odds of a correct response ($e^{b_{1[sparse]}} = 1.06, SE = 0.75, p = 0.94$). 

\textbf{Counter to our (H2) hypothesis, altering the design of the gridline to obscure the triangular shape but make the diagonal grid more prominent does not improve accuracy.} Extending the diagonal grid thorugh the entirety of the square graph space defined by the x and y axesdoes not significantly change the odds of a correct response ($e^{b_{1[grid]}} = 0.59, SE = 0.41, p = 0.43$).  Model predictions are visualized in Figure \ref{fig_4A_accuracy} [B], while parameter estimates and model specification is detailed in Appendix \ref{SGC4A_GRID_MODEL_accuracy}.



##### Visualize

```{r}
#| label: MODEL-VIS-ACC

## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
plot_model(m, vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.95 ) + #manually adjusted for directional test   
  labs(title = "Model Estimate | Odds Ratio",
       subtitle = "",
       x = "Condition") #why no error bars? problem with model?


#EASYSTATS | MODEL | ODDS RATIO
result <- model_parameters(m, exponentiate = TRUE, component = "all")
plot(result)


## | PLOT TESTS

result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)


## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="eff",
           show.intercept = TRUE,
           show.values = TRUE,
           title = "Model Prediction | Probability of Accurate Response",
           axis.title = c("Condition","Probability of Accurate Response"))

#PLOT MODEL PREDICTION
plot_model(m, type = "pred")[[1]] +
  ylim(0,1) 
  # labs(
  #   title = "Model Prediction | Probability of Accurate Response",
  #   subtitle = "Impasse increases Probability of Correct Response"
  # )

```

##### Marginal Effects

```{r}

# https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html#simple
# https://stats.oarc.ucla.edu/stata/faq/how-can-i-understand-a-categorical-by-categorical-interaction-in-logistic-regression-stata-12/
# https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/
  
library(emmeans)

#sanity check reference grid
ref_grid(m)

#PRINT ESTIMATED MARGINAL MEANS
#should be same as summ_preds
emmeans(m,  ~ pretty_condition, type = "response")

##POST-HOC COMPARISONS
print("POSTHOC COMPARISONS")
emmeans(m,  pairwise ~ pretty_condition, 
        type = "response" , adjust = "none") #sidak, tukey


##PLOT INTERACTION
#equivalent to plot_model, type = "int"
# emmip(m, SHAPE * SCALE ,
#       type = "response",
#       CIs = TRUE,
#       linearg = list(linetype = "dashed"),
#       engine = "ggplot")


##PLOT PROBABILITY
plot(ref_grid(m), by = "pretty_condition", type = "response")

```

##### Present

```{r}
## PLOT INTERACTION / marginals
library(ggeffects)

p <- ggpredict(m, terms = c("pretty_condition")) %>% 
  plot(connect.lines = FALSE) + 
  # scale_color_manual(values = fct_rev(paletteer::paletteer_d("nbapalettes::bulls")))+
  # scale_color_manual(values = paletteer::paletteer_d("awtools::gpalette",3))+
  # scale_color_manual(values = paletteer::paletteer_d("lisa::FridaKahlo", 3))+
  # scale_colour_manual(values = paletteer::paletteer_c("viridis::viridis", 2)) + 
  theme_clean() + labs(
  title = "MODEL | Predicted probability of correct response",
  x = "SCALE"
) +scale_y_continuous(limits = c(0,0.01))+
  theme(legend.position="bottom")

p
# ggsave(p, filename = "figures/SGC4A_GRID_accuracy_prediction.png", width = 6, height =4)
```

##### Print

```{r}
#| label: MODEL-TBL-ACC

#SJPLOT | MODEL | TABLE
# tab_model(m)

# #MODEL SUMMARY | save latex table

# models <- list("odds ratios" = m, "(log odds)" = m)
# title = "Study 4A | Question Accuracy"
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              paste("n = ",n_obs(m), "R^2(Conditional) =", round(r2(m)[[1]],2),
#                    "R^2(Marginal) =", round(r2(m)[[2]],2)),
#              "Accuracy  ~ GRID +  (1 | subject) + (1 | q)")
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionsparse" = "GRID[sparse]",
#                              "pretty_conditiongrid" = "GRID[grid]"),
#              title = title,
#              notes = notes)
#              output  = "tables/SGC4A_GRID_GLMER_OverallAccuracy.tex")
# #              # coef_omit = "Intercept",

# extract_eq(m, use_coefs = TRUE, wrap = TRUE)


```
##### Diagnostics

```{r}
print("SANITY CHECK REPORTING")
# report(m)

print("DIAGNOSTICS")
check_model(m)

```


##### BAYESIAN 
For some reason there are convergence difficulties. Try again with the brms version


## H1A \| OVERALL INTERPRETATION STATE

-   **"orthogonal"** \[reference category\] includes orthogonal and satisficing responses ==\> indicates a primarily *orthogonal* state of coordinate system understanding

-   **"other"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular

-   **"angular"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

-   **"triangular"** includes correct triangular =\> indicates a correct triangular coordinate understanding


+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does Ss in the impasse condition produce less orthogonal responses across questions?                                          |
+=======================+=================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q nin 6,9` (13 discriminant test phase items)                                                              |
|                       | -   outcome: `state` ( 3 level factor from high_interpretation )                                                                                |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                          |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  MIXED Multinomial (Logistic) Regression on state predicted by condition                                                                     |
|                       |                                                                                                                                                 |
|                       | Alternative:                                                                                                                                    |
|                       |                                                                                                                                                 |
|                       | -   MIXED Ordinal regression on state (doesn't meet proportional odds assumption-I think)                                                       |
|                       | -   MIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)                                        |
+-----------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup

```{r}
#| label: SETUP-STATE

#:::::::: PREP DATA
df_i = sgc4a_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition)
```

```{r}
#:::::::: STACKED BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  # facet_wrap(~pretty_mode) + 
   labs(title = "Interpretation across all Questions",
       x = "Condition",
       fill = "",
       subtitle="")

#:::::::: STACKED BAR CHART
df_i %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~q) +
   labs(title = "Interpretation by Question",
       x = "Condition",
       fill = "",
       subtitle="")

```


```{r}

#::::::::::::DESCRIPTIVES

table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns


(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row
      addmargins(1)) #sanity check sum of columns

```

#### MIXED MULTINOMIAL REGRESSION


*Does condition affect the response state of of items across the task?*


##### Fit Model \[brms\]

```{r}
#| label: FIT-BRMS-STATE

#BAYESIAN RANDOM ONLY
Bmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), 
                 data = df_i, 
                 family = "categorical",
                 chains = 4, iter = 2500, warmup = 1000,
                 cores = 4, seed = 1234,
                 save_pars = save_pars(all = TRUE),
                 # backend = "cmdstanr",
                 file ="analysis/SGC4A/models/sgc4a_brms_state_Bmm.cat.rSQ_LAB.rds")


#set priors [see justification, in SGC3A]
inf_priors <- c(
   #prior on INTERCEPTS
   #25% chance of each answer in control, scale = from 0.01 to 62%
   prior(normal(-1.1, 1.5),  class = "Intercept", dpar = "muangular"),
   prior(normal(-1.1, 1.5),  class = "Intercept", dpar = "muother"),
   prior(normal(-1.1, 1.5),  class = "Intercept", dpar = "mutriangular"),
   #prior on COEFFICIENT
   #likely to change odds between 0 and 2.4
   prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMSparse", dpar = "muangular"),
   prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMSparse", dpar = "muother"),
   prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMSparse", dpar = "mutriangular"),
  prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMGrid", dpar = "muangular"),
   prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMGrid", dpar = "muother"),
   prior(normal(0, 2.42), class = b, coef="pretty_conditionOrthMGrid", dpar = "mutriangular")
)
# 
# 
# 
# 
# #UNINFORMATIVE PRIOR BAYESIAN MIXED VERSION
# flat_Bmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q),
#                  data = df_i,
#                  family = "categorical",
#                  chains = 4, iter = 2000, warmup = 1000,
#                  cores = 4, seed = 1234,
#                  save_pars = save_pars(all = TRUE),
#                  # backend = "cmdstanr",
#                  file ="analysis/SGC4A/models/sgc4a_brms_state_FLAT_Bmm.cat.CrSQ_LAB.rds")
# # 
# # # determine default priors 
# prior_summary(flat_Bmm.cat.CrSQ)

#INFORMATIVE PRIORS
Bmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), 
                 data = df_i, 
                 family = "categorical",
                 prior = inf_priors,
                 chains = 4, iter = 2500, warmup = 1000,
                 cores = 4, seed = 1234,
                 save_pars = save_pars(all = TRUE),
                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions
                 # backend = "cmdstanr",
                 file ="analysis/SGC4A/models/sgc4a_brms_state_Bmm.cat.CrSQ_LAB.rds"
                 )

```


##### Describe

```{r}
#| label: DESC-BRMS-STATE

# best model
# m <- Bmm.cat.CrSQ
m <- Bmm.cat.CrSQ

#::::::::: PRINT MODEL 

print("PREDICTOR MODEL")
summary(m)
(d <- describe_posterior(ci=.95, Bmm.cat.CrSQ))

print("BAYES FACTOR [comparison to null]")
#think of this like the anova(model) to get p values for each predictor
#has to recompile the models with rstan. total drag
(b <- bayesfactor(Bmm.cat.rSQ, m))

print("DESCRIBE POSTERIOR")

#:::::::: INTERPRET COEFFICIENTS
# se <- sqrt(diag(stats::vcov(m)))
# # table of estimates with 95% CI
# (tab <- cbind(Est = fixef(m),
#               LL = fixef(m) - 1.96 * se,
#               UL = fixef(m) + 1.96 * se))

paste("LOG ODDS")
(l <- describe_posterior(m))
# (tm <- tidy(m,   conf.int = TRUE))

paste("ODDS RATIOS")
(e <- model_parameters(m, exponentiate = TRUE))
# tidy(m,   conf.int = TRUE, exponentiate = TRUE)
# tm %>% mutate(
#   OR.est = exp(estimate),
#   exp.low = exp(conf.low),
#   exp.high = exp(conf.high)
# ) %>% dplyr::select(effect, component, group, term, OR.est, exp.low, exp.high)

paste("PROBABILITIES")

#PREDICT METHOD
newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)
preds <- predict(m, newdata = newdata, type = "response")
preds <- cbind(newdata, preds)
#lengthen data frame to handle multinomial
preds <- preds %>% 
  dplyr::select(-subject, -q) %>% #marginalize over subject and q
  pivot_longer(
  cols = !pretty_condition,
  values_to = "preds",
  names_to = "state",
) 

(p <- preds %>% 
  group_by(pretty_condition, state ) %>%
  summarise(
    median = median(preds),
    se = sd(preds)/sqrt(n()),
    lwr = median - 1.96*se,
    upr = median + 1.96*se))

##DRAWS METHOD
# GENERATE draws from model
# draws <- df_i %>%
#   data_grid(pretty_condition, subject, q) %>% 
#   add_fitted_draws(Bmm.cat.CrSQ,
#                    # n = 100,
#                    # dpar = TRUE,
#                    # transform = TRUE, #gives prob%, otherwise OR
#                    re_formula = NA)
# # draws %>% write_rds(file = "analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds")
# 
# #OR load from file
# # draws <- read_rds(file = "analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds")
# 
# # SUMMARIZE draws from model
# (k <- kable(draws %>%
#   dplyr::select(pretty_condition, .category, .value) %>%
#   group_by(pretty_condition, .category) %>%
#   median_hdci(.value), digits = 4, col.names =
#     c("Condition","Category", "Probability","Lower Cred.I","Upper Cred.I", "CI Width", "Point Type", "Interval Type")) %>%
#   kable_styling())


##EASY STATS INSIGHT 
# https://easystats.github.io/insight/reference/get_predicted.html
# p <- get_predicted(m, predict = "expectation")


```



##### TODO INFERENCE

**UPDATE THIS [template from 3A**

[REPORT POSTERIOR MEDIAN $\exp_{beta}$, 95 \% credible interval, \% probability of direction]

We fit a (bayesian) multinomial logistic regression model with random intercepts for subjects and questions. A Bayes Factor model comparison (against a random intercepts-only model) indicates extreme evidence for a main effect of CONDITION (BF = 1.38e+14). 

**Consistent with our hypothesis, the impasse condition substantially increases the odds of transitional interpretations.** 

Across the entire task participants in the impasse condition were 12 times more likely to offer an 'unknown' rather than orthogonal response compared with those in the control condition ( $e^{\beta_1} = 12.13, 95 \% CI [6.29, 25.24], pd = 100\%$). Participants in the impasse condition were 12 times more likely to offer an 'angular' rather than orthogonal response compared with those in the control condition ( $e^{\beta_1} = 11.48, 95 \% CI [3.95, 37.67], pd = 100\%$), and 34 times more likely to offer an 'triangular' rather than orthogonal response compared with those in the control condition ( $e^{\beta_1} = 33.90, 95 \% CI [6.22, 211.18], pd = 100\%$). 


##### Print
```{r}
#| label: MODEL-TBL-STATE

#SJPLOT | MODEL | TABLE
# tab_model(m)

# #MODEL SUMMARY | save latex table
#model summary doesn't work for brms multinomial

# DOESN'T WORK FOR BRMS
# extract_eq(m, use_coefs = TRUE, wrap = TRUE)
# 
# 
# #GET MODEL ESTIMATES
# t <- as.data.frame(model_parameters(m, exponentiate = TRUE))
# 
# #REFORMAT
# x <- t %>%
#   mutate(
#     Interpretation = word(Parameter, 2, sep = "_"),
#     Interpretation = str_remove_all(Interpretation,"mu"),
#     Interpretation = fct_relevel(Interpretation, levels = c("other","angular","triangular")),
# 
#     Parameter = as.factor(word(Parameter, 3, sep = "_")),
#     Parameter = recode_factor(Parameter,
#                          "Intercept" = "(Intercept)",
#                          "pretty" = "Condition[impasse]"),
#     Median = round(Median,2),
#     CI_low = round(CI_low,2),
#     CI_high = round(CI_high,2),
#     pd = round(pd,2),
#     ROPE_Percentage = round(ROPE_Percentage,2)
#   ) %>%
#   arrange(Interpretation) %>%
#   dplyr::select(-CI, -Rhat, -ESS) %>%
#   rename( "%_in_ROPE"="ROPE_Percentage",
#           "(Odds Ratio)" = "Median") %>%
#   dplyr::select(Interpretation, Parameter, `(Odds Ratio)`, CI_low, CI_high, pd, `%_in_ROPE`)


# 
# #KNIT
# title = "Study 3A (Lab) | Question Interpretation | Mixed Multinomial Regression"
# tab <- kbl(x, format = "latex", caption = title,
#            booktabs = FALSE) %>% kable_classic() %>%
# footnote(general = paste("Model Interpretation ~ ",b$Model[2], "Bayes Factor ", format( exp(b$log_BF[2]), digits =2 ) ), footnote_as_chunk = T, general_title = "")
# writeLines(tab, "tables/SGC3A_LAB_BRMS_state.tex")


```



##### Visualize

```{r}
#| label: VIS-BRMS-STATE


## | PLOT PARAMETERS 

#SJPLOT | MODEL | ODDS RATIO
# plot_model(m, vline.color = "red",
#            show.intercept = TRUE,
#            show.values = TRUE,
#            p.threshold = 0.1, #manually adjust to account for directional test
#            ci.lvl = 0.90 ) + #manually adjusted for directional test
#   labs(title = "Model Estimate | Odds Ratio",
#        subtitle = "",
#        x = "Condition")


#EASYSTATS | MODEL | ODDS RATIO
result <- model_parameters(Bmm.cat.CrSQ, exponentiate = TRUE, component = "all")
plot(result, show_intercept = TRUE, show_labels = TRUE) 
# + theme_clean()

# 
# result <- estimate_density(m,exponentiate = TRUE)
# plot(result,  stack = FALSE, priors = TRUE)

## | PLOT TESTS
result <- equivalence_test(m, rule = "classic", ci=0.9) #classic[tost], , bayes
plot(result)

result <- rope(m)
plot(result)

(result <- pd(m,exponentiate = TRUE))
plot(result, show_intercept = TRUE, show_labels = TRUE)

## | PLOT PREDICTIONS

#SJPLOT | MODEL | PROBABILITIES
# plot_model(m, type="eff",
#            show.intercept = TRUE,
#            show.values = TRUE,
#            title = "Model Prediction | Probability of Accurate Response",
#            axis.title = c("Condition","Probability of Accurate Response"))

# #PLOT MODEL PREDICTION
plot_model(m, type = "pred",
           title = "Model PREDICTION | Probability of Response Interpretation",
           axis.title = c("Condition", "Probability of Response Interpretation"))

#TODO OUTPUT TABLE 
# modelsummary(m)

```

##### COMPARE

```{r}
#| label: COMPARE-STATE-MODELS
# compare_models(m.mbl1, mm.cat.CrSQ)
```

##### Diagnostics

```{r}

#CHECK Fit of posterior predictive to data
pp_check(Bmm.cat.CrSQ, ndraws=1000)

#CHECK posterior vs. priors
result <- estimate_density(Bmm.cat.CrSQ)
plot(result, stack = FALSE, priors= TRUE)

#CHECK model
plot(Bmm.cat.CrSQ)

```

## H1B \| Q1 ACCURACY


The graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their *first exposure* to the unconventional triangular coordinate system.

+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does the frequency of correct (vs) incorrect responses on the first question differ by condition? \[Is response accuracy independent of condition?\]                                                                                   |
+=======================+========================================================================================================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the TRI condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition                                                                                     |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                    |
|                       | -   outcome: *accuracy* ( factor(incorrect/correct) from `score_niceABS` \[absolute score\]                                                                                                                                            |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                                                                                                                 |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  Logistic Regression on `accuracy` predicted by `condition`                                                                                                                                                                         |
|                       |     -   account for difference in odds of correct score by condition                                                                                                                                                                   |
|                       |                                                                                                                                                                                                                                        |
|                       | Alternatives:                                                                                                                                                                                                                          |
|                       |                                                                                                                                                                                                                                        |
|                       | -   Chi-Square test of independence on outcome `accuracy` by `condition`                                                                                                                                                               |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Notes**             | -   CHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial \~ continuous; though with regression we can quantify the size of the effect and overall model fit |
|                       | -   independence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent                                                           |
|                       | -   cell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)                                                                      |
+-----------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup
```{r}
#| label: SETUP-Q1ACC

#:::::::: PREP DATA
df <- df_items %>% filter(q==1)  %>% dplyr::select(accuracy, pretty_condition)

```

#### Describe 
```{r}
#| label: VIS-Q1ACC

#:::::::: STACKED BAR CHART
df %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = accuracy)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  # facet_wrap(~pretty_mode) + 
   labs(#y = "Correct Response on Q 1",
       title = "Q1 Accuracy",
       x = "Condition",
       fill = "",
       subtitle="")


#:::::::: BARSTATS
ggbarstats( data = df, y = pretty_condition, x = accuracy)

```


```{r}
#| label: DESC-Q1ACC

#::::::::::::DESCRIPTIVES

paste("Proportions of Correct Responses by Condition")
table(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns

paste("Number of Correct Responses by Condition")
table(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      addmargins(1) #sanity check sum of columns
```

#### LOGISTIC REGRESSION

Fit a logistic regression predicting accuracy (absolute score) (n = `r nrow(df)`) by condition (k = 2).\

-   Parameter estimate: $\beta_{0}$ = Log Odds of (correct) responses in CONTROL condition
-   $e^{\beta_{0}}$ = ODDS of correct response in CONTROL condition
-   Parameter estimate: $\beta_{1}$ = $\beta_{1impasse}$ Log Odds (Log OR; change in odds for correct response in impasse (vs) control \[log scale\])
-   $e^{\beta_{1}}$ = ODDS RATIO of correct response in IMPASSE (vs) CONTROL
-   **Null hypothesis**:$\beta_{impasse} \le 0$ the odds for a correct response does not change, or decreases
-   **Alternative hypothesis:** $\beta_{impasse} \gt 0$ the odds of a correct response increases

##### Fit Model

*First, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.*

```{r}
#| label: MODEL-FIT-Q1ACC
#| warning: false
#| message: false

# MODEL FITTING ::::::::

#: 1 EMPTY MODEL baseline glm model intercept only
m0 = glm(accuracy ~ 1, data = df, family = "binomial")
# print("EMPTY MODEL")
# summary(m0)

#: 2 CONDITION model
m1 <- glm( accuracy ~ pretty_condition, data = df, family = "binomial")
# print("PREDICTOR MODEL")
summary(m1)
car::Anova(m1)

#: 3 TEST SUPERIOR FIT
paste("AIC wth predictor is lower than empty model?", m0$aic > m1$aic)
test_lrt(m0,m1) #same as anova(m0, m1, test = "Chi")
paste("Likelihood Ratio test is significant? p = ",(test_lrt(m0,m1))$p[2])
```

*The Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .*

##### Describe

```{r}
#| label: MODEL-DESC-Q1ACC

# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: 

print("PREDICTOR MODEL [default two-tailed sig test]")
summary(m1)
car::Anova(m1)

# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: 

# one-sided (right tail) z test for B COEFFICIENT
#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients

#SANITY CHECK 2-tailed test should match the model output
tt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)
paste("p value for two-tailed test, null B = 0 : ",round(tt,3))
ot <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)
paste("BUT we want a one tailed directional, null: B <= 0: ",round(ot,3))
paste("adjusted confint for directional hypothesis")
(dcint <- confint(m1, level = 0.90)) # get 90% for right side))
# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte

#:::::::: INTERPRET COEFFICIENTS

# print("Confidence Interval â€”- LOG ODDS")
# confint(m1) #not adjusted for 1-tailed
print("Coefficients â€”- ODDS RATIOS")
# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted
(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted

print("MODEL PREDICTIONS")
# Retrieve predictions as probabilities 
# (for each level of the predictor)
# pred.control <- predict(m1,data.frame(pretty_condition="control"),type="response")
# #this should match : plogis(intercept coefficient)
# paste("Probability of success in control,", pred.control)
# pred.impasse <- predict(m1,data.frame(pretty_condition="impasse"),type="response")
# #this should match : plogis(intercept coefficient + predictor coeff)
# paste("Probability of success in impasse,", pred.impasse)
```
##### TODO Inference



##### Visualize

```{r}
#| label: MODEL-VIS-Q1ACC
#| message: false
#| warning : false

#SET MODEL
m <- m1

#SJPLOT | MODEL | ODDS RATIO
#library(sjPlot)
plot_model(m, type = "est",
           vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) +  #manually adjusted for directional test   
  scale_y_continuous() + #remove to put on log scale x axis 
  # scale_x_discrete(labels=c("control","impasse"))+
  labs(title = "MODEL ESTIMATE | Q1 Accuracy ~ condition",
       subtitle = "Impasse increases odds of correct response on Q1",
       x = "Condition") + theme_clean()

  
#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="pred")[[1]] +
  ylim(0,1) + #scale y axis to actual range
  labs(title = "MODEL PREDICTION  | Q1 Accuracy ~ condition",
       subtitle = "Impasse increases probability of correct response on Q1",
       x = "Condition") + theme_clean()

```

```{r}
#| label: MODEL-TBL-Q1ACC
#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",

```

##### Diagnostics

```{r}
#| label: MODEL-DIAG-Q1ACC
#| message: false
#| warning: false

# print("SANITY CHECK REPORTING")
# report::report(m)

#print("MODEL PERFORMANCE")
# performance(m)

print("MODEL DIAGNOSTICS")
check_model(m)
```


## H1B \| Q1 INTERPRETATION STATE


While absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn't allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject's response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:

-   **"orthogonal"** \[reference category\] includes orthogonal and satisficing responses ==\> indicates a primarily *orthogonal* state of coordinate system understanding

-   **"other"** includes: blank, reference point, responses that can't be classified (including selecting all datapoints), =\> indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly *not* orthogonal nor triangular

-   **"angular"** includes 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

-   **"triangular"** includes correct triangular and 'lines connecting' responses as well as responses that include both orthogonal *and* triangular answers =\> indicates some degree of angular/triangular coordinate understanding

+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Question     | Does Ss in the impasse condition produce less orthogonal responses on the first question?                                                                                                                                                                                                                                                                 |
+=======================+===========================================================================================================================================================================================================================================================================================================================================================+
| **Hypothesis**        | H1A \| Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question                                                                                                                                                                |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Data**              | -   data: `df_items` where `q == 1`                                                                                                                                                                                                                                                                                                                       |
|                       | -   outcome: `state` ( 4 level factor from 5 level high_interpretation )                                                                                                                                                                                                                                                                                  |
|                       | -   predictor: `condition` \[between-subjects factor\]                                                                                                                                                                                                                                                                                                    |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Analysis Strategy** | 1.  Multinomial (Logistic) Regression on state predicted by condition                                                                                                                                                                                                                                                                                     |
|                       |                                                                                                                                                                                                                                                                                                                                                           |
|                       | Alternative:                                                                                                                                                                                                                                                                                                                                              |
|                       |                                                                                                                                                                                                                                                                                                                                                           |
|                       | -   Ordinal regression on state; but model doesn't satisfy proportional odds assumption (parallel slopes)                                                                                                                                                                                                                                                 |
|                       | -   Multinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can't accurately estimate those comparisons |
+-----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

#### Setup 
```{r}
#| label: SETUP-Q1STATE

#:::::::: PREP DATA
df <- df_items %>% filter(q==1) %>% dplyr::select(pretty_condition, state)

```


#### Describe 
```{r}
#| label: VIS-Q1STATE

#:::::::: STACKED BAR CHART
df %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = state)) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  # facet_wrap(~pretty_mode) + 
   labs(#y = "Correct Response on Q 1",
       title = "Q1 Interpretation",
       x = "Condition",
       fill = "",
       subtitle="")

#:::::::: BARSTATS
ggbarstats( data = df, y = pretty_condition, x = state)

```



```{r}
#| label: DESC-Q1STATE

#::::::::::::DESCRIPTIVES

table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      prop.table(margin=2) %>%  #return proportion (of column)
      addmargins(1) #sanity check sum of columns


(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row
      addmargins(1)) #sanity check sum of columns

```

#### MULTINOMIAL REGRESSION


##### Fit Model

```{r}
#| label: MODEL-FIT-Q1STATE

#check reference level 
print("Categories (first is reference)")
levels(df$state)

#FIT EMPTY MODEL
# print("EMPTY MODEL")
catm.0 <- multinom(state ~ 1, data = df)
# summary(catm.0)

#FIT PREDICTOR MODEL
# print("PREDICTOR MODEL")
catm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)
# summary(catm)

#COMPARE MODEL FIT
paste("AIC wth predictor is lower than empty model?", catm.0$AIC > catm$AIC)
test_lrt(catm.0, catm)

##compare bayesian version
#library(brms)
# b.cat <- brm( state2 ~ pretty_condition, data = df, family = "categorical", backend = "cmdstanr")
# summary(b.cat)
# plot_model(b.cat)
# report(b.cat)
# coefficient estimates are very simliar to catm. super cool!

##compare mclogit version
#"baseline-category logit model
# https://www.elff.eu/software/mclogit/manual/mblogit/
# blm1 <- mblogit(state2 ~ pretty_condition , data = df)
# summary(blm1)
#identical to catm. super cool!

```

*AIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.*

##### Describe

```{r}
#| label: MODEL-DESC-Q1STATE

#set model
m <- catm

#::::::::INTERPRETATION
paste("MODEL SUMMARY")
summary(m)
car::Anova(m)

# calculate z-statistics of coefficients
z_stats <- summary(m)$coefficients/summary(m)$standard.errors
# convert to p-values
p_values <- (1 - pnorm(abs(z_stats)))*2
# display p-values in transposed data frame
(p_values <- data.frame(p = (p_values)))
# display odds ratios in transposed data frame

paste("ODDS RATIOS")
odds_ratios <- data.frame(OR = exp(summary(m)$coefficients))
options(scipen = 2)
(results <- cbind(odds_ratios, p_values))
```

##### TODO Inference


##### Visualize

```{r}
#| label: MODEL-VIS-Q1STATE

#:::::::: PLOT

#SJPLOT | MODEL | ODDS RATIO
#library(sjPlot)
plot_model(m, type = "est",
           vline.color = "red", 
           show.intercept = TRUE, 
           show.values = TRUE,
           p.threshold = 0.1, #manually adjust to account for directional test
           ci.lvl = 0.90 ) +  #manually adjusted for directional test   
  # scale_y_continuous() + #remove to put on log scale x axis 
  # scale_x_discrete(labels=c("control","impasse"))+
  labs(title = "MODEL ESTIMATE  | Q1 Accuracy ~ condition",
       subtitle = "Impasse increases odds of correct response on Q1",
       x = "Condition") + theme_clean()

  
#SJPLOT | MODEL | PROBABILITIES
plot_model(m, type="eff", ci.lvl = 0.95)[[1]] +
  ylim(0,1) +
  labs(title = "MODEL PREDICTION  | Q1 State ~ condition",
       subtitle = "Impasse increases probability of more accurate response states Q1",
       x = "Condition") + theme_clean()

# #MANUALLY BUILD PREDICTION PLOT FACET BY CONDITION RATHER THAN STATE
# p <-plot_model(m, type="eff")[[1]]
# d <- ggplot_build(p)[[1]]  
# points <- d[[2]]
# points <- points %>% mutate(
#   state = recode(PANEL, "1" ="orth", "2"="other", "3" = "trilike", "4"="tri"),
#   condition = recode(x, "1"="control","2"="impasse"),
#   prob = y
# )
# gf_point( prob ~ state, group = ~x, data = points) + 
#   geom_errorbar(aes( x = state, ymin = ymin, ymax = ymax)) + facet_grid(~condition) +ylim(0,1)

```

```{r}
#| label: MODEL-TBL-Q1STATE

#SJPLOT | MODEL | TABLE
tab_model(m)

# #MODEL SUMMARY | save latex table
# models <- list("odds ratios" = m1, "(log odds)" = m1)
# notes = list("* p < 0.05, ** p < 0.01, *** p < 0.001",
#              '$sigma^{2}$ = 3.29" N(subject) = 126 $\tau_{00}$(subject) = 22.22 N(question) = 13 $\tau_{00}$(question) = 0.31'
#                )
# 
# modelsummary(models,
#              exponentiate = c(TRUE, FALSE),
#              shape = term ~ model + statistic,
#              fmt = 2, #two digits w/ trailing zero
#              estimate  = "{estimate} {stars}",
#              statistic = "conf.int",
#              gof_map = c("AIC", "sigma"),
#              gof_omit = 'RMSE|ICC|BIC',
#              coef_rename = c("pretty_conditionimpasse" = "Condition[impasse]"),
#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', 
#              notes = notes,
#              output = "analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex")
# #              # coef_omit = "Intercept",

# modelsummary(mixcat.1, s)
#TODO OUTPUT TABLE 
#https://arelbundock.com/posts/modelsummary_multinomial_logit/


```

##### Diagnostics

```{r}
#| label: MODEL-DIAG-Q1STATE

#EXAMINE PREDICTIONS
#create sample data frame
# test <- data.frame(pretty_condition = c("control", "impasse"))
# pred <- predict(catm, newdata = test, "probs")
# paste("Predicted Probability of Being in Each State")
# ( x <- cbind(test, pred))

print("MODEL PERFORMANCE")
performance(catm)
DescTools::PseudoR2(catm, which = c("McFadden", "CoxSnell", "Nagelkerke"))

#General Goodness of Fit
#library(generalhoslem)
#logitgof(df$state, catm$fitted.values, g = 3)
#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).
#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables
# chisq.test(df$state, predict(catm)) #actual states VS predicted states
# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model

# print("MODEL DIAGNOSTICS")
# check_model(m) can't do overall diagnostics, have to do them on individual model equations

```
