{
  "hash": "543556c68931c40293a673d17da5117e",
  "result": {
    "markdown": "---\nsubtitle: 'Study SGC4A | 2 Response Scoring'\n---\n\n\\newpage\n\n**TODO** update graph subtitles - recode pretty_condition and pretty_interpretation in intro\n\n# Response Scoring {#sec-SGC4A-scoring}\n\n*The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC4A study. This is required because the question type on the graph comprehension task used a 'Multiple Response' (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.)* To review the strategy behind Multiple Response scoring for the SGC project, refer to section @sec-scoring.\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=1, digits=3)\n\nlibrary(kableExtra) #printing tables \nlibrary(ggformula) #quick graphs\nlibrary(pbapply) #progress bar and time estimate for *apply fns\nlibrary(Hmisc) # %nin% operator\nlibrary(tidyverse) #ALL THE THINGS\n```\n:::\n\n## SCORE SGC DATA\n\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section @sec-scoring.\n\nIn SGC_4 we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The **graph comprehension task** asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant's performance, for each question (q=15) we will calculate the following scores:\n\n*An overall, strict score:*\\\n1. **Absolute Score** : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\n\n*Sub-scores, for each alternative graph interpretation*\\\n2. **Triangular Score** : using partial scoring \\[-1/q, +1/p\\] referencing true (Triangular) answer key.\n\n3\\. **Orthogonal Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect Orthogonal) answer key.\n\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n\n4\\. **Tversky Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect connecting-lines strategy) answer key. 5. **Satisficing Score** : using partial scoring \\[-1/q, +1/p\\] referencing (incorrect satisficing strategy) answer key.\n\n### Prepare Answer Keys\n\nWe start by importing answer keys.\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n```\n:::\n\n### Score Items\n\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response `df_items$response` with the answer keys in each interpretation (e.g. `keys_orth`, `keys_tri`, etc...), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial\\[-1/q, +1/p\\] scores for each interpretation. The resulting scores are then stored on each item in `df_items`, and can be used to determine which graph interpretation the subject held.\n\nSpecifically, the following scores are calculated for each item:\n\n**Interpretation Subscores**\n\n-   `score_TRI` How consistent is the response with the **triangular**interpretation?\n-   `score_ORTH` How consistent is the response with the **orthogonal**interpretation?\n-   `score_SATISFICE` is calculated by taking the maximum value of :\n    -   `score_SAT_left` How consistent is the response with the **(left side) Satisficing** interpretation?\n\n    -   `score_SAT_right` How consistent is the response with the **(right side) Satisficing** interpretation\n-   `score_TVERSKY` is calculated by taking the maximum value of:\n    -   `score_TV_max` How consistent is the response with the **(maximal) Tversky** interpretation?\n\n    -   `score_TV_start` How consistent is the response with the **(start-time) Tversky** interpretation?\n\n    -   `score_TV_end` How consistent is the response with the **(end-time) Tversky**i nterpretation?\n\n    -   `score_TV_duration` How consistent is the response with the **(duration) Tversky** interpretation?\n-   `score_REF` Did the response select only the **reference point**?\n-   `score_BOTH` How consistent is the response with **both** the orthogonal and triangular interpretations?\n\n**Absolute Scores**\n\n-   `score_ABS` Is the response strictly correct? (triangular interpretation)\n-   `score_niceABS` Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer *in addition to* they also select the data point referenced in the question.\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_items.rds')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n```\n:::\n\n*note: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records*\n\n::: {.cell hash='2_sgc4A_scoring_cache/html/CALCULATE-SCORES-MAPPLY_ad4db110e933a8b15c62b7b38df91063'}\n\n```{.r .cell-code}\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tri))\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_orth))\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\ndf_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n```\n:::\n\n### Derive Interpretation {#sec-SGC4A-interpretation}\n\nFinally, we use the interpretation subscores to classify the response as a particular interpretation (or \"?\" if the response cannot be classified). [For details, see @sec-SGC3A-interpretation ]\n\n::: {.cell hash='2_sgc4A_scoring_cache/html/DERIVE-INTERPRETATION_40bf806c7556fa825c7f9d3b397af910'}\n\n```{.r .cell-code}\nthreshold_range = 0.5 #set required variance in subscores to be discriminant\nthreshold_frenzy = 4\n\nx = 1\n\nfor (x in 1:nrow(df_items)) {\n  \n  #CALCULATE MAX TVERSKY SUBSCORE\n  t = df_items[x,] %>% select(score_TV_max, score_TV_start, score_TV_end, score_TV_duration) #reshape\n  t.long = gather(t,score, value, 1:4)\n  t.long[t.long == \"\"] = NA #replace empty scores with NA so we can ignore them\n  if(length(unique(t.long$value)) == 1 ){\n    if(is.na(unique(t.long$value))){\n      df_items[x,'score_TVERSKY'] = NA\n      df_items[x,'tv_type'] = NA   \n    }\n  } else {\n    df_items[x,'score_TVERSKY'] = as.numeric(max(t.long$value,na.rm = TRUE))\n    df_items[x,'tv_type'] = t.long[which.max(t.long$value),'score']\n  }\n  \n  #CALCULATE MAX SATISFICING SUBSCORE\n  t = df_items[x,] %>% select(score_SAT_left, score_SAT_right)\n  t.long = gather(t,score, value, 1:2)\n  t.long[t.long == \"\"] = NA #replace empty scores\n  if(length(unique(t.long$value)) == 1 ){\n    if(is.na(unique(t.long$value))){\n      df_items[x,'score_SATISFICE'] = NA\n      df_items[x,'sat_type'] = NA   \n    }\n  } else {\n    df_items[x,'score_SATISFICE'] = as.numeric(max(t.long$value,na.rm = TRUE))\n    df_items[x,'sat_type'] = t.long[which.max(t.long$value),'score']  \n  }\n  \n  #NOW CALCULATE RANGE AMONG SUBSCORES\n  #order of this selection matters in breaking ties! \n  t = df_items[x,] %>% select(score_TRI, score_TVERSKY, score_SATISFICE, score_ORTH)\n  t.long = gather(t,score, value, 1:4)\n  t.long[t.long == \"\"] = NA\n  \n  df_items[x,'top_score'] = as.numeric(max(t.long$value,na.rm = TRUE))\n  df_items[x,'top_type'] = t.long[which.max(t.long$value),'score']\n  \n  #calculate the range between highest and lowest scores \n  r = as.numeric(range(t.long$value,na.rm = TRUE))\n  r = diff(r)\n  df_items[x,'range'] = r\n  \n  #DISCRIMINANT BETWEEN SUBSCORES TO PREDICT BEST FIT INTERPRETATION\n  \n  if (r < threshold_range) {\n      #then we can't predict the interpretation, leave it as \"?\"\n    df_items[x,'best'] = \"?\"\n  } else {\n      p =  df_items[x,'top_type']\n      if (p == \"score_TRI\") {df_items[x,'best'] = \"Triangular\"\n      } else if(p == \"score_ORTH\") {df_items[x,'best'] = \"Orthogonal\"\n      } else if(p == \"score_TVERSKY\") {df_items[x,'best'] = \"Tversky\"\n      } else if(p == \"score_SATISFICE\") {df_items[x,'best'] = \"Satisfice\"}\n  }\n  \n  #CHECK SPECIAL SITUATIONS\n\n  #BOTH TRI AND ORTH?  \n  if (!is.na(df_items[x,'score_BOTH'])) { #only check if both is not null\n      if( df_items[x,'score_BOTH'] == 1) {\n        df_items[x,'best'] = \"both tri + orth\"}\n  }\n  \n  #IS BLANK?\n  if( df_items[x,'num_o'] == 0) {  \n    df_items[x,'best'] = \"blank\"\n  }\n  \n  #IS FRENZY?\n  if( df_items[x,'num_o'] > threshold_frenzy) { \n      df_items[x,'best'] = \"frenzy\"\n  }\n\n  #IS REF POINT?\n  if (!is.na(df_items[x,'score_REF'])) { #only check if the score is NOT null\n      if( df_items[x,'score_REF'] == 1) {\n          df_items[x,'best'] = \"reference\"\n      }\n  }\n\n}#end loop\n\n#cleanup \nrm(t, t.long, x, r,p)\nrm(threshold_frenzy, threshold_range)\n\n#set order of levels for response exploration table\ndf_items$int2 <- factor(df_items$best,\n                                  levels = c(\"Triangular\", \"Tversky\",\n                                             \"Satisfice\", \"Orthogonal\", \"reference\", \"both tri + orth\", \"blank\",\"frenzy\",\"?\"))\n\n#set order of levels\ndf_items$interpretation <- factor(df_items$best,\n                                  levels = c(\"Orthogonal\",\"Satisfice\", \"frenzy\",\"?\",\"reference\",\"blank\",\n                                               \"both tri + orth\", \"Tversky\",\"Triangular\"))\n\n#collapsed representation of scale of interpretations\ndf_items$high_interpretation <- fct_collapse(df_items$interpretation,\n  orthogonal = c(\"Satisfice\", \"Orthogonal\"),\n  neg.trans = c(\"frenzy\",\"?\"),\n  neutral = c(\"reference\",\"blank\"),\n  pos.trans = c(\"Tversky\",\"both tri + orth\"),\n  triangular = \"Triangular\"\n) \n\n#reorder levels\ndf_items$high_interpretation = factor(df_items$high_interpretation, levels= c(\"orthogonal\", \"neg.trans\",\"neutral\",\"pos.trans\",\"triangular\"))\n\n#cleanup \ndf_items <- df_items %>% dplyr::select(-best)\n\n#recode as numeric inase they are char \n# df_items$score_TV_duration <- df_items$score_TV_duration %>% as.numeric()\n# df_items$score_SATISFICE <- df_items$score_SATISFICE %>% as.numeric()\n```\n:::\n\n### Derive Scaled Score {#sec-SGC4A-scaledScore}\n\nThe `interpretation` response variable gives us the finest grain indication of the reader's understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a *scaled_score* that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\n\nSpecifically, we assign the following values to each interpretation:\n\n-   (-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n-   (-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n-   (0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n-   (+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they \"see\" a triangular response, but lack certainty and also select the ORTHOGONAL response)\n-   (+1) TRIANGULAR +1\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_items$score_SCALED <- recode(df_items$interpretation,\n                          \"Orthogonal\" = -1,\n                          \"Satisfice\" = -1,\n                          \"frenzy\" = -0.5,\n                          \"?\" = -0.5,\n                          \"reference\" = 0,\n                          \"blank\" = 0, \n                          \"both tri + orth\" = 0.5,\n                          \"Tversky\" = 0.5,\n                          \"Triangular\" = 1)\n```\n:::\n\n## SUMMARIZE BY SUBJECT\n\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n::: {.cell}\n\n```{.r .cell-code}\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#IMPORT subjects file\ndf_subjects <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#prep items\ndf_items <- df_items %>% mutate(\n  tv_type = as.factor(tv_type),\n  top_type = as.factor(top_type),\n  pretty_condition = recode_factor(condition, \"11111\" = \"control\", \"113\" =  \"cond3\", \"114\"=\"cond4\", \"115\"=\"cond5\")\n)\n\n#summarize SCORES and TIME by subject\nsubjects_summary <- df_items %>% filter(q %nin% c(6,9)) %>% group_by(subject) %>% dplyr::summarise (\n  subject = as.character(subject),\n  pretty_condition = recode_factor(condition, \"11111\" = \"control\", \"113\" =  \"cond3\", \"114\"=\"cond4\", \"115\"=\"cond5\"),\n  s_TRI = sum(score_TRI,na.rm=TRUE),\n  s_ORTH = sum(score_ORTH,na.rm=TRUE),\n  s_TVERSKY = sum(score_TVERSKY,na.rm=TRUE),\n  s_SATISFICE = sum(score_SATISFICE, na.rm=TRUE),\n  s_REF = sum(score_REF,na.rm=TRUE),\n  s_ABS = sum(score_ABS,na.rm=TRUE),\n  s_NABS = sum(score_niceABS,na.rm=TRUE),\n  s_SCALED = sum(score_SCALED,na.rm=TRUE),\n  DV_percent_NABS = s_NABS/13,\n  rt_m = sum(rt_s)/60,\n  item_avg_rt = mean(rt_s),\n  item_min_rt = min(rt_s),\n  item_max_rt = max(rt_s),\n  item_n_TRI = sum(interpretation == \"Triangular\"),\n  item_n_ORTH = sum(interpretation == \"Orthogonal\"),\n  item_n_TV = sum(interpretation == \"Tversky\"),\n  item_n_SAT = sum(interpretation == \"Satisfice\"),\n  item_n_OTHER = sum(interpretation %nin% c(\"Triangular\",\"Orthogonal\",\"Tversky\",\"Satisfice\")),\n  item_n_POS = sum(high_interpretation == \"pos.trans\"),\n  item_n_NEG = sum(high_interpretation == \"neg.trans\"),\n  item_n_NEUTRAL = sum(high_interpretation == \"neutral\")\n) %>% arrange(subject) %>% slice(1L)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\n#summarize first scaffold item of interest by subject\nsubjects_q1 <- df_items %>% filter(q == 1) %>% mutate(\n  item_q1_NABS = score_niceABS,\n  item_q1_SCALED = score_SCALED,\n  item_q1_interpretation = interpretation,\n  item_q1_rt = rt_s,\n) %>% dplyr::select(subject, item_q1_NABS, item_q1_SCALED, item_q1_interpretation,item_q1_rt) %>% arrange(subject)\n\n#summarize last test item of interest by subject\nsubjects_q5 <- df_items %>% filter(q == 5) %>% mutate(\n  item_q5_NABS = score_niceABS,\n  item_q5_SCALED = score_SCALED,\n  item_q5_interpretation = interpretation,\n  item_q5_rt = rt_s,\n) %>% dplyr::select(subject, item_q5_NABS, item_q5_SCALED, item_q5_interpretation,item_q5_rt) %>% arrange(subject)\n\n#summarize first test item of interest by subject\nsubjects_q7 <- df_items %>% filter(q == 7) %>% mutate(\n  item_q7_NABS = score_niceABS,\n  item_q7_interpretation = interpretation,\n  item_q7_rt = rt_s,\n) %>% dplyr::select(subject, item_q7_NABS, item_q7_interpretation,item_q7_rt) %>% arrange(subject)\n\n#summarize last test item of interest by subject\nsubjects_q15 <- df_items %>% filter(q == 15) %>% mutate(\n  item_q15_NABS = score_niceABS,\n  item_q15_interpretation = interpretation,\n  item_q15_rt = rt_s,\n) %>% dplyr::select(subject, item_q15_NABS, item_q15_interpretation,item_q15_rt) %>% arrange(subject)\n\n#summarize scaffold phase performance\nsubjects_scaffold <- df_items %>% filter(q<6)  %>% group_by(subject) %>% dplyr::summarise (\n  item_scaffold_NABS = sum(score_niceABS),\n  item_scaffold_rt = sum(rt_s)\n)%>% dplyr::select(subject, item_scaffold_NABS, item_scaffold_rt) %>% arrange(subject)\n\n#summarize test phase performance\nsubjects_test <- df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% group_by(subject) %>% dplyr::summarise (\n  item_test_NABS = sum(score_niceABS),\n  item_test_rt = sum(rt_s)\n)%>% dplyr::select(subject, item_test_NABS, item_test_rt) %>% arrange(subject)\n\n#SANITY CHECK SUBJECT ORDER BEFORE MERGE; BOTH SHOULD BE TRUE\nunique(subjects_summary$subject == df_subjects$subject)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in subjects_summary$subject == df_subjects$subject: longer object length\nis not a multiple of shorter object length\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_q1$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_q5$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_q7$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_q15$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_scaffold$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nunique(subjects_summary$subject == subjects_test$subject)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\n#CAREFULLY CHECK THIS — RELIES ON \nx = merge(df_subjects, subjects_summary)\nx = merge(x, subjects_q1)\nx = merge(x, subjects_q5)\nx = merge(x, subjects_q7)\nx = merge(x, subjects_q15)\nx = merge(x, subjects_scaffold)\nx = merge(x, subjects_test)\ndf_subjects <- x %>% dplyr::select(-absolute_score) #drop absolute score from webapp that includes Q6 and Q9\n\n#cleanup\nrm(subjects_q1, subjects_q5, subjects_q7, subjects_q15, subjects_scaffold, subjects_test, subjects_summary, x)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#filter for valid items\nx <- df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(subject,mode, condition, q,score_niceABS) \n\n#pivot wider\nwide <- x %>% pivot_wider(names_from=q, names_glue = \"q_{q}\", values_from = score_niceABS)\n\n#calc stepwise cumulative score\nwide$c1 = wide$q_1\nwide$c2 = wide$c1 + wide$q_2\nwide$c3 = wide$c2 + wide$q_3\nwide$c4 = wide$c3 + wide$q_4\nwide$c5 = wide$c4 + wide$q_5\nwide$c6 = wide$c5 + wide$q_7\nwide$c7 = wide$c6 + wide$q_8\nwide$c8 = wide$c7 + wide$q_10\nwide$c9 = wide$c8 + wide$q_11\nwide$c10 = wide$c9 + wide$q_12\nwide$c11 = wide$c10 + wide$q_13\nwide$c12 = wide$c11 + wide$q_14\nwide$c13 = wide$c12 + wide$q_15\nwide <- wide %>% dplyr::select(subject,mode, condition,c1,c2,c3,c4,c5,c6, c7,c8,c9, c10,c11,c12,c13)\n\n#lengthen \ndf_absolute_progress <- wide %>% pivot_longer(cols= c1:c13, names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\ndf_absolute_progress$question <- as.integer(df_absolute_progress$question)\n\n\n#cleanup \nrm(x,wide)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#filter for valid items\nx <- df_items %>% filter(q %nin% c(6,9)) %>% select(subject,mode, condition, q,score_SCALED)\n\n#pivot wider\nwide <- x %>% pivot_wider(names_from=q, names_glue = \"q_{q}\", values_from = score_SCALED)\n\n#calc stepwise cumulative score\nwide$c1 = wide$q_1\nwide$c2 = wide$c1 + wide$q_2\nwide$c3 = wide$c2 + wide$q_3\nwide$c4 = wide$c3 + wide$q_4\nwide$c5 = wide$c4 + wide$q_5\nwide$c6 = wide$c5 + wide$q_7\nwide$c7 = wide$c6 + wide$q_8\nwide$c8 = wide$c7 + wide$q_10\nwide$c9 = wide$c8 + wide$q_11\nwide$c10 = wide$c9 + wide$q_12\nwide$c11 = wide$c10 + wide$q_13\nwide$c12 = wide$c11 + wide$q_14\nwide$c13 = wide$c12 + wide$q_15\nwide <- wide %>% select(subject,mode, condition,c1,c2,c3,c4,c5,c6, c7,c8,c9, c10,c11,c12,c13)\n\n#lengthen \ndf_scaled_progress <- wide %>% pivot_longer(cols= c1:c13, names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\ndf_scaled_progress$question <- as.integer(df_scaled_progress$question)\n\n#cleanup \nrm(x,wide)\n```\n:::\n\n## EXPLORE DISTRIBUTIONS\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_condition = recode_factor(condition, \"11111\" = \"control\", \"113\" =  \"cond3\", \"114\"=\"cond4\", \"115\"=\"cond5\"),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n```\n:::\n\n### Absolute Score\n\n::: {.cell}\n\n```{.r .cell-code}\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/DISTR-ABSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\n# gf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n#   gf_facet_grid(pretty_condition~q) + \n#   labs( x = \"Absolute Score\", \n#         title = \"Distribution of Absolute Score (by Item)\",\n#         subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n#         y = \"Proprition of Subjects\") +\n#   scale_fill_discrete(name = \"Condition\") +  \n#   theme_minimal()\n\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\n# gf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\n# gf_facet_grid(pretty_condition ~. )+\n#   labs( x = \"Total Absolute Score\",\n#         title = \"Distribution of Total Absolute Score (by Subject)\",\n#         subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n#         y = \"Proportion of Subjects\") +\n#   scale_fill_discrete(name = \"Condition\") +\n#   theme_minimal() + theme(legend.position = \"blank\")\n```\n:::\n\n### Scaled Score\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/DISTR-SCALEDSCORE-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION SCALED SCORE BY ITEM\n# gf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n#   gf_facet_grid(q~pretty_condition) + \n#   labs( x = \"Scaled Score\", \n#         title = \"Distribution of Scaled Score (by Item)\",\n#         subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n#         y = \"Proportion of Subjects\") +\n#   scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n#   theme_minimal() + theme(legend.position=\"blank\")\n\n#DISTRIBUTION SCALED SCORE BY SUBJECT\n# gf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>%\n#   gf_facet_grid(pretty_condition ~. )+\n#   labs( x = \"Total Scaled Score\",\n#         title = \"Distribution of Total Scaled Score (by Subject)\",\n#         subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n#         y = \"Number of Subjects\") +\n#   scale_fill_discrete(name = \"Condition\") +\n#   theme_minimal()\n```\n:::\n\n-   TODO: INVESTIGATE if some of the scores assigned to 0 should be assigned to -0.5 to balance\n-   TODO: INVESTIGATE DISTRIBUTIONS of each subscore type\n\n### Interpretations\n\n::: {.cell}\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/DISTR-INTERPRETATIONS-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/DISTR-INTERPRETATIONS-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/DISTR-INTERPRETATIONS-3.png){width=672}\n:::\n:::\n\n### Progress over Task\n\n::: {.cell}\n\n```{.r .cell-code}\n#recode factors\ndf_absolute_progress <- df_absolute_progress %>% mutate(\n    pretty_condition = recode_factor(condition, \"11111\" = \"control\", \"113\" =  \"cond3\", \"114\"=\"cond4\", \"115\"=\"cond5\")\n)\n\ndf_scaled_progress <- df_scaled_progress %>% mutate(\n    pretty_condition = recode_factor(condition, \"11111\" = \"control\", \"113\" =  \"cond3\", \"114\"=\"cond4\", \"115\"=\"cond5\")\n)\n\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/VIZ-PROGRESS-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n```\n\n::: {.cell-output-display}\n![](2_sgc4A_scoring_files/figure-html/VIZ-PROGRESS-2.png){width=672}\n:::\n:::\n\n### Interpretation Subscores\n\n::: {.cell}\n\n```{.r .cell-code}\n# gf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n#   gf_facet_wrap( ~ pretty_condition) + \n#   labs( title = \"Distribution of Total Triangular Score\",\n#         subtitle = \"Impasse shifts density toward higher Triagular scores\",\n#         x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n#         theme_minimal() + theme(legend.position = \"blank\")\n# \n# \n# gf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n#   gf_facet_wrap( ~ pretty_condition) + \n#   labs( title = \"Distribution of Total Orthogonal Score\",\n#         subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n#         x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n#         theme_minimal() + theme(legend.position = \"blank\")\n# \n# gf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n#   gf_facet_wrap( ~ pretty_condition) + \n#   labs( title = \"Distribution of Total Tversky Score\",\n#         subtitle = \"Impasse shifts density toward higher Tversky scores\",\n#         x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n#         theme_minimal() + theme(legend.position = \"blank\")\n# \n# gf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n#   gf_facet_wrap( ~ pretty_condition) + \n#   labs( title = \"Distribution of Total Satisfice Score\",\n#         subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n#         x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n#         theme_minimal() + theme(legend.position = \"blank\")\n```\n:::\n\n## EXPLORE RESPONSES\n\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\nTODO\n\n## EXPORT\n\nFinally, we export the scores for each item (`df_items`) and summarized over subjects (`df_subjects`), as well as cumulative progress dataframes (`df_absolute_progress`, `df_scaled_progress`)\n\n::: {.cell}\n\n```{.r .cell-code}\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4A/data/2-scored-data/sgc4a_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4A/data/2-scored-data/sgc4a_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.rds\") # to R data structure file\n```\n:::\n\n## RESOURCES\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9      purrr_0.3.4     \n [5] readr_2.1.2      tidyr_1.2.0      tibble_3.1.7     tidyverse_1.3.1 \n [9] Hmisc_4.7-0      Formula_1.2-4    survival_3.3-1   lattice_0.20-45 \n[13] pbapply_1.5-0    ggformula_0.10.1 ggridges_0.5.3   scales_1.2.0    \n[17] ggstance_0.3.5   ggplot2_3.3.6    kableExtra_1.3.4\n\nloaded via a namespace (and not attached):\n [1] fs_1.5.2            bit64_4.0.5         lubridate_1.8.0    \n [4] webshot_0.5.3       RColorBrewer_1.1-3  httr_1.4.3         \n [7] tools_4.2.1         backports_1.4.1     utf8_1.2.2         \n[10] R6_2.5.1            rpart_4.1.16        DBI_1.1.3          \n[13] colorspace_2.0-3    nnet_7.3-17         withr_2.5.0        \n[16] tidyselect_1.1.2    gridExtra_2.3       curl_4.3.2         \n[19] bit_4.0.4           compiler_4.2.1      cli_3.3.0          \n[22] rvest_1.0.2         htmlTable_2.4.0     xml2_1.3.3         \n[25] labeling_0.4.2      mosaicCore_0.9.0    checkmate_2.1.0    \n[28] systemfonts_1.0.4   digest_0.6.29       foreign_0.8-82     \n[31] rmarkdown_2.14      svglite_2.1.0       rio_0.5.29         \n[34] base64enc_0.1-3     jpeg_0.1-9          pkgconfig_2.0.3    \n[37] htmltools_0.5.2     labelled_2.9.1      dbplyr_2.2.1       \n[40] fastmap_1.1.0       readxl_1.4.0        htmlwidgets_1.5.4  \n[43] rlang_1.0.3         rstudioapi_0.13     farver_2.1.0       \n[46] generics_0.1.2      jsonlite_1.8.0      vroom_1.5.7        \n[49] zip_2.2.0           magrittr_2.0.3      Matrix_1.4-1       \n[52] Rcpp_1.0.8.3        munsell_0.5.0       fansi_1.0.3        \n[55] lifecycle_1.0.1     stringi_1.7.6       yaml_2.3.5         \n[58] MASS_7.3-57         plyr_1.8.7          grid_4.2.1         \n[61] parallel_4.2.1      crayon_1.5.1        haven_2.5.0        \n[64] splines_4.2.1       hms_1.1.1           knitr_1.39         \n[67] pillar_1.7.0        reprex_2.0.1        glue_1.6.2         \n[70] evaluate_0.15       latticeExtra_0.6-29 data.table_1.14.2  \n[73] modelr_0.1.8        tzdb_0.3.0          png_0.1-7          \n[76] vctrs_0.4.1         tweenr_1.0.2        cellranger_1.1.0   \n[79] gtable_0.3.0        polyclip_1.10-0     assertthat_0.2.1   \n[82] openxlsx_4.2.5      xfun_0.31           ggforce_0.3.3      \n[85] broom_0.8.0         viridisLite_0.4.0   cluster_2.1.3      \n[88] ellipsis_0.3.2     \n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}