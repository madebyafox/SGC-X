---
subtitle: 'Study SGC3A | 3 Description'
---

\newpage

# Description {#sec-SGC3A-description}

*The purpose of this notebook is describe the distributions of dependent variables for Study SGC3A.*

+------------------------+
| Pre-Requisite          |
+========================+
| 2_sgc3A_scoring.qmd    |
+------------------------+

```{r}
#| label: SETUP
#| warning : false
#| message : false

library(Hmisc) # %nin% operator
library(mosaic) #simple descriptives [favstats]

library(kableExtra) #printing tables 
library(vcd) #mosaicplots
library(ggpubr) #arrange plots
library(ggformula) #quick easy plots
library(ggdist) # uncertainty viz
library(ggstatsplot) #stats plots 4 dummies
library(ggeasy) #theme editing. the way it should be

library(multimode) #test for multimodality
library(fitdistrplus) #fitting distributions
library(performance) #multimodality

library(tidyverse) #ALL THE THINGS

#OUTPUT OPTIONS
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
options(ggplot2.summarise.inform = FALSE)
options(scipen=1, digits=3)

#GRAPH THEMEING
theme_set(theme_minimal()) 

```

```{r}
#| label: IMPORT-DATA
#| warning : false
#| message : false

# HACK WD FOR LOCAL RUNNING?
# imac = "/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN"
# mbp = "/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN"
# setwd(mbp)

#IMPORT DATA 
df_items <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_items.rds')
df_subjects <- read_rds('analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds') 
df_absolute_progress <- read_csv('analysis/SGC3A/data/2-scored-data/sgc3a_absolute_progress.csv')
df_scaled_progress <- read_csv('analysis/SGC3A/data/2-scored-data/sgc3a_scaled_progress.csv')

#SETUP PERCENTAGE SCORE FOR TEST PHASE ONLY
df_subjects <- df_subjects %>% mutate(
  DV_ptest_NABS = item_test_NABS /8
) 

#SEPARATE ITEM AND SUBJECTS BY MODALITY
df_lab <- df_subjects %>% filter(mode == "lab-synch")
df_online <- df_subjects %>% filter(mode == "asynch")

#TREAT QS AS FACTORS
df_items$q = as.factor(df_items$q)

```

## SAMPLE

### Data Collection

Data was initially collected (in person, SONA groups in computer lab) in Fall 2017. In Spring 2018, additional data were collected after small modifications were made to the experimental platform to increase the size of multiple-choice input buttons, and to add an additional free-response question following the main task block. In Fall 2021, the study was replicated using asynchronous, online SONA pool, with additional participants collected in Winter 2022.

```{r}
#| label : INSPECT-DATA-COLLECTION

title = "Participants by Condition and Data Collection Period"
cols = c("Control Condition","Impasse Condition","Total for Period")
cont <- table(df_subjects$pretty_mode, df_subjects$condition)
cont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()

```

### Participants

```{r}
#| label: DESC-PARTICIPANTS

#Describe participants
subject.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(age) %>% unlist() %>% favstats(),
  "online" = df_online %>% filter(mode == "asynch") %>% dplyr::select(age) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()
) 

subject.stats$percent.male <- c(
  (df_lab %>%  filter(gender=="Male") %>% count())$n/count(df_lab) %>% unlist(),
  (df_online %>% filter(gender=="Male") %>% count())$n/count(df_online) %>% unlist(),
  (df_subjects %>% filter(gender=="Male") %>% count())$n/count(df_subjects) %>% unlist()
)

subject.stats$percent.female <- c(
  (df_lab %>%  filter(gender=="Female") %>% count())$n/count(df_lab) %>% unlist(),
  (df_online %>% filter(gender=="Female") %>% count())$n/count(df_online) %>% unlist(),
  (df_subjects %>% filter(gender=="Female") %>% count())$n/count(df_subjects) %>% unlist()
)

subject.stats$percent.other <- c(
  (df_lab %>%  filter(gender %nin% c("Female","Male")) %>% count())$n/count(df_lab) %>% unlist(),
  (df_online %>% filter(gender %nin% c("Female","Male")) %>% count())$n/count(df_online) %>% unlist(),
  (df_subjects %>% filter(gender %nin% c("Female","Male")) %>% count())$n/count(df_subjects) %>% unlist()
)

title = "Descriptive Statistics of Participant Age and Gender"
subject.stats %>% kbl (caption = title) %>% kable_classic()%>% 
  footnote(general = "Age in Years", 
           general_title = "Note: ",footnote_as_chunk = T) 
```

For **in-person** collection, `r subject.stats["lab",]$n` participants (`r round((subject.stats["lab",]$percent.male),2) * 100` % male, `r round((subject.stats["lab",]$percent.female),2) * 100` % female, `r round((subject.stats["lab",]$percent.other),2) * 100` % other) undergraduate STEM majors at a public American University participated *in person* in exchange for course credit (age: `r (subject.stats['lab','min'])` - `r (subject.stats['lab','max'])` years). Participants were randomly assigned to one of two experimental groups.

For **online replication** `r subject.stats["online",]$n` participants (`r round((subject.stats["online",]$percent.male),2) * 100` % male, `r round((subject.stats["online",]$percent.female),2) * 100` % female, `r round((subject.stats["online",]$percent.other),2) * 100` % other)  undergraduate STEM majors at a public American University participated *online, asynchronously* in exchange for course credit (age: `r (subject.stats['online','min'])` - `r (subject.stats['online','max'])` years). Participants were randomly assigned to one of two experimental groups.

Combined **overall** `r subject.stats["combined",]$n` participants (`r round((subject.stats["combined",]$percent.male),2) * 100` % male, `r round((subject.stats["combined",]$percent.female),2) * 100` % female, `r round((subject.stats["combined",]$percent.other),2) * 100` % other)  undergraduate STEM majors at a public American University participated in exchange for course credit (age: `r (subject.stats['combined','min'])` - `r (subject.stats['combined','max'])` years).

## RESPONSE ACCURACY

### Subject Level Scores

Subject level scores summarize the the response accuracy by a particular participant across all discriminant items in the graph comprehension task.

#### Test Phase Absolute Score

Recall from [Section -@sec-absolute-scoring] that the absolute score (following the dichotomous scoring approach) `s_NABS` indicates if the subject's response for a particular item was *perfectly* correct: whether they selected all correct answer options and no others (excluding certain allowed exceptions, such as also selecting the data point referenced in the question). The absolute score for an individual item is either 0 or 1. When summarized across the entire set of discriminant items, the total absolute score for an individual subject ranges from \[0,13\]. When summarized across just the test phase (final items following scaffolding phase) scores for an individual subject range from \[0,8\]. First we examine performance on the test phase (final 8 questions, appears after scaffolding phase). This tells us how the participants perform *after* exposure to the 5 scaffolding questions (in the impasse condition).

```{r}
#| label: DESC-SUBJ-ABS-TEST
#| 
title = "Descriptive Statistics of TEST PHASE Response Accuracy (Total Absolute Score)"
abs.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats()
) 
abs.stats %>% kbl (caption = title) %>% kable_classic() %>% 
  footnote(general = "# questions correct [0,8]", 
           general_title = "Note: ",footnote_as_chunk = T) 

```

For *in person* collection, total absolute scores in the TEST phase (n = `r abs.stats["lab",]$n`) range from `r round(abs.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(abs.stats["lab",]$mean,2)`, SD = `r round(abs.stats["lab",]$sd,2)`).

For *online replication*, (online) total absolute scores in the TEST phase (n = `r abs.stats["online",]$n`) range from `r round(abs.stats["online",]$min,2)` to `r round(abs.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["online",]$mean,2)`, SD = `r round(abs.stats["online",]$sd,2)`).

When combined *overall*, total absolute accuracy scores in the TEST phase (n = `r abs.stats["combined",]$n`) range from `r round(abs.stats["combined",]$min,2)` to `r round(abs.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["combined",]$mean,2)`, SD = `r round(abs.stats["combined",]$sd,2)`).



```{r}
#| label: VIS-SUBJ-ABS-TEST

#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE
  gf_props(~item_test_NABS, data = df_subjects) + 
  labs(x = "number of correct responses (test phase)",
       y = "% of subjects",
       title = "Distribution of TEST Absolute Score ",
       subtitle = "Modes at high and low ends of scale suggest concentration of high (vs) low understanding") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_test_NABS", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of TEST Absolute Score",
        subtitle ="Pattern of response is similar across data collection modes but differs by condition",
        x = "Total Absolute Score (Test Phase)", y = "number of subjects") +
  theme_minimal() + theme(legend.position = "blank")

##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = item_test_NABS,
                        fill = pretty_condition) ) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.1,
    width = 1, 
    point_colour = NA
   ) + 
  geom_boxplot(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_NABS),
    width = .15, 
    outlier.shape = NA
  ) + 
  geom_point(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_NABS, color = pretty_condition),
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .05
  )) + labs( 
    title = "Distribution of TEST Absolute Score ",
    x = "Condition", y = "Total Absolute Score (Test Phase)") +
  theme(legend.position = "blank") + 
  coord_cartesian(xlim = c(0.5, NA), clip = "off")

#STATSPLOT
ggbetweenstats(y = item_test_NABS, x = pretty_condition, data = df_subjects,
               type = "nonparametric", var.equal = FALSE,
               pairwide.display = "significant", )


#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION
ggplot(data = df_subjects, aes(item_test_NABS)) + 
  stat_ecdf(geom = "step") +
  facet_grid(pretty_condition~pretty_mode) + 
  labs( title = "Empirical Cumulative Density Function — TEST Absolute Score ",
        x = "Total Absolute Score (Test Phase) [0,8]", 
        y = "Cumulative Probability")

#NOTE this is clobbered by the shift function imports; so I load those later
  


```

Visual inspection of this distribution suggests it is not normal, and likely bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018). TODO REFERENCE

```{r}
#| label: CHECK-SUBJ-ABS-TEST

multimode::modetest(df_subjects$item_test_NABS)
n_modes = multimode::nmodes(df_subjects$item_test_NABS, bw=2) #bw = 2questions/15 = 0.15%
l_modes = multimode::locmodes(df_subjects$item_test_NABS,mod0 =  n_modes, display = TRUE)
```

The excess mass test for multimodality suggests the distribution is infact multimodal (m = 0.1, p \< 0.001), with two identifiable modes at `r l_modes$location[1]` and `r l_modes$location[3]`, and an antimode at `r l_modes$location[2]`.

::: callout-note
**Condition appears (through visual inspection) to yield a positive influence on Total Absolute Score in the TEST Phase, across data collection modalities.**
:::


#### Test Phase Absolute Percentage

Test Phase Score converted to percentage. 

```{r}

title = "Descriptive Statistics of TEST PHASE Response Accuracy (% Accuracy Absolute Score)"
abs.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats()
) 
abs.stats %>% kbl (caption = title) %>% kable_classic() %>% 
  footnote(general = "% questions correct [0 - 100%]", 
           general_title = "Note: ",footnote_as_chunk = T) 

```

For *in person* collection, total absolute scores in the TEST phase (n = `r abs.stats["lab",]$n`) range from `r round(abs.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(abs.stats["lab",]$mean,2)`, SD = `r round(abs.stats["lab",]$sd,2)`).

For *online replication*, (online) total absolute scores in the TEST phase (n = `r abs.stats["online",]$n`) range from `r round(abs.stats["online",]$min,2)` to `r round(abs.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["online",]$mean,2)`, SD = `r round(abs.stats["online",]$sd,2)`).

When combined *overall*, total absolute accuracy scores in the TEST phase (n = `r abs.stats["combined",]$n`) range from `r round(abs.stats["combined",]$min,2)` to `r round(abs.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["combined",]$mean,2)`, SD = `r round(abs.stats["combined",]$sd,2)`).

```{r}

#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE
  gf_props(~DV_ptest_NABS, data = df_subjects) + 
  labs(x = "number of correct responses (test phase)",
       y = "% of subjects",
       title = "Distribution of TEST Absolute Score ",
       subtitle = "Modes at high and low ends of scale suggest concentration of high (vs) low understanding") 

##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "DV_ptest_NABS",
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of TEST Absolute Score",
        subtitle ="Pattern of response is similar across data collection modes but differs by condition",
        x = "Total Absolute Score (Test Phase)", y = "number of subjects") +
  theme_minimal() + theme(legend.position = "blank")

##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = DV_ptest_NABS,
                        fill = pretty_condition) ) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.1,
    width = 1, 
    point_colour = NA
   ) + 
  geom_boxplot(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = DV_ptest_NABS),
    width = .15, 
    outlier.shape = NA
  ) + 
  geom_point(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = DV_ptest_NABS, color = pretty_condition),
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .05
  )) + labs( 
    title = "Distribution of TEST Absolute Score ",
    x = "Condition", y = "Total Absolute Score (Test Phase)") +
  theme(legend.position = "blank") + 
  coord_cartesian(xlim = c(0.5, NA), clip = "off")

#STATSPLOT
ggbetweenstats(y = DV_ptest_NABS, x = pretty_condition, data = df_subjects,
               type = "nonparametric", var.equal = FALSE,
               pairwide.display = "significant", )


#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION
ggplot(data = df_subjects, aes(DV_ptest_NABS)) + 
  stat_ecdf(geom = "step") +
  facet_grid(pretty_condition~pretty_mode) + 
  labs( title = "Empirical Cumulative Density Function — TEST Absolute Score ",
        x = "Total Absolute Score (Test Phase) [0,8]", 
        y = "Cumulative Probability")

#NOTE this is clobbered by the shift function imports; so I load those later
  


```

#### Test Phase Scaled Scores

The test phase scaled score `s_SCALED` summarizes the scaled score on the 8 strategy-discriminant questions in the test phase, for each subject. This score ranges from from -8 (all orthogonal) to 8 (all triangular). Recall that the `s_SCALED` score for an item is a numeric representation of the strategy-consistent response, scaled from -1 to +1 (see [Section -@sec-SGC3A-scaledScore])

Most importantly, the Scaled score gives us a way of quantitatively examining how correctly a participant interpreted the coordinate system across the entire set of items. It offers a more nuanced look into performance than absolute score.

```{r}
#| label: DESC-SUBJ-SCALED-TEST

title = "Descriptive Statistics of Response Accuracy (Total Scaled Score)"
scaled.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats()
) 
scaled.stats %>% kbl (caption = title) %>% kable_classic()

```

For **in person collection**, TEST phase scaled scores (n = `r scaled.stats["lab",]$n`) range from `r round(scaled.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(scaled.stats["lab",]$mean,2)`, SD = `r round(scaled.stats["lab",]$sd,2)`).

For **online replication**, TEST phase scaled scores (n = `r scaled.stats["online",]$n`) range from `r round(scaled.stats["online",]$min,2)` to `r round(scaled.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(scaled.stats["online",]$mean,2)`, SD = `r round(scaled.stats["online",]$sd,2)`).

When combined **overall**, TEST phase scaled scores (n = `r scaled.stats["combined",]$n`) range from `r round(scaled.stats["combined",]$min,2)` to `r round(scaled.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(scaled.stats["combined",]$mean,2)`, SD = `r round(scaled.stats["combined",]$sd,2)`).

```{r}
#| label: VIS-SUBJ-SCALED-TEST

#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL SCALED
gf_props(~item_test_SCALED, data = df_subjects) +
  labs(x = "total scaled score (test phase)",
       y = "% of subjects",
       title = "Distribution of TEST Scaled Score ",
       subtitle = "Modes at high and low ends of scale suggest concentration of high (vs) low understanding") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_test_SCALED",binwidth=1,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE) 
facet(p, facet.by=c("pretty_condition","pretty_mode")) + 
  labs( title = "Distribution of TEST Scaled Score",
        subtitle ="Pattern of response is similar across data collection modes but differs by condition",
        x = "total scaled score (test phase)", y = "number of participants") + 
 theme_minimal() + theme(legend.position = "blank") 


##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = item_test_SCALED,
                        fill = pretty_condition) ) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.1,
    width = 1, 
    point_colour = NA
   ) + 
  geom_boxplot(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_SCALED),
    width = .15, 
    outlier.shape = NA
  ) + 
  geom_point(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_SCALED, color = pretty_condition),
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .05
  )) + labs( 
    title = "Distribution of TEST Scaled Score ",
    x = "Condition", y = "Total Scaled Score (Test Phase)") +
  theme(legend.position = "blank") + 
  coord_cartesian(xlim = c(0.5, NA), clip = "off")

#EASY STATS
ggbetweenstats(y = item_test_SCALED, x = pretty_condition, data = df_subjects,
               type = "nonparametric", var.equal = FALSE,
               pairwide.display = "significant", )


#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION
ggplot(data = df_subjects, aes(item_test_SCALED)) + 
  stat_ecdf(geom = "step") + 
  facet_grid(pretty_condition ~ pretty_mode) + 
  labs( title = "Empirical Cumulative Density Function — Test Phase Scaled Score",
        x = "Test Phase Scaled Score [-8,8]", 
        y = "Cumulative Probability") 

```

Visual inspection of this distribution suggests it is not normal, and perhaps perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).

```{r}
#| label: CHECK-SUBJ-SCALED-TEST

multimode::modetest(df_subjects$item_test_SCALED)
n_modes = multimode::nmodes(df_subjects$item_test_SCALED, bw=2) #bw = 2questions/15 = 0.15%
l_modes = multimode::locmodes(df_subjects$item_test_SCALED,mod0 =  n_modes, display = TRUE)
```

The excess mass test for multimodality suggests the distribution is in fact multimodal (m = 0.1, p \< 0.001), with two identifiable modes at `r l_modes$location[1]` and `r l_modes$location[3]`, and an antimode at `r l_modes$location[2]`.

### First Item Scores

Next we consider the response accuracy on *just* the first question of the graph comprehension task: a subject's first exposure to the TM graph.

#### First Item Absolute Score

```{r}
#| label: DESC-FIRST-ABSOLUTE


title = "Proportion of Correct Response on First Item (Lab)"
item.contingency <- df_lab %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Correct Response on First Item (Online)"
item.contingency <- df_online %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Correct Response on First Item (Combined)"
item.contingency <- df_subjects %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)
item.contingency %>% kbl (caption = title) %>% kable_classic()


```

Across data collection sessions, first-item accuracy is consistent across experimental conditions. Incorrect answers are far more frequent (78%) than correct answers (22%). Accuracy is somewhat improved in the IMPASSE condition, with roughly 28% of all IMPASSE-condition questions answered correctly, compared to only 14% in the CONTROL condition.

```{r}
#| label: VIS-FIRST-ABSOLUTE

#PROPORTIONAL BAR CHART
gf_props(~item_q1_NABS, data = df_subjects) +
  labs(x = "response accuracy",
       y = "% subjects",
       title = "Proportion of Correct Responses on First Item",
       subtitle="")+
  theme(legend.position = "none")+theme_ggdist()

#STACKED BAR CHART
df_subjects %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = as.factor(item_q1_NABS))) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~pretty_mode) + 
  labs(x = "response accuracy",
       title = "Proportion of Correct Responses on First Item (by Modality and Condition)",
       x = "Condition",
       fill = "",
       subtitle="Impasse Condition yields a greater proportion of correct responses")


#MOSAIC PLOT
vcd::mosaic(main="Proportion of Correct Responses on First Item",
            data = df_subjects, item_q1_NABS ~ pretty_condition, rot_labels=c(0,90,0,0), 
            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = "right",
            spacing = spacing_dimequal(unit(1:2, "lines"))) 

#STATSPLOT
ggbarstats(
  x = item_q1_NABS,
  y = pretty_condition, 
  data = df_subjects
)

```

#### First Item Scaled Score

At the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1. (note: we evaluate scaled_score on the first item rather than interpretation, because no orthogonal interpretation is available in the impasse condition)

```{r}
#| label: DESC-FIRST-SCALED
title = "Descriptive Statistics of Response Accuracy (First Item Scaled Score)"
firstscaled.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats()
) 
firstscaled.stats %>% kbl (caption = title) %>% kable_classic()

```

For **in person** collection, first item scaled scores (n = `r firstscaled.stats["lab",]$n`) range from `r round(firstscaled.stats["lab",]$min,2)` to `r round(firstscaled.stats["lab",]$max,2)` with a mean score of (M = `r round(firstscaled.stats["lab",]$mean,2)`, SD = `r round(firstscaled.stats["lab",]$sd,2)`).

For **online replication**, (online) first item scaled scores (n = `r firstscaled.stats["online",]$n`) range from `r round(firstscaled.stats["online",]$min,2)` to `r round(firstscaled.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(firstscaled.stats["online",]$mean,2)`, SD = `r round(firstscaled.stats["online",]$sd,2)`).

When combined **overall**, first item scaled scores (n = `r firstscaled.stats["combined",]$n`) range from `r round(firstscaled.stats["combined",]$min,2)` to `r round(firstscaled.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(firstscaled.stats["combined",]$mean,2)`, SD = `r round(firstscaled.stats["combined",]$sd,2)`).

```{r}
#| label: VIS-FIRST-SCALED

#GGFORMULA | PROPORTIONAL HISTOGRAM SUBJECT FIRST SCALED
gf_props(~item_q1_SCALED, data = df_subjects) +
  labs(x = "scaled score (first item)",
       y = "% of subjects",
       title = "Distribution of First Item Scaled Score",
       subtitle = "") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_q1_SCALED", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE) 
facet(p, facet.by=c("pretty_condition","pretty_mode")) + 
  labs( title = "Distribution of First Item Scaled Score (by Mode and Condition)",
        subtitle ="Impasse condition yields more intermediate scores (indicating uncertainty)",
        x = "scaled score (firt item) ", y = "number of participants") + 
  theme_minimal() + theme(legend.position = "blank") 

#STACKED BAR CHART
df_subjects %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = as.factor(item_q1_SCALED))) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~pretty_mode) + 
  labs(x = "response accuracy",
       title = "Type of Responses on First Item (by Modality and Condition)",
       x = "Condition",
       fill = "",
       subtitle="Impasse Condition yields a greater proportion of correct responses")

#STATSPLOT
ggbarstats(
  x = item_q1_SCALED,
  y = pretty_condition, 
  data = df_subjects
)
  
```

### Interpretation Scores

Next we consider the the interpretations assigned to each response. For each response given by a participant to a question, we assign an interpretation label based on the interpretation the response most closely matches (see @sec-scoring-interpretation).

```{r}
#| label: DESC-TOTAL-INTEPRETATIONS

title = "Proportion of Interpretations Across Items Items By Condition (Lab)"
item.contingency <- df_items %>% filter(mode == "lab-synch") %>% dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Interpretations Across Items Items By Condition (Online)"
item.contingency <- df_items %>% filter(mode == "asynch") %>% dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Interpretations Across Items Items By Condition (Combined)"
item.contingency <- df_items %>%  dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()


```

```{r}
#| label: VIS-ITEM-INTERPRETATION


#PROPORTIONAL BAR CHART
gf_propsh(~interpretation, data = df_items, fill = ~pretty_condition) %>% 
  gf_facet_grid(pretty_condition~pretty_mode) +
  labs(x = "% of items",
       title = "Proportion of Interpretations Across Items",
       subtitle="Impasse Condition yields shift from Orthogonal to alternative interpretations")+
  theme(legend.position = "none")

#STACKED BAR CHART
df_items %>% 
  ggplot(data = .,
         mapping = aes(x = pretty_condition,
                       fill = as.factor(interpretation))) +
  geom_bar(position = "fill" ) + #,color = "black") +
  scale_fill_brewer(palette = "Set1")  +
  facet_wrap(~pretty_mode) + 
  labs(x = "response accuracy",
       title = "Response Types on All Items (by Modality and Condition)",
       x = "Condition",
       fill = "",
       subtitle="Impasse Condition yields a greater proportion of correct responses")


#MOSAIC PLOT
vcd::mosaic(main="Proportion of Interpretations across Conditions",
            data = df_items, pretty_condition ~ interpretation, rot_labels=c(0,90,0,0),
            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = "right",
            spacing = spacing_dimequal(unit(1:2, "lines")))

#STATSPLOT
ggbarstats(
  x = high_interpretation,
  y = pretty_condition, 
  data = df_items
)

```


### Cumulative Task Performance

```{r}
#| label: VIZ-PROGRESS

#VISUALIZE progress over time ABSOLUTE score 
ggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + 
 geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +
 facet_wrap(~pretty_condition) + 
 labs (title = "Cumulative Absolute Score over sequence of task", x = "Question" , y = "Cumulative Absolute Score") + 
 scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +
 theme_minimal() + theme(legend.position = "blank")

#VISUALIZE progress over time SCALED score 
ggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + 
 geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +
 facet_wrap(~pretty_condition) + 
 labs (title = "Cumulative Scaled Score over sequence of task", x = "Question" , y = "Cumulative Scaled Score") + 
 scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +
 theme_minimal() + theme(legend.position = "blank")

```


## RESPONSE LATENCY

### Time on Task

Here we consider the time spent on the graph comprehension task portion of the study.

```{r DESCRIBE-TOTALTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_lab%>% dplyr::select(totaltime_m) %>% unlist()  %>%  favstats(),
  "online"= df_online %>% dplyr::select(totaltime_m) %>% unlist() %>% favstats(),
  "combined"= df_subjects %>% dplyr::select(totaltime_m) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of First Response Time (seconds)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Response time _on the graph comprehension task_  for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Response time _on the graph comprehension task_ for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

Response time _on the graph comprehension task_ for *combined* subjects (n = `r time.stats["combined",]$n`) ranged from `r round(time.stats["combined",]$min,2)` to `r round(time.stats["combined",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["combined",]$mean,2)`, SD = `r round(time.stats["combined",]$sd,2)`).

```{r}
#| label : VIS-TOTALTIME
#| message : false
#| warning : false


#HISTOGRAM
gf_dhistogram(~totaltime_m, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Distribution of Task Time (minutes)", subtitle = "fit by gamma distribution", x = "Task Time (minutes)", y = "% items")


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "totaltime_m", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
   labs(title="Distribution of Task Time (minutes)", subtitle = "fit by gamma distribution", x = "Task Time (minutes)", y = "% items") + 
  theme_minimal() + theme(legend.position = "blank")
                
```



### Time on First Item 

Here we consider the time spent on just the first individual item (first exposure to graph).

```{r DESCRIBE-FIRSTTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_lab%>% dplyr::select(item_q1_rt) %>% unlist()  %>%  favstats(),
  "online"= df_online %>% dplyr::select(item_q1_rt) %>% unlist() %>% favstats(),
  "combined"= df_subjects %>% dplyr::select(item_q1_rt) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of First Response Time (seconds)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Response time _on the first item_  for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Response time _on the first item_ for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

Response time _on the first item_ for *combined* subjects (n = `r time.stats["combined",]$n`) ranged from `r round(time.stats["combined",]$min,2)` to `r round(time.stats["combined",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["combined",]$mean,2)`, SD = `r round(time.stats["combined",]$sd,2)`).

```{r}
#| label : VIS-FIRSTTIME
#| message : false
#| warning : false


#HISTOGRAM
gf_dhistogram(~item_q1_rt, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Distribution of First Item Response Time (seconds)", subtitle = "fit by gamma distribution", x = "First Item Response Time (seconds)", y = "% items")


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_q1_rt", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of First Item Response Time (seconds)",
        subtitle ="",
        x = "First Item Response Time (seconds)", y = "number of items") +
  theme_minimal() + theme(legend.position = "blank")



#recode as boolean correct
df_subjects <- df_subjects %>% mutate(
  item_q1_NABS = as.logical(item_q1_NABS)
)

##RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = item_q1_rt, color = item_q1_NABS) ) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.2, 
    adjust = .5, 
    width = .6, 
    .width = 0, 
    point_colour = NA) + 
  geom_boxplot(
    width = .15, 
    outlier.shape = NA
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .1
  )) + 
  labs( title = "Distribution of First Item Response Time (seconds)",
        subtitle ="",
        y = "First Item Response Time (s)", x = "Condition") +
  theme_ggdist() 
# + theme(legend.position = "blank")
# + coord_cartesian(xlim = c(1.2, NA), clip = "off")
                
```

### Time on Item 

Here we consider the time spent on an individual item (across all items).

```{r DESCRIBE-ITEMTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_items %>% filter(mode == "lab-synch") %>% dplyr::select(rt_s) %>% unlist()  %>%  favstats(),
  "online"= df_items %>% filter(mode == "lab-synch") %>% dplyr::select(rt_s) %>% unlist() %>% favstats(),
  "combined"= df_items %>%   dplyr::select(rt_s) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of Item Response Latency (seconds)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Time on an individual item for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Time on an individual item  for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

Time on an individual item for *combined* subjects (n = `r time.stats["combined",]$n`) ranged from `r round(time.stats["combined",]$min,2)` to `r round(time.stats["combined",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["combined",]$mean,2)`, SD = `r round(time.stats["combined",]$sd,2)`).

```{r}
#| label : VIS-ITEMTIME
#| message : false
#| warning : false


#HISTOGRAM
gf_dhistogram(~rt_s, data = df_items) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Distribution of Item Response Time (seconds)", 
       subtitle = "fit by gamma distribution", x = "Item Response Time (seconds)", y = "% items") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_items, x = "rt_s", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of Item Response Time (seconds)",
        subtitle ="",
        x = "Item Response Time (seconds)", y = "number of items") +
  theme_minimal() + theme(legend.position = "blank")


#recode as boolean correct
df_items <- df_items %>% mutate(
  score_niceABS = as.logical(score_niceABS)
)

##RAINCLOUD USING GGDISTR
ggplot(df_items, aes(x = pretty_condition, y = rt_s, color = score_niceABS) ) + 
  ggdist::stat_halfeye(
    side = "left",
    # position = position_dodgejust(),
    justification = 1.5, 
    # adjust = .5, 
    width = .5, 
    .width = 0, 
    point_colour = NA) + 
  geom_boxplot(
    width = .15, 
    outlier.shape = NA,
    position = position_dodge2()
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitterdodge(
      # seed = 1,
      dodge.width = 0.5,
      jitter.width = 0.075
  )) +
  labs( title = "Distribution of Item Response Time (seconds)",
        subtitle ="",
        y = "Item Response Time (s)", x = "Condition") +
  theme_ggdist() 
# + theme(legend.position = "blank")
# + coord_cartesian(xlim = c(1.2, NA), clip = "off")
                
```

### Time on SCAFFOLD Phase

Here we consider _just_ the time spent on the first five items of the task (the scaffold phase).

```{r DESCRIBE-SCAFFOLDTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(item_scaffold_rt) %>% unlist()  %>%  favstats(),
  "online"= df_online %>% dplyr::select(item_scaffold_rt) %>% unlist() %>% favstats(),
  "combined"= df_subjects %>% dplyr::select(item_scaffold_rt) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of SCAFFOLD Phase Response Latency (minutes)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Total time on SCAFFOLD phase for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Total time on SCAFFOLD phase for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

Total time on SCAFFOLD phase for *combined* subjects (n = `r time.stats["combined",]$n`) ranged from `r round(time.stats["combined",]$min,2)` to `r round(time.stats["combined",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["combined",]$mean,2)`, SD = `r round(time.stats["combined",]$sd,2)`).

```{r}
#| label : VIS-SCAFFOLDTIME
#| message : false
#| warning : false


#HISTOGRAM
gf_dhistogram(~item_scaffold_rt, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Distribution of SCAFFOLD Phase Response Time (minutes)", subtitle = "fit by gamma distribution", x = "Scaffold Phase Time (minutes)", y = "% subjects") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_scaffold_rt", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of SCAFFOLD Phase Response Time (minutes)",
        subtitle ="",
        x = "Scaffold Phase Time (minutes)", y = "number of subjects") +
  theme_minimal() + theme(legend.position = "blank")

##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = item_scaffold_rt, fill = pretty_condition)) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.2, 
    adjust = .5, 
    width = .6, 
    .width = 0, 
    point_colour = NA) + 
  geom_boxplot(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_scaffold_rt),
    width = .15, 
    outlier.shape = NA
  ) + 
  geom_point(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_scaffold_rt, color = pretty_condition),
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .05
  ))+ labs( title = "Distribution of SCAFFOLD Phase Response Time (minutes)",
        subtitle ="",
        y = "Total Study Time (minutes)", x = "Condition") +
  theme_ggdist() + theme(legend.position = "blank") #+
  # coord_cartesian(xlim = c(0.5, NA), clip = "off")
                
```

### Time on TEST Phase

Here we consider _just_ the time spent on the remaining eight discriminant items of the task (the test phase).

```{r DESCRIBE-TESTTIME}
#DESCRIBE distribution of response time
time.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(item_test_rt) %>% unlist()  %>%  favstats(),
  "online"= df_online %>% dplyr::select(item_test_rt) %>% unlist() %>% favstats(),
  "combined"= df_subjects %>% dplyr::select(item_test_rt) %>% unlist() %>% favstats()
)

title = "Descriptive Statistics of TEST Phase Response Latency (minutes)"
time.stats %>% kbl(caption = title) %>% kable_classic()
```

Total time on TEST phase for *in person* subjects (n = `r time.stats["lab",]$n`) ranged from `r round(time.stats["lab",]$min,2)` to `r round(time.stats["lab",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["lab",]$mean,2)`, SD = `r round(time.stats["lab",]$sd,2)`).

Total time on TEST phase for *online replication* subjects (n = `r time.stats["online",]$n`) ranged from `r round(time.stats["online",]$min,2)` to `r round(time.stats["online",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["online",]$mean,2)`, SD = `r round(time.stats["online",]$sd,2)`).

Total time on TEST phase for *combined* subjects (n = `r time.stats["combined",]$n`) ranged from `r round(time.stats["combined",]$min,2)` to `r round(time.stats["combined",]$max,2)` minutes with a mean duration of (M = `r round(time.stats["combined",]$mean,2)`, SD = `r round(time.stats["combined",]$sd,2)`).

```{r}
#| label : VIS-TESTTIME
#| message : false
#| warning : false


#HISTOGRAM
gf_dhistogram(~item_test_rt, data = df_subjects) %>%
  gf_vline(xintercept = ~time.stats["lab",]$mean, color = "black") %>% 
  gf_fitdistr(dist="gamma", color="red")+
  labs(title="Distribution of TEST Phase Response Time (minutes)", subtitle = "fit by gamma distribution", x = "Test Phase Time (minutes)", y = "% subjects") 


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "item_test_rt", binwidth = 0.5,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of TEST Phase Response Time (minutes)",
        subtitle ="",
        x = "Test Phase Time (minutes)", y = "number of subjects") +
  theme_minimal() + theme(legend.position = "blank")


##VERTICAL RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = item_test_rt, fill = pretty_condition)) + 
  ggdist::stat_halfeye(
    side = "left",
    justification = 1.2, 
    adjust = .5, 
    width = .6, 
    .width = 0, 
    point_colour = NA) + 
  geom_boxplot(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_rt),
    width = .15, 
    outlier.shape = NA
  ) + 
  geom_point(
    inherit.aes = FALSE, #supress fill
    mapping = aes(x=pretty_condition, y = item_test_rt, color = pretty_condition),
    size = 1.3,
    alpha = .3,
    position = position_jitter( 
      seed = 1, width = .05
  ))+ 
  labs( title = "Distribution of TEST Phase Response Time (minutes)",
        subtitle ="",
        y = "Total Study Time (minutes)", x = "Condition") +
  theme_ggdist() + theme(legend.position = "blank") #+
  # coord_cartesian(xlim = c(0.5, NA), clip = "off")
                
```

## EXPLORING RELATIONSHIPS

### ACCURACY (VS) LATENCY

#### Total Task 
```{r}

#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( s_SCALED ~ rt_m, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "Total (Scaled) Score by TOTAL Item Response Time",
    subtitle = "", 
    x = "Total Item Response Time (minutes)", y = "Total Scaled Score "
  ) + theme(legend.position = "blank")


#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( s_SCALED ~ item_avg_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "Total (Scaled) Score by MEAN Item Response Time",
    subtitle = "", 
    x = "Average Item Response Time (seconds)", y = "Total Scaled Score"
  ) + theme(legend.position = "blank")


#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( s_SCALED ~ item_max_rt, data = df_subjects %>% filter(item_max_rt < 400), alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "Total (Scaled) Score by MAX Item Response Time",
    subtitle = "", 
    x = "MAX Item Response Time (s)", y = "Total Scaled Score "
  ) + theme(legend.position = "blank")

#NOTE: LOG transforms of the RT do not yield linear relationships

```

#### Phase Specific

```{r}
#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( s_SCALED ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "Total (Scaled) Score by SCAFFOLD PHASE Item Response Time",
    subtitle = "", 
    x = "SCAFFOLD PHASE Item Response Time (minutes)", y = "TOTAL Scaled Score "
  ) + theme(legend.position = "blank")

#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( item_scaffold_NABS ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "SCAFFOLD (Scaled) Score by SCAFFOLD PHASE Item Response Time",
    subtitle = "", 
    x = "SCAFFOLD PHASE Item Response Time (minutes)", y = "SCAFFOLD Scaled Score "
  ) + theme(legend.position = "blank")

#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( item_test_NABS ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "TEST (Scaled) Score by SCAFFOLD PHASE Item Response Time",
    subtitle = "", 
    x = "SCAFFOLD PHASE Item Response Time (minutes)", y = "TEST Scaled Score "
  ) + theme(legend.position = "blank")

#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]
gf_jitter( item_test_NABS ~ item_avg_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% 
  gf_facet_wrap(~pretty_condition) + labs(
    title = "TEST (Scaled) Score by SCAFFOLD PHASE Item Response Time",
    subtitle = "", 
    x = "AVERAGE Item Response Time (minutes)", y = "TEST Scaled Score "
  ) + theme(legend.position = "blank")

#NOTE: LOG transforms of the RT do not yield linear relationships
```
#### Average Item RT by Accuracy

```{r}

q.stats <- df_items %>% filter(q != 6) %>% dplyr::group_by(q, pretty_condition, score_niceABS) %>% dplyr::summarise(
  m = mean(rt_s),
  sd = sd(rt_s),
  sd = tidyr::replace_na(sd,0),
  lo = m-sd/2,
  hi = m+sd/2,
  group = paste(pretty_condition,"-",score_niceABS)
)

gf_line( m ~ q, group = ~group,  color = ~as.factor(score_niceABS),data = q.stats) %>% 
  gf_point() %>% 
  gf_ribbon(lo+hi~q) %>% 
  gf_facet_wrap(~pretty_condition) + scale_color_manual(values=c("red","green")) + 
  labs(title = "Average Item Response Time by Absolute Score",
       subtitle = "Correct responses are generally faster [computational efficiency] except on Q1 [learning]",
       x = "Question", y = "Averate Item Response Time", color="Correct Response")


#GGDIST LINERIBBON
# df_items %>%
#   ggplot(aes(y = rt_s, x = q,  fill = pretty_condition)) +
#   stat_lineribbon(alpha = 1/4, point_interval = "mean_qi") + facet_wrap(~pretty_condition)
```


```{r}

q.stats <- df_items %>% filter(q %nin% c(6,9)) %>% dplyr::group_by(q, pretty_condition, interpretation) %>% dplyr::summarise(
  m = mean(rt_s),
  sd = sd(rt_s),
  sd = tidyr::replace_na(sd,0),
  lo = m-sd/2,
  hi = m+sd/2,
  group = paste(pretty_condition,"-",score_SCALED)
)

gf_line( m ~ as.factor(q), group = ~group,  color = ~interpretation,data = q.stats) %>% 
  gf_point() %>% 
  gf_ribbon(lo+hi~as.factor(q)) %>% 
  gf_facet_grid(interpretation~pretty_condition) + #+ scale_color_manual(values=c("red","green")) + 
  labs(title = "Average Item Response Time by Interpretation",
       subtitle = "Correct responses are generally faster [computational efficiency] except on Q1 [learning]",
       caption="NOTE: Points with no ribbon indicate singular response",
       x = "Question", y = "Averate Item Response Time", color="Interpretation")

#GGDIST LINERIBBON
df_items %>% filter(q %nin% c(6,9)) %>% mutate( interpretation = recode(interpretation, "reference" = "blank", "frenzy" = "?")) %>% 
  ggplot(aes(y = rt_s, x = q,  fill = interpretation)) +
  stat_lineribbon(alpha = 1/4, point_interval = "mean_qi") + 
  facet_grid(interpretation ~ pretty_condition) + 
  labs( title = "Average Response Time by Question Interpretation", x = "Question", y="Averate Item Response Time (s)")

```





## REPLICATION CHECK

### Data Collection Mode on Absolute Score

**Does Mode Change Effect of Condition on Score?**

To verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of ABSOLUTE SCORE for each condition, and examine whether data collection modality is a significant predictor of variance in absolute score

```{r}
#| label : MODEL-ABSCORE-BY-MODALITY

paste("Two Sample T-Test for S_ABS LAB vs. ONLINE control condition")
t.test(data = df_subjects %>% filter(condition == 111), s_ABS ~ mode )

paste("Two Sample T-Test for S_ABS LAB vs. ONLINE impasse condition")
t.test(data = df_subjects %>% filter(condition == 121), s_ABS ~ mode )

paste("OLS Linear Regression Predicting Absolute Score by Data Collection Mode")
summary(lm(data = df_subjects, formula = s_ABS ~ mode ))

```

Both t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative absolute score indicates that data collection mode is not a significant predictor, explaining only 0.01% of variance in absolute score, F(1,328) = 1.03, p \> 0.05.

::: callout-decision
**It is reasonable to infer that data from both in-person and remote studies arise from the same data generating process.**
:::

### Data Collection Mode on Cumulative Score

**Are the by-condition group means significantly different by data collection modality?**

To verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of SCALED SCORE for each condition.

```{r}
#| label : MODEL-SCALEDSCORE-BY-MODALITY

paste("Two Sample T-Test for s_SCALED LAB vs. ONLINE control condition")
t.test(data = df_subjects %>% filter(condition == 111), s_SCALED ~ mode )

paste("Two Sample T-Test for s_SCALED LAB vs. ONLINE impasse condition")
t.test(data = df_subjects %>% filter(condition == 121), s_SCALED ~ mode )

paste("OLS Linear Regression Predicting Scaled Score by Data Collection Mode")
summary(lm(data = df_subjects, formula = s_SCALED ~ mode ))

```

Both t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative scaled score indicates that data collection mode is not a significant predictor, explaining less than 0.001% of variance in absolute score, F(1,328) = 0.0078, p \> 0.05.

::: callout-decision
**It is reasonable to infer that data from both in-person and remote studies arise from the same data generating process.**
:::


## ARCHIVE

Sample ridgeplot code

```{r}

#RIDGEPLOT
# ggplot(data = df_subjects, aes(x = s_NABS, y = mode)) +
#   geom_density_ridges() + xlim(0,13)+
#   facet_wrap(~condition, labeller = label_both) +
# labs(x = "total number correct ",
# y = "proportion of subjects",
#        title = "Subject Cumulative Score (Absolute)",
#        subtitle = "Score distributions are comparable across modalities and different across conditions") +
#   theme_minimal()

```

### What Kind of Distribution is Total Score?

What kind of distribution is the Total Absolute Score (TEST Phase) data? We use the `fitdistrplus` package to compare the distribution of this variable to a variety of probability distribution families. First, we transform the \# correct items to % correct items by dividing it by the total number of items (n = 8).

```{r}
#| label: FIT-DIST-TOTAL-ABS-TEST

#describe the distribution
descdist(data = df_subjects$item_test_NABS/8, discrete = FALSE, boot = 1000)

print("FIT A NORMAL DISTRIBUTION")
normal_ = fitdist(df_subjects$item_test_NABS/8,"norm")
plot(normal_)

print("FIT A BETA DISTRIBUTION")
beta_ = fitdist(df_subjects$item_test_NABS/8,"beta", method="mme" )
plot(beta_)
summary(beta_)

```

Interpreting the Cullen and Frey graph, it *appears* that number percentage of correct responses per subject may follow a beta distribution (u-shape tpe). If we fit this variable using both a normal and beta distribution (using method of moments), it appears that the beta distribution provides a much better fit. The parameter estimates for the beta distribution are: shape1 = `r beta_$estimate[1]`, shape2 = `r beta_$estimate[2]`. The beta distribution is a flexible distribution insofar as it can model a wide range of shapes with its two parameters. TODO: HOW might this be applied to the total score data?

**Analysis Notes** - This distribution is very bimodal, so OLS linear regression estimating means may not be informative, as the mean actually falls near the location of the anitmode (least common value) - Should investigate log transform to see if residuals of LM will be normal (no) - Should investigate beta regression

### Whole Task Scores

##### Absolute Score

Total Scores that include *both* Scaffolding Phase as well as Test Phase performance.

```{r}
#| label: DESC-SUBJ-ABS
title = "Descriptive Statistics of Response Accuracy (Total Absolute Score)"
abs.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(s_NABS) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(s_NABS) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(s_NABS) %>% unlist() %>% favstats()
) 
abs.stats %>% kbl (caption = title) %>% kable_classic()

```

For *in person* collection, total absolute scores (n = `r abs.stats["lab",]$n`) range from `r round(abs.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(abs.stats["lab",]$mean,2)`, SD = `r round(abs.stats["lab",]$sd,2)`).

For *online replication*, (online) total absolute accuracy scores (n = `r abs.stats["online",]$n`) range from `r round(abs.stats["online",]$min,2)` to `r round(abs.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["online",]$mean,2)`, SD = `r round(abs.stats["online",]$sd,2)`).

When combined *overall*, total absolute accuracy scores (n = `r abs.stats["combined",]$n`) range from `r round(abs.stats["combined",]$min,2)` to `r round(abs.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(abs.stats["combined",]$mean,2)`, SD = `r round(abs.stats["combined",]$sd,2)`).

```{r}
#| label: VIS-SUBJ-ABS

#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE
  gf_props(~s_NABS, data = df_subjects) + 
  labs(x = "number of correct responses",
       y = "% of subjects",
       title = "Distribution of Task Absolute Score",
       subtitle = "Modes at high and low ends of scale suggest concentration of high (vs) low understanding") + 
  theme_minimal()


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "s_NABS", binwidth = 1,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE)
facet(p, facet.by=c("pretty_condition","pretty_mode")) +
  labs( title = "Distribution of Task Absolute Score (by Mode and Condition)",
        subtitle ="Pattern of response is the same across data collection modes but differs by condition",
        x = "Total Absolute Score", y = "number of subjects") +
  theme_minimal() + theme(legend.position = "blank")

##RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = s_NABS, fill = pretty_condition)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .15, 
    outlier.shape = NA
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter(
      seed = 1, width = .1
    )
  ) + labs(
    title = "Distribution of Task Absolute Score",
    x = "Condition", y = "Total Absolute Score"
  ) + theme_ggdist() + theme(legend.position = "blank")
# + coord_cartesian(xlim = c(1.2, NA), clip = "off")


#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION
ggplot(data = df_subjects, aes(s_NABS)) + 
  stat_ecdf(geom = "step") + 
  facet_grid(pretty_condition ~ pretty_mode) + 
  labs( title = "Empirical Cumulative Density Function — Task Absolute Score",
        x = "Task Absolute Score [0,13]", 
        y = "Cumulative Probability") + theme_minimal()
  
```

Visual inspection of this distribution suggests it is not normal, and likely bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018). TODO REFERENCE

```{r}
#| label: CHECK-SUBJ-ABS

multimode::modetest(df_subjects$s_NABS)
n_modes = multimode::nmodes(df_subjects$s_NABS, bw=2) #bw = 2questions/15 = 0.15%
l_modes = multimode::locmodes(df_subjects$s_NABS,mod0 =  n_modes, display = TRUE)
```

The excess mass test for multimodality suggests the distribution is infact multimodal (m = 0.1, p \< 0.001), with two identifiable modes at `r l_modes$location[1]` and `r l_modes$location[3]`, and an antimode at `r l_modes$location[2]`.

::: callout-note
**Condition appears (through visual inspection) to yield a positive influence on Total Absolute Score (across the entire task), across data collection modalities.**
:::

##### Scaled Score

```{r}
#| label: DESC-SUBJ-SCALED

title = "Descriptive Statistics of Response Accuracy (Total Scaled Score)"
scaled.stats <- rbind(
  "lab"= df_lab %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats(),
  "online" = df_online %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats(),
  "combined" = df_subjects %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats()
) 
scaled.stats %>% kbl (caption = title) %>% kable_classic()

```

For **in person collection**, total scaled scores (n = `r scaled.stats["lab",]$n`) range from `r round(scaled.stats["lab",]$min,2)` to `r round(abs.stats["lab",]$max,2)` with a mean score of (M = `r round(scaled.stats["lab",]$mean,2)`, SD = `r round(scaled.stats["lab",]$sd,2)`).

For **online replication**, total scaled scores (n = `r scaled.stats["online",]$n`) range from `r round(scaled.stats["online",]$min,2)` to `r round(scaled.stats["online",]$max,2)` with a slightly lower mean score of (M = `r round(scaled.stats["online",]$mean,2)`, SD = `r round(scaled.stats["online",]$sd,2)`).

When combined **overall**, total scaled scores (n = `r scaled.stats["combined",]$n`) range from `r round(scaled.stats["combined",]$min,2)` to `r round(scaled.stats["combined",]$max,2)` with a slightly lower mean score of (M = `r round(scaled.stats["combined",]$mean,2)`, SD = `r round(scaled.stats["combined",]$sd,2)`).

```{r}
#| label: VIS-SUBJ-SCALED

#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL SCALED
gf_props(~s_SCALED, data = df_subjects) +
  labs(x = "total scaled score",
       y = "% of subjects",
       title = "Distribution of Total Scaled Score",
       subtitle = "Modes at high and low ends of scale suggest concentration of high (vs) low understanding") + 
  theme_minimal()


##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE
p <- gghistogram(df_subjects, x = "s_SCALED",binwidth=1,
   add = "mean", rug = TRUE,
   fill = "pretty_condition", #, palette = c("#00AFBB", "#E7B800"),
   add_density = TRUE) 
facet(p, facet.by=c("pretty_condition","pretty_mode")) + 
  labs( title = "Distribution of Total Scaled Score (by Condition and Mode)",
        subtitle ="Pattern of response is similar across data collection modes but differs by condition",
        x = "total scaled score", y = "number of participants") + 
  theme_minimal() + theme(legend.position = "blank") 

##RAINCLOUD USING GGDISTR
ggplot(df_subjects, aes(x = pretty_condition, y = s_SCALED, fill = pretty_condition)) + 
  ggdist::stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA) + 
  geom_boxplot(
    width = .15, 
    outlier.shape = NA
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter(
      seed = 1, width = .1
    )
  ) + labs(
    title = "Distribution of Task Scaled Score ",
    x = "Condition", y = "Total Scaled Score"
  ) + theme_ggdist() + theme(legend.position = "blank")
# + coord_cartesian(xlim = c(1.2, NA), clip = "off")

#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION
ggplot(data = df_subjects, aes(s_SCALED)) + 
  stat_ecdf(geom = "step") + 
  facet_grid(pretty_condition ~ pretty_mode) + 
  labs( title = "Empirical Cumulative Density Function — Task Scaled Score",
        x = "Task Scaled Score [-13, 13]", 
        y = "Cumulative Probability") + theme_minimal()

```

Visual inspection of this distribution suggests it is not normal, and perhaps perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).

```{r}
#| label: CHECK-SUBJ-SCALED

multimode::modetest(df_subjects$s_SCALED)
n_modes = multimode::nmodes(df_subjects$s_SCALED, bw=2) #bw = 2questions/15 = 0.15%
l_modes = multimode::locmodes(df_subjects$s_SCALED,mod0 =  n_modes, display = TRUE)
```

The excess mass test for multimodality suggests the distribution is in fact multimodal (m = 0.1, p \< 0.001), with two identifiable modes at `r l_modes$location[1]` and `r l_modes$location[3]`, and an antimode at `r l_modes$location[2]`.

**Analysis Notes** - As with absolute score, the distribution of scaled score is very bimodal - Same need to investigate transformations and alternative distributions for regression

::: callout-note
**Condition appears (through visual inspection) to yield a positive influence on Total Scaled Score across data collection modalities.**
:::

### Item Level Scores

#### Item Absolute Score

Whole Task Accuracy summarized over items rather than subjects

```{r}

x <- df_items %>% mutate(score = as.logical(score_ABS))

title = "Proportion of Correct Items By Condition (Lab)"

item.contingency <- df_items %>% filter(mode == "lab-synch") %>% dplyr::select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

title = "Proportion of Correct Items By Condition (Online)"
item.contingency <- df_items %>% filter(mode == "asynch") %>% dplyr::select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()
item.contingency %>% kbl (caption = title) %>% kable_classic()

```

```{r}

#VISUALIZE distribution of response accuracy across ITEMS

#HISTOGRAM
stats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_niceABS))
gf_props(~score_niceABS, data = df_items) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) +
  labs(x = "Item Absolute Score",
       title = "Item Absolute Score",
       subtitle="Across modalities, the impasse condition yielded more correct responses")+
  theme_minimal()

```

#### Item Scaled Score

At the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1.

```{r}

title = "Descriptive Statistics of Item Response Accuracy (Scaled Score)"
scaled.stats.items <- rbind(
  "lab"= df_items %>% filter(mode == 'lab-synch') %>% dplyr::select(score_SCALED) %>% unlist() %>% favstats(),
  "online" = df_items %>% filter(mode == "asynch") %>% dplyr::select(score_SCALED) %>% unlist() %>% favstats()
) 
scaled.stats.items %>% kbl (caption = title) %>% kable_classic()

```

```{r}

#VISUALIZE distribution of response accuracy across ITEMS

#HISTOGRAM
stats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_SCALED))
gf_props(~score_SCALED, data = df_items) %>% 
  gf_facet_grid(condition~mode, labeller = label_both) %>% 
  gf_vline(data = stats, xintercept = ~mean, color = "red") +
  labs(x = "Scaled Score for Item",
       y = "Proportion of Items",
       title = "Distribution of Accuracy per Item (Scale Score)",
       subtitle="The impasse condition shifts density toward the positive score")+
  theme_minimal()

```


## RESOURCES

-   https://rpkgs.datanovia.com/ggpubr/reference/index.html
-   Appropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/)]{style="color: red;"}.
-   Especially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data



```{r}
#| label: session
sessionInfo()
```