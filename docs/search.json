[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SGC-X",
    "section": "",
    "text": "Study SGC2 | Description\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC2 | Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC3A | (Lab) Hypothesis Testing\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC3A | (OSPAN) Hypothesis Testing\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC3A | (Relication) Hypothesis Testing\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC3A | 2 Response Scoring\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC3A | 3 Description\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC3A | Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC4A | 1 Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC4A | 2 Response Scoring\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC4A | 3 Description\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC4B | 1 Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC4B | 2 Response Scoring\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC4C | 1 Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC4C | 2 Response Scoring\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy SGC5A | 1 Introduction\n\n\n\n\n\n\n\n\n\n \n\n\n\nStudy SGC5A | 2 Response Scoring\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "analysis/SGC2/1_sgc2_introduction.html",
    "href": "analysis/SGC2/1_sgc2_introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "In Study Two we examine if scaffolding is effective in aiding untrained students to understand the Triangular Model (TM) graph. We know that students are unlikely to construct the correct interpretation of the TM without assistance. Guided by the results of the Study One Design Task, we created four scaffolds. We test the effectiveness of these scaffolds by seeking to replicate the Qiang et.al (2014) finding that after 20 minutes of video training, students perform faster and more accurately with the unconventional TM than the conventional Linear Model (LM). Will our participants show similar performance on the TM with scaffolds rather than formal instruction? Further, will engagement with the TM in a reading task be sufficient for students to reproduce the graph in a subsequent drawing task?\nTo try the study yourself: http://morning-gorge-17056.herokuapp.com/\nEnter “github” as your session code, and number of the condition you wish to test\n0 = control (no-scaffold), 1 = “what-text”, 2 = “how-text”, 3 = “static-image”, 4 = “interactive-image”"
  },
  {
    "objectID": "analysis/SGC2/1_sgc2_introduction.html#methods",
    "href": "analysis/SGC2/1_sgc2_introduction.html#methods",
    "title": "1  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a 5 (scaffold: none-control, what-text, how-text, static image, interactive image) x 2 (graph: LM, TM) mixed design, with scaffold as a between-subjects variable and graph as a within-subject variable. To test our hypothesis that exposure to the conventional LM acts as a scaffold for the TM, we counterbalanced the order of graph-reading tasks (order: LM-first, TM-first). For each task we measured response accuracy and time. For the follow-up graph-drawing task, a team of raters coded the type of graph produced by each participant.\n\n\n\nMaterials\n\nScaffolds\nFor the first five questions of each graph-reading task, participants saw their assigned scaffold along with the designated graph. On the following ten questions, the scaffold was not present. Examples of each scaffold-condition for the TM and LM graphs are shown in the table above.\n\n\nThe Graph Drawing Task\nIn the  graph drawing task participants were given a sheet of isometric dot paper and a table containing a set of 10 time intervals. Isometric dot paper equally supports the construction of lines at 0, 45 and 90 degrees, thus minimizing any biasing effects of the paper on the type of graph the participants chose to draw. Participants were directed to draw a triangular graph of the data (“like the triangle graph you saw in the previous task”), using the pencil, eraser and ruler provided.\n \n\n\n\nProcedure\nParticipants completed the study individually in a computer lab. Each participant was randomly assigned to one of five conditions which determined what additional information (scaffold) they received while solving the first five problems with each graph: no-scaffold (control), ‘what’ text, ‘how’-text, static-image, and interactive-image. After a short introduction they continued to the first of two graph reading tasks (graph order counterbalanced). After completing the first graph reading task, they were introduced to the second scenario, and completed the second graph reading task with the remaining graph. Finally, participants completed the graph drawing task. They finished the study by completing a short demographic survey, and reading the debriefing text. The runtime of the entire study ranged from 20 to 60 minutes.\n\n\nSample\nData was collected by convenience sample of a university subject pool. Data were collected in the Spring of 2017 with, in-person, with large groups of students simultaneously completing the study (independently) in a computer lab."
  },
  {
    "objectID": "analysis/SGC2/1_sgc2_introduction.html#analysis",
    "href": "analysis/SGC2/1_sgc2_introduction.html#analysis",
    "title": "1  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\nnote: Unlike studies SGC3 and onwards, scoring for SGC2 is already included in the raw data files.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(mbp)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC2/data/2-scored-data/sgc2_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC2/data/2-scored-data/sgc2_items.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \nrio::export(df_subjects, \"analysis/SGC2/data/2-scored-data/sgc2_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC2/data/2-scored-data/sgc2_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC2/1_sgc2_introduction.html#resources",
    "href": "analysis/SGC2/1_sgc2_introduction.html#resources",
    "title": "1  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9      purrr_0.3.4     \n [5] readr_2.1.2      tidyr_1.2.0      tibble_3.1.7     tidyverse_1.3.1 \n [9] Hmisc_4.7-0      ggplot2_3.3.6    Formula_1.2-4    survival_3.3-1  \n[13] lattice_0.20-45  kableExtra_1.3.4 codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] fs_1.5.2            lubridate_1.8.0     bit64_4.0.5        \n [4] webshot_0.5.3       RColorBrewer_1.1-3  httr_1.4.3         \n [7] tools_4.2.1         backports_1.4.1     utf8_1.2.2         \n[10] R6_2.5.1            rpart_4.1.16        DBI_1.1.3          \n[13] colorspace_2.0-3    nnet_7.3-17         withr_2.5.0        \n[16] tidyselect_1.1.2    gridExtra_2.3       bit_4.0.4          \n[19] curl_4.3.2          compiler_4.2.1      cli_3.3.0          \n[22] rvest_1.0.2         htmlTable_2.4.0     xml2_1.3.3         \n[25] scales_1.2.0        checkmate_2.1.0     systemfonts_1.0.4  \n[28] digest_0.6.29       foreign_0.8-82      rmarkdown_2.14     \n[31] svglite_2.1.0       rio_0.5.29          base64enc_0.1-3    \n[34] jpeg_0.1-9          pkgconfig_2.0.3     htmltools_0.5.2    \n[37] labelled_2.9.1      dbplyr_2.2.1        fastmap_1.1.0      \n[40] highr_0.9           htmlwidgets_1.5.4   rlang_1.0.3        \n[43] readxl_1.4.0        rstudioapi_0.13     generics_0.1.2     \n[46] jsonlite_1.8.0      vroom_1.5.7         zip_2.2.0          \n[49] magrittr_2.0.3      Matrix_1.4-1        Rcpp_1.0.8.3       \n[52] munsell_0.5.0       fansi_1.0.3         lifecycle_1.0.1    \n[55] stringi_1.7.6       yaml_2.3.5          grid_4.2.1         \n[58] parallel_4.2.1      crayon_1.5.1        haven_2.5.0        \n[61] splines_4.2.1       hms_1.1.1           knitr_1.39         \n[64] pillar_1.7.0        reprex_2.0.1        glue_1.6.2         \n[67] evaluate_0.15       latticeExtra_0.6-29 data.table_1.14.2  \n[70] modelr_0.1.8        png_0.1-7           vctrs_0.4.1        \n[73] tzdb_0.3.0          cellranger_1.1.0    gtable_0.3.0       \n[76] assertthat_0.2.1    xfun_0.31           openxlsx_4.2.5     \n[79] broom_0.8.0         viridisLite_0.4.0   cluster_2.1.3      \n[82] ellipsis_0.3.2"
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html",
    "href": "analysis/SGC2/3_sgc2_description.html",
    "title": "2  Description",
    "section": "",
    "text": "The purpose of this notebook is describe the distributions of dependent variables for Study SGC2."
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#sample",
    "href": "analysis/SGC2/3_sgc2_description.html#sample",
    "title": "2  Description",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData was initially collected (in person, SONA groups in computer lab) in Spring 2017.\n\n\nCODE\ntitle = \"Participants by Condition and (counterbalanced) Task-order\"\ncols = c(\"Control\",\"Text[what]\",\"Text[how]\",\"Image[static]\", \"Image[ixv]\",\"Total\")\ncont <- table(df_subjects$order, df_subjects$pretty_condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and (counterbalanced) Task-order\n \n  \n      \n    Control \n    Text[what] \n    Text[how] \n    Image[static] \n    Image[ixv] \n    Total \n  \n \n\n  \n    LM-First \n    29 \n    31 \n    30 \n    30 \n    34 \n    154 \n  \n  \n    TM-First \n    32 \n    28 \n    36 \n    32 \n    34 \n    162 \n  \n  \n    Sum \n    61 \n    59 \n    66 \n    62 \n    68 \n    316 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <- df_subjects %>% dplyr::select(AGE) %>% unlist() %>% favstats() \n\nsubject.stats$percent.female <- df_subjects %>% filter(GENDER==\"Female\") %>% count() %>% pull()/nrow(df_subjects)\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.female \n  \n \n\n  \n     \n    17 \n    19 \n    20 \n    21 \n    33 \n    20.5 \n    2.2 \n    316 \n    0 \n    0.69 \n  \n\n\nNote:   Age in Years\n\n\n\n\nFor in person data collection 316 participants (69 % female ) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 17 - 33 years)."
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#response-accuracy",
    "href": "analysis/SGC2/3_sgc2_description.html#response-accuracy",
    "title": "2  Description",
    "section": "RESPONSE ACCURACY",
    "text": "RESPONSE ACCURACY\n\nBlock Scores\nSubject level scores summarize the the response accuracy by a particular participant across all blocks of the two graph comprehension tasks. The task score refers to the number of questions correct (absolute scoring) in each block (linear graph, triangular graph) of the graph comprehension task.\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy by Block (Total Absolute Score)\"\nabs.stats <- rbind(\n  \"linear.block\"= df_subjects %>% dplyr::select(linear_score) %>% unlist() %>% favstats(),\n  \"triangular.block\" = df_subjects %>% dplyr::select(triangular_score) %>% unlist() %>% favstats(),\n  \"block.differences\" = df_subjects %>% dplyr::select(score_diff) %>% unlist() %>% favstats(),\n  \"total\" = df_subjects %>% dplyr::select(totalScore) %>% unlist() %>% favstats()\n)\n\nabs.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"block # questions correct [0,15]; DIFF = triangular - linear\",\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nDescriptive Statistics of Response Accuracy by Block (Total Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    linear.block \n    2 \n    10 \n    11 \n    13 \n    15 \n    10.95 \n    2.13 \n    316 \n    0 \n  \n  \n    triangular.block \n    0 \n    5 \n    10 \n    12 \n    15 \n    8.77 \n    4.45 \n    316 \n    0 \n  \n  \n    block.differences \n    -13 \n    -5 \n    -1 \n    1 \n    5 \n    -2.18 \n    4.11 \n    316 \n    0 \n  \n  \n    total \n    6 \n    16 \n    22 \n    26 \n    31 \n    20.98 \n    6.00 \n    316 \n    0 \n  \n\n\nNote:   block # questions correct [0,15]; DIFF = triangular - linear\n\n\n\n\nTotal absolute scores for the LINEAR graph (n = 316) range from 2 to 15 with a mean score of (M = 10.95, SD = 2.13).\nTotal absolute scores for the TRIANGULAR graph (n = 316) range from 0 to 15 with a mean score of (M = 8.77, SD = 4.45).\nTotal absolute scores across the ENTIRE TASK (n = 316) range from 6 to 31 with a mean score of (M = 20.98, SD = 6).\nDifference scores (difference between TRIANGULAR and LINEAR) scores for each participant (n = 316) range from -13 to 5 with a mean score of (M = -2.18, SD = 4.11). (note: negative difference scores indicate the participant performed better on the linear block than the triangular block.)\n\nBy Block\n\n\nCODE\n#DATA SETUP\nlong_scores <- df_subjects %>% dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios,linear_score, triangular_score) %>% pivot_longer(\n  cols = ends_with(\"score\"),\n  names_to = \"graph\",\n  values_to = \"score\"\n)\n\n#DISTRIBUTION OF SCORES BY GRAPH\nstats <- favstats(score~graph, data = long_scores)\ngf_dhistogram(~score, fill = ~graph, binwidth = 0.5,data = long_scores) %>%\n  gf_vline(xintercept = ~mean, color = ~graph, data = stats) %>%\n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(~ graph) +\n  labs( title = \"Distribution of Score (by Block)\",\n        subtitle =\"Performance on Linear Graph is better than Triangular\",\n        x = \"Block Score (# correct)\", y = \"proportion of subjects\") +\n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_scores, aes(x = graph, y = score,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of Score (by Block) \",\n    x = \"Condition\", y = \"Score (# correct)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nTODO explore interactions ::: {.cell}\n\nCODE\n# \n# \n# library(interactions)\nm = lm(score ~ graph + pretty_condition + order + tm_scenarios, data = long_scores)\nm2 = lm(score ~ graph * pretty_condition * order * tm_scenarios, data = long_scores)\n# \n# cat_plot(model = m, pred = graph, modx = order, mod2 = pretty_condition,\n#          INT.TYPE = \"confidence\", int.width = 0.95,\n#          rug = TRUE)\n# \n# cat_plot(model = m2, pred = graph, modx = tm_scenarios, mod2 = pretty_condition,\n#          INT.TYPE = \"confidence\", int.width = 0.95,\n#          rug = TRUE)\n# \n# # cat_plot(model = m, pred = graph, modx = tm_scenarios, mod2 = pretty_condition,\n# #          INT.TYPE = \"confidence\", int.width = 0.95,\n# #          rug = TRUE)\n\n:::\n\n\nBy Condition\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\nstats <- favstats(score ~ pretty_condition+graph, data = long_scores)\ngf_dhistogram(~score, fill = ~pretty_condition, binwidth = 0.5,data = long_scores) %>% \n  gf_dens(color = ~pretty_condition) %>%  \n  # gf_vline(xintercept = ~mean, data = stats) %>% \n  gf_facet_grid(pretty_condition ~ graph) +\n  labs( title = \"Distribution of Score (by Condition)\",\n        subtitle =\"\",\n        x = \"Block Score (# correct)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_scores, aes(x = graph, y = score,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~pretty_condition) + labs( \n    title = \"Distribution of Score (by Condition) \",\n    x = \"Condition\", y = \"Score (# correct)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nBy Order\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~score, fill = ~graph, binwidth = 0.5,data = long_scores) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~order) +\n  labs( title = \"Distribution of Score (by Order)\",\n        subtitle =\"\",\n        x = \"Block Score (# correct)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_scores, aes(x = graph, y = score,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~order) + labs( \n    title = \"Distribution of Score (by Order)\",\n    x = \"Graph\", y = \"Score (# correct)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nBy Scenario\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~score, fill = ~graph, binwidth = 0.5,data = long_scores) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~tm_scenarios) +\n  labs( title = \"Distribution of Score (by Scenario)\",\n        subtitle =\"\",\n        x = \"Block Score (# correct)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_scores, aes(x = graph, y = score,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = score, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~tm_scenarios) + labs( \n    title = \"Distribution of Score (by Scenario) \",\n    x = \"Graph\", y = \"Score (# correct)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\n\nBlock Difference Scores\n\n\nCODE\n#DIFFERENCE SCORE BY SUBJECT\ngf_line(score~graph, group=~subject, color = ~order, data = long_scores) %>% \n  gf_facet_grid(order~pretty_condition) + \n  labs(title = \"Block Scores by Condition\") + easy_remove_legend()\n\n\n\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~score_diff, fill = ~pretty_condition, binwidth = 0.5,data = df_subjects) %>% \n  # gf_dens(color = ~graph) %>%  \n  gf_facet_grid(order~pretty_condition) +\n  labs( title = \"Block Difference Score (by Condition)\",\n        subtitle =\"\",\n        x = \"Difference Score (Triangular - Linear)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\n\n\nItem Scores\nTask Accuracy summarized over items rather than subjects\n\n\nCODE\ndf <- df_items %>% filter(graph %in% c(\"linear\",\"triangular\"))\n\n#VISUALIZE distribution of response accuracy across ITEMS\n\n#HISTOGRAM by Condition\n# gf_props(~correct, data = df) %>% \n#   gf_facet_grid(pretty_condition~graph, labeller = label_both) +\n#   labs(x = \"Item Accuracy\",\n#        title = \"Item Accuracy by Graph and Condition\",\n#        subtitle=\"\")\n\n#STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = graph,\n                       fill = score)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_condition) +\n   labs(y = \"Proportion of Items\",\n       title = \"Item Accuracy by Graph and Condition\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#HISTOGRAM\n# gf_props(~correct, data = df) %>% \n#   gf_facet_grid(scenario~graph, labeller = label_both) +\n#   labs(x = \"Item Accuracy\",\n#        title = \"Item Accuracy by Graph and (TM Graph) Scenario\",\n#        subtitle=\"\")\n\n#STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = graph,\n                       fill = score)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~scenario) +\n   labs(y = \"Proportion of Items\",\n       title = \"Item Accuracy by Graph and (TM Graph) Scenario\",\n       x = \"TM Graph Scenario\",\n       fill = \"\",\n       subtitle=\"If the scenarios are of equal difficulty, these should be the same\")\n\n\n\n\n\nCODE\n#HISTOGRAM\n# gf_props(~correct, data = df) %>% \n#   gf_facet_grid(order~graph, labeller = label_both) +\n#   labs(x = \"Item Accuracy\",\n#        title = \"Item Accuracy by Graph and Block Order\",\n#        subtitle=\"\")\n\n#STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = graph,\n                       fill = score)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~order) +\n   labs(y = \"Proportion of Items\",\n       title = \"Item Accuracy by Graph and Block Order\",\n       x = \"Block Order\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = graph,\n                       fill = score)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs( \n     #y = \"Proportion of Items\",\n       title = \"Item Accuracy by Graph and Question Number\",\n       x = \"Question Number\",\n       fill = \"\",\n       subtitle=\"\")"
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#response-latency",
    "href": "analysis/SGC2/3_sgc2_description.html#response-latency",
    "title": "2  Description",
    "section": "RESPONSE LATENCY",
    "text": "RESPONSE LATENCY\n\nTime on Block\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Time by Block\"\ntime.stats <- rbind(\n  \"linear.block\"= df_subjects %>% dplyr::select(LM_T_M) %>% unlist() %>% favstats(),\n  \"triangular.block\" = df_subjects %>% dplyr::select(TM_T_M) %>% unlist() %>% favstats(),\n  \"block.differences\" = df_subjects %>% dplyr::select(DIFF_T_M) %>% unlist() %>% favstats(),\n  \"total\" = df_subjects %>% dplyr::select(TOTAL_T_M) %>% unlist() %>% favstats()\n)\n\ntime.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"time in minutes; DIFF = triangular - linear\",\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nDescriptive Statistics of Response Time by Block\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    linear.block \n    3.92 \n    7.63 \n    8.87 \n    10.440 \n    23.1 \n    9.20 \n    2.53 \n    316 \n    0 \n  \n  \n    triangular.block \n    3.14 \n    8.82 \n    10.40 \n    12.502 \n    26.8 \n    10.85 \n    3.28 \n    316 \n    0 \n  \n  \n    block.differences \n    -12.66 \n    -3.15 \n    -1.42 \n    0.472 \n    12.9 \n    -1.64 \n    3.09 \n    316 \n    0 \n  \n  \n    total \n    21.91 \n    34.66 \n    39.66 \n    45.853 \n    66.1 \n    40.42 \n    8.54 \n    316 \n    0 \n  \n\n\nNote:   time in minutes; DIFF = triangular - linear\n\n\n\n\nResponse time (in minutes) for the LINEAR graph (n = 316) range from 3.92 to 23.06 with a mean time of (M = 9.2, SD = 2.53).\nResponse time (in minutes) for the TRIANGULAR graph (n = 316) range from 3.14 to 26.82 with a mean time of (M = 10.85, SD = 3.28).\nResponse time (in minutes) across the ENTIRE TASK (n = 316) range from 21.91 to 66.12 with a mean time of (M = 40.42, SD = 8.54).\nDifference in response time (in minutes) (difference between TRIANGULAR - LINEAR) for each participant (n = 316) range from -12.66 to 12.95 with a mean difference in time of (M = -1.64, SD = 3.09). (note: negative difference scores indicate the participant performed faster on the linear block than the triangular block.)\n\n\nCODE\n#DATA SETUP\nlong_times <- df_subjects %>% dplyr::select(subject,pretty_condition,order,lm_scenarios,tm_scenarios, LM_T_M, TM_T_M) %>% pivot_longer(\n  cols = ends_with(\"M\"),\n  names_to = \"graph\",\n  values_to = \"time\") %>% mutate(\n    graph = recode(graph, \"LM_T_M\" = \"Linear Graph\", \"TM_T_M\" = \"Triangular Graph\")\n  )\n\n#DISTRIBUTION OF SCORES BY GRAPH\nstats <- favstats(time~graph, data = long_times)\ngf_dhistogram(~time, fill = ~graph, binwidth = 0.5,data = long_times) %>%\n  gf_vline(xintercept = ~mean, color = ~graph, data = stats) %>%\n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(~ graph) +\n  labs( title = \"Distribution of Response Time\",\n        subtitle =\"Performance on Linear Graph is faster than Triangular\",\n        x = \"Block Score (# correct)\", y = \"number of subjects\") +\n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_times, aes(x = graph, y = time,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of Response Time by Graph \",\n    x = \"Condition\", y = \"Response Time (minutes)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF TIME BY GRAPH\nstats <- favstats(time ~ pretty_condition+graph, data = long_times)\ngf_dhistogram(~time, fill = ~pretty_condition, binwidth = 0.5,data = long_times) %>% \n  gf_dens(color = ~pretty_condition) %>%  \n  gf_facet_grid(pretty_condition ~ graph) +\n  labs( title = \"Distribution of Response Time (by Condition)\",\n        subtitle =\"\",\n        x = \"Response Time (minutes)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_times, aes(x = graph, y = time,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~pretty_condition) + labs( \n    title = \"Distribution of Response Time by Graph \",\n    x = \"Condition\", y = \"Response Time (minutes)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF TIMES BY GRAPH\ngf_dhistogram(~time, fill = ~graph, binwidth = 0.5,data = long_times) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~order) +\n  labs( title = \"Distribution of Response Time (by Order)\",\n        subtitle =\"\",\n        x = \"Response Time (minutes)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_times, aes(x = graph, y = time,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~order) + labs( \n    title = \"Distribution of Response Time (by Order)\",\n    x = \"\", y = \"Response Time (minutes)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~time, fill = ~graph, binwidth = 0.5,data = long_times) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~tm_scenarios) +\n  labs( title = \"Distribution of Response Time (by Scenario)\",\n        subtitle =\"\",\n        x = \"Response Time (minutes)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(long_times, aes(x = graph, y = time,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = time, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~tm_scenarios) + labs( \n    title = \"Distribution of Response Time (by Scenario) \",\n    x = \"TM Scenario\", y = \"Respone Time (minutes)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DIFFERENCE TIME BY SUBJECT\ngf_line(time~graph, group=~subject, color = ~order, data = long_times) %>% \n  gf_facet_grid(order~pretty_condition) + \n  labs(title = \"Response Times by Condition\") + easy_remove_legend()\n\n\n\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~DIFF_T_M, fill = ~pretty_condition, binwidth = 0.5,data = df_subjects) %>% \n  # gf_dens(color = ~graph) %>%  \n  gf_facet_grid(order~pretty_condition) +\n  labs( title = \"Block Time Difference (by Condition)\",\n        subtitle =\"\",\n        x = \"Difference Time (Triangular - Linear)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\n\n\nTime on Item\n\n\nCODE\ntitle = \"Descriptive Statistics of Item Response Time by Block\"\ntime.stats <- rbind(\n  \"linear.block\"= df_items %>% filter(graph == \"linear\") %>% dplyr::select(rt_sec) %>% unlist() %>% favstats(),\n  \"triangular.block\" = df_items %>%  filter(graph == \"triangular\") %>% dplyr::select(rt_sec) %>% unlist() %>% favstats()\n)\n\ntime.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"time in minutes; DIFF = triangular - linear\",\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nDescriptive Statistics of Item Response Time by Block\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    linear.block \n    4 \n    21 \n    31 \n    45 \n    302 \n    36.8 \n    24.2 \n    4740 \n    0 \n  \n  \n    triangular.block \n    2 \n    23 \n    36 \n    55 \n    401 \n    43.4 \n    30.8 \n    4739 \n    0 \n  \n\n\nNote:   time in minutes; DIFF = triangular - linear\n\n\n\n\nItem Response time (in seconds) for the LINEAR graph (n = 4740) range from 4 to 302 with a mean time of (M = 36.81, SD = 24.21).\nItem Response time (in seconds) for the TRIANGULAR graph (n = 4739) range from 2 to 401 with a mean time of (M = 43.38, SD = 30.83).\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\nstats <- favstats(rt_sec~graph, data = df)\ngf_dhistogram(~rt_sec, fill = ~graph, binwidth = 0.5,data = df) %>%\n  gf_vline(xintercept = ~mean, color = ~graph, data = stats) %>%\n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(~ graph) +\n  labs( title = \"Distribution of Response Time\",\n        subtitle =\"Performance on Linear Graph is faster than Triangular\",\n        x = \"Block Score (# correct)\", y = \"number of subjects\") +\n  easy_remove_legend()\n\n\nWarning: Removed 1 rows containing missing values (geom_vline).\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = graph, y = rt_sec,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec, color = graph),\n    size = 1.3,\n    alpha = .05,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of Item Response Time by Graph \",\n    x = \"Condition\", y = \"Response Time (seconds)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF TIME BY GRAPH\nstats <- favstats(rt_sec ~ pretty_condition+graph, data = df)\ngf_dhistogram(~rt_sec, fill = ~pretty_condition, binwidth = 0.5,data = df) %>% \n  gf_dens(color = ~pretty_condition) %>%  \n  gf_facet_grid(pretty_condition ~ graph) +\n  labs( title = \"Distribution of Item Response Time (by Condition)\",\n        subtitle =\"\",\n        x = \"Response Time (seconds)\", y = \"proportion of items\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = graph, y = rt_sec,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~pretty_condition) + labs( \n    title = \"Distribution of Item Response Time by Graph \",\n    x = \"Condition\", y = \"Response Time (seconds)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF TIMES BY GRAPH\ngf_dhistogram(~rt_sec, fill = ~graph, binwidth = 0.5,data = df) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~order) +\n  labs( title = \"Distribution of Item Response Time (by Order)\",\n        subtitle =\"\",\n        x = \"Item Response Time (sec)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = graph, y = rt_sec,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~order) + labs( \n    title = \"Distribution of Item Response Time (by Order)\",\n    x = \"\", y = \"Response Time (seconds)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\n\n\nCODE\n#DISTRIBUTION OF SCORES BY GRAPH\ngf_dhistogram(~rt_sec, fill = ~graph, binwidth = 0.5,data = df) %>% \n  gf_dens(color = ~graph) %>%  \n  gf_facet_grid(graph~scenario) +\n  labs( title = \"Distribution of Item Response Time (by Scenario)\",\n        subtitle =\"\",\n        x = \"Response Time (seconds)\", y = \"number of subjects\") + \n  easy_remove_legend()\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df, aes(x = graph, y = rt_sec,\n                        fill = graph) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=graph, y = rt_sec, color = graph),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + \n  facet_wrap(~scenario) + labs( \n    title = \"Distribution of Item Response Time (by Scenario) \",\n    x = \"TM Scenario\", y = \"Item Response Time (seconds)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")"
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#drawing-task",
    "href": "analysis/SGC2/3_sgc2_description.html#drawing-task",
    "title": "2  Description",
    "section": "DRAWING TASK",
    "text": "DRAWING TASK\nFinally, we explore the distribution of graph types produced by participants during the graph drawing task.\n\n\nCODE\ngf_props(~draw_type, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Type of Graph drawn by Participant\"\n  )"
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#exploring-relationships",
    "href": "analysis/SGC2/3_sgc2_description.html#exploring-relationships",
    "title": "2  Description",
    "section": "EXPLORING RELATIONSHIPS",
    "text": "EXPLORING RELATIONSHIPS\n\nBlock Accuracy\n\n\nCODE\n#SCATTERPLOT \ngf_jitter( linear_score ~ triangular_score, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Relationship between Linear and Triangular Block Scores\",\n    subtitle = \"\", \n    x = \"Linear Score\", y = \"Triangular Score\"\n  ) + easy_remove_legend()\n\n\n\n\n\n\n\nTime + Accuracy\n\n\nCODE\nq.stats <- df %>%  dplyr::group_by(graph, q, pretty_condition, score) %>% dplyr::summarise(\n  m = mean(rt_sec),\n  sd = sd(rt_sec),\n  sd = tidyr::replace_na(sd,0),\n  lo = m-sd/2,\n  hi = m+sd/2,\n  group = paste(pretty_condition,\"-\",score)\n)\n\ngf_line( m ~ q, group = ~group,  color = ~score, data = q.stats) %>% \n  gf_point() %>% \n  gf_ribbon(lo+hi~q) %>% \n  gf_facet_grid(graph~pretty_condition) + scale_color_manual(values=c(\"red\",\"green\")) + \n  labs(title = \"Average Item Response Time by Absolute Score\",\n       subtitle = \"\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Correct Response\")\n\n\n\n\n\nCODE\n#GGDIST LINERIBBON\ndf %>%\n  ggplot(aes(y = rt_sec, x = q,  fill = pretty_condition)) +\n  stat_lineribbon(alpha = 1/4, point_interval = \"mean_qi\") + facet_grid(graph~pretty_condition)+labs(title = \"Average Item Response Time by Absolute Score\",\n       subtitle = \"\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Correct Response\")"
  },
  {
    "objectID": "analysis/SGC2/3_sgc2_description.html#resources",
    "href": "analysis/SGC2/3_sgc2_description.html#resources",
    "title": "2  Description",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] forcats_0.5.1      stringr_1.4.0      purrr_0.3.4        readr_2.1.2       \n [5] tidyr_1.2.0        tibble_3.1.7       tidyverse_1.3.1    performance_0.9.1 \n [9] fitdistrplus_1.1-8 MASS_7.3-57        multimode_1.5      ggeasy_0.1.3      \n[13] ggdist_3.1.1       ggpubr_0.4.0       vcd_1.4-10         kableExtra_1.3.4  \n[17] mosaic_1.8.3       ggridges_0.5.3     mosaicData_0.20.2  ggformula_0.10.1  \n[21] ggstance_0.3.5     dplyr_1.0.9        Matrix_1.4-1       Hmisc_4.7-0       \n[25] ggplot2_3.3.6      Formula_1.2-4      survival_3.3-1     lattice_0.20-45   \n\nloaded via a namespace (and not attached):\n [1] colorspace_2.0-3     ggsignif_0.6.3       ellipsis_0.3.2      \n [4] mclust_5.4.10        leaflet_2.1.1        htmlTable_2.4.0     \n [7] fs_1.5.2             base64enc_0.1-3      ggdendro_0.1.23     \n[10] rstudioapi_0.13      farver_2.1.0         ggrepel_0.9.1       \n[13] lubridate_1.8.0      mvtnorm_1.1-3        fansi_1.0.3         \n[16] xml2_1.3.3           splines_4.2.1        rootSolve_1.8.2.3   \n[19] knitr_1.39           polyclip_1.10-0      jsonlite_1.8.0      \n[22] broom_0.8.0          dbplyr_2.2.1         cluster_2.1.3       \n[25] png_0.1-7            ggforce_0.3.3        compiler_4.2.1      \n[28] httr_1.4.3           backports_1.4.1      assertthat_0.2.1    \n[31] fastmap_1.1.0        cli_3.3.0            tweenr_1.0.2        \n[34] htmltools_0.5.2      tools_4.2.1          gtable_0.3.0        \n[37] glue_1.6.2           Rcpp_1.0.8.3         carData_3.0-5       \n[40] cellranger_1.1.0     vctrs_0.4.1          svglite_2.1.0       \n[43] crosstalk_1.2.0      insight_0.18.0       lmtest_0.9-40       \n[46] xfun_0.31            rvest_1.0.2          lifecycle_1.0.1     \n[49] mosaicCore_0.9.0     rstatix_0.7.0        zoo_1.8-10          \n[52] scales_1.2.0         hms_1.1.1            RColorBrewer_1.1-3  \n[55] yaml_2.3.5           gridExtra_2.3        labelled_2.9.1      \n[58] rpart_4.1.16         latticeExtra_0.6-29  stringi_1.7.6       \n[61] highr_0.9            checkmate_2.1.0      rlang_1.0.3         \n[64] pkgconfig_2.0.3      systemfonts_1.0.4    distributional_0.3.0\n[67] pracma_2.3.8         evaluate_0.15        labeling_0.4.2      \n[70] ks_1.13.5            htmlwidgets_1.5.4    tidyselect_1.1.2    \n[73] plyr_1.8.7           magrittr_2.0.3       R6_2.5.1            \n[76] generics_0.1.2       DBI_1.1.3            pillar_1.7.0        \n[79] haven_2.5.0          foreign_0.8-82       withr_2.5.0         \n[82] abind_1.4-5          nnet_7.3-17          modelr_0.1.8        \n[85] crayon_1.5.1         car_3.1-0            KernSmooth_2.23-20  \n[88] utf8_1.2.2           tzdb_0.3.0           rmarkdown_2.14      \n[91] jpeg_0.1-9           readxl_1.4.0         data.table_1.14.2   \n[94] reprex_2.0.1         diptest_0.76-0       digest_0.6.29       \n[97] webshot_0.5.3        munsell_0.5.0        viridisLite_0.4.0"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_introduction.html",
    "href": "analysis/SGC3A/1_sgc3A_introduction.html",
    "title": "4  Introduction",
    "section": "",
    "text": "In Study 3A we explore the extent to which confronting a learner with an implicit obstacle (a mental impasse) influences their interpretation of the underlying coordinate system. This is a hypothesis that emerged from analysis of Study 2, leading us to suspect that presenting a learner with a situation that induces a state of impasse will increase the probability that learners experience a moment of insight, and in turn restructure their interpretation of the coordinate system.\nIn the context of Study 2, an impasse state was (unintentionally) induced when the combination of question + data set yielded no available answer in the incorrect (cartesian) interpretation of the graph. In Study 3A, we test this hypothesis by comparing performance between a (treatment) group receiving impasse-inducing questions followed by normal questions, and a non-impasse control."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_introduction.html#methods",
    "href": "analysis/SGC3A/1_sgc3A_introduction.html#methods",
    "title": "4  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Scaffold: control,impasse)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 19.1. The list of questions can be found here.\n\n\n\nFigure 4.2: Sample Question (Q=1) for Graph Comprehension Task\n\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\nThe green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line. We hypothesize that this presents the reader with an obstacle, at which point they are forced to confront their interpretation of the coordinate system and (ideally) develop a new strategy.\n\n\n\nFigure 4.3: Sample Question (Q=1) graphs for each condition\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items.\n(3A) The first five items in the task are defined as the SCAFFOLDING block. In the IMPASSE condition, the first five questions included an IMPASSE problem state. For participants in the CONTROL condition, the dataset was structure such that there was always an available ‘orthogonal answer’ for the first 5 questions.\n(3B) The remaining 10 items are defined as the TESTING block. In both conditions, these questions were not structured as impasse (i.e. contained an available orthogonal answer)\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData was collected by convenience sample of a university subject pool. Initial data (Fall 2017, Spring 2018) were collected in-person, with large groups of students simultaneously completing the study (independently) in a computer lab. In Fall 2021 and Winter 2022 we collected additional data to replicate results in a remote format (students completing the study asynchronously on their own computers)."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_introduction.html#analysis",
    "href": "analysis/SGC3A/1_sgc3A_introduction.html#analysis",
    "title": "4  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\nBefore analysis, data files from individual data collection periods are harmonized into a common data format.\n\n\n\n\n\n\n\nPre-Requisite\nFollowed By\n\n\n\n\nspring17_clean_data.Rmd  spring18_clean_data.Rmd  fall21_clean_data.Rmd  winter2022_clean_sgc3a.Rmd\n2_sgc3A_scoring.qmd\n\n\n\nData for study SGC_3A were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n\n\nPeriod\nModality\n\n\n\n\nFall 2017\nin person, SONA groups in computer lab\n\n\nSpring 2018\nin person, SONA groups in computer lab\n\n\nFall 2021\nasynchronous, online, SONA\n\n\nWinter 2022\nasynchronous, online, SONA\n\n\n\nData collected in Fall 2017 (in person pilot) were analyzed and published as a Cognitive Science Society conference paper (“When Graph Comprehension is an Insight Problem). Additional data were collected in person in Spring 2018. Combined, Fall 2017 and Spring 2018 constitute the original SGC_3A study, conducted in person. Data collected in Fall 2021, Winter 2022 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application. The replication study was conducted to validate the use of remote, asynchronous data collection during the Covid-19 pandemic.\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3A/data/0-session-level/fall17_sgc3a_participants.csv\" #COGSCI18 data\nspring18 <- \"analysis/SGC3A/data/0-session-level/spring18_sgc3a_participants.csv\"\nfall21 <- \"analysis/SGC3A/data/0-session-level/fall21_sgc3a_participants.csv\"\nwinter22 <- \"analysis/SGC3A/data/0-session-level/winter22_sgc3a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  dplyr::select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_condition = recode_factor(condition, \"111\" = \"control\", \"121\" =  \"impasse\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#IMPORT OSPAN DATA \nospan <- read_csv(\"analysis/SGC3A/data/0-session-level/fall21_scored_ospan.csv\") %>% mutate(\n  subject = SUBJECTID\n) %>% dplyr::select(-SUBJECTID)\n\n#MERGE OSPAN DATA WITH SGC DATA \n#special dataframe with just ospan subjects\n#should be 133 subjects. Some of the 200 who completed the task failed the \n#attention check question. Others were allocated to SGC4A pilot. \n#note that rather than adding OSPAN data to main dataframe, the after-scored data\n#will be manually joined to df_ospan during exploratory analysis\ndf_ospan <- df_subjects %>% filter(\n  subject %in% ospan$subject\n) %>% merge(ospan) %>% rename(\n  OSPAN.order_num = order_num,\n  OSPAN.order_acc = order_acc,\n  OSPAN.math_acc = math_acc,\n  OSPAN.weighted = weighted\n) \n\n##CALCULATE OSPAN SPLIT\n#calculate ospan median split\nmedian_split <- median(df_ospan$OSPAN.weighted)\ndf_ospan <- df_ospan %>% mutate(\n  ospan_split = as.factor(OSPAN.weighted > median_split),\n  ospan_split = recode_factor(ospan_split, \"TRUE\" = \"high-memory\", \"FALSE\" = \"low-memory\")\n)\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,fall21,spring18,winter22)\n\n\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    fall17 \n    27 \n    27 \n    54 \n  \n  \n    spring18 \n    35 \n    37 \n    72 \n  \n  \n    fall21 \n    68 \n    71 \n    139 \n  \n  \n    winter22 \n    28 \n    37 \n    65 \n  \n  \n    Sum \n    158 \n    172 \n    330 \n  \n\n\n\n\n\nCODE\ntitle = \"Subset of Participants who completed OSPAN TASK [Fall 2021]\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_ospan$mode, df_ospan$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nSubset of Participants who completed OSPAN TASK [Fall 2021]\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    lab-synch \n    0 \n    0 \n    0 \n  \n  \n    asynch \n    65 \n    68 \n    133 \n  \n  \n    Sum \n    65 \n    68 \n    133 \n  \n\n\n\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3A/data/0-session-level/fall17_sgc3a_blocks.csv\"\nspring18 <- \"analysis/SGC3A/data/0-session-level/spring18_sgc3a_blocks.csv\"\nfall21 <- \"analysis/SGC3A/data/0-session-level/fall21_sgc3a_blocks.csv\"\nwinter22 <- \"analysis/SGC3A/data/0-session-level/winter22_sgc3a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% dplyr::select(q,relation) %>% unique()\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% dplyr::select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% dplyr::select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#add back pretty condition \ndf_items <- df_items %>% mutate(\n  pretty_condition = recode_factor(condition, \"111\" = \"control\", \"121\" =  \"impasse\"),\n  pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,fall21,spring18,winter22, map_relations)\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC3A/data/1-study-level/sgc3a_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC3A/data/1-study-level/sgc3a_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC3A/data/1-study-level/sgc3a_freeresponse.csv\", row.names = FALSE)\nwrite.csv(df_ospan,\"analysis/SGC3A/data/1-study-level/sgc3a_ospan.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC3A/data/1-study-level/sgc3a_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC3A/data/1-study-level/sgc3a_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html",
    "title": "5  Response Scoring",
    "section": "",
    "text": "TODO\nThe purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC3A study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#score-sgc-data",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#score-sgc-data",
    "title": "5  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_both <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_both\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC3A/data/1-study-level/sgc3a_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC3A/data/1-study-level/sgc3a_items.rds')\n\n#ADD TEMP IMPASSE COLUMN\ndf_items <- df_items %>% mutate(\n  IMPASSE = substr(condition,2,2),\n  IMPASSE = recode_factor(IMPASSE, \"1\"=\"none\", \"2\"=\"IMPASSE\")\n)\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#TROUBLESHOOTING\n# backup <- df_items\n# df_items <- backup %>% sample_n(20)\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tri))\n\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_BOTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_both))\n\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\n\n#OLD score_BOTH... new one is above (explicitly in key)\n# df_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items #%>% head(16) %>% tail(1)\ntemp <- derive_interpretation(temp)\n\n\n[1] \"DERIVING INTERPRETATION\"\n\n\nCODE\ndf_items <- temp\n\n\n\n\nSPECIAL EXCEPTION PROCESSING\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nALSO reconciles issues when interpetation == triangular but scoreniceabs = 0 ::: {.cell}\n\nCODE\n# #temp setup for protection\n# backup <- df_items\ntemp <- df_items %>% mutate(\n  override = \"\"\n)\n\n## IMPASS Q==2. \"EK\" derives as 'TRI', should be tversky MAX\ntemp <- temp %>% mutate_when(\n  (q==2) & (IMPASSE ==\"IMPASSE\") & (response == \"EK\"),\n  tv_type = \"score_TV_max\",\n  int2 = \"Tversky\", #override from TRI\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n## CONTROL. Q==3. \"A\" derives as 'unknown', should be tversky duration\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"A\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n## CONTROL  Q==3 \"EFK\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"EFK\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASS  Q==3 \"AF\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE  Q==3 \"AFG\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE  Q==3 \"AH\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AH\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n## IMPASSE  Q==3 \"AO\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE  Q==3 \"AOU\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AOU\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## CONTROL Q==4 AH Derives as TRI RECODE as TVERSKY\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"AH\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n\n## CONTROL Q==4 DEU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 DEOU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEOU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 KU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"KU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## IMPASSE Q==4 BD Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BD\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 BDEG Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BDEG\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 AFG Derives as SATISFICE RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from Satisfice\n  interpretation = \"?\", #override from Satisfice\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE Q==4 DH Derives as TRI RECODE as BOTH\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"DH\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AU Derives as TRI RECODE as satisfice\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AU\"),\n  int2 = \"Satisfice\", #override from Triangular\n  interpretation = \"Satisfice\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AZ Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AZ\"),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AFG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n\n## IMPASSE Q==5 AF Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 FO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response == \"FO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 FO, HO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"HO\",\"FO\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 KO Derives as TRI RECODE as tversky_duration\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response == \"KO\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n##  Q==7 HOX Derives as TRI but incorrect\n#includes H which is at rather than under 5 hours.\n#give credit \ntemp <- temp %>% mutate_when(\n  (q==7)  & (response %in% c(\"HOX\")),\n  score_niceABS = 1\n)\n\n##  Q==7 AX, MO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MO\",\"AX\")) ,\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==7 MOX, MX  Derives as TRI RECODE as tversky\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MOX\", \"MX\", \"DX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 CFGO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8) & (response == \"CFGO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AGK Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AGK\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 FG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response %in% c(\"FG\",\"CG\",\"CFG\",\"CGM\",\"CM\",\"ACGP\",\"GM\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==11 M Derives as TRI MISSING RESPONSE\n##LEAVE AS TRI + OVERRIDE SCORENABS\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response == \"M\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==11 BLM Derives as TRI set at both\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response == \"BLM\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n##  Q==11 EKM Derives as TRI set at other\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"EKM\",\"JM\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==12 GP Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==12)  & (response == \"GP\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 E Derives as TRI but incorrect\n##LEAVE AS TRI + OVERRIDE SCORENABS\n##one of two correct answers\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response == \"E\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==13 CE Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"CE\",\"EH\")),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 FX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"FX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 OX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"OX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 EX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"EX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 CX Derives as TRI but incorrect \n#within visual margin... give credit\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response == \"CX\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n#  Q==15  Derives as TRI but incorrect \n#missing 1 right answer or within 0.5hr visual error \ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"X\",\"CK\",\"K\",\"GKX\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==15 DJNX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"DJNX\", \"OX\")),\n  # tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 AKPX Derives as TRI set at OTHER\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"AKPX\",\"GK\",\"JX\",\"LX\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n#SET BACK\ndf_items <- temp\n\n:::\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#summarize-by-subject",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#summarize-by-subject",
    "title": "5  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC3A/data/1-study-level/sgc3a_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#explore-distributions",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#explore-distributions",
    "title": "5  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_wrap(~pretty_condition)+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE TEST PHASE\ngf_props(~item_test_NABS, fill = ~pretty_condition, \n             data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Absolute Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\nresult <- two_sample_test(data = df_subjects, x = pretty_condition, y = s_NABS,\n                          type = \"nonparametric\", var.equal = FALSE,alternative = \"less\",\n                          k = 2L, conf.level = 0.89, effsize.type = \"g\",\n                          bf.prior = 0.707, tr = 0.2, nboot = 100L)\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\",\n                results.subtitle = FALSE,\n                subtitle = result$expression[[1]])\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE TEST PHASE\ngf_histogram(~item_test_SCALED, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Scaled Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Scaled Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\nresult <- two_sample_test(data = df_subjects, x = pretty_condition, y = s_SCALED,\n                          type = \"nonparametric\", var.equal = FALSE,alternative = \"less\",\n                          k = 2L, conf.level = 0.89, effsize.type = \"g\",\n                          bf.prior = 0.707, tr = 0.2, nboot = 100L)\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_SCALED,\n                type = \"non-parametric\",\n                title = \"Total Scaled Score [directional test]\",\n                results.subtitle = FALSE,\n                subtitle = result$expression[[1]])\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\nggbarstats( data = df, x = score_STATE, y = pretty_condition)\n\n\n\n\n\nCODE\nggbarstats( data = df, x = high_interpretation, y = pretty_condition)\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"Impasse shifts density toward higher Triagular scores\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#explore-responses",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#explore-responses",
    "title": "5  Response Scoring",
    "section": "EXPLORE RESPONSES",
    "text": "EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n\nCODE\ngf_props(~ score_niceABS, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Item Absolute Score\", title = \"Distribution of Accuracy  | ALL ITEMS \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | ALL ITEMS \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nSCAFFOLD PHASE\nThe first five questions constitute the ‘scaffold’ (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\nQuestion #1\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ1. Control Condition\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\n\n\n\nFigure 5.1: Question 1 — Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Control Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    A \n    OI \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    CF \n    Z \n  \n  \n    Tversky [start diagonal] \n    F \n    Z \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nHere we summarize the distinct response options given by participants on this item. Each letter in response indicates a checkbox selected by the participant (See Figure 17.1 ). n indicates the number of participants who gave this response, while interpretation indicates the graph interpretation most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\nNotice that for this Question, the Triangular answer is the same as the Tversky [start diagonal] answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 2) %>% \n  # pack_rows(\"Orthogonal\", 3, 3) %>% \n  # pack_rows(\"Other\", 4, 4)  %>% \n  # pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    22 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    CF \n    3 \n    Tversky \n    0 \n    0.923 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    A \n    129 \n    Orthogonal \n    0 \n    -0.077 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AF \n    1 \n    both tri + orth \n    0 \n    0.923 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n    DIJ \n    1 \n    ? \n    0 \n    -0.231 \n    -0.214 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.077 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as ? .\n\n\n\n\n\n\n\nWhich shifts start at 11am?\n\n\n\n\n\n\nResponse: A\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, projecting an invisible orthogonal line upward, and locating data point A.\n\n\n\n\nResponse: F\n\nindicates the triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point F.\n\n\n\n\nResponse: C, F\n\nindicates a maximal-Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following both the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C.\n\n\n\n\nResponse: A , F\n\nThe reader selects both triangular and orthogonal-consistent data points\nPossibly indicates uncertainty or confusion\n\n\n\n\nThree responses were given that were not consistent with any of the identified interpretations. Note that options highlighted in light grey are considered within the range of ‘visual error’, defined by 0.5hr offset from the interpretation-specific projection.\n\n\n\n\n\n\n\n\nD I J\nX\nZ\n[found this subject F86ZM, thought maybe this was a missed ‘F’, but they have a series of other unknown answers]\n\n\n\n\n\n\n\n\n\n\n\n\nQ1. Impasse Condition\n\n\n\nFigure 5.2: Question 1 — Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Impasse Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    O \n     \n  \n  \n    Satisficing [right] \n    AI \n     \n  \n  \n    Tversky [maximal] \n    CF \n     \n  \n  \n    Tversky [start diagonal] \n    F \n     \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nNotice that there is no orthogonal answer for this question. This is the purpose of the impasse condition, to remove the possibility of selecting the orthogonal answer, we expect learners will be more likely to restructure their understanding of the coordinate system, and arrive at a correct (triangular) interpretation.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 4) %>% \n  # pack_rows(\"Satisfice\", 5, 9) %>% \n  # pack_rows(\"Other\", 10, 10) %>% \n  # pack_rows(\"Unknown\", 11, 12) %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    49 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.071 \n    NA \n    1.0 \n  \n  \n    CF \n    14 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    -0.143 \n    NA \n    0.5 \n  \n  \n    C \n    3 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    -0.071 \n    NA \n    0.5 \n  \n  \n    CO \n    1 \n    Tversky \n    0 \n    -0.143 \n    0.929 \n    0.929 \n    NA \n    0.5 \n  \n  \n    O \n    28 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    AI \n    9 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    A \n    4 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    AO \n    2 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    0.929 \n    NA \n    -1.0 \n  \n  \n    I \n    2 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n     \n    57 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n    E \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.071 \n    NA \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.071 \n    NA \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as ? .\nTODO ADJUST ‘both’ to select for both tri/satisfice or both tri/orth\n\n\n\n\n\n\n\nWhich shifts start at 11am?\n\n\n\n\n\n\nResponse: F\n\nindicates the triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point F.\n\n\n\n\nResponse: [C, F]\n\nindicates a maximal-Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following both the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C gridline.\n\n\n\n\nResponses: [AOI]\n\nindicates a satisficing strategy\nConsistent with the reader identifying the datapoints nearest to the orthogonal projection from the reference point point\n\n\n\n\nTwo responses were given that were not consistent with any of the identified interpretations.\n\n\n\n\n\n\n[E],[X]\n\n\n\n\n\n\n\n\n\n\n\nQuestion #2\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ2. Control Condition\n\n\n\nFigure 5.3: Q2—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==2)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n    E \n    G \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AKJX \n    Z \n  \n  \n    Tversky [start diagonal] \n    AK \n    Z \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 4) %>% \n  # pack_rows(\"Orthogonal\", 5, 7) %>%\n  # pack_rows(\"Other\", 8, 8)  %>% \n  # pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    24 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    DK \n    1 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    J \n    4 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AK \n    1 \n    Tversky \n    0 \n    0.917 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    E \n    121 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DE \n    3 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EG \n    1 \n    Orthogonal \n    0 \n    -0.167 \n    -0.154 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    D \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\nWhich shift(s) start at the same time as D?\n\n\n\n\nReponse: E (also EG, DE)\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (D) on the graph, projecting an invisible orthogonal line through it, and locating data point E.\n\n\n\n\nResponse: K (also KD)\n\nindicates an triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (D) on the graph, and following its descending-leftward diagonal gridline, and locating data point K.\n\n\n\n\nResponse: AK\n\nindicates an Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (D) on the graph, and following its descending-leftward diagonal gridline, and locating data point K then continuing along the connecting ascending leftward diagonal locating data point A.\n\n\n\n\nResponse: J\n\nindicates an Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (D) on the graph, and following its horizontal gridline to the y-axis, locating data point J.\n\n\n\n\nResponse: D\n\nthe reader selected only the reference point\nConsistent with the reader identifying the reference point (D) on the graph\nPossibly indicates uncertainty or confusion\n\n\n\n\n\n\n\n\n\n\n\nB\nC\n\n\n\n\n\n\n\n\n\n\n\nQ2. Impasse Condition\n\n\n\nFigure 5.4: Q2—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==2)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Impasse Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n    G \n     \n  \n  \n    Tversky [maximal] \n    JKEX \n    Z \n  \n  \n    Tversky [start diagonal] \n    K \n    Z \n  \n  \n    Tversky [end diagonal] \n    EX \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 10) %>% \n  # pack_rows(\"Satisfice\", 11, 12) %>%\n  # pack_rows(\"Other\", 13, 16)  %>% \n  # pack_rows(\"Unknown\", 17, 18)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    69 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    DK \n    1 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    J \n    12 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    EK \n    3 \n    Tversky \n    0 \n    0.917 \n    0.917 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    EX \n    2 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    E \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    EKX \n    1 \n    Tversky \n    0 \n    0.833 \n    0.917 \n    -0.231 \n    NA \n    0.5 \n  \n  \n    HJZ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.846 \n    -0.231 \n    NA \n    0.5 \n  \n  \n    JK \n    1 \n    Tversky \n    0 \n    0.917 \n    0.923 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    G \n    19 \n    Satisfice \n    0 \n    -0.083 \n    -0.077 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    BG \n    2 \n    Satisfice \n    0 \n    -0.167 \n    -0.154 \n    0.923 \n    NA \n    -1.0 \n  \n  \n    BEG \n    1 \n    Satisfice \n    0 \n    -0.250 \n    0.333 \n    0.846 \n    NA \n    -1.0 \n  \n  \n    D \n    7 \n    reference \n    0 \n    0.000 \n    NA \n    0.000 \n    NA \n    0.0 \n  \n  \n     \n    43 \n    blank \n    0 \n    0.000 \n    NA \n    0.000 \n    NA \n    0.0 \n  \n  \n    ACDFHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.250 \n    0.250 \n    -0.846 \n    NA \n    -0.5 \n  \n  \n    BEGKUZ \n    1 \n    frenzy \n    0 \n    0.667 \n    0.667 \n    0.615 \n    NA \n    -0.5 \n  \n  \n    C \n    6 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.167 \n    -0.154 \n    -0.154 \n    NA \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\n\nQuestion #3\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ3. Control Condition\n\n\n\nFigure 5.5: Q3—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==3)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Control Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    Z \n    FIO \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AUBFOJ \n     \n  \n  \n    Tversky [start diagonal] \n    OJ \n     \n  \n  \n    Tversky [end diagonal] \n    F \n    Z \n  \n  \n    Tversky [duration line] \n    AUB \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    24 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    0.0 \n    1.0 \n  \n  \n    A \n    18 \n    Tversky \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    ABU \n    4 \n    Tversky \n    0 \n    -0.250 \n    1.000 \n    NA \n    -0.3 \n    0.5 \n  \n  \n    O \n    3 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    0.0 \n    0.5 \n  \n  \n    JO \n    2 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    DJO \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.917 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    KO \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    Z \n    94 \n    Orthogonal \n    0 \n    0.000 \n    0.000 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    C \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n    ABDEFGHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    AH \n    1 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    DE \n    1 \n    ? \n    0 \n    -0.167 \n    -0.167 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    EFK \n    1 \n    ? \n    0 \n    0.833 \n    0.833 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    EU \n    1 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    U \n    1 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 17)  \n\n\nTODO\n\naddress RESPONSE FKE which is classified as Triangular but doesn’t seem to fit this interpretation?\nShould O,K be considered Tvresky ?\nconsider adding trapdoor on n_q, such that score is penalized (OR interpretation is not predicted?) if the Ss selects more than 1 extra options, or is missing more than 2 options?\nLEFT OFF HERE\n\n\n\n\n\n\n\n\nWhat shift(s) begin when C ends?\n\n\n\n\n\n\nResponse: Z\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (C) then using the duration encoded on the y-axis (2) , project along the horizontal gridline by two hours, and then project an invisible orthogonal line through that time (12PM) locating data point Z.\n\n\n\n\nResponse: F\n\nindicates a (correct) triangular interpretation of the coordinate system\nConsistent with the reader identifying the reference point (C) on the graph, and following the descending gridline to the x-axis to identify the end-time (11AM) and then following the ascending gridline to identify datapoints starting at 11AM and locating data point F.\n\n\n\n\nResponse: AUB (also A)\n\nindicates a Tversky strategy following connecting lines (duration)\nConsistent with the reader identifying the reference point (C) on the graph, and following the horizontal y-axis gridline and locating data points A U B.\n\n\n\n\nResponse: OJ\n\nindicates a Tversky strategy following connecting lines (start-time)\nConsistent with the reader identifying the reference point (C) on the graph, and following the ascending diagonal gridline and locating data points O J.\n\n\n\n\nResponse: C\n\nthe participant selected the point referenced in the question\npossibly indicates confusion or uncertainty\n\n\n\n\nResponse: AIOZFHJXKUDEGB\n\nthe participant selects all (or nearly all) the data points\npossibly indicates confusion or uncertainty\n\n\n\n\nSix responses (from 9 participants) appear inconsistent with any interpretation.\n\n\n\n\n\n\n\n\nK (n=3)\nAH (n=1)\nDE (n=1)\n\n\n\n\n\n\n\n\n\nUE (n=1)\nU (n=1)\nE (n=1)\n\n\n\n\n\n\n\n\n\n\nQ3. Impasse Condition\n\n\n\nFigure 5.6: Q3—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==3)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Impasse Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    AI \n     \n  \n  \n    Satisficing [right] \n    F \n     \n  \n  \n    Tversky [maximal] \n    BJ \n     \n  \n  \n    Tversky [start diagonal] \n    J \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    B \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nTODO investigate these responses 17 at O?\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    61 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    1.000 \n    NA \n    1.0 \n  \n  \n    B \n    8 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    AF \n    5 \n    Tversky \n    0 \n    0.923 \n    -0.154 \n    0.923 \n    NA \n    0.5 \n  \n  \n    AH \n    5 \n    Tversky \n    0 \n    -0.154 \n    -0.154 \n    0.417 \n    NA \n    0.5 \n  \n  \n    AOU \n    3 \n    Tversky \n    0 \n    -0.231 \n    -0.231 \n    0.333 \n    NA \n    0.5 \n  \n  \n    J \n    3 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    AO \n    2 \n    Tversky \n    0 \n    -0.154 \n    -0.154 \n    0.417 \n    NA \n    0.5 \n  \n  \n    BE \n    1 \n    Tversky \n    0 \n    -0.154 \n    0.923 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    BJ \n    1 \n    Tversky \n    0 \n    -0.154 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    HJZ \n    1 \n    Tversky \n    0 \n    -0.231 \n    0.846 \n    -0.231 \n    NA \n    0.5 \n  \n  \n    A \n    7 \n    Satisfice \n    0 \n    -0.077 \n    -0.077 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    AI \n    3 \n    Satisfice \n    0 \n    -0.154 \n    -0.154 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    AFI \n    2 \n    Satisfice \n    0 \n    0.846 \n    -0.231 \n    0.917 \n    NA \n    -1.0 \n  \n  \n    AIO \n    2 \n    Satisfice \n    0 \n    -0.231 \n    -0.231 \n    0.917 \n    NA \n    -1.0 \n  \n  \n    C \n    2 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n     \n    36 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n    ABDEFGHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    -0.5 \n  \n  \n    ABDEFGHJKUZ \n    1 \n    frenzy \n    0 \n    0.231 \n    0.250 \n    0.231 \n    NA \n    -0.5 \n  \n  \n    BDEFGHJKU \n    1 \n    frenzy \n    0 \n    0.385 \n    0.417 \n    0.385 \n    NA \n    -0.5 \n  \n  \n    BDEFGHJKUXZ \n    1 \n    frenzy \n    0 \n    0.231 \n    0.250 \n    0.231 \n    NA \n    -0.5 \n  \n  \n    O \n    17 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    DK \n    2 \n    ? \n    0 \n    -0.154 \n    -0.154 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    AFG \n    1 \n    ? \n    0 \n    0.846 \n    -0.231 \n    0.846 \n    NA \n    -0.5 \n  \n  \n    FJZ \n    1 \n    ? \n    0 \n    0.846 \n    0.846 \n    0.846 \n    NA \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    KO \n    1 \n    ? \n    0 \n    -0.154 \n    -0.154 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    U \n    1 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>% \n#   pack_rows(\"Lines-Connect\", 3, 5) %>% \n#   pack_rows(\"Satisfice\", 6, 15) %>% \n#   pack_rows(\"Other\", 16, 21) %>% \n#   pack_rows(\"Unknown\", 22, 29) \n\n\n\n\n\nQuestion #4\n[PLACEHOLDER — NOT YET CONSIDERED THIS QUESTION]\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ4. Control Condition\n\n\n\nFigure 5.7: Q4—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==4)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n    U \n    OF \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    29 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    B \n    3 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AH \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    U \n    87 \n    Orthogonal \n    0 \n    -0.071 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    2 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n     \n    6 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACFHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.286 \n    0.286 \n    NA \n    0.333 \n    -0.5 \n  \n  \n    DE \n    14 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    E \n    6 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DEOU \n    1 \n    ? \n    0 \n    -0.286 \n    -0.286 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    DEU \n    1 \n    ? \n    0 \n    -0.214 \n    -0.214 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    KU \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    0.917 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 3) %>% \n#   pack_rows(\"Orthogonal\", 4, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 16) \n\n\n\nTBL4 test\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n |\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\nQ4. Impasse Condition\n\n\n\nFigure 5.8: Q4—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==4)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Impasse Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    FO \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nTODO investigate D? add to tversky or orth?\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    64 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    B \n    6 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    BH \n    2 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    O \n    11 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    F \n    8 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    FO \n    7 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    DH \n    1 \n    both tri + orth \n    0 \n    0.929 \n    0.929 \n    -0.154 \n    NA \n    0.5 \n  \n  \n     \n    20 \n    blank \n    0 \n    0.000 \n    0.000 \n    0.000 \n    NA \n    0.0 \n  \n  \n    ACFHIJKOUZ \n    1 \n    frenzy \n    0 \n    0.357 \n    0.357 \n    0.385 \n    NA \n    -0.5 \n  \n  \n    D \n    35 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    A \n    5 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    BD \n    2 \n    ? \n    0 \n    -0.143 \n    0.929 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    G \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    AFG \n    1 \n    ? \n    0 \n    -0.214 \n    -0.214 \n    0.346 \n    NA \n    -0.5 \n  \n  \n    AI \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    BDEG \n    1 \n    ? \n    0 \n    -0.286 \n    0.786 \n    -0.308 \n    NA \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 6) %>% \n#   pack_rows(\"Satisfice\", 7, 10) %>% \n#   pack_rows(\"Other\", 11, 12) %>% \n#   pack_rows(\"Unknown\", 13, 19) \n\n\n\n\n\nQuestion #5\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ5. Control Condition\n\n\n\nFigure 5.9: Q5—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==5)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    O \n    AZ \n  \n  \n    Orthgonal \n    U \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    UGX \n    AZKD \n  \n  \n    Tversky [start diagonal] \n    X \n     \n  \n  \n    Tversky [end diagonal] \n    UG \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    O \n    50 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    FG \n    2 \n    Tversky \n    0 \n    -0.182 \n    0.417 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    G \n    1 \n    Tversky \n    0 \n    -0.091 \n    0.500 \n    NA \n    -0.077 \n    0.5 \n  \n  \n    KO \n    1 \n    Tversky \n    0 \n    0.909 \n    -0.143 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    X \n    1 \n    Tversky \n    0 \n    -0.091 \n    1.000 \n    NA \n    -0.077 \n    0.5 \n  \n  \n    U \n    64 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    HU \n    1 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    I \n    1 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    6 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    F \n    10 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    FO \n    3 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    H \n    3 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    B \n    2 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DJ \n    2 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DEHJ \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HJ \n    1 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>% \n#   pack_rows(\"Lines-Connect\", 5, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 9) %>% \n#   pack_rows(\"Other\", 10, 11) %>% \n#   pack_rows(\"Unknown\", 12, 22) \n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\nQ5. Impasse Condition\n\n\n\nFigure 5.10: Q5—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==5)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Impasse Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    A \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    FUZ \n     \n  \n  \n    Satisficing [right] \n    H \n     \n  \n  \n    Tversky [maximal] \n    OX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    A \n    83 \n    Triangular \n    1 \n    1.000 \n    -0.083 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    AI \n    1 \n    Triangular \n    1 \n    1.000 \n    -0.083 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    O \n    6 \n    Tversky \n    0 \n    -0.077 \n    0.500 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    AFG \n    5 \n    Tversky \n    0 \n    0.846 \n    -0.250 \n    0.152 \n    NA \n    0.5 \n  \n  \n    AF \n    4 \n    Tversky \n    0 \n    0.923 \n    -0.167 \n    0.242 \n    NA \n    0.5 \n  \n  \n    AO \n    2 \n    Tversky \n    0 \n    0.923 \n    0.417 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    CO \n    1 \n    Tversky \n    0 \n    -0.154 \n    0.417 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    JO \n    1 \n    Tversky \n    0 \n    -0.154 \n    0.417 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    OX \n    1 \n    Tversky \n    0 \n    -0.154 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    X \n    1 \n    Tversky \n    0 \n    -0.077 \n    0.500 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    H \n    11 \n    Satisfice \n    0 \n    -0.077 \n    -0.083 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    HK \n    3 \n    Satisfice \n    0 \n    -0.154 \n    -0.167 \n    0.923 \n    NA \n    -1.0 \n  \n  \n    FU \n    2 \n    Satisfice \n    0 \n    -0.154 \n    -0.167 \n    0.667 \n    NA \n    -1.0 \n  \n  \n    AU \n    1 \n    Satisfice \n    0 \n    0.923 \n    -0.167 \n    0.242 \n    NA \n    -1.0 \n  \n  \n    FHZ \n    1 \n    Satisfice \n    0 \n    -0.231 \n    -0.250 \n    0.846 \n    NA \n    -1.0 \n  \n  \n    HKUZ \n    1 \n    Satisfice \n    0 \n    -0.308 \n    -0.333 \n    0.769 \n    NA \n    -1.0 \n  \n  \n    UXZ \n    1 \n    Satisfice \n    0 \n    -0.231 \n    0.333 \n    0.576 \n    NA \n    -1.0 \n  \n  \n    I \n    2 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n     \n    24 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n    ABCFGUZ \n    1 \n    frenzy \n    0 \n    0.538 \n    -0.583 \n    0.636 \n    NA \n    -0.5 \n  \n  \n    ACDEFHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.154 \n    0.167 \n    0.182 \n    NA \n    -0.5 \n  \n  \n    FHJKX \n    1 \n    frenzy \n    0 \n    -0.385 \n    0.167 \n    0.692 \n    NA \n    -0.5 \n  \n  \n    K \n    5 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    C \n    2 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    DJ \n    2 \n    ? \n    0 \n    -0.154 \n    -0.167 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    0.333 \n    NA \n    -0.5 \n  \n  \n    AZ \n    1 \n    ? \n    0 \n    0.923 \n    -0.167 \n    0.242 \n    NA \n    -0.5 \n  \n  \n    DG \n    1 \n    ? \n    0 \n    -0.154 \n    -0.167 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    U \n    1 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    0.333 \n    NA \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    0.333 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 7) %>% \n#   pack_rows(\"Lines-Connect\", 8, 13) %>% \n#   pack_rows(\"Orthogonal\", 14, 16) %>% \n#   pack_rows(\"Other\", 17, 21) %>% \n#   pack_rows(\"Unknown\", 22, 31) \n\n\n\n\n\n\nTESTING PHASE\nThe following 10 questions were the same for both conditions.\n\nQuestion #7\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 5.11: Q7-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    OX \n     \n  \n  \n    Orthgonal \n    BF \n    M \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    IJZNCHOX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n    IJZN \n     \n  \n  \n    Tversky [duration line] \n    CH \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #7\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    OX \n    93 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    IJ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.500 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    CH \n    1 \n    Tversky \n    0 \n    -0.125 \n    1.000 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    DJNX \n    1 \n    Tversky \n    0 \n    0.312 \n    0.357 \n    NA \n    -0.267 \n    0.5 \n  \n  \n    HK \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.438 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    MOX \n    1 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    MX \n    1 \n    Tversky \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    BF \n    203 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FZ \n    16 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    MO \n    2 \n    ? \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AX \n    1 \n    ? \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    GK \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    KM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>%\n#   pack_rows(\"Lines-Connect\", 6, 9) %>%\n#   pack_rows(\"Orthogonal\", 10, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 17)\n\n\n\n\nQuestion #8\n\n\n\nFigure 5.12: Q8-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    E \n    F \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #8\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    64 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    AGK \n    4 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    CG \n    3 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    FG \n    3 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.071 \n    0.5 \n  \n  \n    AG \n    2 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    CFGO \n    2 \n    Tversky \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    ACGP \n    1 \n    Tversky \n    0 \n    0.800 \n    NA \n    NA \n    -0.286 \n    0.5 \n  \n  \n    CFG \n    1 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    CGM \n    1 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    CM \n    1 \n    Tversky \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    GM \n    1 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    E \n    157 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EIJ \n    5 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EFIJ \n    3 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EF \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EI \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EFI \n    1 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n     \n    12 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJNOZ \n    2 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    EFGIJ \n    2 \n    frenzy \n    0 \n    0.733 \n    NA \n    NA \n    0.786 \n    -0.5 \n  \n  \n    CDGHLNOXZ \n    1 \n    frenzy \n    0 \n    0.533 \n    NA \n    NA \n    -0.571 \n    -0.5 \n  \n  \n    DEIJN \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    0.714 \n    -0.5 \n  \n  \n    IJ \n    17 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    I \n    7 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    EFG \n    3 \n    ? \n    0 \n    0.867 \n    NA \n    NA \n    0.929 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    O \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    A \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AK \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    C \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    DN \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    IJM \n    2 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    L \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    M \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    CX \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    DHNZ \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DIJN \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    EFGI \n    1 \n    ? \n    0 \n    0.800 \n    NA \n    NA \n    0.857 \n    -0.5 \n  \n  \n    HLO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    KL \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Orthogonal\", 11, 16) %>%\n#   pack_rows(\"Other\", 17, 21) %>%\n#   pack_rows(\"Unknown\", 22, 45)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #10\n\n\n\nFigure 5.13: Q10-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    E \n     \n  \n  \n    Orthgonal \n    X \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    EGZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n    E \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #10\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    E \n    103 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    EF \n    1 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    23 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    XZ \n    2 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n    CG \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    G \n    1 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    HLPZ \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.812 \n    NA \n    -0.250 \n    0.5 \n  \n  \n    X \n    139 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BX \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.938 \n    -1.0 \n  \n  \n    FX \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AMX \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    -0.188 \n    NA \n    0.875 \n    -1.0 \n  \n  \n    F \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    6 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    B \n    27 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    6 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IJ \n    2 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    P \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    BO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    HLP \n    1 \n    ? \n    0 \n    -0.188 \n    -0.188 \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>%\n#   pack_rows(\"Lines-Connect\", 3, 7) %>%\n#   pack_rows(\"Orthogonal\", 8, 11) %>%\n#   pack_rows(\"Other\", 12, 14) %>%\n#   pack_rows(\"Unknown\", 15, 27)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #11\n\n\n\nFigure 5.14: Q11-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at 12pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    ML \n     \n  \n  \n    Orthgonal \n    FB \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #11\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    LM \n    99 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.125 \n    1.0 \n  \n  \n    M \n    7 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    BF \n    201 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    B \n    4 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BFXZ \n    1 \n    Orthogonal \n    0 \n    -0.250 \n    NA \n    NA \n    0.875 \n    -1.0 \n  \n  \n    BH \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    0.438 \n    -1.0 \n  \n  \n    BLM \n    2 \n    both tri + orth \n    0 \n    0.938 \n    NA \n    NA \n    0.375 \n    0.5 \n  \n  \n     \n    4 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACDGHKLMNOPXZ \n    1 \n    frenzy \n    0 \n    0.312 \n    NA \n    NA \n    -0.812 \n    -0.5 \n  \n  \n    DHLMNOXZ \n    1 \n    frenzy \n    0 \n    0.625 \n    NA \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    J \n    2 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    CX \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    EKM \n    1 \n    ? \n    0 \n    0.375 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    XZ \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 9) %>%\n#   pack_rows(\"Other\", 10, 12) %>%\n#   pack_rows(\"Unknown\", 13, 17)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #12\n\n\n\nFigure 5.15: Q12-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    GZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #12\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    98 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    FG \n    3 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    4 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    BZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n    GP \n    1 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    B \n    206 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    5 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    E \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    FM \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Lines-Connect\", 4, 6) %>%\n#   pack_rows(\"Orthogonal\", 7, 8) %>%\n#   pack_rows(\"Other\", 9, 10) %>%\n#   pack_rows(\"Unknown\", 11, 14)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #13\n\n\n\nFigure 5.16: Q13-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts end when Z begins?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EF \n     \n  \n  \n    Orthgonal \n    FX \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #13\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EF \n    91 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    0.433 \n    1.0 \n  \n  \n    E \n    1 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.067 \n    1.0 \n  \n  \n    FX \n    141 \n    Orthogonal \n    0 \n    0.433 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    X \n    9 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    OX \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    KX \n    3 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    ACX \n    1 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.367 \n    -1.0 \n  \n  \n    BX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    CX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    DJNX \n    1 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.300 \n    -1.0 \n  \n  \n    GX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    JX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    HN \n    13 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BF \n    11 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    F \n    10 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    EX \n    6 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    HL \n    5 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HLP \n    5 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    BM \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DN \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    AG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CE \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CGO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    DKM \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HZ \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    LP \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    NZ \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Orthogonal\", 4, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 36)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #14\n\n\n\nFigure 5.17: Q14-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at 3pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    X \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XJND \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    JND \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #14\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    X \n    107 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.059 \n    1.0 \n  \n  \n    FX \n    2 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    EX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    OX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    B \n    150 \n    Orthogonal \n    0 \n    -0.059 \n    -0.059 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    12 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BIO \n    2 \n    Orthogonal \n    0 \n    -0.176 \n    -0.176 \n    NA \n    0.882 \n    -1.0 \n  \n  \n    BX \n    2 \n    both tri + orth \n    0 \n    0.941 \n    0.941 \n    NA \n    0.941 \n    0.5 \n  \n  \n     \n    29 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    O \n    5 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    G \n    3 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    A \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    HLP \n    2 \n    ? \n    0 \n    -0.176 \n    -0.176 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    AH \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    DHO \n    1 \n    ? \n    0 \n    -0.176 \n    0.200 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    HL \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.118 \n    0.267 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 7) %>%\n#   pack_rows(\"Other\", 8, 9) %>%\n#   pack_rows(\"Unknown\", 10, 22)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #15\n\n\n\nFigure 5.18: Q15-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Coffee breaks happen halfway through a shift. Which shifts share a break at 2pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    XK \n     \n  \n  \n    Orthgonal \n    EF \n    B \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XKZ \n     \n  \n  \n    Tversky [start diagonal] \n    Z \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #15\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    KX \n    100 \n    Triangular \n    1 \n    1.000 \n    0.667 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    X \n    6 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    CX \n    2 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    CK \n    1 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    K \n    1 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    FZ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    0.433 \n    0.5 \n  \n  \n    DJNX \n    2 \n    Tversky \n    0 \n    0.312 \n    0.133 \n    NA \n    -0.267 \n    0.5 \n  \n  \n    OZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    Z \n    1 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    EF \n    118 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    17 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    13 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    E \n    8 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    4 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BEF \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    -0.176 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EFZ \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    0.882 \n    NA \n    0.933 \n    -1.0 \n  \n  \n    EI \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FI \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    11 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    G \n    4 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    B \n    3 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    C \n    3 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    O \n    3 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BM \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    M \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AKPX \n    1 \n    ? \n    0 \n    0.875 \n    0.533 \n    NA \n    -0.267 \n    -0.5 \n  \n  \n    BG \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    DN \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    FX \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    GK \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HN \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    JX \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    LX \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Lines-Connect\", 11, 13) %>%\n#   pack_rows(\"Orthogonal\", 14, 22) %>%\n#   pack_rows(\"Other\", 23, 23) %>%\n#   pack_rows(\"Unknown\", 24, 44)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nNON-DISCRIMINANT QUESTIONS\n\nQuestion #6 NONDISCRIM\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 5.19: Q6-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) are six hours long?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EG \n     \n  \n  \n    Orthgonal \n    EG \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\nTODO discuss non discriminant\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #6\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EG \n    330 \n    both tri + orth \n    1 \n    1 \n    NA \n    NA \n    1 \n    0.5 \n  \n\n\n\n\n\n\n\nQuestion #9 NONDISCRIM\n\n\n\nFigure 5.20: Q9-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) begins before J begins and ends during B?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    I \n     \n  \n  \n    Orthgonal \n    I \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  pack_rows(\"Other\", 1, 2) %>%\n  pack_rows(\"Unknown\", 3, 19)\n\n\n\nFrequency of Selected Response Options for Question #9\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  Other\n\n    I \n    247 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    23 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  Unknown\n\n    E \n    29 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    F \n    6 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    EI \n    3 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    FI \n    3 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AGN \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CHO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    -0.5 \n  \n  \n    IM \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#export",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#export",
    "title": "5  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\n\n\nCODE\ntable(df_subjects$mode, df_subjects$condition) %>% addmargins()\n\n\n           \n            111 121 Sum\n  lab-synch  62  64 126\n  asynch     96 108 204\n  Sum       158 172 330\n\n\n\nSGC3A Lab Study\n\n\nCODE\n# SGC3A IS JUST IN LAB\ndf_lab <- df_subjects %>% filter(mode == \"lab-synch\")\n\n#conditions\ntable(df_lab$mode, df_lab$condition) %>% addmargins()\n\n\n           \n            111 121 Sum\n  lab-synch  62  64 126\n  asynch      0   0   0\n  Sum        62  64 126\n\n\nCODE\n#filter items and progress\ndf_lab_items <- df_items %>% filter(subject %in% df_lab$subject)\ndf_lab_absolute <- df_absolute_progress %>% filter(subject %in% df_lab$subject)\ndf_lab_scaled <- df_scaled_progress %>% filter(subject %in% df_lab$subject)\n\n#confirm items and subjects\nnrow(df_lab_items) / nrow(df_lab) == 15\n\n\n[1] TRUE\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_lab,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_LAB.csv\", row.names = FALSE)\nwrite.csv(df_lab_items,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_LAB.csv\", row.names = FALSE)\nwrite.csv(df_lab_absolute,\"analysis/SGC3A/data/2-scored-data/sgc3a_absolute_progress_LAB.csv\", row.names = FALSE)\nwrite.csv(df_lab_scaled,\"analysis/SGC3A/data/2-scored-data/sgc3a_scaled_progress_LAB.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_lab, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_LAB.rds\") # to R data structure file\nrio::export(df_lab_items, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_LAB.rds\") # to R data structure file\n\n\n\n\nSGC3A OSPAN\n\n\nCODE\n## get (all) SGC3 online \ndf_online <- df_subjects %>% filter(mode == \"asynch\")\ntable(df_online$mode, df_online$condition) %>% addmargins()\n\n\n           \n            111 121 Sum\n  lab-synch   0   0   0\n  asynch     96 108 204\n  Sum        96 108 204\n\n\nCODE\n## get (just ospan) SGC3 OSPAN\n\n#load ospan scores\ndf_ospan <- read_csv('analysis/SGC3A/data/1-study-level/sgc3a_ospan.csv') %>% \n  dplyr::select(subject, OSPAN.order_num, OSPAN.order_acc, OSPAN.math_acc, OSPAN.weighted, ospan_split) \n\n\nRows: 133 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): subject, term, mode, gender, language, schoolyear, country, effort...\ndbl  (7): condition, age, totaltime_m, OSPAN.order_num, OSPAN.math_acc, OSPA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCODE\ntemp_dfs <- df_online %>% filter(subject %in% df_ospan$subject)\n#scored ospan subjects\ndf_ospan <- merge(df_ospan, temp_dfs)\ntable(df_ospan$condition)\n\n\n\n111 121 \n 65  68 \n\n\nCODE\n#filter items and progress\ndf_ospan_items <- df_items %>% filter(subject %in% df_ospan$subject)\ndf_ospan_absolute <- df_absolute_progress %>% filter(subject %in% df_ospan$subject)\ndf_ospan_scaled <- df_scaled_progress %>% filter(subject %in% df_ospan$subject)\n\n#confirm items and subjects\nnrow(df_ospan_items) / nrow(df_ospan) == 15\n\n\n[1] TRUE\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_ospan,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_OSPAN.csv\", row.names = FALSE)\nwrite.csv(df_ospan_items,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_OSPAN.csv\", row.names = FALSE)\nwrite.csv(df_ospan_absolute,\"analysis/SGC3A/data/2-scored-data/sgc3a_absolute_progress_OSPAN.csv\", row.names = FALSE)\nwrite.csv(df_ospan_scaled,\"analysis/SGC3A/data/2-scored-data/sgc3a_scaled_progress_OSPAN.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_ospan, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_OSPAN.rds\") # to R data structure file\nrio::export(df_ospan_items, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_OSPAN.rds\") # to R data structure file\n\n\n\n\nSGC3A ONLINE REPLICATION\n\n\nCODE\n## get (not ospan) SGC3 online \ndf_rep <- df_subjects %>% filter(mode == \"asynch\") %>% \n  filter(subject %nin% df_ospan$subject)\ntable(df_rep$mode, df_rep$condition) %>% addmargins()\n\n\n           \n            111 121 Sum\n  lab-synch   0   0   0\n  asynch     31  40  71\n  Sum        31  40  71\n\n\nCODE\n#filter items and progress\ndf_rep_items <- df_items %>% filter(subject %in% df_rep$subject)\ndf_rep_absolute <- df_absolute_progress %>% filter(subject %in% df_rep$subject)\ndf_rep_scaled <- df_scaled_progress %>% filter(subject %in% df_rep$subject)\n\n#confirm items and subjects\nnrow(df_rep_items) / nrow(df_rep) == 15\n\n\n[1] TRUE\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_rep,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_REP.csv\", row.names = FALSE)\nwrite.csv(df_rep_items,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_REP.csv\", row.names = FALSE)\nwrite.csv(df_rep_absolute,\"analysis/SGC3A/data/2-scored-data/sgc3a_absolute_progress_REP.csv\", row.names = FALSE)\nwrite.csv(df_rep_scaled,\"analysis/SGC3A/data/2-scored-data/sgc3a_scaled_progress_REP.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_rep, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_REP.rds\") # to R data structure file\nrio::export(df_rep_items, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_REP.rds\") # to R data structure file\n\n\n\n\nSGC3A ALL DATA\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_ALL.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_ALL.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC3A/data/2-scored-data/sgc3a_absolute_progress_ALL.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC3A/data/2-scored-data/sgc3a_scaled_progress_ALL.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants_ALL.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC3A/data/2-scored-data/sgc3a_scored_items_ALL.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#resources",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#resources",
    "title": "5  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\nset operations\nhttps://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html\nkableExtra tables\nhttps://haozhu233.github.io/kableExtra/awesome_table_in_html.html#grouped_columns__rows\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1          stringr_1.4.0          dplyr_1.0.9           \n [4] purrr_0.3.4            readr_2.1.2            tidyr_1.2.0           \n [7] tibble_3.1.7           tidyverse_1.3.1        tidyfst_1.6.5         \n[10] statsExpressions_1.3.2 ggstatsplot_0.9.3      Hmisc_4.7-0           \n[13] Formula_1.2-4          survival_3.3-1         lattice_0.20-45       \n[16] pbapply_1.5-0          ggformula_0.10.1       ggridges_0.5.3        \n[19] scales_1.2.0           ggstance_0.3.5         ggplot2_3.3.6         \n[22] kableExtra_1.3.4      \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.1-1          colorspace_2.0-3       rio_0.5.29            \n  [4] ellipsis_0.3.2         estimability_1.4       htmlTable_2.4.0       \n  [7] fs_1.5.2               parameters_0.18.1      base64enc_0.1-3       \n [10] rstudioapi_0.13        farver_2.1.0           MatrixModels_0.5-0    \n [13] ggrepel_0.9.1          bit64_4.0.5            fansi_1.0.3           \n [16] mvtnorm_1.1-3          lubridate_1.8.0        xml2_1.3.3            \n [19] codetools_0.2-18       splines_4.2.1          knitr_1.39            \n [22] polyclip_1.10-0        zeallot_0.1.0          jsonlite_1.8.0        \n [25] broom_0.8.0            cluster_2.1.3          dbplyr_2.2.1          \n [28] png_0.1-7              effectsize_0.7.0       ggforce_0.3.3         \n [31] compiler_4.2.1         httr_1.4.3             emmeans_1.7.5         \n [34] backports_1.4.1        assertthat_0.2.1       Matrix_1.4-1          \n [37] fastmap_1.1.0          cli_3.3.0              tweenr_1.0.2          \n [40] htmltools_0.5.2        tools_4.2.1            coda_0.19-4           \n [43] gtable_0.3.0           glue_1.6.2             Rcpp_1.0.8.3          \n [46] cellranger_1.1.0       vctrs_0.4.1            svglite_2.1.0         \n [49] insight_0.18.0         xfun_0.31              openxlsx_4.2.5        \n [52] rvest_1.0.2            lifecycle_1.0.1        mosaicCore_0.9.0      \n [55] MASS_7.3-57            zoo_1.8-10             vroom_1.5.7           \n [58] BayesFactor_0.9.12-4.4 hms_1.1.1              parallel_4.2.1        \n [61] sandwich_3.0-2         rematch2_2.1.2         RColorBrewer_1.1-3    \n [64] prismatic_1.1.0        curl_4.3.2             yaml_2.3.5            \n [67] gridExtra_2.3          labelled_2.9.1         rpart_4.1.16          \n [70] latticeExtra_0.6-29    stringi_1.7.6          highr_0.9             \n [73] paletteer_1.4.0        bayestestR_0.12.1      checkmate_2.1.0       \n [76] zip_2.2.0              boot_1.3-28            fstcore_0.9.12        \n [79] rlang_1.0.3            pkgconfig_2.0.3        systemfonts_1.0.4     \n [82] evaluate_0.15          labeling_0.4.2         patchwork_1.1.1       \n [85] htmlwidgets_1.5.4      bit_4.0.4              tidyselect_1.1.2      \n [88] plyr_1.8.7             magrittr_2.0.3         R6_2.5.1              \n [91] generics_0.1.2         multcomp_1.4-19        DBI_1.1.3             \n [94] pillar_1.7.0           haven_2.5.0            foreign_0.8-82        \n [97] withr_2.5.0            datawizard_0.4.1       nnet_7.3-17           \n[100] performance_0.9.1      modelr_0.1.8           crayon_1.5.1          \n[103] utf8_1.2.2             tzdb_0.3.0             correlation_0.8.1     \n[106] rmarkdown_2.14         jpeg_0.1-9             readxl_1.4.0          \n[109] grid_4.2.1             data.table_1.14.2      reprex_2.0.1          \n[112] digest_0.6.29          webshot_0.5.3          xtable_1.8-4          \n[115] munsell_0.5.0          fst_0.9.8              viridisLite_0.4.0"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#archive",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#archive",
    "title": "5  Response Scoring",
    "section": "ARCHIVE",
    "text": "ARCHIVE\nPrior versions of functions for for-loop version of scoring, not optimized to use mapply\n\n\nCODE\n# #CALCULATE THE TRIANGULAR, ORTHOGONAL OR TVERSKIAN SUBSCORES FROM KEYFRAME\n# calc_sub_score <- function(question, cond, response,keyframe){\n# \n#   #STEP 1 GET KEY\n#   if (question < 6) #for q1 - q5 find key for question by condition\n#   {\n#     # print(keyframe)\n#     #GET KEY FOR THIS SCORE TYPE, QUESTION AND CONDITION\n#     p =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#     q =  keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n#     pn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_p)\n#     qn = keyframe %>% filter(Q == question) %>% filter(condition == cond) %>% select(n_q)\n# \n#   } else {\n#     #GET KEY FOR THIS SCORE TYPE, QUESTION\n#     p =  keyframe %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#     q =  keyframe %>% filter(Q == question) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n#     pn = keyframe %>% filter(Q == question) %>% select(n_p)\n#     qn = keyframe %>% filter(Q == question) %>% select(n_q)\n#   }\n# \n#   #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n#   \n#   #if response is not empty, split apart response for set comparison\n#     if(response != \"\")\n#     { response = response %>% str_split(\"\") %>% unlist()}\n#     \n#   ps = length(intersect(response,p))\n#   qs = length(intersect(response,q))\n#   # df_items[x,'tri_ps'] = tri_ps\n#   # df_items[x,'tri_qs'] = tri_qs\n# \n#   #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION\n#   x = f_partialP(ps,pn,qs,qn) %>% unlist() %>% as.numeric()\n#   \n#   #cleanup\n#   rm(p,q,pn,qn,ps,qs)\n#   return(x)\n# \n# }\n# \n# #CALCULATE THE REFERENCE SCORES\n# calc_ref_score <- function(question, cond, response){\n#   \n#     #1. GET reference point from REF_POINT column in raw keys\n#     ref_p = keys_raw %>% filter(Q == question) %>% filter(condition == cond) %>% select(REF_POINT) %>% pull(REF_POINT) %>% str_split(\"\") %>% unlist()\n#      \n#     #2. if response has more than one character, it can't be correct\n#     #there is only ever 1 reference character\n#     n = nchar(response)\n#     if (n == 0) {x = 0}\n#     else if(n>1) {x = 0}\n#     else {\n#       #3 is the response PRECISELY the REFERENCE POINT?\n#       x = ref_p == response\n#       x = as.numeric(x)  \n#     }\n#     \n#     #cleanup\n#     rm(ref_p, response, question, cond)   \n#     return(x) #1 = match, 0 = not match\n# }\n# \n# \n# #CALCULATE SCORE BASED ON UNION OF ORTH & TRI (SUBJECT SELECTS BOTH ANSWERS )\n# calc_both_score <- function(question, cond, response){\n#   \n#TRAPDOOR \n#   #since no orth responses exist for impasse condition q1 - q5, set to 0\n#   if (question < 6 & cond == 121) {x = NA}\n#   \n#   #ELSE \n#   #calculate union of ORTH and TRI\n#   else {\n#     if (question < 6 & cond == 111) #for q1 - q5 find key for question by condition\n#   {\n#      #grab the tri and orth keys for this question as well as N option set\n#      tri_p =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      orth_p = keys_orth %>% filter(Q == question) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      set_n =  keys_tri %>%  filter(Q == question) %>% filter(condition == cond) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n#      #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n#      both_p = union(tri_p, orth_p) #the selection of tri and p\n#      #2. calc answers that should't be selected as diffrence between N [same for all keys] and both_p\n#      both_q = setdiff(set_n,both_p)\n#      both_pn = length(both_p)\n#      both_qn = length(both_q)\n#   } else{\n#     \n#      #grab the tri and orth keys for this question as well as N option set\n#      tri_p =  keys_tri %>%  filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      orth_p = keys_orth %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n#      set_n =  keys_tri %>%  filter(Q == question) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n#      #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n#      both_p = union(tri_p, orth_p) #the selection of tri and p\n#      #2. calc answers that shouldn't be selected as difference between N [same for all keys] and both_p\n#      both_q = setdiff(set_n,both_p)\n#      both_pn = length(both_p)\n#      both_qn = length(both_q)\n#   }\n#     \n#   #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n#   \n#   #if response is not empty, split apart response for set comparison\n#     if(response != \"\")\n#     { response = response %>% str_split(\"\") %>% unlist()}\n#   \n#     both_ps = length(intersect(response,both_p))\n#     both_qs = length(intersect(response,both_q))\n#   \n#  \n#   #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n#   x = f_partialP(both_ps,both_pn,both_qs,both_qn)%>% unlist() %>% as.numeric()\n#   \n#   #cleanup\n#   rm(both_p,both_q,both_pn,both_qn,both_ps,both_qs, question, cond, response )   \n#   }\n#   \n#   return(x) #true correct, trues, false correct, falses\n# }\n\n\nLooping to do the scoring (not using MAPPLY)\n\n\nCODE\n#RUN THIS OR THE CALCULATE-SCORES-MAPPLY\n# df_items = trad \n# \n# pb <- timerProgressBar() \n# on.exit(close(pb)) \n#  \n# #CALCULATE SUBSCORES (in loop)\n# \n# for (x in 1:nrow(df_items)) {\n#   \n#   #show progress bar \n#   setTimerProgressBar(pb, x) \n#   \n#   #PREPARE ITEMS FOR SCORING\n#   #sort response vectors alphabetically\n#   #doesn't impact scoring, but does impact response display tables\n#    df_items[x,'response'] <-  df_items[x,'response'] %>% str_split(\"\") %>% unlist() %>% sort() %>% str_c(collapse=\"\")\n# \n#   #get properties of the RESPONSE ITEM\n#   qu = df_items[x,'q'] %>% as.numeric()\n#   cond = as.character(df_items[x,'condition']) %>% as.numeric()\n#   r = df_items[x,'response'] \n# \n#   #calculate the main subscores\n#   df_items[x,'score_TRI'] = calc_sub_score(qu, cond, r,keys_tri)\n#   df_items[x,'score_ORTH'] = calc_sub_score(qu, cond, r,keys_orth)\n#   df_items[x,'score_SATISFICE'] = calc_sub_score(qu, cond, r,keys_satisfice)\n#   df_items[x,'score_TV_max'] = calc_sub_score(qu, cond, r,keys_tversky_max)\n#   df_items[x,'score_TV_start'] = calc_sub_score(qu, cond, r,keys_tversky_start)\n#   df_items[x,'score_TV_end'] = calc_sub_score(qu, cond, r,keys_tversky_end)\n#   df_items[x,'score_TV_duration'] = calc_sub_score(qu, cond, r, keys_tversky_duration)\n#   \n#   #calculate special subscores\n#   df_items[x,'score_REF'] = calc_ref_score(qu, cond, r)\n#   df_items[x,'score_BOTH'] = calc_both_score(qu, cond, r)\n# }\n# \n# #CALCULATE ABSOLUTE SCORES\n# #calculate absolute scores dichotomous\n# df_items$score_ABS = as.integer(df_items$correct)\n# #niceABS indicates if the response is correct without penalizing the allowable triangular options(ie. the ref point)\n# df_items$score_niceABS  <- as.integer((df_items$score_TRI == 1))\n#  \n# #cleanup\n# rm(qu,cond,r, x)\n\n# trad_scored = df_items\n\n\nsanity check equivalence of for-loop and mapply scoring\n\n\nCODE\n#CHECK EQUIVALENCE OF LOOP AND MAPPLY SCORING \n# tests = data.frame (\n#   alt_tri = alt_scored$score_TRI,\n#   trad_tri = trad_scored$score_TRI,\n#   alt_orth = alt_scored$score_ORTH,\n#   trad_orth = trad_scored$score_ORTH,\n#   alt_ref = alt_scored$score_REF,\n#   trad_ref = trad_scored$score_REF,\n#   alt_tv_max = alt_scored$score_TV_max,\n#   trad_tv_max = trad_scored$score_TV_max,\n#   alt_tv_dur = alt_scored$score_TV_duration,\n#   trad_tv_dur = trad_scored$score_TV_duration,\n#   alt_tv_start = alt_scored$score_TV_start,\n#   trad_tv_start = trad_scored$score_TV_start,\n#   alt_tv_end = alt_scored$score_TV_end,\n#   trad_tv_end = trad_scored$score_TV_end,\n#   alt_both = alt_scored$score_BOTH,\n#   trad_both = trad_scored$score_BOTH,\n#   trad_response = trad_scored$response,\n#   alt_response = alt_scored$response,\n#   q_match = trad_scored$q == alt_scored$q,\n#   q = trad_scored$q,\n#   c_match = trad_scored$condition == alt_scored$condition,\n#   condition = trad_scored$condition\n# )\n# \n# tests$tri = tests$alt_tri == tests$trad_tri\n# tests$orth = tests$alt_orth == tests$trad_orth\n# tests$ref = tests$alt_ref == tests$trad_ref\n# tests$tvdur = tests$alt_tv_dur == tests$trad_tv_dur\n# tests$tvstart = tests$alt_tv_start == tests$trad_tv_start\n# tests$tvend = tests$alt_tv_end == tests$trad_tv_end\n# tests$both = tests$alt_both == tests$trad_both\n# \n# #CHECKS \n# unique(tests$tri)\n# unique(tests$orth)\n# unique(tests$ref)\n# unique(tests$tvdur)\n# unique(tests$tvstart)\n# unique(tests$tvend)\n# unique(tests$both)\n# \n# unique(alt_scored$score_ABS == trad_scored$score_ABS)\n# unique(alt_scored$score_niceABS == trad_scored$score_niceABS)\n\n\nPrior inline version of derive interpretation, before externalizing to a function in the scoring script.\n\n\nCODE\n# threshold_range = 0.5 #set required variance in subscores to be discriminant\n# threshold_frenzy = 4\n# \n# for (x in 1:nrow(df_items)) {\n#   \n#   #CALCULATE MAX TVERSKY SUBSCORE\n#   t = df_items[x,] %>% select(score_TV_max, score_TV_start, score_TV_end, score_TV_duration) #reshape\n#   t.long = gather(t,score, value, 1:4)\n#   t.long[t.long == \"\"] = NA #replace empty scores with NA so we can ignore them\n#   if(length(unique(t.long$value)) == 1 ){\n#     if(is.na(unique(t.long$value))){\n#       df_items[x,'score_TVERSKY'] = NA\n#       df_items[x,'tv_type'] = NA   \n#     }\n#   } else {\n#     df_items[x,'score_TVERSKY'] = as.numeric(max(t.long$value,na.rm = TRUE))\n#     df_items[x,'tv_type'] = t.long[which.max(t.long$value),'score']\n#   }\n#   \n#   #CALCULATE MAX SATISFICING SUBSCORE\n#   t = df_items[x,] %>% select(score_SAT_left, score_SAT_right)\n#   t.long = gather(t,score, value, 1:2)\n#   t.long[t.long == \"\"] = NA #replace empty scores\n#   if(length(unique(t.long$value)) == 1 ){\n#     if(is.na(unique(t.long$value))){\n#       df_items[x,'score_SATISFICE'] = NA\n#       df_items[x,'sat_type'] = NA   \n#     }\n#   } else {\n#     df_items[x,'score_SATISFICE'] = as.numeric(max(t.long$value,na.rm = TRUE))\n#     df_items[x,'sat_type'] = t.long[which.max(t.long$value),'score']  \n#   }\n#   \n#   #NOW CALCULATE RANGE AMONG SUBSCORES\n#   #order of this selection matters in breaking ties! \n#   t = df_items[x,] %>% select(score_TRI, score_TVERSKY, score_SATISFICE, score_ORTH)\n#   t.long = gather(t,score, value, 1:4)\n#   t.long[t.long == \"\"] = NA\n#   \n#   df_items[x,'top_score'] = as.numeric(max(t.long$value,na.rm = TRUE))\n#   df_items[x,'top_type'] = t.long[which.max(t.long$value),'score']\n#   \n#   #calculate the range between highest and lowest scores \n#   r = as.numeric(range(t.long$value,na.rm = TRUE))\n#   r = diff(r)\n#   df_items[x,'range'] = r\n#   \n#   #DISCRIMINANT BETWEEN SUBSCORES TO PREDICT BEST FIT INTERPRETATION\n#   \n#   if (r < threshold_range) {\n#       #then we can't predict the interpretation, leave it as \"?\"\n#     df_items[x,'best'] = \"?\"\n#   } else {\n#       p =  df_items[x,'top_type']\n#       if (p == \"score_TRI\") {df_items[x,'best'] = \"Triangular\"\n#       } else if(p == \"score_ORTH\") {df_items[x,'best'] = \"Orthogonal\"\n#       } else if(p == \"score_TVERSKY\") {df_items[x,'best'] = \"Tversky\"\n#       } else if(p == \"score_SATISFICE\") {df_items[x,'best'] = \"Satisfice\"}\n#   }\n#   \n#   #CHECK SPECIAL SITUATIONS\n# \n#   #BOTH TRI AND ORTH?  \n#   if (!is.na(df_items[x,'score_BOTH'])) { #only check if both is not null\n#       if( df_items[x,'score_BOTH'] == 1) {\n#         df_items[x,'best'] = \"both tri + orth\"}\n#   }\n#   \n#   #IS BLANK?\n#   if( df_items[x,'num_o'] == 0) {  \n#     df_items[x,'best'] = \"blank\"\n#   }\n#   \n#   #IS FRENZY?\n#   if( df_items[x,'num_o'] > threshold_frenzy) { \n#       df_items[x,'best'] = \"frenzy\"\n#   }\n# \n#   #IS REF POINT?\n#   if (!is.na(df_items[x,'score_REF'])) { #only check if the score is NOT null\n#       if( df_items[x,'score_REF'] == 1) {\n#           df_items[x,'best'] = \"reference\"\n#       }\n#   }\n# \n# }#end loop\n# \n# #cleanup \n# rm(t, t.long, x, r,p)\n# rm(threshold_frenzy, threshold_range)\n# \n# #set order of levels for response exploration table\n# df_items$int2 <- factor(df_items$best,\n#                                   levels = c(\"Triangular\", \"Tversky\",\n#                                              \"Satisfice\", \"Orthogonal\", \"reference\", \"both tri + orth\", \"blank\",\"frenzy\",\"?\"))\n# \n# #set order of levels\n# df_items$interpretation <- factor(df_items$best,\n#                                   levels = c(\"Orthogonal\",\"Satisfice\", \"frenzy\",\"?\",\"reference\",\"blank\",\n#                                                \"both tri + orth\", \"Tversky\",\"Triangular\"))\n# \n# #collapsed representation of scale of interpretations\n# df_items$high_interpretation <- fct_collapse(df_items$interpretation,\n#   orthogonal = c(\"Satisfice\", \"Orthogonal\"),\n#   neg.trans = c(\"frenzy\",\"?\"),\n#   neutral = c(\"reference\",\"blank\"),\n#   pos.trans = c(\"Tversky\",\"both tri + orth\"),\n#   triangular = \"Triangular\"\n# ) \n# \n# #reorder levels\n# df_items$high_interpretation = factor(df_items$high_interpretation, levels= c(\"orthogonal\", \"neg.trans\",\"neutral\",\"pos.trans\",\"triangular\"))\n# \n# #cleanup \n# df_items <- df_items %>% dplyr::select(-best)\n# \n# #recode as numeric inase they are char \n# # df_items$score_TV_duration <- df_items$score_TV_duration %>% as.numeric()\n# # df_items$score_SATISFICE <- df_items$score_SATISFICE %>% as.numeric()\n\n\nOld inline calculation of score_SCALED before externalizing as function\n\n\nCODE\n# df_items$score_SCALED <- recode(df_items$interpretation,\n#                           \"Orthogonal\" = -1,\n#                           \"Satisfice\" = -1,\n#                           \"frenzy\" = -0.5,\n#                           \"?\" = -0.5,\n#                           \"reference\" = 0,\n#                           \"blank\" = 0, \n#                           \"both tri + orth\" = 0.5,\n#                           \"Tversky\" = 0.5,\n#                           \"Triangular\" = 1)\n\n\nOriginal summary by subject before externalizing as function\n\n\nCODE\n# #prep items\n# df_items <- df_items %>% mutate(\n#   tv_type = as.factor(tv_type),\n#   top_type = as.factor(top_type)\n# )\n# \n# #summarize SCORES and TIME by subject\n# subjects_summary <- df_items %>% filter(q %nin% c(6,9)) %>% group_by(subject) %>% dplyr::summarise (\n#   subject = as.character(subject),\n#   pretty_condition = recode_factor(condition, \"111\" = \"control\", \"121\" =  \"impasse\"),\n#   s_TRI = sum(score_TRI,na.rm=TRUE),\n#   s_ORTH = sum(score_ORTH,na.rm=TRUE),\n#   s_TVERSKY = sum(score_TVERSKY,na.rm=TRUE),\n#   s_SATISFICE = sum(score_SATISFICE, na.rm=TRUE),\n#   s_REF = sum(score_REF,na.rm=TRUE),\n#   s_ABS = sum(score_ABS,na.rm=TRUE),\n#   s_NABS = sum(score_niceABS,na.rm=TRUE),\n#   s_SCALED = sum(score_SCALED,na.rm=TRUE),\n#   DV_percent_NABS = s_NABS/13,\n#   rt_m = sum(rt_s)/60,\n#   item_avg_rt = mean(rt_s),\n#   item_min_rt = min(rt_s),\n#   item_max_rt = max(rt_s),\n#   item_n_TRI = sum(interpretation == \"Triangular\"),\n#   item_n_ORTH = sum(interpretation == \"Orthogonal\"),\n#   item_n_TV = sum(interpretation == \"Tversky\"),\n#   item_n_SAT = sum(interpretation == \"Satisfice\"),\n#   item_n_OTHER = sum(interpretation %nin% c(\"Triangular\",\"Orthogonal\",\"Tversky\",\"Satisfice\")),\n#   item_n_POS = sum(high_interpretation == \"pos.trans\"),\n#   item_n_NEG = sum(high_interpretation == \"neg.trans\"),\n#   item_n_NEUTRAL = sum(high_interpretation == \"neutral\")\n# ) %>% arrange(subject) %>% slice(1L)\n# \n# #summarize first scaffold item of interest by subject\n# subjects_q1 <- df_items %>% filter(q == 1) %>% mutate(\n#   item_q1_NABS = score_niceABS,\n#   item_q1_SCALED = score_SCALED,\n#   item_q1_interpretation = interpretation,\n#   item_q1_rt = rt_s,\n# ) %>% dplyr::select(subject, item_q1_NABS, item_q1_SCALED, item_q1_interpretation,item_q1_rt) %>% arrange(subject)\n# \n# #summarize last test item of interest by subject\n# subjects_q5 <- df_items %>% filter(q == 5) %>% mutate(\n#   item_q5_NABS = score_niceABS,\n#   item_q5_SCALED = score_SCALED,\n#   item_q5_interpretation = interpretation,\n#   item_q5_rt = rt_s,\n# ) %>% dplyr::select(subject, item_q5_NABS, item_q5_SCALED, item_q5_interpretation,item_q5_rt) %>% arrange(subject)\n# \n# #summarize first test item of interest by subject\n# subjects_q7 <- df_items %>% filter(q == 7) %>% mutate(\n#   item_q7_NABS = score_niceABS,\n#   item_q7_interpretation = interpretation,\n#   item_q7_rt = rt_s,\n# ) %>% dplyr::select(subject, item_q7_NABS, item_q7_interpretation,item_q7_rt) %>% arrange(subject)\n# \n# #summarize last test item of interest by subject\n# subjects_q15 <- df_items %>% filter(q == 15) %>% mutate(\n#   item_q15_NABS = score_niceABS,\n#   item_q15_interpretation = interpretation,\n#   item_q15_rt = rt_s,\n# ) %>% dplyr::select(subject, item_q15_NABS, item_q15_interpretation,item_q15_rt) %>% arrange(subject)\n# \n# #summarize scaffold phase performance\n# subjects_scaffold <- df_items %>% filter(q<6)  %>% group_by(subject) %>% dplyr::summarise (\n#   item_scaffold_NABS = sum(score_niceABS),\n#   item_scaffold_SCALED = sum(score_SCALED),\n#   item_scaffold_rt = sum(rt_s)\n# )%>% dplyr::select(subject, item_scaffold_NABS, item_scaffold_SCALED, item_scaffold_rt) %>% arrange(subject)\n# \n# #summarize test phase performance\n# subjects_test <- df_items %>% filter(q %nin% c(1,2,3,4,5,6,9)) %>% group_by(subject) %>% dplyr::summarise (\n#   item_test_NABS = sum(score_niceABS),\n#   item_test_SCALED = sum(score_SCALED),\n#   item_test_rt = sum(rt_s)\n# )%>% dplyr::select(subject, item_test_NABS, item_test_SCALED, item_test_rt) %>% arrange(subject)\n# \n# #import subjects\n# df_subjects <- read_rds('analysis/SGC3A/data/1-study-level/sgc3a_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n# \n# #SANITY CHECK SUBJECT ORDER BEFORE MERGE; BOTH SHOULD BE TRUE\n# unique(subjects_summary$subject == df_subjects$subject)\n# unique(subjects_summary$subject == subjects_q1$subject)\n# unique(subjects_summary$subject == subjects_q5$subject)\n# unique(subjects_summary$subject == subjects_q7$subject)\n# unique(subjects_summary$subject == subjects_q15$subject)\n# unique(subjects_summary$subject == subjects_scaffold$subject)\n# unique(subjects_summary$subject == subjects_test$subject)\n# \n# #CAREFULLY CHECK THIS — RELIES ON \n# x = merge(df_subjects, subjects_summary)\n# x = merge(x, subjects_q1)\n# x = merge(x, subjects_q5)\n# x = merge(x, subjects_q7)\n# x = merge(x, subjects_q15)\n# x = merge(x, subjects_scaffold)\n# x = merge(x, subjects_test)\n# df_subjects <- x %>% dplyr::select(-absolute_score) #drop absolute score from webapp that includes Q6 and Q9\n# \n# #cleanup\n# rm(subjects_q1, subjects_q5, subjects_q7, subjects_q15, subjects_scaffold, subjects_test, subjects_summary, x)\n\n\nSummarize Cummulative Progress versions before functionize\n\n\nCODE\n# #SUMMARIZE-CUMULATIVE ABSOLUTE PROGRESS\n# \n# \n# #filter for valid items\n# x <- df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(subject,mode, pretty_condition, q,score_niceABS) \n# \n# #pivot wider\n# wide <- x %>% pivot_wider(names_from=q, names_glue = \"q_{q}\", values_from = score_niceABS)\n# \n# #calc stepwise cumulative score\n# wide$c1 = wide$q_1\n# wide$c2 = wide$c1 + wide$q_2\n# wide$c3 = wide$c2 + wide$q_3\n# wide$c4 = wide$c3 + wide$q_4\n# wide$c5 = wide$c4 + wide$q_5\n# wide$c6 = wide$c5 + wide$q_7\n# wide$c7 = wide$c6 + wide$q_8\n# wide$c8 = wide$c7 + wide$q_10\n# wide$c9 = wide$c8 + wide$q_11\n# wide$c10 = wide$c9 + wide$q_12\n# wide$c11 = wide$c10 + wide$q_13\n# wide$c12 = wide$c11 + wide$q_14\n# wide$c13 = wide$c12 + wide$q_15\n# wide <- wide %>% dplyr::select(subject,mode, pretty_condition,c1,c2,c3,c4,c5,c6, c7,c8,c9, c10,c11,c12,c13)\n# \n# #lengthen \n# df_absolute_progress <- wide %>% pivot_longer(cols= c1:c13, names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\n# df_absolute_progress$question <- as.integer(df_absolute_progress$question)\n# \n# \n# #cleanup \n# rm(x,wide)\n#   \n# # SUMMARIZE-CUMULATIVE SCALED PROGRESS\n# \n# #filter for valid items\n# x <- df_items %>% filter(q %nin% c(6,9)) %>% select(subject,mode, pretty_condition, q,score_SCALED)\n# \n# #pivot wider\n# wide <- x %>% pivot_wider(names_from=q, names_glue = \"q_{q}\", values_from = score_SCALED)\n# \n# #calc stepwise cumulative score\n# wide$c1 = wide$q_1\n# wide$c2 = wide$c1 + wide$q_2\n# wide$c3 = wide$c2 + wide$q_3\n# wide$c4 = wide$c3 + wide$q_4\n# wide$c5 = wide$c4 + wide$q_5\n# wide$c6 = wide$c5 + wide$q_7\n# wide$c7 = wide$c6 + wide$q_8\n# wide$c8 = wide$c7 + wide$q_10\n# wide$c9 = wide$c8 + wide$q_11\n# wide$c10 = wide$c9 + wide$q_12\n# wide$c11 = wide$c10 + wide$q_13\n# wide$c12 = wide$c11 + wide$q_14\n# wide$c13 = wide$c12 + wide$q_15\n# wide <- wide %>% select(subject,mode, pretty_condition,c1,c2,c3,c4,c5,c6, c7,c8,c9, c10,c11,c12,c13)\n# \n# #lengthen \n# df_scaled_progress <- wide %>% pivot_longer(cols= c1:c13, names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\n# df_scaled_progress$question <- as.integer(df_scaled_progress$question)\n# \n# #cleanup \n# rm(x,wide)"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html",
    "href": "analysis/SGC3A/3_sgc3A_description.html",
    "title": "5  Description",
    "section": "",
    "text": "The purpose of this notebook is describe the distributions of dependent variables for Study SGC3A."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#sample",
    "href": "analysis/SGC3A/3_sgc3A_description.html#sample",
    "title": "5  Description",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData was initially collected (in person, SONA groups in computer lab) in Fall 2017. In Spring 2018, additional data were collected after small modifications were made to the experimental platform to increase the size of multiple-choice input buttons, and to add an additional free-response question following the main task block. In Fall 2021, the study was replicated using asynchronous, online SONA pool, with additional participants collected in Winter 2022.\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$pretty_mode, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    laboratory \n    62 \n    64 \n    126 \n  \n  \n    online-replication \n    96 \n    108 \n    204 \n  \n  \n    Sum \n    158 \n    172 \n    330 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(age) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% filter(mode == \"asynch\") %>% dplyr::select(age) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\n) \n\nsubject.stats$percent.male <- c(\n  (df_lab %>%  filter(gender==\"Male\") %>% count())$n/count(df_lab) %>% unlist(),\n  (df_online %>% filter(gender==\"Male\") %>% count())$n/count(df_online) %>% unlist(),\n  (df_subjects %>% filter(gender==\"Male\") %>% count())$n/count(df_subjects) %>% unlist()\n)\n\nsubject.stats$percent.female <- c(\n  (df_lab %>%  filter(gender==\"Female\") %>% count())$n/count(df_lab) %>% unlist(),\n  (df_online %>% filter(gender==\"Female\") %>% count())$n/count(df_online) %>% unlist(),\n  (df_subjects %>% filter(gender==\"Female\") %>% count())$n/count(df_subjects) %>% unlist()\n)\n\nsubject.stats$percent.other <- c(\n  (df_lab %>%  filter(gender %nin% c(\"Female\",\"Male\")) %>% count())$n/count(df_lab) %>% unlist(),\n  (df_online %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())$n/count(df_online) %>% unlist(),\n  (df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())$n/count(df_subjects) %>% unlist()\n)\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.male \n    percent.female \n    percent.other \n  \n \n\n  \n    lab \n    18 \n    19 \n    20 \n    21 \n    33 \n    20.4 \n    2.12 \n    126 \n    0 \n    0.373 \n    0.619 \n    0.008 \n  \n  \n    online \n    18 \n    20 \n    20 \n    21 \n    31 \n    20.6 \n    2.00 \n    204 \n    0 \n    0.304 \n    0.672 \n    0.025 \n  \n  \n    combined \n    18 \n    19 \n    20 \n    21 \n    33 \n    20.5 \n    2.05 \n    330 \n    0 \n    0.330 \n    0.652 \n    0.018 \n  \n\n\nNote:   Age in Years\n\n\n\n\nFor in-person collection, 126 participants (37 % male, 62 % female, 1 % other) undergraduate STEM majors at a public American University participated in person in exchange for course credit (age: 18 - 33 years). Participants were randomly assigned to one of two experimental groups.\nFor online replication 204 participants (30 % male, 67 % female, 2 % other) undergraduate STEM majors at a public American University participated online, asynchronously in exchange for course credit (age: 18 - 31 years). Participants were randomly assigned to one of two experimental groups.\nCombined overall 330 participants (33 % male, 65 % female, 2 % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 33 years)."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#response-accuracy",
    "href": "analysis/SGC3A/3_sgc3A_description.html#response-accuracy",
    "title": "5  Description",
    "section": "RESPONSE ACCURACY",
    "text": "RESPONSE ACCURACY\n\nSubject Level Scores\nSubject level scores summarize the the response accuracy by a particular participant across all discriminant items in the graph comprehension task.\n\nTest Phase Absolute Score\nRecall from ?sec-absolute-scoring that the absolute score (following the dichotomous scoring approach) s_NABS indicates if the subject’s response for a particular item was perfectly correct: whether they selected all correct answer options and no others (excluding certain allowed exceptions, such as also selecting the data point referenced in the question). The absolute score for an individual item is either 0 or 1. When summarized across the entire set of discriminant items, the total absolute score for an individual subject ranges from [0,13]. When summarized across just the test phase (final items following scaffolding phase) scores for an individual subject range from [0,8]. First we examine performance on the test phase (final 8 questions, appears after scaffolding phase). This tells us how the participants perform after exposure to the 5 scaffolding questions (in the impasse condition).\n\n\nCODE\ntitle = \"Descriptive Statistics of TEST PHASE Response Accuracy (Total Absolute Score)\"\nabs.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(item_test_NABS) %>% unlist() %>% favstats()\n) \nabs.stats %>% kbl (caption = title) %>% kable_classic() %>% \n  footnote(general = \"# questions correct [0,8]\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of TEST PHASE Response Accuracy (Total Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    0 \n    0 \n    0 \n    6 \n    8 \n    2.53 \n    3.32 \n    126 \n    0 \n  \n  \n    online \n    0 \n    0 \n    0 \n    6 \n    8 \n    2.16 \n    3.19 \n    204 \n    0 \n  \n  \n    combined \n    0 \n    0 \n    0 \n    6 \n    8 \n    2.30 \n    3.24 \n    330 \n    0 \n  \n\n\nNote:   # questions correct [0,8]\n\n\n\n\nFor in person collection, total absolute scores in the TEST phase (n = 126) range from 0 to 8 with a mean score of (M = 2.53, SD = 3.32).\nFor online replication, (online) total absolute scores in the TEST phase (n = 204) range from 0 to 8 with a slightly lower mean score of (M = 2.16, SD = 3.19).\nWhen combined overall, total absolute accuracy scores in the TEST phase (n = 330) range from 0 to 8 with a slightly lower mean score of (M = 2.3, SD = 3.24).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE\n  gf_props(~item_test_NABS, data = df_subjects) + \n  labs(x = \"number of correct responses (test phase)\",\n       y = \"% of subjects\",\n       title = \"Distribution of TEST Absolute Score \",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_test_NABS\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of TEST Absolute Score\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"Total Absolute Score (Test Phase)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_test_NABS,\n                        fill = pretty_condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_NABS),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_NABS, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of TEST Absolute Score \",\n    x = \"Condition\", y = \"Total Absolute Score (Test Phase)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbetweenstats(y = item_test_NABS, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\nCODE\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(item_test_NABS)) + \n  stat_ecdf(geom = \"step\") +\n  facet_grid(pretty_condition~pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — TEST Absolute Score \",\n        x = \"Total Absolute Score (Test Phase) [0,8]\", \n        y = \"Cumulative Probability\")\n\n\n\n\n\nCODE\n#NOTE this is clobbered by the shift function imports; so I load those later\n\n\nVisual inspection of this distribution suggests it is not normal, and likely bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018). TODO REFERENCE\n\n\nCODE\nmultimode::modetest(df_subjects$item_test_NABS)\n\n\nWarning in multimode::modetest(df_subjects$item_test_NABS): A modification of\nthe data was made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$item_test_NABS\nExcess mass = 0.1, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\nn_modes = multimode::nmodes(df_subjects$item_test_NABS, bw=2) #bw = 2questions/15 = 0.15%\nl_modes = multimode::locmodes(df_subjects$item_test_NABS,mod0 =  n_modes, display = TRUE)\n\n\nWarning in multimode::locmodes(df_subjects$item_test_NABS, mod0 = n_modes, : If\nthe density function has an unbounded support, artificial modes may have been\ncreated in the tails\n\n\n\n\n\nThe excess mass test for multimodality suggests the distribution is infact multimodal (m = 0.1, p < 0.001), with two identifiable modes at 0.013 and 7.894, and an antimode at 2.867.\n\n\n\n\n\n\nNote\n\n\n\nCondition appears (through visual inspection) to yield a positive influence on Total Absolute Score in the TEST Phase, across data collection modalities.\n\n\n\n\nTest Phase Absolute Percentage\nTest Phase Score converted to percentage.\n\n\nCODE\ntitle = \"Descriptive Statistics of TEST PHASE Response Accuracy (% Accuracy Absolute Score)\"\nabs.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(DV_ptest_NABS) %>% unlist() %>% favstats()\n) \nabs.stats %>% kbl (caption = title) %>% kable_classic() %>% \n  footnote(general = \"% questions correct [0 - 100%]\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of TEST PHASE Response Accuracy (% Accuracy Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    0 \n    0 \n    0 \n    0.75 \n    1 \n    0.316 \n    0.415 \n    126 \n    0 \n  \n  \n    online \n    0 \n    0 \n    0 \n    0.75 \n    1 \n    0.270 \n    0.399 \n    204 \n    0 \n  \n  \n    combined \n    0 \n    0 \n    0 \n    0.75 \n    1 \n    0.288 \n    0.405 \n    330 \n    0 \n  \n\n\nNote:   % questions correct [0 - 100%]\n\n\n\n\nFor in person collection, total absolute scores in the TEST phase (n = 126) range from 0 to 1 with a mean score of (M = 0.32, SD = 0.42).\nFor online replication, (online) total absolute scores in the TEST phase (n = 204) range from 0 to 1 with a slightly lower mean score of (M = 0.27, SD = 0.4).\nWhen combined overall, total absolute accuracy scores in the TEST phase (n = 330) range from 0 to 1 with a slightly lower mean score of (M = 0.29, SD = 0.41).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE\n  gf_props(~DV_ptest_NABS, data = df_subjects) + \n  labs(x = \"number of correct responses (test phase)\",\n       y = \"% of subjects\",\n       title = \"Distribution of TEST Absolute Score \",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"DV_ptest_NABS\",\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\n\n\nWarning: Using `bins = 30` by default. Pick better value with the argument\n`bins`.\n\n\nCODE\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of TEST Absolute Score\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"Total Absolute Score (Test Phase)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = DV_ptest_NABS,\n                        fill = pretty_condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = DV_ptest_NABS),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = DV_ptest_NABS, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of TEST Absolute Score \",\n    x = \"Condition\", y = \"Total Absolute Score (Test Phase)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbetweenstats(y = DV_ptest_NABS, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\nCODE\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(DV_ptest_NABS)) + \n  stat_ecdf(geom = \"step\") +\n  facet_grid(pretty_condition~pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — TEST Absolute Score \",\n        x = \"Total Absolute Score (Test Phase) [0,8]\", \n        y = \"Cumulative Probability\")\n\n\n\n\n\nCODE\n#NOTE this is clobbered by the shift function imports; so I load those later\n\n\n\n\nTest Phase Scaled Scores\nThe test phase scaled score s_SCALED summarizes the scaled score on the 8 strategy-discriminant questions in the test phase, for each subject. This score ranges from from -8 (all orthogonal) to 8 (all triangular). Recall that the s_SCALED score for an item is a numeric representation of the strategy-consistent response, scaled from -1 to +1 (see Section 4.1.4)\nMost importantly, the Scaled score gives us a way of quantitatively examining how correctly a participant interpreted the coordinate system across the entire set of items. It offers a more nuanced look into performance than absolute score.\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total Scaled Score)\"\nscaled.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(item_test_SCALED) %>% unlist() %>% favstats()\n) \nscaled.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total Scaled Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    -8 \n    -8.0 \n    -6.00 \n    6 \n    8 \n    -2.11 \n    6.69 \n    126 \n    0 \n  \n  \n    online \n    -8 \n    -7.5 \n    -5.75 \n    5 \n    8 \n    -2.32 \n    6.29 \n    204 \n    0 \n  \n  \n    combined \n    -8 \n    -8.0 \n    -6.00 \n    6 \n    8 \n    -2.24 \n    6.43 \n    330 \n    0 \n  \n\n\n\n\n\nFor in person collection, TEST phase scaled scores (n = 126) range from -8 to 1 with a mean score of (M = -2.11, SD = 6.69).\nFor online replication, TEST phase scaled scores (n = 204) range from -8 to 8 with a slightly lower mean score of (M = -2.32, SD = 6.29).\nWhen combined overall, TEST phase scaled scores (n = 330) range from -8 to 8 with a slightly lower mean score of (M = -2.24, SD = 6.44).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL SCALED\ngf_props(~item_test_SCALED, data = df_subjects) +\n  labs(x = \"total scaled score (test phase)\",\n       y = \"% of subjects\",\n       title = \"Distribution of TEST Scaled Score \",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_test_SCALED\",binwidth=1,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE) \nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) + \n  labs( title = \"Distribution of TEST Scaled Score\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"total scaled score (test phase)\", y = \"number of participants\") + \n theme_minimal() + theme(legend.position = \"blank\") \n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_test_SCALED,\n                        fill = pretty_condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_SCALED),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_SCALED, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of TEST Scaled Score \",\n    x = \"Condition\", y = \"Total Scaled Score (Test Phase)\") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nCODE\n#EASY STATS\nggbetweenstats(y = item_test_SCALED, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\nCODE\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(item_test_SCALED)) + \n  stat_ecdf(geom = \"step\") + \n  facet_grid(pretty_condition ~ pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — Test Phase Scaled Score\",\n        x = \"Test Phase Scaled Score [-8,8]\", \n        y = \"Cumulative Probability\") \n\n\n\n\n\nVisual inspection of this distribution suggests it is not normal, and perhaps perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).\n\n\nCODE\nmultimode::modetest(df_subjects$item_test_SCALED)\n\n\nWarning in multimode::modetest(df_subjects$item_test_SCALED): A modification of\nthe data was made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$item_test_SCALED\nExcess mass = 0.2, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\nn_modes = multimode::nmodes(df_subjects$item_test_SCALED, bw=2) #bw = 2questions/15 = 0.15%\nl_modes = multimode::locmodes(df_subjects$item_test_SCALED,mod0 =  n_modes, display = TRUE)\n\n\nWarning in multimode::locmodes(df_subjects$item_test_SCALED, mod0 = n_modes, :\nIf the density function has an unbounded support, artificial modes may have been\ncreated in the tails\n\n\n\n\n\nThe excess mass test for multimodality suggests the distribution is in fact multimodal (m = 0.1, p < 0.001), with two identifiable modes at -7.721 and 7.822, and an antimode at 1.93.\n\n\n\nFirst Item Scores\nNext we consider the response accuracy on just the first question of the graph comprehension task: a subject’s first exposure to the TM graph.\n\nFirst Item Absolute Score\n\n\nCODE\ntitle = \"Proportion of Correct Response on First Item (Lab)\"\nitem.contingency <- df_lab %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Response on First Item (Lab)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    0 \n    0.839 \n    0.703 \n    0.77 \n  \n  \n    1 \n    0.161 \n    0.297 \n    0.23 \n  \n  \n    Sum \n    1.000 \n    1.000 \n    1.00 \n  \n\n\n\n\n\nCODE\ntitle = \"Proportion of Correct Response on First Item (Online)\"\nitem.contingency <- df_online %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Response on First Item (Online)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    0 \n    0.875 \n    0.722 \n    0.794 \n  \n  \n    1 \n    0.125 \n    0.278 \n    0.206 \n  \n  \n    Sum \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\nCODE\ntitle = \"Proportion of Correct Response on First Item (Combined)\"\nitem.contingency <- df_subjects %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Response on First Item (Combined)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    0 \n    0.861 \n    0.715 \n    0.785 \n  \n  \n    1 \n    0.139 \n    0.285 \n    0.215 \n  \n  \n    Sum \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\nAcross data collection sessions, first-item accuracy is consistent across experimental conditions. Incorrect answers are far more frequent (78%) than correct answers (22%). Accuracy is somewhat improved in the IMPASSE condition, with roughly 28% of all IMPASSE-condition questions answered correctly, compared to only 14% in the CONTROL condition.\n\n\nCODE\n#PROPORTIONAL BAR CHART\ngf_props(~item_q1_NABS, data = df_subjects) +\n  labs(x = \"response accuracy\",\n       y = \"% subjects\",\n       title = \"Proportion of Correct Responses on First Item\",\n       subtitle=\"\")+\n  theme(legend.position = \"none\")+theme_ggdist()\n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(item_q1_NABS))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n  labs(x = \"response accuracy\",\n       title = \"Proportion of Correct Responses on First Item (by Modality and Condition)\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nCODE\n#MOSAIC PLOT\nvcd::mosaic(main=\"Proportion of Correct Responses on First Item\",\n            data = df_subjects, item_q1_NABS ~ pretty_condition, rot_labels=c(0,90,0,0), \n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\"))) \n\n\n\n\n\nCODE\n#STATSPLOT\nggbarstats(\n  x = item_q1_NABS,\n  y = pretty_condition, \n  data = df_subjects\n)\n\n\n\n\n\n\n\nFirst Item Scaled Score\nAt the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1. (note: we evaluate scaled_score on the first item rather than interpretation, because no orthogonal interpretation is available in the impasse condition)\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (First Item Scaled Score)\"\nfirstscaled.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats()\n) \nfirstscaled.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (First Item Scaled Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    -1 \n    -1 \n    -1 \n    0.5 \n    1 \n    -0.298 \n    0.849 \n    126 \n    0 \n  \n  \n    online \n    -1 \n    -1 \n    -1 \n    0.5 \n    1 \n    -0.287 \n    0.812 \n    204 \n    0 \n  \n  \n    combined \n    -1 \n    -1 \n    -1 \n    0.5 \n    1 \n    -0.291 \n    0.825 \n    330 \n    0 \n  \n\n\n\n\n\nFor in person collection, first item scaled scores (n = 126) range from -1 to 1 with a mean score of (M = -0.3, SD = 0.85).\nFor online replication, (online) first item scaled scores (n = 204) range from -1 to 1 with a slightly lower mean score of (M = -0.29, SD = 0.81).\nWhen combined overall, first item scaled scores (n = 330) range from -1 to 1 with a slightly lower mean score of (M = -0.29, SD = 0.83).\n\n\nCODE\n#GGFORMULA | PROPORTIONAL HISTOGRAM SUBJECT FIRST SCALED\ngf_props(~item_q1_SCALED, data = df_subjects) +\n  labs(x = \"scaled score (first item)\",\n       y = \"% of subjects\",\n       title = \"Distribution of First Item Scaled Score\",\n       subtitle = \"\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_q1_SCALED\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE) \nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) + \n  labs( title = \"Distribution of First Item Scaled Score (by Mode and Condition)\",\n        subtitle =\"Impasse condition yields more intermediate scores (indicating uncertainty)\",\n        x = \"scaled score (firt item) \", y = \"number of participants\") + \n  theme_minimal() + theme(legend.position = \"blank\") \n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(item_q1_SCALED))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n  labs(x = \"response accuracy\",\n       title = \"Type of Responses on First Item (by Modality and Condition)\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbarstats(\n  x = item_q1_SCALED,\n  y = pretty_condition, \n  data = df_subjects\n)\n\n\n\n\n\n\n\n\nInterpretation Scores\nNext we consider the the interpretations assigned to each response. For each response given by a participant to a question, we assign an interpretation label based on the interpretation the response most closely matches (see ?sec-scoring-interpretation).\n\n\nCODE\ntitle = \"Proportion of Interpretations Across Items Items By Condition (Lab)\"\nitem.contingency <- df_items %>% filter(mode == \"lab-synch\") %>% dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Interpretations Across Items Items By Condition (Lab)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    Orthogonal \n    0.297 \n    0.116 \n    0.414 \n  \n  \n    Satisfice \n    0.000 \n    0.028 \n    0.028 \n  \n  \n    frenzy \n    0.002 \n    0.005 \n    0.007 \n  \n  \n    ? \n    0.026 \n    0.053 \n    0.079 \n  \n  \n    reference \n    0.001 \n    0.004 \n    0.005 \n  \n  \n    blank \n    0.008 \n    0.034 \n    0.042 \n  \n  \n    both tri + orth \n    0.060 \n    0.056 \n    0.116 \n  \n  \n    Tversky \n    0.004 \n    0.017 \n    0.021 \n  \n  \n    Triangular \n    0.094 \n    0.195 \n    0.288 \n  \n  \n    Sum \n    0.492 \n    0.508 \n    1.000 \n  \n\n\n\n\n\nCODE\ntitle = \"Proportion of Interpretations Across Items Items By Condition (Online)\"\nitem.contingency <- df_items %>% filter(mode == \"asynch\") %>% dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Interpretations Across Items Items By Condition (Online)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    Orthogonal \n    0.260 \n    0.122 \n    0.382 \n  \n  \n    Satisfice \n    0.000 \n    0.024 \n    0.024 \n  \n  \n    frenzy \n    0.002 \n    0.001 \n    0.003 \n  \n  \n    ? \n    0.050 \n    0.066 \n    0.116 \n  \n  \n    reference \n    0.000 \n    0.002 \n    0.002 \n  \n  \n    blank \n    0.013 \n    0.055 \n    0.068 \n  \n  \n    both tri + orth \n    0.056 \n    0.061 \n    0.117 \n  \n  \n    Tversky \n    0.011 \n    0.023 \n    0.035 \n  \n  \n    Triangular \n    0.078 \n    0.175 \n    0.253 \n  \n  \n    Sum \n    0.471 \n    0.529 \n    1.000 \n  \n\n\n\n\n\nCODE\ntitle = \"Proportion of Interpretations Across Items Items By Condition (Combined)\"\nitem.contingency <- df_items %>%  dplyr::select(interpretation, pretty_condition) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Interpretations Across Items Items By Condition (Combined)\n \n  \n      \n    control \n    impasse \n    Sum \n  \n \n\n  \n    Orthogonal \n    0.274 \n    0.120 \n    0.394 \n  \n  \n    Satisfice \n    0.000 \n    0.025 \n    0.025 \n  \n  \n    frenzy \n    0.002 \n    0.003 \n    0.004 \n  \n  \n    ? \n    0.041 \n    0.061 \n    0.102 \n  \n  \n    reference \n    0.001 \n    0.002 \n    0.003 \n  \n  \n    blank \n    0.011 \n    0.047 \n    0.058 \n  \n  \n    both tri + orth \n    0.058 \n    0.059 \n    0.117 \n  \n  \n    Tversky \n    0.009 \n    0.021 \n    0.029 \n  \n  \n    Triangular \n    0.084 \n    0.183 \n    0.267 \n  \n  \n    Sum \n    0.479 \n    0.521 \n    1.000 \n  \n\n\n\n\n\n\n\nCODE\n#PROPORTIONAL BAR CHART\ngf_propsh(~interpretation, data = df_items, fill = ~pretty_condition) %>% \n  gf_facet_grid(pretty_condition~pretty_mode) +\n  labs(x = \"% of items\",\n       title = \"Proportion of Interpretations Across Items\",\n       subtitle=\"Impasse Condition yields shift from Orthogonal to alternative interpretations\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(interpretation))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~pretty_mode) + \n  labs(x = \"response accuracy\",\n       title = \"Response Types on All Items (by Modality and Condition)\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nCODE\n#MOSAIC PLOT\nvcd::mosaic(main=\"Proportion of Interpretations across Conditions\",\n            data = df_items, pretty_condition ~ interpretation, rot_labels=c(0,90,0,0),\n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\")))\n\n\n\n\n\nCODE\n#STATSPLOT\nggbarstats(\n  x = high_interpretation,\n  y = pretty_condition, \n  data = df_items\n)\n\n\n\n\n\n\n\nCumulative Task Performance\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#response-latency",
    "href": "analysis/SGC3A/3_sgc3A_description.html#response-latency",
    "title": "5  Description",
    "section": "RESPONSE LATENCY",
    "text": "RESPONSE LATENCY\n\nTime on Task\nHere we consider the time spent on the graph comprehension task portion of the study.\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_lab%>% dplyr::select(totaltime_m) %>% unlist()  %>%  favstats(),\n  \"online\"= df_online %>% dplyr::select(totaltime_m) %>% unlist() %>% favstats(),\n  \"combined\"= df_subjects %>% dplyr::select(totaltime_m) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of First Response Time (seconds)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of First Response Time (seconds)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    6.01 \n    10.50 \n    12.2 \n    14.4 \n    23.9 \n    12.8 \n    3.37 \n    126 \n    0 \n  \n  \n    online \n    2.91 \n    9.18 \n    11.5 \n    15.0 \n    111.0 \n    13.4 \n    9.21 \n    204 \n    0 \n  \n  \n    combined \n    2.91 \n    9.55 \n    12.0 \n    14.7 \n    111.0 \n    13.2 \n    7.53 \n    330 \n    0 \n  \n\n\n\n\n\nResponse time on the graph comprehension task for in person subjects (n = 126) ranged from 6.01 to 23.86 minutes with a mean duration of (M = 12.8, SD = 3.37).\nResponse time on the graph comprehension task for online replication subjects (n = 204) ranged from 2.91 to 111.02 minutes with a mean duration of (M = 13.37, SD = 9.21).\nResponse time on the graph comprehension task for combined subjects (n = 330) ranged from 2.91 to 111.02 minutes with a mean duration of (M = 13.16, SD = 7.53).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~totaltime_m, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of Task Time (minutes)\", subtitle = \"fit by gamma distribution\", x = \"Task Time (minutes)\", y = \"% items\")\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"totaltime_m\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n   labs(title=\"Distribution of Task Time (minutes)\", subtitle = \"fit by gamma distribution\", x = \"Task Time (minutes)\", y = \"% items\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nTime on First Item\nHere we consider the time spent on just the first individual item (first exposure to graph).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_lab%>% dplyr::select(item_q1_rt) %>% unlist()  %>%  favstats(),\n  \"online\"= df_online %>% dplyr::select(item_q1_rt) %>% unlist() %>% favstats(),\n  \"combined\"= df_subjects %>% dplyr::select(item_q1_rt) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of First Response Time (seconds)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of First Response Time (seconds)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    7.22 \n    26.6 \n    39.3 \n    52.2 \n    161 \n    44.5 \n    26.2 \n    126 \n    0 \n  \n  \n    online \n    4.84 \n    19.9 \n    31.0 \n    48.9 \n    306 \n    43.3 \n    41.3 \n    204 \n    0 \n  \n  \n    combined \n    4.84 \n    22.3 \n    34.0 \n    50.7 \n    306 \n    43.8 \n    36.2 \n    330 \n    0 \n  \n\n\n\n\n\nResponse time on the first item for in person subjects (n = 126) ranged from 7.22 to 161.36 minutes with a mean duration of (M = 44.53, SD = 26.22).\nResponse time on the first item for online replication subjects (n = 204) ranged from 4.84 to 305.94 minutes with a mean duration of (M = 43.32, SD = 41.27).\nResponse time on the first item for combined subjects (n = 330) ranged from 4.84 to 305.94 minutes with a mean duration of (M = 43.78, SD = 36.23).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~item_q1_rt, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of First Item Response Time (seconds)\", subtitle = \"fit by gamma distribution\", x = \"First Item Response Time (seconds)\", y = \"% items\")\n\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_q1_rt\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of First Item Response Time (seconds)\",\n        subtitle =\"\",\n        x = \"First Item Response Time (seconds)\", y = \"number of items\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#recode as boolean correct\ndf_subjects <- df_subjects %>% mutate(\n  item_q1_NABS = as.logical(item_q1_NABS)\n)\n\n##RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_q1_rt, color = item_q1_NABS) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.2, \n    adjust = .5, \n    width = .6, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .1\n  )) + \n  labs( title = \"Distribution of First Item Response Time (seconds)\",\n        subtitle =\"\",\n        y = \"First Item Response Time (s)\", x = \"Condition\") +\n  theme_ggdist() \n\n\n\n\n\nCODE\n# + theme(legend.position = \"blank\")\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n\n\n\n\nTime on Item\nHere we consider the time spent on an individual item (across all items).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_items %>% filter(mode == \"lab-synch\") %>% dplyr::select(rt_s) %>% unlist()  %>%  favstats(),\n  \"online\"= df_items %>% filter(mode == \"lab-synch\") %>% dplyr::select(rt_s) %>% unlist() %>% favstats(),\n  \"combined\"= df_items %>%   dplyr::select(rt_s) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of Item Response Latency (seconds)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Item Response Latency (seconds)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    1.264 \n    13.8 \n    24.9 \n    46.1 \n    336 \n    35.5 \n    33.1 \n    1890 \n    0 \n  \n  \n    online \n    1.264 \n    13.8 \n    24.9 \n    46.1 \n    336 \n    35.5 \n    33.1 \n    1890 \n    0 \n  \n  \n    combined \n    0.003 \n    12.5 \n    23.7 \n    43.9 \n    532 \n    35.2 \n    37.2 \n    4950 \n    0 \n  \n\n\n\n\n\nTime on an individual item for in person subjects (n = 1890) ranged from 1.26 to 336.03 minutes with a mean duration of (M = 35.47, SD = 33.12).\nTime on an individual item for online replication subjects (n = 1890) ranged from 1.26 to 336.03 minutes with a mean duration of (M = 35.47, SD = 33.12).\nTime on an individual item for combined subjects (n = 4950) ranged from 0 to 531.52 minutes with a mean duration of (M = 35.24, SD = 37.21).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~rt_s, data = df_items) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of Item Response Time (seconds)\", \n       subtitle = \"fit by gamma distribution\", x = \"Item Response Time (seconds)\", y = \"% items\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_items, x = \"rt_s\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of Item Response Time (seconds)\",\n        subtitle =\"\",\n        x = \"Item Response Time (seconds)\", y = \"number of items\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#recode as boolean correct\ndf_items <- df_items %>% mutate(\n  score_niceABS = as.logical(score_niceABS)\n)\n\n##RAINCLOUD USING GGDISTR\nggplot(df_items, aes(x = pretty_condition, y = rt_s, color = score_niceABS) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    # position = position_dodgejust(),\n    justification = 1.5, \n    # adjust = .5, \n    width = .5, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA,\n    position = position_dodge2()\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitterdodge(\n      # seed = 1,\n      dodge.width = 0.5,\n      jitter.width = 0.075\n  )) +\n  labs( title = \"Distribution of Item Response Time (seconds)\",\n        subtitle =\"\",\n        y = \"Item Response Time (s)\", x = \"Condition\") +\n  theme_ggdist() \n\n\n\n\n\nCODE\n# + theme(legend.position = \"blank\")\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n\n\n\n\nTime on SCAFFOLD Phase\nHere we consider just the time spent on the first five items of the task (the scaffold phase).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(item_scaffold_rt) %>% unlist()  %>%  favstats(),\n  \"online\"= df_online %>% dplyr::select(item_scaffold_rt) %>% unlist() %>% favstats(),\n  \"combined\"= df_subjects %>% dplyr::select(item_scaffold_rt) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of SCAFFOLD Phase Response Latency (minutes)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of SCAFFOLD Phase Response Latency (minutes)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    1.235 \n    2.66 \n    3.71 \n    4.92 \n    11.1 \n    4.03 \n    1.88 \n    126 \n    0 \n  \n  \n    online \n    0.614 \n    2.10 \n    2.92 \n    4.31 \n    15.4 \n    3.52 \n    2.26 \n    204 \n    0 \n  \n  \n    combined \n    0.614 \n    2.29 \n    3.25 \n    4.58 \n    15.4 \n    3.72 \n    2.13 \n    330 \n    0 \n  \n\n\n\n\n\nTotal time on SCAFFOLD phase for in person subjects (n = 126) ranged from 1.24 to 11.1 minutes with a mean duration of (M = 4.03, SD = 1.88).\nTotal time on SCAFFOLD phase for online replication subjects (n = 204) ranged from 0.61 to 15.39 minutes with a mean duration of (M = 3.52, SD = 2.26).\nTotal time on SCAFFOLD phase for combined subjects (n = 330) ranged from 0.61 to 15.39 minutes with a mean duration of (M = 3.72, SD = 2.13).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~item_scaffold_rt, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of SCAFFOLD Phase Response Time (minutes)\", subtitle = \"fit by gamma distribution\", x = \"Scaffold Phase Time (minutes)\", y = \"% subjects\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_scaffold_rt\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of SCAFFOLD Phase Response Time (minutes)\",\n        subtitle =\"\",\n        x = \"Scaffold Phase Time (minutes)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_scaffold_rt, fill = pretty_condition)) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.2, \n    adjust = .5, \n    width = .6, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_scaffold_rt),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_scaffold_rt, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  ))+ labs( title = \"Distribution of SCAFFOLD Phase Response Time (minutes)\",\n        subtitle =\"\",\n        y = \"Total Study Time (minutes)\", x = \"Condition\") +\n  theme_ggdist() + theme(legend.position = \"blank\") #+\n\n\n\n\n\nCODE\n  # coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\nTime on TEST Phase\nHere we consider just the time spent on the remaining eight discriminant items of the task (the test phase).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(item_test_rt) %>% unlist()  %>%  favstats(),\n  \"online\"= df_online %>% dplyr::select(item_test_rt) %>% unlist() %>% favstats(),\n  \"combined\"= df_subjects %>% dplyr::select(item_test_rt) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of TEST Phase Response Latency (minutes)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of TEST Phase Response Latency (minutes)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    1.022 \n    2.97 \n    3.75 \n    4.76 \n    10.8 \n    4.00 \n    1.37 \n    126 \n    0 \n  \n  \n    online \n    0.703 \n    3.10 \n    3.89 \n    5.17 \n    13.5 \n    4.41 \n    2.24 \n    204 \n    0 \n  \n  \n    combined \n    0.703 \n    3.03 \n    3.80 \n    4.99 \n    13.5 \n    4.26 \n    1.96 \n    330 \n    0 \n  \n\n\n\n\n\nTotal time on TEST phase for in person subjects (n = 126) ranged from 1.02 to 10.85 minutes with a mean duration of (M = 4, SD = 1.37).\nTotal time on TEST phase for online replication subjects (n = 204) ranged from 0.7 to 13.49 minutes with a mean duration of (M = 4.41, SD = 2.24).\nTotal time on TEST phase for combined subjects (n = 330) ranged from 0.7 to 13.49 minutes with a mean duration of (M = 4.26, SD = 1.96).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~item_test_rt, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of TEST Phase Response Time (minutes)\", subtitle = \"fit by gamma distribution\", x = \"Test Phase Time (minutes)\", y = \"% subjects\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_test_rt\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of TEST Phase Response Time (minutes)\",\n        subtitle =\"\",\n        x = \"Test Phase Time (minutes)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_test_rt, fill = pretty_condition)) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.2, \n    adjust = .5, \n    width = .6, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_rt),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = item_test_rt, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  ))+ \n  labs( title = \"Distribution of TEST Phase Response Time (minutes)\",\n        subtitle =\"\",\n        y = \"Total Study Time (minutes)\", x = \"Condition\") +\n  theme_ggdist() + theme(legend.position = \"blank\") #+\n\n\n\n\n\nCODE\n  # coord_cartesian(xlim = c(0.5, NA), clip = \"off\")"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#exploring-relationships",
    "href": "analysis/SGC3A/3_sgc3A_description.html#exploring-relationships",
    "title": "5  Description",
    "section": "EXPLORING RELATIONSHIPS",
    "text": "EXPLORING RELATIONSHIPS\n\nACCURACY (VS) LATENCY\n\nTotal Task\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ rt_m, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by TOTAL Item Response Time\",\n    subtitle = \"\", \n    x = \"Total Item Response Time (minutes)\", y = \"Total Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ item_avg_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by MEAN Item Response Time\",\n    subtitle = \"\", \n    x = \"Average Item Response Time (seconds)\", y = \"Total Scaled Score\"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ item_max_rt, data = df_subjects %>% filter(item_max_rt < 400), alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by MAX Item Response Time\",\n    subtitle = \"\", \n    x = \"MAX Item Response Time (s)\", y = \"Total Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#NOTE: LOG transforms of the RT do not yield linear relationships\n\n\n\n\nPhase Specific\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by SCAFFOLD PHASE Item Response Time\",\n    subtitle = \"\", \n    x = \"SCAFFOLD PHASE Item Response Time (minutes)\", y = \"TOTAL Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( item_scaffold_NABS ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"SCAFFOLD (Scaled) Score by SCAFFOLD PHASE Item Response Time\",\n    subtitle = \"\", \n    x = \"SCAFFOLD PHASE Item Response Time (minutes)\", y = \"SCAFFOLD Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( item_test_NABS ~ item_scaffold_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"TEST (Scaled) Score by SCAFFOLD PHASE Item Response Time\",\n    subtitle = \"\", \n    x = \"SCAFFOLD PHASE Item Response Time (minutes)\", y = \"TEST Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( item_test_NABS ~ item_avg_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"TEST (Scaled) Score by SCAFFOLD PHASE Item Response Time\",\n    subtitle = \"\", \n    x = \"AVERAGE Item Response Time (minutes)\", y = \"TEST Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#NOTE: LOG transforms of the RT do not yield linear relationships\n\n\n\n\nAverage Item RT by Accuracy\n\n\nCODE\nq.stats <- df_items %>% filter(q != 6) %>% dplyr::group_by(q, pretty_condition, score_niceABS) %>% dplyr::summarise(\n  m = mean(rt_s),\n  sd = sd(rt_s),\n  sd = tidyr::replace_na(sd,0),\n  lo = m-sd/2,\n  hi = m+sd/2,\n  group = paste(pretty_condition,\"-\",score_niceABS)\n)\n\ngf_line( m ~ q, group = ~group,  color = ~as.factor(score_niceABS),data = q.stats) %>% \n  gf_point() %>% \n  gf_ribbon(lo+hi~q) %>% \n  gf_facet_wrap(~pretty_condition) + scale_color_manual(values=c(\"red\",\"green\")) + \n  labs(title = \"Average Item Response Time by Absolute Score\",\n       subtitle = \"Correct responses are generally faster [computational efficiency] except on Q1 [learning]\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Correct Response\")\n\n\n\n\n\nCODE\n#GGDIST LINERIBBON\n# df_items %>%\n#   ggplot(aes(y = rt_s, x = q,  fill = pretty_condition)) +\n#   stat_lineribbon(alpha = 1/4, point_interval = \"mean_qi\") + facet_wrap(~pretty_condition)\n\n\n\n\nCODE\nq.stats <- df_items %>% filter(q %nin% c(6,9)) %>% dplyr::group_by(q, pretty_condition, interpretation) %>% dplyr::summarise(\n  m = mean(rt_s),\n  sd = sd(rt_s),\n  sd = tidyr::replace_na(sd,0),\n  lo = m-sd/2,\n  hi = m+sd/2,\n  group = paste(pretty_condition,\"-\",score_SCALED)\n)\n\ngf_line( m ~ as.factor(q), group = ~group,  color = ~interpretation,data = q.stats) %>% \n  gf_point() %>% \n  gf_ribbon(lo+hi~as.factor(q)) %>% \n  gf_facet_grid(interpretation~pretty_condition) + #+ scale_color_manual(values=c(\"red\",\"green\")) + \n  labs(title = \"Average Item Response Time by Interpretation\",\n       subtitle = \"Correct responses are generally faster [computational efficiency] except on Q1 [learning]\",\n       caption=\"NOTE: Points with no ribbon indicate singular response\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Interpretation\")\n\n\n\n\n\nCODE\n#GGDIST LINERIBBON\ndf_items %>% filter(q %nin% c(6,9)) %>% mutate( interpretation = recode(interpretation, \"reference\" = \"blank\", \"frenzy\" = \"?\")) %>% \n  ggplot(aes(y = rt_s, x = q,  fill = interpretation)) +\n  stat_lineribbon(alpha = 1/4, point_interval = \"mean_qi\") + \n  facet_grid(interpretation ~ pretty_condition) + \n  labs( title = \"Average Response Time by Question Interpretation\", x = \"Question\", y=\"Averate Item Response Time (s)\")"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#replication-check",
    "href": "analysis/SGC3A/3_sgc3A_description.html#replication-check",
    "title": "5  Description",
    "section": "REPLICATION CHECK",
    "text": "REPLICATION CHECK\n\nData Collection Mode on Absolute Score\nDoes Mode Change Effect of Condition on Score?\nTo verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of ABSOLUTE SCORE for each condition, and examine whether data collection modality is a significant predictor of variance in absolute score\n\n\nCODE\npaste(\"Two Sample T-Test for S_ABS LAB vs. ONLINE control condition\")\n\n\n[1] \"Two Sample T-Test for S_ABS LAB vs. ONLINE control condition\"\n\n\nCODE\nt.test(data = df_subjects %>% filter(condition == 111), s_ABS ~ mode )\n\n\n\n    Welch Two Sample t-test\n\ndata:  s_ABS by mode\nt = 0.5, df = 120, p-value = 0.6\nalternative hypothesis: true difference in means between group lab-synch and group asynch is not equal to 0\n95 percent confidence interval:\n -1.09  1.84\nsample estimates:\nmean in group lab-synch    mean in group asynch \n                   2.68                    2.30 \n\n\nCODE\npaste(\"Two Sample T-Test for S_ABS LAB vs. ONLINE impasse condition\")\n\n\n[1] \"Two Sample T-Test for S_ABS LAB vs. ONLINE impasse condition\"\n\n\nCODE\nt.test(data = df_subjects %>% filter(condition == 121), s_ABS ~ mode )\n\n\n\n    Welch Two Sample t-test\n\ndata:  s_ABS by mode\nt = 1, df = 135, p-value = 0.3\nalternative hypothesis: true difference in means between group lab-synch and group asynch is not equal to 0\n95 percent confidence interval:\n -0.727  2.435\nsample estimates:\nmean in group lab-synch    mean in group asynch \n                   5.44                    4.58 \n\n\nCODE\npaste(\"OLS Linear Regression Predicting Absolute Score by Data Collection Mode\")\n\n\n[1] \"OLS Linear Regression Predicting Absolute Score by Data Collection Mode\"\n\n\nCODE\nsummary(lm(data = df_subjects, formula = s_ABS ~ mode ))\n\n\n\nCall:\nlm(formula = s_ABS ~ mode, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.08  -3.51  -2.51   4.49   9.49 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     4.08       0.44    9.27   <2e-16 ***\nmodeasynch     -0.57       0.56   -1.02     0.31    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.94 on 328 degrees of freedom\nMultiple R-squared:  0.00314,   Adjusted R-squared:  0.000105 \nF-statistic: 1.03 on 1 and 328 DF,  p-value: 0.31\n\n\nBoth t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative absolute score indicates that data collection mode is not a significant predictor, explaining only 0.01% of variance in absolute score, F(1,328) = 1.03, p > 0.05.\n\n\n\n\n\n\nDecision\n\n\n\nIt is reasonable to infer that data from both in-person and remote studies arise from the same data generating process.\n\n\n\n\nData Collection Mode on Cumulative Score\nAre the by-condition group means significantly different by data collection modality?\nTo verify that the data collected in the lab and remotely online are comparable, we perform a t-test on group means of SCALED SCORE for each condition.\n\n\nCODE\npaste(\"Two Sample T-Test for s_SCALED LAB vs. ONLINE control condition\")\n\n\n[1] \"Two Sample T-Test for s_SCALED LAB vs. ONLINE control condition\"\n\n\nCODE\nt.test(data = df_subjects %>% filter(condition == 111), s_SCALED ~ mode )\n\n\n\n    Welch Two Sample t-test\n\ndata:  s_SCALED by mode\nt = -0.1, df = 117, p-value = 0.9\nalternative hypothesis: true difference in means between group lab-synch and group asynch is not equal to 0\n95 percent confidence interval:\n -3.15  2.83\nsample estimates:\nmean in group lab-synch    mean in group asynch \n                  -6.52                   -6.36 \n\n\nCODE\npaste(\"Two Sample T-Test for s_SCALED LAB vs. ONLINE impasse condition\")\n\n\n[1] \"Two Sample T-Test for s_SCALED LAB vs. ONLINE impasse condition\"\n\n\nCODE\nt.test(data = df_subjects %>% filter(condition == 121), s_SCALED ~ mode )\n\n\n\n    Welch Two Sample t-test\n\ndata:  s_SCALED by mode\nt = 0.5, df = 130, p-value = 0.6\nalternative hypothesis: true difference in means between group lab-synch and group asynch is not equal to 0\n95 percent confidence interval:\n -2.08  3.49\nsample estimates:\nmean in group lab-synch    mean in group asynch \n                  1.008                   0.306 \n\n\nCODE\npaste(\"OLS Linear Regression Predicting Scaled Score by Data Collection Mode\")\n\n\n[1] \"OLS Linear Regression Predicting Scaled Score by Data Collection Mode\"\n\n\nCODE\nsummary(lm(data = df_subjects, formula = s_SCALED ~ mode ))\n\n\n\nCall:\nlm(formula = s_SCALED ~ mode, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-10.30  -7.80  -4.42  10.33  15.83 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   -2.698      0.853   -3.16   0.0017 **\nmodeasynch    -0.135      1.085   -0.12   0.9011   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.58 on 328 degrees of freedom\nMultiple R-squared:  4.71e-05,  Adjusted R-squared:  -0.003 \nF-statistic: 0.0155 on 1 and 328 DF,  p-value: 0.901\n\n\nBoth t-tests are non-significant with 95% confidence intervals including 0. Further, an OLS linear regression model predicting cumulative scaled score indicates that data collection mode is not a significant predictor, explaining less than 0.001% of variance in absolute score, F(1,328) = 0.0078, p > 0.05.\n\n\n\n\n\n\nDecision\n\n\n\nIt is reasonable to infer that data from both in-person and remote studies arise from the same data generating process."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#archive",
    "href": "analysis/SGC3A/3_sgc3A_description.html#archive",
    "title": "5  Description",
    "section": "ARCHIVE",
    "text": "ARCHIVE\nSample ridgeplot code\n\n\nCODE\n#RIDGEPLOT\n# ggplot(data = df_subjects, aes(x = s_NABS, y = mode)) +\n#   geom_density_ridges() + xlim(0,13)+\n#   facet_wrap(~condition, labeller = label_both) +\n# labs(x = \"total number correct \",\n# y = \"proportion of subjects\",\n#        title = \"Subject Cumulative Score (Absolute)\",\n#        subtitle = \"Score distributions are comparable across modalities and different across conditions\") +\n#   theme_minimal()\n\n\n\nWhat Kind of Distribution is Total Score?\nWhat kind of distribution is the Total Absolute Score (TEST Phase) data? We use the fitdistrplus package to compare the distribution of this variable to a variety of probability distribution families. First, we transform the # correct items to % correct items by dividing it by the total number of items (n = 8).\n\n\nCODE\n#describe the distribution\ndescdist(data = df_subjects$item_test_NABS/8, discrete = FALSE, boot = 1000)\n\n\n\n\n\nsummary statistics\n------\nmin:  0   max:  1 \nmedian:  0 \nmean:  0.287 \nestimated sd:  0.405 \nestimated skewness:  0.876 \nestimated kurtosis:  1.93 \n\n\nCODE\nprint(\"FIT A NORMAL DISTRIBUTION\")\n\n\n[1] \"FIT A NORMAL DISTRIBUTION\"\n\n\nCODE\nnormal_ = fitdist(df_subjects$item_test_NABS/8,\"norm\")\nplot(normal_)\n\n\n\n\n\nCODE\nprint(\"FIT A BETA DISTRIBUTION\")\n\n\n[1] \"FIT A BETA DISTRIBUTION\"\n\n\nCODE\nbeta_ = fitdist(df_subjects$item_test_NABS/8,\"beta\", method=\"mme\" )\nplot(beta_)\n\n\n\n\n\nCODE\nsummary(beta_)\n\n\nFitting of the distribution ' beta ' by matching moments \nParameters : \n       estimate\nshape1   0.0721\nshape2   0.1786\nLoglikelihood:  Inf   AIC:  -Inf   BIC:  -Inf \n\n\nInterpreting the Cullen and Frey graph, it appears that number percentage of correct responses per subject may follow a beta distribution (u-shape tpe). If we fit this variable using both a normal and beta distribution (using method of moments), it appears that the beta distribution provides a much better fit. The parameter estimates for the beta distribution are: shape1 = 0.072, shape2 = 0.179. The beta distribution is a flexible distribution insofar as it can model a wide range of shapes with its two parameters. TODO: HOW might this be applied to the total score data?\nAnalysis Notes - This distribution is very bimodal, so OLS linear regression estimating means may not be informative, as the mean actually falls near the location of the anitmode (least common value) - Should investigate log transform to see if residuals of LM will be normal (no) - Should investigate beta regression\n\n\nWhole Task Scores\n\nAbsolute Score\nTotal Scores that include both Scaffolding Phase as well as Test Phase performance.\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total Absolute Score)\"\nabs.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(s_NABS) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(s_NABS) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(s_NABS) %>% unlist() %>% favstats()\n) \nabs.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    0 \n    0 \n    1 \n    9.00 \n    13 \n    4.11 \n    5.09 \n    126 \n    0 \n  \n  \n    online \n    0 \n    0 \n    1 \n    8.00 \n    13 \n    3.52 \n    4.89 \n    204 \n    0 \n  \n  \n    combined \n    0 \n    0 \n    1 \n    8.75 \n    13 \n    3.75 \n    4.97 \n    330 \n    0 \n  \n\n\n\n\n\nFor in person collection, total absolute scores (n = 126) range from 0 to 13 with a mean score of (M = 4.11, SD = 5.09).\nFor online replication, (online) total absolute accuracy scores (n = 204) range from 0 to 13 with a slightly lower mean score of (M = 3.52, SD = 4.89).\nWhen combined overall, total absolute accuracy scores (n = 330) range from 0 to 13 with a slightly lower mean score of (M = 3.75, SD = 4.97).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE\n  gf_props(~s_NABS, data = df_subjects) + \n  labs(x = \"number of correct responses\",\n       y = \"% of subjects\",\n       title = \"Distribution of Task Absolute Score\",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") + \n  theme_minimal()\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"s_NABS\", binwidth = 1,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) +\n  labs( title = \"Distribution of Task Absolute Score (by Mode and Condition)\",\n        subtitle =\"Pattern of response is the same across data collection modes but differs by condition\",\n        x = \"Total Absolute Score\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = s_NABS, fill = pretty_condition)) + \n  ggdist::stat_halfeye(\n    adjust = .5, \n    width = .6, \n    .width = 0, \n    justification = -.3, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter(\n      seed = 1, width = .1\n    )\n  ) + labs(\n    title = \"Distribution of Task Absolute Score\",\n    x = \"Condition\", y = \"Total Absolute Score\"\n  ) + theme_ggdist() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n\n\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(s_NABS)) + \n  stat_ecdf(geom = \"step\") + \n  facet_grid(pretty_condition ~ pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — Task Absolute Score\",\n        x = \"Task Absolute Score [0,13]\", \n        y = \"Cumulative Probability\") + theme_minimal()\n\n\n\n\n\nVisual inspection of this distribution suggests it is not normal, and likely bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018). TODO REFERENCE\n\n\nCODE\nmultimode::modetest(df_subjects$s_NABS)\n\n\nWarning in multimode::modetest(df_subjects$s_NABS): A modification of the data\nwas made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$s_NABS\nExcess mass = 0.1, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\nn_modes = multimode::nmodes(df_subjects$s_NABS, bw=2) #bw = 2questions/15 = 0.15%\nl_modes = multimode::locmodes(df_subjects$s_NABS,mod0 =  n_modes, display = TRUE)\n\n\nWarning in multimode::locmodes(df_subjects$s_NABS, mod0 = n_modes, display =\nTRUE): If the density function has an unbounded support, artificial modes may\nhave been created in the tails\n\n\n\n\n\nThe excess mass test for multimodality suggests the distribution is infact multimodal (m = 0.1, p < 0.001), with two identifiable modes at 0.26 and 12.261, and an antimode at 6.985.\n\n\n\n\n\n\nNote\n\n\n\nCondition appears (through visual inspection) to yield a positive influence on Total Absolute Score (across the entire task), across data collection modalities.\n\n\n\n\nScaled Score\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total Scaled Score)\"\nscaled.stats <- rbind(\n  \"lab\"= df_lab %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats(),\n  \"online\" = df_online %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats(),\n  \"combined\" = df_subjects %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats()\n) \nscaled.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total Scaled Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    -13 \n    -12.0 \n    -7.50 \n    8.75 \n    13 \n    -2.70 \n    10.08 \n    126 \n    0 \n  \n  \n    online \n    -13 \n    -10.0 \n    -7.00 \n    6.62 \n    13 \n    -2.83 \n    9.26 \n    204 \n    0 \n  \n  \n    combined \n    -13 \n    -10.5 \n    -7.25 \n    7.50 \n    13 \n    -2.78 \n    9.56 \n    330 \n    0 \n  \n\n\n\n\n\nFor in person collection, total scaled scores (n = 126) range from -13 to 13 with a mean score of (M = -2.7, SD = 10.08).\nFor online replication, total scaled scores (n = 204) range from -13 to 13 with a slightly lower mean score of (M = -2.83, SD = 9.26).\nWhen combined overall, total scaled scores (n = 330) range from -13 to 13 with a slightly lower mean score of (M = -2.78, SD = 9.56).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL SCALED\ngf_props(~s_SCALED, data = df_subjects) +\n  labs(x = \"total scaled score\",\n       y = \"% of subjects\",\n       title = \"Distribution of Total Scaled Score\",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") + \n  theme_minimal()\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"s_SCALED\",binwidth=1,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE) \nfacet(p, facet.by=c(\"pretty_condition\",\"pretty_mode\")) + \n  labs( title = \"Distribution of Total Scaled Score (by Condition and Mode)\",\n        subtitle =\"Pattern of response is similar across data collection modes but differs by condition\",\n        x = \"total scaled score\", y = \"number of participants\") + \n  theme_minimal() + theme(legend.position = \"blank\") \n\n\n\n\n\nCODE\n##RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = s_SCALED, fill = pretty_condition)) + \n  ggdist::stat_halfeye(\n    adjust = .5, \n    width = .6, \n    .width = 0, \n    justification = -.3, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter(\n      seed = 1, width = .1\n    )\n  ) + labs(\n    title = \"Distribution of Task Scaled Score \",\n    x = \"Condition\", y = \"Total Scaled Score\"\n  ) + theme_ggdist() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(s_SCALED)) + \n  stat_ecdf(geom = \"step\") + \n  facet_grid(pretty_condition ~ pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — Task Scaled Score\",\n        x = \"Task Scaled Score [-13, 13]\", \n        y = \"Cumulative Probability\") + theme_minimal()\n\n\n\n\n\nVisual inspection of this distribution suggests it is not normal, and perhaps perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).\n\n\nCODE\nmultimode::modetest(df_subjects$s_SCALED)\n\n\nWarning in multimode::modetest(df_subjects$s_SCALED): A modification of the data\nwas made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$s_SCALED\nExcess mass = 0.1, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\nn_modes = multimode::nmodes(df_subjects$s_SCALED, bw=2) #bw = 2questions/15 = 0.15%\nl_modes = multimode::locmodes(df_subjects$s_SCALED,mod0 =  n_modes, display = TRUE)\n\n\nWarning in multimode::locmodes(df_subjects$s_SCALED, mod0 = n_modes, display =\nTRUE): If the density function has an unbounded support, artificial modes may\nhave been created in the tails\n\n\n\n\n\nThe excess mass test for multimodality suggests the distribution is in fact multimodal (m = 0.1, p < 0.001), with two identifiable modes at -11.195 and 12.103, and an antimode at 2.942.\nAnalysis Notes - As with absolute score, the distribution of scaled score is very bimodal - Same need to investigate transformations and alternative distributions for regression\n\n\n\n\n\n\nNote\n\n\n\nCondition appears (through visual inspection) to yield a positive influence on Total Scaled Score across data collection modalities.\n\n\n\n\n\nItem Level Scores\n\nItem Absolute Score\nWhole Task Accuracy summarized over items rather than subjects\n\n\nCODE\nx <- df_items %>% mutate(score = as.logical(score_ABS))\n\ntitle = \"Proportion of Correct Items By Condition (Lab)\"\n\nitem.contingency <- df_items %>% filter(mode == \"lab-synch\") %>% dplyr::select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Items By Condition (Lab)\n \n  \n      \n    111 \n    121 \n    Sum \n  \n \n\n  \n    0 \n    0.344 \n    0.268 \n    0.613 \n  \n  \n    1 \n    0.148 \n    0.240 \n    0.387 \n  \n  \n    Sum \n    0.492 \n    0.508 \n    1.000 \n  \n\n\n\n\n\nCODE\ntitle = \"Proportion of Correct Items By Condition (Online)\"\nitem.contingency <- df_items %>% filter(mode == \"asynch\") %>% dplyr::select(score_ABS, condition) %>% table() %>% prop.table() %>% addmargins()\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Items By Condition (Online)\n \n  \n      \n    111 \n    121 \n    Sum \n  \n \n\n  \n    0 \n    0.342 \n    0.307 \n    0.649 \n  \n  \n    1 \n    0.128 \n    0.223 \n    0.351 \n  \n  \n    Sum \n    0.471 \n    0.529 \n    1.000 \n  \n\n\n\n\n\n\n\nCODE\n#VISUALIZE distribution of response accuracy across ITEMS\n\n#HISTOGRAM\nstats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_niceABS))\ngf_props(~score_niceABS, data = df_items) %>% \n  gf_facet_grid(condition~mode, labeller = label_both) +\n  labs(x = \"Item Absolute Score\",\n       title = \"Item Absolute Score\",\n       subtitle=\"Across modalities, the impasse condition yielded more correct responses\")+\n  theme_minimal()\n\n\n\n\n\n\n\nItem Scaled Score\nAt the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1.\n\n\nCODE\ntitle = \"Descriptive Statistics of Item Response Accuracy (Scaled Score)\"\nscaled.stats.items <- rbind(\n  \"lab\"= df_items %>% filter(mode == 'lab-synch') %>% dplyr::select(score_SCALED) %>% unlist() %>% favstats(),\n  \"online\" = df_items %>% filter(mode == \"asynch\") %>% dplyr::select(score_SCALED) %>% unlist() %>% favstats()\n) \nscaled.stats.items %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Item Response Accuracy (Scaled Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    -1 \n    -1 \n    -0.5 \n    1 \n    1 \n    -0.128 \n    0.877 \n    1890 \n    0 \n  \n  \n    online \n    -1 \n    -1 \n    -0.5 \n    1 \n    1 \n    -0.136 \n    0.842 \n    3060 \n    0 \n  \n\n\n\n\n\n\n\nCODE\n#VISUALIZE distribution of response accuracy across ITEMS\n\n#HISTOGRAM\nstats = df_items %>% group_by(condition, mode) %>% dplyr::summarise(mean = mean(score_SCALED))\ngf_props(~score_SCALED, data = df_items) %>% \n  gf_facet_grid(condition~mode, labeller = label_both) %>% \n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"Scaled Score for Item\",\n       y = \"Proportion of Items\",\n       title = \"Distribution of Accuracy per Item (Scale Score)\",\n       subtitle=\"The impasse condition shifts density toward the positive score\")+\n  theme_minimal()"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_description.html#resources",
    "href": "analysis/SGC3A/3_sgc3A_description.html#resources",
    "title": "5  Description",
    "section": "RESOURCES",
    "text": "RESOURCES\n\nhttps://rpkgs.datanovia.com/ggpubr/reference/index.html\nAppropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/)]{style=“color: red;”}.\nEspecially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data\n\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] forcats_0.5.1      stringr_1.4.0      purrr_0.3.4        readr_2.1.2       \n [5] tidyr_1.2.0        tibble_3.1.7       tidyverse_1.3.1    performance_0.9.1 \n [9] fitdistrplus_1.1-8 MASS_7.3-57        multimode_1.5      ggeasy_0.1.3      \n[13] ggstatsplot_0.9.3  ggdist_3.1.1       ggpubr_0.4.0       vcd_1.4-10        \n[17] kableExtra_1.3.4   mosaic_1.8.3       ggridges_0.5.3     mosaicData_0.20.2 \n[21] ggformula_0.10.1   ggstance_0.3.5     dplyr_1.0.9        Matrix_1.4-1      \n[25] Hmisc_4.7-0        ggplot2_3.3.6      Formula_1.2-4      survival_3.3-1    \n[29] lattice_0.20-45   \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.4.0           backports_1.4.1        systemfonts_1.0.4     \n  [4] plyr_1.8.7             splines_4.2.1          crosstalk_1.2.0       \n  [7] leaflet_2.1.1          TH.data_1.1-1          digest_0.6.29         \n [10] htmltools_0.5.2        fansi_1.0.3            magrittr_2.0.3        \n [13] checkmate_2.1.0        paletteer_1.4.0        cluster_2.1.3         \n [16] ks_1.13.5              tzdb_0.3.0             mosaicCore_0.9.0      \n [19] modelr_0.1.8           vroom_1.5.7            sandwich_3.0-2        \n [22] svglite_2.1.0          jpeg_0.1-9             colorspace_2.0-3      \n [25] rvest_1.0.2            ggrepel_0.9.1          haven_2.5.0           \n [28] xfun_0.31              prismatic_1.1.0        crayon_1.5.1          \n [31] jsonlite_1.8.0         zeallot_0.1.0          zoo_1.8-10            \n [34] glue_1.6.2             polyclip_1.10-0        gtable_0.3.0          \n [37] emmeans_1.7.5          MatrixModels_0.5-0     webshot_0.5.3         \n [40] statsExpressions_1.3.2 distributional_0.3.0   car_3.1-0             \n [43] abind_1.4-5            scales_1.2.0           mvtnorm_1.1-3         \n [46] DBI_1.1.3              rstatix_0.7.0          Rcpp_1.0.8.3          \n [49] viridisLite_0.4.0      xtable_1.8-4           htmlTable_2.4.0       \n [52] bit_4.0.4              mclust_5.4.10          foreign_0.8-82        \n [55] datawizard_0.4.1       htmlwidgets_1.5.4      httr_1.4.3            \n [58] RColorBrewer_1.1-3     ellipsis_0.3.2         pkgconfig_2.0.3       \n [61] farver_2.1.0           dbplyr_2.2.1           nnet_7.3-17           \n [64] utf8_1.2.2             effectsize_0.7.0       labeling_0.4.2        \n [67] tidyselect_1.1.2       rlang_1.0.3            cellranger_1.1.0      \n [70] munsell_0.5.0          tools_4.2.1            cli_3.3.0             \n [73] generics_0.1.2         broom_0.8.0            evaluate_0.15         \n [76] fastmap_1.1.0          ggdendro_0.1.23        yaml_2.3.5            \n [79] rematch2_2.1.2         bit64_4.0.5            fs_1.5.2              \n [82] knitr_1.39             rootSolve_1.8.2.3      pbapply_1.5-0         \n [85] pracma_2.3.8           xml2_1.3.3             correlation_0.8.1     \n [88] compiler_4.2.1         rstudioapi_0.13        png_0.1-7             \n [91] ggsignif_0.6.3         reprex_2.0.1           tweenr_1.0.2          \n [94] stringi_1.7.6          highr_0.9              parameters_0.18.1     \n [97] vctrs_0.4.1            pillar_1.7.0           lifecycle_1.0.1       \n[100] lmtest_0.9-40          estimability_1.4       data.table_1.14.2     \n[103] insight_0.18.0         patchwork_1.1.1        R6_2.5.1              \n[106] latticeExtra_0.6-29    KernSmooth_2.23-20     gridExtra_2.3         \n[109] BayesFactor_0.9.12-4.4 codetools_0.2-18       boot_1.3-28           \n[112] assertthat_0.2.1       withr_2.5.0            multcomp_1.4-19       \n[115] parallel_4.2.1         diptest_0.76-0         bayestestR_0.12.1     \n[118] hms_1.1.1              rpart_4.1.16           labelled_2.9.1        \n[121] coda_0.19-4            rmarkdown_2.14         carData_3.0-5         \n[124] ggforce_0.3.3          lubridate_1.8.0        base64enc_0.1-3"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "",
    "text": "The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study.\nResearch Questions\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task?\nExperimental Hypothesis\nLearners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.\nNull Hypothesis\nNo significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#sample",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#sample",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    fall17 \n    27 \n    27 \n    54 \n  \n  \n    spring18 \n    35 \n    37 \n    72 \n  \n  \n    Sum \n    62 \n    64 \n    126 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.male \n    percent.female \n    percent.other \n  \n \n\n  \n     \n    18 \n    19 \n    20 \n    21 \n    33 \n    20.4 \n    2.12 \n    126 \n    0 \n    0.373 \n    0.619 \n    0.008 \n  \n\n\nNote:   Age in Years\n\n\n\n\nOverall 126 participants (37 % male, 62 % female, 1 % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 33 years)."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1a-overall-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1a-overall-accuracy",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "H1A | OVERALL ACCURACY",
    "text": "H1A | OVERALL ACCURACY\n\n\n\n\n\n\n\nResearch Question\nDo Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?\n\n\n\n\nHypothesis\n(H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.\n\n\nData\ndata: df_items where q nin 6,9 (the 13 discriminating Qs ), df_subjects\noutcome:\n\n[at item level] : accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\n[subject level]: accuracy (number of test phase qs correct from total s_NABS)\n\npredictor: condition [between-subjects factor]\n\n\nAnalysis Strategy\n\nWilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (s_NABS)\nMixed Logistic Regression\naccuracy ~ condition + (1 | subject ) + (1 | question)\nmodel effect of condition on probability of correct response [during test phase] while accounting for subject (and item-level?) effects\n\n\n\nAlternatives\n\nOrdinal Mixed Logistic Regression on scaled_score\nOLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals\n\n\n\nNotes\nAlso exploring:\n\nHurdle model (mixture model w/ binomial + [poisson or negbinom count; 0s from 1 DGP)\nZero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)\nBeta regression hurdle model? (mixture with location and scale parameters [mean, variance] and hurdles for floor and ceiling effects)\nOther way to account for the severe bimodality?\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q)\n\ndf_s <- df_subjects %>% \n   dplyr::select(pretty_condition, task_percent)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 2))+\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n  # coord_flip() +\n  theme(legend.position=\"bottom\")+\n   labs(title = \"DISTRIBUTION | Question Accuracy\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs(title = \"DISTRIBUTION | Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n\n\n\n\n\nCODE\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  # gf_facet_grid(pretty_condition ~ pretty_mode) %>%\n  gf_facet_grid(~pretty_condition) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"DISTRIBUTION | Total Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#:::::::: RAINCLOUD WITH STATS\n  \ndf <- df_s %>% mutate(task_percent = task_percent*100)\n\np <-   ggbetweenstats(data = df, x = pretty_condition, y = task_percent,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               # package = \"RColorBrewer\",\n               # palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  # aes(color = pretty_condition, fill = pretty_condition),\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  theme(axis.text.x = element_text(angle = 90)))\n               ) +\n  ggdist::stat_halfeye(\n    alpha = 0.7, \n    point_colour = NA,\n    adjust = .5, \n    width = .5, .width = 0, \n    justification = -.5) +\n  geom_boxplot(\n    alpha = 0.1,\n    width = .2, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 2,\n    alpha = .5,\n    position = position_jitter(\n      seed = 1, width = .08, height = 1.5\n    )\n  )  +\ncoord_flip() + theme_clean() + theme(legend.position = \"blank\")\np$layers[[3]]=NULL #remove default boxplot\ne <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE)\n#labels are layer 4\np + labs(title = \"STUDY 3A | DISTRIBUTION of Total Score\",\n         y = \"Percentage of correct responses across task\", x = \"\",\n         # caption=e$expression[[1]],\n         subtitle = \"Impasse condition yields greater variance and more high scores\")\n\n\n\n\n\n\n\nDescribe\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0 \n    0 \n    0.077 \n    0.692 \n    1 \n    0.316 \n    0.392 \n    126 \n    0 \n  \n\n\n\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\n \n  \n    pretty_condition \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    control \n    0 \n    0.000 \n    0.000 \n    0.154 \n    1 \n    0.210 \n    0.370 \n    62 \n    0 \n  \n  \n    impasse \n    0 \n    0.058 \n    0.346 \n    0.846 \n    1 \n    0.419 \n    0.387 \n    64 \n    0 \n  \n\n\n\n\n\n\nWILCOXON RANK SUM (Mann-Whitney Test)\n\nNon parametric alternative to t-test; compares median rather than mean by ranking data\nDoes not assume normality\nDoes not assume equal variance of samples (homogeneity of variance)\n\n\nTest\n\n\nCODE\n(w <- wilcox.test(df_s$task_percent ~ df_s$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df_s$task_percent by df_s$pretty_condition\nW = 1243, p-value = 7e-05\nalternative hypothesis: true location shift is less than 0\n\n\nCODE\nreport(w)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_s$task_percent and df_s$pretty_condition suggests that the effect is negative, statistically significant, and large (W = 1243.00, p < .001; r (rank biserial) = -0.37, 95% CI [-1.00, -0.22])\n\n\n\n\nInference\n(not reported)\nBecause the distribution of the outcome variable is not normally distributed, we evaluate the effect of CONDITION on ACCURACY via a non-parametric test. Consistent with our hypothesis, a Wilcoxon rank sum test (with continuity correction) on ACCURACY by CONDITION indicates that data in each condition likely come from different population distributions (W = 1243, p < 0.001; one-tailed), and that the distribution of the control condition is less (i.e. shifted to the left/ lower scores) than the impasse condition (^{r} = -0.37, 95% CI [-1.00, -0.22]), a large-sized effect.\n\n\nVisualize\n\n\nCODE\nggbetweenstats( x = pretty_condition, y = task_percent, data = df_s,\n                type = \"nonparametric\", var.equal = FALSE)\n\n\n\n\n\n\n\n\nMIXED LOGISTIC REGRESSION\nFit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.\n\nFit Model\n\n\nCODE\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n\n\n[1] TRUE\n\n\nCODE\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n\n\n[1] TRUE\n\n\nCODE\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n\n\n[1] \"Empty fixed model\"\n\n\nCODE\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n\n\n[1] \"Subject intercept random model\"\n\n\nCODE\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |    Chi2 |      p\n--------------------------------------------------\nm0    |      glm |  1 |         |         |       \nmm.rS | glmerMod |  2 |       1 | 1011.83 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  4.82063151679782e-222\"\n\n\nCODE\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n\n\n[1] \"Subject Intercept + Item intercept random model\"\n\n\nCODE\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.rSQ | glmerMod |  3 |       1 | 15.82 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0000697594950188617\"\n\n\nCODE\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n\n\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n\n\nCODE\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n#summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |       |       \nmm.CrSQ | glmerMod |  4 |       1 | 18.66 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0000156066263742927\"\n\n\nCODE\n# control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n\n\nA likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.\n\n\nDescribe\n\n\nCODE\n#::::::::: SETUP\nm <- mm.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n    1006     1028     -499      998     1634 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.316 -0.136 -0.052  0.168  5.522 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 22.216   4.713   \n q       (Intercept)  0.308   0.555   \nNumber of obs: 1638, groups:  subject, 126; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -5.51       1.02   -5.40  6.5e-08 ***\npretty_conditionimpasse     4.32       1.12    3.87  0.00011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.802\n\n\nCODE\nprint(\"SIGNIFICANCE TEST [non directional]\")\n\n\n[1] \"SIGNIFICANCE TEST [non directional]\"\n\n\nCODE\ncar::Anova(m)\n\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)    \npretty_condition    15  1    0.00011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\npaste(\"MODEL INFO\")\n\n\n[1] \"MODEL INFO\"\n\n\nCODE\nglance(m)\n\n\n# A tibble: 1 × 7\n   nobs sigma logLik   AIC   BIC deviance df.residual\n  <int> <dbl>  <dbl> <dbl> <dbl>    <dbl>       <int>\n1  1638     1  -499. 1006. 1028.     630.        1634\n\n\nCODE\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n# se <- sqrt(diag(stats::vcov(m)))\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n\n\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   -5.51       1.02     -5.40  6.49e-8    -7.51     -3.51\n2 fixed    <NA>   pret…    4.32       1.12      3.87  1.08e-4     2.14      6.51\n3 ran_pars subje… sd__…    4.71      NA        NA    NA          NA        NA   \n4 ran_pars q      sd__…    0.555     NA        NA    NA          NA        NA   \n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n# (e <- exp(tab))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n\n\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…  0.00406   0.00413     -5.40  6.49e-8  5.50e-4    0.0299\n2 fixed    <NA>   pret… 75.5      84.3          3.87  1.08e-4  8.46e+0  674.    \n3 ran_pars subje… sd__…  4.71     NA           NA    NA       NA         NA     \n4 ran_pars q      sd__…  0.555    NA           NA    NA       NA         NA     \n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\n#setup df \nnewdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n\n\nWarning: executing %dopar% sequentially: no parallel backend registered\n\n\nCODE\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(pretty_condition, fit, lwr, upr) %>% \n  group_by(pretty_condition) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n\n\n# A tibble: 2 × 4\n  pretty_condition  median    lower  upper\n  <fct>              <dbl>    <dbl>  <dbl>\n1 control          0.00387 0.000643 0.0235\n2 impasse          0.239   0.0630   0.595 \n\n\n\n\nINFERENCE\n(In Dissertation)\nWe fit a mixed effects binomial logistic regression model with random intercepts for subjects and questions. Note that we choose to model these data at the item (i.e. question) rather than than subject (i.e. total score) level because the structure of a mixed effects model allows us to differentiate between random variance introduced by individual subjects and questions, versus the expected systematic variance of CONDITION. A likelihood ratio test indicates that a model including a fixed effect of CONDITION explains significantly more variance in the data than an intercepts-only baseline model (\\(\\chi^2 (3) = 18.66, p < 0.001\\)). The explanatory power of the entire model is substantial (\\(conditional \\ R^2 = 0.89\\)) and the part related to the fixed effect CONDITION (\\(marginal \\ R^2\\)) explains 15% of variance. Consistent with our hypothesis, the impasse condition substantially increases the odds of a correct response. Across the entire task participants in the impasse condition were 75 times more likely to offer a correct response, compared with those in the control condition ( \\(e^{\\beta_1} = 75.51, p < 0.001\\), \\(95 \\% \\  CI [8.46, 674]\\)). Based on the fixed effect of CONDITION, The model predicts that the probability of a correct response in the control condition is effectively 0% (95% CI [6.8e-4, 0.02]), and the probability of a correct response in the impasse condition increases to 24% (95% CI [0.06, 0.60]).\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.00\n0.00 – 0.03\n<0.001\n\n\npretty condition[impasse]\n75.51\n8.46 – 673.76\n<0.001\n\n\nRandom Effects\n\n\n\nσ2\n3.29\n\n\n\nτ00 subject\n22.22\n\n\nτ00 q\n0.31\n\n\nICC\n0.87\n\n\nN subject\n126\n\n\nN q\n13\n\nObservations\n1638\n\n\nMarginal R2 / Conditional R2\n0.153 / 0.892\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n\n#SJPLOT | MODEL | lOG ODDS\nplot_model(m, transform = NULL,\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, transform = \"exp\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.05, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | Log Odds\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result) + labs(\n#     title = \"Model ESTIMATE | ODDS RATIO\"\n#   )\n\n## | PLOT TESTS\n# result <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n# plot(result)\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"pred\")[[1]]  +\n  ylim(0,1) +\n  labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"Impasse increases probability of correct response\",\n    y = \"Probability of Correct Response\", x = \"Condition\"\n  )\n\n\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n\n\n\n\n\nCODE\n#GGDIST | MODEL | PREDICTED PROBABILITIES\npreds %>% \n  ggplot(aes( x = fit, y = pretty_condition, fill = pretty_condition)) + \n  stat_halfeye(alpha = 0.5, normalize = \"xy\") + \n  xlim(0,0.3) + theme_clean() + labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"TODO check preds to see if fixed or includes random\"\n  )\n\n\n\n\n\nCODE\n# SIMULATE FIXED EFFECTS\n# simulate values of fixed effects \n# (feEx <- FEsim(m,  oddsRatio = FALSE, n.sims = 1000))\n# PLOT estimates of fixed effects\n# plotFEsim(feEx) +\n#   theme_bw() + labs(title = \"Coefficient Plot of InstEval Model\",\n#                     x = \"Median Effect Estimate\")\n\n# SIMULATE RANDOM EFFECTS\n# simulate values of random effects\n# reEx <- REsim(m)\n# PLOT estimates of random effects\n# plotREsim(reEx)\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n\n\n[1] \"DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)\n\n\n\n\n\n\n\nSanity Check :: Bayesian\n\n\nCODE\n# ## 0 | SETUP\n# #confirm 13 items [all discriminating items]\n# nrow(df_i) / nrow(df_s) == 13\n# #confirm all factors \n# is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n# \n#\n# \n# print(\"FIXED Condition + Subject & Item random intercepts\")\n# Bmm.CrSQ <- brm( accuracy ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"bernoulli\",\n#                  chains = 4, iter = 2000, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_acc_Bmm.CrSQ_LAB.rds\")\n# \n# #get Priors \n# # describe_priors(Bmm.CrSQ)\n# \n# #GRAPHICAL POSTERIOR PREDICTION CHECKS\n# pp_check(Bmm.CrSQ)\n# \n# #DESCRIBE MODEL\n# (d <- describe_posterior(ci=.95, Bmm.CrSQ))\n# \n# #SEE MODEL\n# plot(pd(Bmm.CrSQ))\n# #convert to a pd value\n# (pds <- pd_to_p(d$pd))\n\n\nA likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.\n\n\nCODE\n# #::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n# ##WORKING\n# ## VIS probability of correct response\n# #TAKES A REALLY LONG TIME\n# \n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(\"analysis/SGC3A/models/draws_BB.catCrSQ.rds\")\n# \n# #2| VISUALIZE PREDICTIONS | GGDIST\n# ##TODO figure out height normalization.\n# ##do it with much smaller number of draws \n# #TODO adjust bandwidth/smoothing? + put on same line + \n# #TAKES A REAAALY LONG TIME\n# # draws %>% sample_n(1000) %>% \n# #   ggplot(aes(x = .value,  y = 0, fill = pretty_condition)) +\n# #   stat_slab(width = c(.95), alpha = 1, normalize=\"xy\") +\n# #   #normalize = all, panels, xy, groups, none\n# #   xlim(0,1) + labs(\n# #     title = \"Model Predicted Probability of Correct Response\",\n# #     x = \"probability of correct response\",\n# #     y = \"Interpretation\"\n# #   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1a-overall-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1a-overall-interpretation-state",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "H1A | OVERALL INTERPRETATION STATE",
    "text": "H1A | OVERALL INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses across questions?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items\n\n\nData\n\ndata: df_items where q nin 6,9 (13 discriminant test phase items)\noutcome: state ( 3 level factor from high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMIXED Multinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nMIXED Ordinal regression on state (doesn’t meet proportional odds assumption-I think)\nMIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  # facet_wrap(~pretty_mode) + \n  theme(legend.position = \"bottom\")+\n   labs(title = \"DISTRIBUTION of Interpretation\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  facet_wrap(~q) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. In the impasse condition, there are also more positive transition (i.e. triangle-like) and neutral (ie. blank or uncertain response types) than in the control condition.\n\n\nDescribe\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse     Sum\n  orthogonal 0.69727 0.32692 0.50916\n  other      0.07320 0.19231 0.13370\n  angular    0.00993 0.03846 0.02442\n  triangular 0.21960 0.44231 0.33272\n  Sum        1.00000 1.00000 1.00000\n\n\nCODE\n(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n            \n             control impasse  Sum\n  orthogonal     562     272  834\n  other           59     160  219\n  angular          8      32   40\n  triangular     177     368  545\n  Sum            806     832 1638\n\n\n\n\nMIXED MULTINOMIAL REGRESSION\nDoes condition affect the response state of of items across the task?\nFit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\nCan use mclogit mblogit() with random effect or bayesian brms package b/c nlme, lme4 don’t support random effects on multinomial (ie no categorical family on glmer())\nAlternative would be to manually run [k-1] X binomial mixed models [should compare outcomes]\n[k-1] equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) [essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing [reference category] vs [this category])\nFor each equation:\n\n\\(\\beta_{0}\\) = Log Odds of [this category type vs. reference category type) response in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of [this category type vs. reference category type] response in CONTROL condition\n\\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for [this category] type response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of [this. vs reference category type] response in IMPASSE (vs) CONTROL\nTwo-tailed NHST Null hypothesis: \\(\\beta_{impasse} = 0\\) the odds for [this category of response vs. reference] are not different for IMPASSE condition\nAlternative hypothesis: \\(\\beta_{impasse} \\ne 0\\) the odds of [this category of response vs. reference] increases or decreases for IMPASSE condition\n\n\n\nFit Model [mblogit]\n\n\nCODE\n#https://www.elff.eu/software/mclogit/manual/mblogit/\n#\"baseline category logit\" model matches multinom()\n\n#check reference level \nprint(\"Categories (first is reference)\")\n\n\n[1] \"Categories (first is reference)\"\n\n\nCODE\nlevels(df_i$state)\n\n\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n\n\nCODE\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nmm.cat.rSQ <- mblogit(state ~ 1 , \n                      random = list( ~ 1|subject, ~1|q), \n                      data = df_i)\n\n\n\nIteration 1 - deviance = 2540 - criterion = 0.821\nIteration 2 - deviance = 2130 - criterion = 0.0764\nIteration 3 - deviance = 2018 - criterion = 0.0241\nIteration 4 - deviance = 1942 - criterion = 0.00947\nIteration 5 - deviance = 1890 - criterion = 0.00588\nIteration 6 - deviance = 1908 - criterion = 0.00469\nIteration 7 - deviance = 1881 - criterion = 0.0216\nIteration 8 - deviance = 1912 - criterion = 0.0101\nIteration 9 - deviance = 1897 - criterion = 0.0089\nIteration 10 - deviance = 1905 - criterion = 0.00172\nIteration 11 - deviance = 1934 - criterion = 0.000253\nIteration 12 - deviance = 1887 - criterion = 0.0168\nIteration 13 - deviance = 1906 - criterion = 0.00498\nIteration 14 - deviance = 1917 - criterion = 0.0023\nIteration 15 - deviance = 1828 - criterion = 0.0177\nIteration 16 - deviance = 1851 - criterion = 0.00603\nIteration 17 - deviance = 1903 - criterion = 0.000756\nIteration 18 - deviance = 1885 - criterion = 0.0197\nIteration 19 - deviance = 1899 - criterion = 0.00449\nIteration 20 - deviance = 1915 - criterion = 0.00144\nIteration 21 - deviance = 1879 - criterion = 0.00235\nIteration 22 - deviance = 1911 - criterion = 0.00166\nIteration 23 - deviance = 1888 - criterion = 0.0101\nIteration 24 - deviance = 1921 - criterion = 0.00392\nIteration 25 - deviance = 1898 - criterion = 0.00654\n\n\nWarning: Algorithm did not converge\n\n\nCODE\n#summary(mm.cat.rSQ)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nmm.cat.CrSQ <- mblogit(state ~ pretty_condition , \n                  random = list( ~ 1|subject, ~1|q), \n                  data = df_i)\n\n\n\nIteration 1 - deviance = 2516 - criterion = 0.818\nIteration 2 - deviance = 2152 - criterion = 0.0677\nIteration 3 - deviance = 1988 - criterion = 0.0332\nIteration 4 - deviance = 1943 - criterion = 0.00696\nIteration 5 - deviance = 1920 - criterion = 0.00226\nIteration 6 - deviance = 1903 - criterion = 0.000947\nIteration 7 - deviance = 1895 - criterion = 0.00044\nIteration 8 - deviance = 1891 - criterion = 0.000212\nIteration 9 - deviance = 1891 - criterion = 0.0000998\nIteration 10 - deviance = 1891 - criterion = 0.0000456\nIteration 11 - deviance = 1891 - criterion = 0.0000207\nIteration 12 - deviance = 1891 - criterion = 9.59e-06\nIteration 13 - deviance = 1891 - criterion = 4.67e-06\nIteration 14 - deviance = 1891 - criterion = 2.41e-06\nIteration 15 - deviance = 1891 - criterion = 1.32e-06\nIteration 16 - deviance = 1891 - criterion = 7.49e-07\nIteration 17 - deviance = 1891 - criterion = 4.38e-07\nIteration 18 - deviance = 1891 - criterion = 2.6e-07\nIteration 19 - deviance = 1891 - criterion = 1.55e-07\nIteration 20 - deviance = 1891 - criterion = 9.29e-08\nIteration 21 - deviance = 1891 - criterion = 5.56e-08\nIteration 22 - deviance = 1891 - criterion = 3.32e-08\nIteration 23 - deviance = 1891 - criterion = 1.98e-08\nIteration 24 - deviance = 1891 - criterion = 1.18e-08\nIteration 25 - deviance = 1891 - criterion = 7.04e-09\nconverged\n\n\nCODE\n# summary(mm.cat.CrSQ)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(mm.cat.rSQ) > AIC(mm.cat.CrSQ))\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(mm.cat.rSQ, mm.cat.CrSQ)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        |    Model | df | df_diff |  Chi2 |      p\n------------------------------------------------------\nmm.cat.rSQ  | mmblogit | 15 |         |       |       \nmm.cat.CrSQ | mmblogit | 18 |       3 | 18.39 | < .001\n\n\n\n\nDescribe\n\n\nCODE\nm <- mm.cat.CrSQ\n\n#DESCRIBE MODEL\nsummary(m)\n\n\nWarning in sqrt(diag(vcov.phi)): NaNs produced\n\n\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df_i, random = list(~1 | \n    subject, ~1 | q))\n\nEquation for other vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.574      0.527   -4.88  1.1e-06 ***\npretty_conditionimpasse    2.488      0.385    6.47  9.9e-11 ***\n\nEquation for angular vs orthogonal:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  -4.804      0.800   -6.00  1.9e-09 ***\ntri(Intercept)               -2.924      0.782   -3.74  0.00018 ***\npretty_conditionimpasse       2.989      0.614    4.87  1.1e-06 ***\ntripretty_conditionimpasse    3.454      0.795    4.34  1.4e-05 ***\n\nEquation for triangular vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.924      0.782   -3.74  0.00018 ***\npretty_conditionimpasse    3.454      0.795    4.34 0.000014 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Co-)Variances:\nGrouping level: subject \n             Estimate            Std.Err.      \nother~1       2.93                NaN          \nangular~1     3.15  5.29         1.25 2.60     \ntriangular~1  5.43  8.25 16.08   3.26 5.21 8.49\n\nGrouping level: q \n             Estimate         Std.Err.      \nother~1      2.54             12.0          \nangular~1    2.88 4.91        19.0 29.7     \ntriangular~1 2.13 3.54 3.36   15.1 23.6 18.6\n\nNull Deviance:     4540 \nResidual Deviance: 1890 \nNumber of Fisher Scoring iterations:  25\nNumber of observations\n  Groups by subject: 126\n  Groups by q: 13\n  Individual observations:  1638\n\n\nCODE\n#INTERPRET COEFFICIENTS\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n\n\nWarning: The `tidy()` method for objects of class mmblogit is not maintained by\nthe broom team, and is only supported through the lm tidier method. Please be\ncautious in interpreting and reporting broom output.\n\nWarning: NaNs produced\n\n\n# A tibble: 6 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  <chr>                    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 other~(Intercept)        -2.57     0.527     -4.88 1.06e- 6    -3.61     -1.54\n2 angular~(Intercept)      -4.80     0.800     -6.00 1.92e- 9    -6.37     -3.24\n3 triangular~(Intercep…    -2.92     0.782     -3.74 1.85e- 4    -4.46     -1.39\n4 other~pretty_conditi…     2.49     0.385      6.47 9.94e-11     1.73      3.24\n5 angular~pretty_condi…     2.99     0.614      4.87 1.13e- 6     1.78      4.19\n6 triangular~pretty_co…     3.45     0.795      4.34 1.40e- 5     1.90      5.01\n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n\n\nWarning: The `tidy()` method for objects of class mmblogit is not maintained by\nthe broom team, and is only supported through the lm tidier method. Please be\ncautious in interpreting and reporting broom output.\n\nWarning: NaNs produced\n\n\n# A tibble: 6 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  <chr>                    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 other~(Intercept)        -2.57     0.527     -4.88 1.06e- 6    -3.61     -1.54\n2 angular~(Intercept)      -4.80     0.800     -6.00 1.92e- 9    -6.37     -3.24\n3 triangular~(Intercep…    -2.92     0.782     -3.74 1.85e- 4    -4.46     -1.39\n4 other~pretty_conditi…     2.49     0.385      6.47 9.94e-11     1.73      3.24\n5 angular~pretty_condi…     2.99     0.614      4.87 1.13e- 6     1.78      4.19\n6 triangular~pretty_co…     3.45     0.795      4.34 1.40e- 5     1.90      5.01\n\n\nCODE\n# paste(\"MODEL INFO\")\n# glance(m)\n\n#PERFORMANCE\nperformance(m)\n\n\n# Indices of model performance\n\nAIC       |       BIC |  RMSE | Sigma\n-------------------------------------\n21103.626 | 21200.848 | 0.242 | 1.077\n\n\n\n\nTODO Inference\n\nBeing in the IMPASSE condition increases the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 12 (z = 6.48, p < 0.001) . Participants in the impasse condition were 12x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control.\nBeing in the IMPASSE condition increases the odds of giving ‘triangle-like’ response rather than an orthogonal (or satisficing) response by a factor of 29 (z = 4.63, p < 0.001 ). Participants in the impasse condition were more than 29x as likely to give an a triangular response rather than an orthogonal response compared to participants in control.\nAs with the (binary) logistic regression on accuracy ~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 in the control condition. (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \nstate\n\n\nPredictors\nEstimates\nCI\np\n\n\nother~(Intercept)\n-2.57\n-3.61 – -1.54\n<0.001\n\n\nangular~(Intercept)\n-4.80\n-6.37 – -3.24\n<0.001\n\n\ntriangular~(Intercept)\n-2.92\n-4.46 – -1.39\n<0.001\n\n\nother~prettyconditionimpasse\n2.49\n1.73 – 3.24\n<0.001\n\n\nangular~prettyconditionimpasse\n2.99\n1.78 – 4.19\n<0.001\n\n\ntriangular~prettyconditionimpasse\n3.45\n1.90 – 5.01\n<0.001\n\n\n\nN subject\n126\n\n\nN q\n13\n\nObservations\n1638\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, \n           transform = \"exp\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE)\n\n\n\n\n\nCODE\n#TODO SEPARATE THIS BY EQUATION \n# ms <- model_parameters(Bmm.cat.CrSQ, component = \"conditional\")\n# m1 <- ms %>% filter(str_detect(Parameter, \"muother\"))\n# plot(m1)\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result, show_labels = TRUE, n_columns = 3)\n\n\n\n\n\nCODE\n# result <- simulate_parameters(m)\n# plot(result, stack = FALSE)\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n\n\nWarning: Could not estimate a good default ROPE range. Using 'c(-0.1, 0.1)'.\n\n\nCODE\nplot(result)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")[[1]] + \n#   ylim(0,1) + labs(\n#     title = \"Model Prediction | Probability of Accurate Response\",\n#     subtitle = \"Impasse increases Probability of Correct Response\"\n#   )\n\n#TODO EMMEANS for the estimated marginal means\n\n\n\n\nDiagnostics\n\n\nCODE\n# check_model(m)\n\n\n\n\nFit Model [brms]\n\n\nCODE\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.rSQ_LAB.rds\")\n\n\n#UNINFORMATIVE PRIOR BAYESIAN MIXED VERSION\n# flat_Bmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"categorical\",\n#                  chains = 4, iter = 2500, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  save_pars = save_pars(all = TRUE),\n#                  # backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_state_FLAT_Bmm.cat.CrSQ_LAB.rds\")\n\n\n# determine default priors \n# prior_summary(flat_Bmm.cat.CrSQ)\n\n#set priors [see justification, below]\ninf_priors <- c(\n  # too strong?\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muangular\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muother\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\")\n)\n\n#INFORMATIVE PRIORS\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 prior = inf_priors,\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.CrSQ_LAB.rds\"\n                 )\n\n\nCompiling Stan program...\n\n\nStart sampling\n\n\nCODE\n#a bayes factor model comparison of the flat vs informative prior models suggest convicing evidence that \n#informative prior model is a better fit\n# bayesfactor(Bmm.cat.CrSQ, flat_Bmm.cat.CrSQ)\n\n# PRIORS LOGIC \n# https://www.bayesrulesbook.com/chapter-13.html#building-the-logistic-regression-model\n\n#expectation for probability of _better_ response [in control]?\n#very low probability center: 0.1% [very low]; as logodds = logit(0.001) = -6.91\n#range from 0 to 55%  logit(0.55) = 0.201\n#probability of 0.1 to 55% is equivalent to [logodds] -6.91 +/ 2* 0.201\n#therefore... prior for intercept => Normal(−6.91, 0)\n\n\n#expectation for probability of _better_ response [in impasse]?\n#increases probablity from 0 % \n# 0 [very low]; as OR  = exp(0) = 1\n#range from 0 to 90%  exp(0.9) = 2.46\n#probability of 0 to 90% is equivalent to [ODDS scale] 1 +/ 2* 2.42\n#on log odds scale ? [0, ]\n#therefore... prior for intercept => Normal(1, 2.42)\n                             # prior = normal(0.07, 0.035),\n\n\n\n\nDescribe\n\n\nCODE\n# best model\nm <- Bmm.cat.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1638) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.43      0.36     0.89     2.29 1.00     1738\nsd(muangular_Intercept)        2.24      0.85     1.08     4.35 1.00     1351\nsd(mutriangular_Intercept)     0.99      0.27     0.59     1.59 1.00     1710\n                           Tail_ESS\nsd(muother_Intercept)          3069\nsd(muangular_Intercept)        2388\nsd(mutriangular_Intercept)     2989\n\n~subject (Number of levels: 126) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.32      0.19     0.99     1.71 1.00     1738\nsd(muangular_Intercept)        1.78      0.40     1.05     2.63 1.00     1839\nsd(mutriangular_Intercept)     4.51      0.50     3.63     5.59 1.00     1084\n                           Tail_ESS\nsd(muother_Intercept)          3080\nsd(muangular_Intercept)        2074\nsd(mutriangular_Intercept)     2016\n\nPopulation-Level Effects: \n                                     Estimate Est.Error l-95% CI u-95% CI Rhat\nmuother_Intercept                       -3.09      0.47    -4.02    -2.18 1.00\nmuangular_Intercept                     -5.71      0.81    -7.29    -4.14 1.00\nmutriangular_Intercept                  -3.63      0.74    -5.13    -2.19 1.00\nmuother_pretty_conditionimpasse          2.46      0.35     1.80     3.14 1.00\nmuangular_pretty_conditionimpasse        2.74      0.61     1.59     3.99 1.00\nmutriangular_pretty_conditionimpasse     3.58      0.88     1.91     5.41 1.01\n                                     Bulk_ESS Tail_ESS\nmuother_Intercept                        1223     2382\nmuangular_Intercept                      1676     3000\nmutriangular_Intercept                    985     1988\nmuother_pretty_conditionimpasse          2101     3314\nmuangular_pretty_conditionimpasse        3170     3521\nmutriangular_pretty_conditionimpasse      658     1468\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCODE\n(d <- describe_posterior(ci=.95, Bmm.cat.CrSQ))\n\n\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |   pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -3.09 | [-4.02, -2.18] | 100% | [-0.18, 0.18] |        0% | 1.003 | 1218.00\nmuangular_Intercept                  |  -5.69 | [-7.29, -4.14] | 100% | [-0.18, 0.18] |        0% | 1.002 | 1620.00\nmutriangular_Intercept               |  -3.60 | [-5.13, -2.19] | 100% | [-0.18, 0.18] |        0% | 1.004 |  983.00\nmuother_pretty_conditionimpasse      |   2.45 | [ 1.80,  3.14] | 100% | [-0.18, 0.18] |        0% | 1.000 | 2080.00\nmuangular_pretty_conditionimpasse    |   2.73 | [ 1.59,  3.99] | 100% | [-0.18, 0.18] |        0% | 1.000 | 3066.00\nmutriangular_pretty_conditionimpasse |   3.55 | [ 1.91,  5.41] | 100% | [-0.18, 0.18] |        0% | 1.006 |  652.00\n\n\nCODE\nprint(\"BAYES FACTOR [comparison to null]\")\n\n\n[1] \"BAYES FACTOR [comparison to null]\"\n\n\nCODE\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(Bmm.cat.rSQ, m))\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nBayes Factors for Model Comparison\n\n    Model                                            BF\n[2] pretty_condition + (1 | subject) + (1 | q) 1.27e+16\n\n* Against Denominator: [1] 1 + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n\n\nCODE\nprint(\"DESCRIBE POSTERIOR\")\n\n\n[1] \"DESCRIBE POSTERIOR\"\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n# se <- sqrt(diag(stats::vcov(m)))\n# # table of estimates with 95% CI\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n(l <- describe_posterior(m))\n\n\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |   pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -3.09 | [-4.02, -2.18] | 100% | [-0.18, 0.18] |        0% | 1.003 | 1218.00\nmuangular_Intercept                  |  -5.69 | [-7.29, -4.14] | 100% | [-0.18, 0.18] |        0% | 1.002 | 1620.00\nmutriangular_Intercept               |  -3.60 | [-5.13, -2.19] | 100% | [-0.18, 0.18] |        0% | 1.004 |  983.00\nmuother_pretty_conditionimpasse      |   2.45 | [ 1.80,  3.14] | 100% | [-0.18, 0.18] |        0% | 1.000 | 2080.00\nmuangular_pretty_conditionimpasse    |   2.73 | [ 1.59,  3.99] | 100% | [-0.18, 0.18] |        0% | 1.000 | 3066.00\nmutriangular_pretty_conditionimpasse |   3.55 | [ 1.91,  5.41] | 100% | [-0.18, 0.18] |        0% | 1.006 |  652.00\n\n\nCODE\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nParameter                            |   Median |         95% CI |   pd | % in ROPE |  Rhat |     ESS\n-----------------------------------------------------------------------------------------------------\nmuother_Intercept                    |     0.05 | [0.02,   0.11] | 100% |        0% | 1.003 | 1218.00\nmuangular_Intercept                  | 3.38e-03 | [0.00,   0.02] | 100% |        0% | 1.002 | 1620.00\nmutriangular_Intercept               |     0.03 | [0.01,   0.11] | 100% |        0% | 1.004 |  983.00\nmuother_pretty_conditionimpasse      |    11.58 | [6.03,  23.19] | 100% |        0% | 1.000 | 2080.00\nmuangular_pretty_conditionimpasse    |    15.30 | [4.89,  54.22] | 100% |        0% | 1.000 | 3066.00\nmutriangular_pretty_conditionimpasse |    34.71 | [6.72, 223.29] | 100% |        0% | 1.006 |  652.00\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nCODE\n# tidy(m,   conf.int = TRUE, exponentiate = TRUE)\n# tm %>% mutate(\n#   OR.est = exp(estimate),\n#   exp.low = exp(conf.low),\n#   exp.high = exp(conf.high)\n# ) %>% dplyr::select(effect, component, group, term, OR.est, exp.low, exp.high)\n\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#PREDICT METHOD\nnewdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\npreds <- predict(m, newdata = newdata, type = \"response\")\npreds <- cbind(newdata, preds)\n#lengthen data frame to handle multinomial\npreds <- preds %>% \n  dplyr::select(-subject, -q) %>% #marginalize over subject and q\n  pivot_longer(\n  cols = !pretty_condition,\n  values_to = \"preds\",\n  names_to = \"state\",\n) \n\n(p <- preds %>% \n  group_by(pretty_condition, state ) %>%\n  summarise(\n    median = median(preds),\n    se = sd(preds)/sqrt(n()),\n    lwr = median - 1.96*se,\n    upr = median + 1.96*se))\n\n\n# A tibble: 8 × 6\n# Groups:   pretty_condition [2]\n  pretty_condition state              median       se      lwr     upr\n  <fct>            <chr>               <dbl>    <dbl>    <dbl>   <dbl>\n1 control          P(Y = angular)    0.00283 0.000740  0.00138 0.00428\n2 control          P(Y = orthogonal) 0.878   0.0123    0.853   0.902  \n3 control          P(Y = other)      0.036   0.00361   0.0289  0.0431 \n4 control          P(Y = triangular) 0.0152  0.0127   -0.00968 0.0400 \n5 impasse          P(Y = angular)    0.0134  0.00211   0.00929 0.0175 \n6 impasse          P(Y = orthogonal) 0.239   0.0100    0.219   0.259  \n7 impasse          P(Y = other)      0.125   0.00656   0.112   0.138  \n8 impasse          P(Y = triangular) 0.368   0.0131    0.342   0.394  \n\n\nCODE\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n\n\n\n\nINFERENCE\n[REPORT POSTERIOR MEDIAN \\(\\exp_{beta}\\), 95 % credible interval, % probability of direction]\nWe fit a (bayesian) multinomial logistic regression model with random intercepts for subjects and questions. A Bayes Factor model comparison (against a random intercepts-only model) indicates extreme evidence for a main effect of CONDITION (BF = 9.31e+15). Consistent with our hypothesis, the impasse condition substantially increases the odds of transitional interpretations.\nAcross the entire task participants in the impasse condition were 12 times more likely to offer an ‘unknown’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 11.58, 95 \\% CI [6.03, 23.19], pd = 100\\%\\)). Participants in the impasse condition were 15 times more likely to offer an ‘angular’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 15.30, 95 \\% CI [4.89, 54.22], pd = 100\\%\\)), and 35 times more likely to offer an ‘triangular’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 34.71, 95 \\% CI [6.72, 223.29], pd = 100\\%\\)).\nThe model estimates that probability of an orthogonal response in the control condition is 92% vs only 38% in IMPASSE The probability of an unknown/uncertain response in the control condition is 4%, vs 20% in impasse The probability of an angular response in the control condition is less than 1%, vs 2% in impasse. The probability of an triangular response in the control condition is 3%, vs 40% in impasse.\nThe impasse condition decreases the probability of an orthogonal response by 54% The impasse condition increases the probability of an uknown/uncertain response by 16% The impasse condition increases the probability of an angular response by 1% the impasse condition increase the probability of a triangular response by 37%\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n'bayes_R2' is not defined for unordered categorical models.\n\n\n\n\n \nstate: other\nstate: angular\nstate: triangular\nstate: other_pretty\nstate: angular_pretty\nstate: triangular_pretty\n\n\nPredictors\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\n\n\nIntercept\n0.00\n0.00 – 0.02\n\n\n0.05\n0.02 – 0.11\n\n\n0.03\n0.01 – 0.11\n\n\n\n\nconditionimpasse\n\n\n15.30\n4.89 – 54.22\n\n\n11.58\n6.03 – 23.19\n\n\n34.71\n6.72 – 223.29\n\n\nRandom Effects\n\n\n\nσ2\n0.40\n\n\n\nτ00\n1.43\n\n\nICC\n0.22\n\n\nN subject\n126\n\n\nN q\n13\n\nObservations\n1638\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n# \n# \n# ## POINT ESTIMATES IN PROBABILITY\n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #2 | SUMMARIZE draws \n# k <- kable(draws %>%\n#   select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 2, col.names = \n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>% \n#   kable_styling()\n# k\n\n#COMPARISONS\n# c <- draws %>% \n#   # dplyr::select(pretty_condition, .category, .value) %>%\n#   compare_levels(variable = .value, by = pretty_condition, \n#                  comparison = list(c(\"control\",\"impasse\"))) \n#                                    # c(\"adots\",\"interval\"),\n#                                    # c(\"adots\",\"mean\"),\n#                                    # c(\"adots\",\"text\"),\n#                                    # c(\"density\",\"interval\"),\n#                                    # c(\"density\",\"mean\"),\n#                                    # c(\"density\",\"text\"),\n#                                    # c(\"interval\",\"mean\"),\n#                                    # c(\"interval\",\"text\"),\n#                                    # c(\"mean\",\"text\")\n#                                    \n# c %>%\n#   ggplot(aes(x = .value, y = reorder(x =pretty_condition, X = .value)))+\n#   stat_interval(.width = .95, color = \"black\") +\n#   geom_vline(xintercept = 0)+\n#   theme_bw()+\n#   # coord_cartesian(xlim = c(-.5,1)) +\n#   theme_tidybayes() \n# comps\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test\n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(Bmm.cat.CrSQ, exponentiate = TRUE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n\n\n\n\n\nCODE\n# + theme_clean()\n\n# \n# result <- estimate_density(m,exponentiate = TRUE)\n# plot(result,  stack = FALSE, priors = TRUE)\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\nPicking joint bandwidth of 0.0804\n\n\nWarning: Removed 3600 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\nCODE\nresult <- rope(m)\nplot(result)\n\n\n\n\n\nCODE\n(result <- pd(m,exponentiate = TRUE))\n\n\nProbability of Direction\n\nParameter                            |   pd\n-------------------------------------------\nmuother_Intercept                    | 100%\nmuangular_Intercept                  | 100%\nmutriangular_Intercept               | 100%\nmuother_pretty_conditionimpasse      | 100%\nmuangular_pretty_conditionimpasse    | 100%\nmutriangular_pretty_conditionimpasse | 100%\n\n\nCODE\nplot(result, show_intercept = TRUE, show_labels = TRUE)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")\n\n\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n\n\n$pretty_condition\n\n\n\n\n\nCODE\n#TODO EMMEANS for the estimated marginal means\n\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n\n\n\n\nCODE\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\ndraws <- df_i %>%\n  data_grid(pretty_condition, subject, q) %>%\n  add_fitted_draws(Bmm.cat.CrSQ,\n                   # n = 100,\n                   # dpar = TRUE,\n                   # transform = TRUE, #gives prob%, otherwise OR\n                   re_formula = NA)\n\n\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\nUse [add_]epred_draws() to get the expectation of the posterior predictive.\nUse [add_]linpred_draws() to get the distribution of the linear predictor.\nFor example, you used [add_]fitted_draws(..., scale = \"response\"), which\nmeans you most likely want [add_]epred_draws(...).\n\n\nCODE\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\nd <- draws %>% sample_n(10) %>% \n  ggplot(aes(x = .value,  y = .category, fill = pretty_condition)) +\n  stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\") +\n  # stat_halfeye(.width = c(.95), alpha = .6,interval_alpha = 0,point_alpha = 0, normalize = \"groups\") +\n  #   #normalize = all, panels, xy, groups, none\n  xlim(0,1) + labs(\n    title = \"Model Predicted Probability of Correct Response\",\n    x = \"probability of correct response\",\n    y = \"Interpretation\"\n  ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # \n# # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\nd\n\n\n\n\n\n\n\nDiagnostics\n\n\nCODE\n#CHECK Fit of posterior predictive to data\npp_check(Bmm.cat.CrSQ, ndraws=1000)\n\n\n\n\n\nCODE\n#CHECK posterior vs. priors\nresult <- estimate_density(Bmm.cat.CrSQ)\nplot(result, stack = FALSE, priors= TRUE)\n\n\n\n\n\nCODE\n#CHECK model\nplot(Bmm.cat.CrSQ)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOMPARE MBLOGIT to BRMS\n\n\nCODE\ncompare_models(mm.cat.CrSQ, Bmm.cat.CrSQ)\n\n\nParameter                            |          mm.cat.CrSQ |         Bmm.cat.CrSQ\n----------------------------------------------------------------------------------\nother~(Intercept)                    | -2.57 (-3.61, -1.54) |                     \nangular~(Intercept)                  | -4.80 (-6.37, -3.24) |                     \ntriangular~(Intercept)               | -2.92 (-4.46, -1.39) |                     \nother~pretty conditionimpasse        |  2.49 ( 1.73,  3.24) |                     \nangular~pretty conditionimpasse      |  2.99 ( 1.78,  4.19) |                     \ntriangular~pretty conditionimpasse   |  3.45 ( 1.90,  5.01) |                     \nmuother_Intercept                    |                      | -3.09 (-4.02, -2.18)\nmuangular_Intercept                  |                      | -5.69 (-7.29, -4.14)\nmutriangular_Intercept               |                      | -3.60 (-5.13, -2.19)\nmuother_pretty_conditionimpasse      |                      |  2.45 ( 1.80,  3.14)\nmuangular_pretty_conditionimpasse    |                      |  2.73 ( 1.59,  3.99)\nmutriangular_pretty_conditionimpasse |                      |  3.55 ( 1.91,  5.41)\n----------------------------------------------------------------------------------\nObservations                         |                 1638 |                 1638\n\n\nThe predictions of the manual, frequentist mixed multinomial and bayesian mixed multinomial models are comparable."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1b-q1-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1b-q1-accuracy",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "H1B | Q1 ACCURACY",
    "text": "H1B | Q1 ACCURACY\nDo Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?\nThe graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their first exposure to the unconventional triangular coordinate system.\n\n\n\n\n\n\n\nResearch Question\nDoes the frequency of correct (vs) incorrect responses on the first question differ by condition? [Is response accuracy independent of condition?]\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition\n\n\nData\n\ndata: df_items where q == 1\noutcome: accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nLogistic Regression on accuracy predicted by condition\n\naccount for difference in odds of correct score by condition\n\n\nAlternatives:\n\nChi-Square test of independence on outcome accuracy by condition\n\n\n\nNotes\n\nCHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial ~ continuous; though with regression we can quantify the size of the effect and overall model fit\nindependence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent\ncell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)\n\n\n\n\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1)  %>% dplyr::select(accuracy, pretty_condition)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of incorrect (vs) correct responses in each condition for each data collection modality (left/right facet) reveals that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition (marginal probability of incorrect). In the impasse condition, the difference in proportions is smaller than the control condition (conditional probability of success in impasse; (i.e) There are more correct responses in the impasse condition than the control condition).\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n\n\n[1] \"Proportions of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            control impasse   Sum\n  incorrect   0.839   0.703 0.770\n  correct     0.161   0.297 0.230\n  Sum         1.000   1.000 1.000\n\n\nCODE\npaste(\"Number of Correct Responses by Condition\")\n\n\n[1] \"Number of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            control impasse Sum\n  incorrect      52      45  97\n  correct        10      19  29\n  Sum            62      64 126\n\n\n\n\nLOGISTIC REGRESSION\nFit a logistic regression predicting accuracy (absolute score) (n = 126) by condition (k = 2).\n\n\nParameter estimate: \\(\\beta_{0}\\) = Log Odds of (correct) responses in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of correct response in CONTROL condition\nParameter estimate: \\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for correct response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\nNull hypothesis:\\(\\beta_{impasse} \\le 0\\) the odds for a correct response does not change, or decreases\nAlternative hypothesis: \\(\\beta_{impasse} \\gt 0\\) the odds of a correct response increases\n\n\nFit Model\nFirst, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.\n\n\nCODE\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m1)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.839  -0.839  -0.593  -0.593   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.345   -4.77  1.8e-06 ***\npretty_conditionimpasse    0.786      0.441    1.79    0.074 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 135.95  on 125  degrees of freedom\nResidual deviance: 132.63  on 124  degrees of freedom\nAIC: 136.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\ncar::Anova(m1)\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.31  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 3.31 | 0.069\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0687084837283363\"\n\n\nThe Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .\n\n\nDescribe\n\n\nCODE\n#best model \nm <- m1\n\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n\n\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n\n\nCODE\nsummary(m)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.839  -0.839  -0.593  -0.593   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.345   -4.77  1.8e-06 ***\npretty_conditionimpasse    0.786      0.441    1.79    0.074 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 135.95  on 125  degrees of freedom\nResidual deviance: 132.63  on 124  degrees of freedom\nAIC: 136.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\ncar::Anova(m)\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.31  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n##TODO need to do for each coeff\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m, level = 0.90)) # get 90% for right side))\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\n# print(\"Coefficients —- ODDS RATIOS\")\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n# (e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n# (l <- describe_posterior(m))\n(tm <- tidy(m,   conf.int = TRUE))\n\n\n# A tibble: 2 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  <chr>                     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)              -1.65      0.345     -4.77 1.80e-6  -2.39       -1.02\n2 pretty_conditionimpas…    0.786     0.441      1.79 7.42e-2  -0.0595      1.68\n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nParameter                  | Odds Ratio |   SE |       95% CI |     z |      p\n------------------------------------------------------------------------------\n(Intercept)                |       0.19 | 0.07 | [0.09, 0.36] | -4.77 | < .001\npretty condition [impasse] |       2.20 | 0.97 | [0.94, 5.38] |  1.79 | 0.074 \n\n\n\nUncertainty intervals (profile-likelihood) and p-values (two-tailed)\n  computed using a Wald z-distribution approximation.\n\n\nCODE\nprint(\"MODEL PREDICTIONS\")\n\n\n[1] \"MODEL PREDICTIONS\"\n\n\nCODE\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\npaste(\"Probability of success in control,\", pred.control)\n\n\n[1] \"Probability of success in control, 0.161290322580645\"\n\n\nCODE\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\npaste(\"Probability of success in impasse,\", pred.impasse)\n\n\n[1] \"Probability of success in impasse, 0.296875000000275\"\n\n\n\n\nInference\nWe fit a logistic regression model to explore the effect of experimental condition on probability of a correct answer on the first question. In this model, the effect of condition is statistically significant (z = 1.79, p = 0.04, one-tailed). The model predicts that the odds of a correct response on the first question in the impasse condition increase by nearly 120% (\\(e^{beta_{impasse}}\\) = 2.19, 95% CI [1.08, 4.63]) over the control condition. The intercept** \\(\\beta_{0}\\) **parameter is also significant, (\\(e^{b_{0}}\\) = 0.19, p < 0.001, 95% CI [0.11, 0.33]) indicating that the odds of a correct response in the control condition are significantly less than even (less than 50/50 chance of correct response in control condition).\nEquivalent statements:\n\nbeing in impasse condition increases log odds of correct response by 0.79 (over control)\nbeing in impasse increases odds of correct response in impasse over control increases by factor of 2.19\nprobability of correct response in impasse predicted as 30%, vs only 16% in control condition\n\n\n\nVisualize\n\n\nCODE\n#SET MODEL\nm <- m1\n\n#GGSTATS | MODEL | LOG ODDS \n# ggcoefstats(m1, output = \"plot\", \n#               conf.level = 0.90) + \n#   labs(x = \"Log Odds Estimate\", \n#        title = \"LOGODDS | Q1 Accuracy ~ condition\",\n#        subtitle = \"(p is for two tailed test)\")\n\n\n#PARAMETERS | MODEL | SIMULATED PARAMETERS\n# similar to bayesian dist of estimate\n# result <- simulate_parameters(m1)\n# #rename params so intercept is plotted \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result) \n\n#EQUIVALENCE TEST [not sure if appropriate for log model?]\n# https://journals.sagepub.com/doi/10.1177/2515245918770963#:~:text=Consequently%2C%20when%20reporting%20an%20equivalence,values%20is%20smaller%20than%20alpha.\n# https://easystats.github.io/parameters/reference/equivalence_test.lm.html\n# (result <- equivalence_test(m1, rule = \"classic\", component = c(\"all\")))\n# plot(result,   show_intercept = TRUE) + \n#   scale_y_discrete(labels = c(\"impasse\", \"control\")) + \n#   labs( title = \"Equivalence Test for Model Parameter Estimates\")\n\n\n#PARAMETERS | MODEL | ODDS RATIO \n# result <- model_parameters(m1,exponentiate = TRUE)\n# #rename params \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result,   show_intercept = TRUE) +  labs(\n#   title = \"Model Parameter Estimates\"\n# ) + theme_clean() + theme(legend.position=\"blank\")\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  scale_y_continuous() + #remove to put on log scale x axis \n  scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"pred\")[[1]] +\n  ylim(0,1) + #scale y axis to actual range\n  labs(title = \"MODEL PREDICTION  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases probability of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.19\n0.09 – 0.36\n<0.001\n\n\npretty condition[impasse]\n2.20\n0.94 – 5.38\n0.074\n\n\nObservations\n126\n\n\nR2 Tjur\n0.026\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report::report(m1)\n\n#print(\"MODEL PERFORMANCE\")\n# performance(m1)\n\nprint(\"MODEL DIAGNOSTICS\")\n\n\n[1] \"MODEL DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m1)"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1b-q1-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_lab_hypotesting.html#h1b-q1-interpretation-state",
    "title": "6  SGC3A (Lab) Hypothesis Testing",
    "section": "H1B | Q1 INTERPRETATION STATE",
    "text": "H1B | Q1 INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses on the first question?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question\n\n\nData\n\ndata: df_items where q == 1\noutcome: state ( 4 level factor from 5 level high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMultinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nOrdinal regression on state; but model doesn’t satisfy proportional odds assumption (parallel slopes)\nMultinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can’t accurately estimate those comparisons\n\n\n\n\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1) %>% dplyr::select(pretty_condition, state)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. We see that around half of the ‘incorrect’ (i.e. not triangular) responses in the impasse condition are not orthogonal-like, but “other/unknown”.\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse    Sum\n  orthogonal  0.8065  0.3125 0.5556\n  other       0.0161  0.2812 0.1508\n  angular     0.0161  0.1094 0.0635\n  triangular  0.1613  0.2969 0.2302\n  Sum         1.0000  1.0000 1.0000\n\n\nCODE\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n            \n             control impasse Sum\n  orthogonal      50      20  70\n  other            1      18  19\n  angular          1       7   8\n  triangular      10      19  29\n  Sum             62      64 126\n\n\n\n\nMULTINOMIAL REGRESSION\nDoes condition affect the response state of Q1?\nFit a logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\n3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) [essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing [reference category] vs [this category])\nFor each equation:\n\n\\(\\beta_{0}\\) = Log Odds of [this category type vs. reference category type) response in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of [this category type vs. reference category type] response in CONTROL condition\n\\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for [this category] type response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of [this. vs reference category type] response in IMPASSE (vs) CONTROL\nTwo-tailed NHST Null hypothesis: \\(\\beta_{impasse} = 0\\) the odds for [this category of response vs. reference] are not different for IMPASSE condition\nAlternative hypothesis: \\(\\beta_{impasse} \\ne 0\\) the odds of [this category of response vs. reference] increases or decreases for IMPASSE condition\n\n\n\nFit Model [MBLOGIT]\n\n\nCODE\n#check reference level \nprint(\"Categories (first is reference)\")\n\n\n[1] \"Categories (first is reference)\"\n\n\nCODE\nlevels(df$state)\n\n\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n\n\nCODE\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\nmbl.0 <- mblogit(state ~ 1, data = df)\n\n\n\nIteration 1 - deviance = 286 - criterion = 0.388\nIteration 2 - deviance = 283 - criterion = 0.00742\nIteration 3 - deviance = 283 - criterion = 0.0000165\nIteration 4 - deviance = 283 - criterion = 3.71e-11\nconverged\n\n\nCODE\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\nmbl.C <- mblogit(formula = state ~ pretty_condition, data = df, model = TRUE)\n\n\n\nIteration 1 - deviance = 248 - criterion = 0.296\nIteration 2 - deviance = 244 - criterion = 0.0167\nIteration 3 - deviance = 244 - criterion = 0.00155\nIteration 4 - deviance = 244 - criterion = 0.0000328\nIteration 5 - deviance = 244 - criterion = 2.72e-08\nIteration 6 - deviance = 244 - criterion = 2.04e-14\nconverged\n\n\nCODE\n#IDENTICAL TO MULTINOM() FROM nnet.. but multinom doesn't handle mixed\n#so use mblogit for consistency, but need catm for anova test\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\n\n# weights:  12 (6 variable)\ninitial  value 174.673090 \niter  10 value 121.936407\nfinal  value 121.916800 \nconverged\n\n\nCODE\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", AIC(mbl.0) > AIC(mbl.C))\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(mbl.0, mbl.C)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)\n\nName  |   Model | df | df_diff |  Chi2 |      p\n-----------------------------------------------\nmbl.0 | mblogit |  3 |         |       |       \nmbl.C | mblogit |  6 |       3 | 60.50 | < .001\n\n\nCODE\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n\n\nAIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.\n\n\nDescribe\n\n\nCODE\n#set model\nm <- mbl.C\n\n#confirm models match \ncompare_models(mbl.C, catm)\n\n\nParameter                          |                mbl.C |                 catm\n--------------------------------------------------------------------------------\n(Intercept)                        |                      | -3.91 (-5.91, -1.91)\n(Intercept)                        |                      | -3.91 (-5.91, -1.91)\n(Intercept)                        |                      | -1.61 (-2.30, -0.92)\nother~(Intercept)                  | -3.91 (-5.90, -1.93) |                     \nangular~(Intercept)                | -3.91 (-5.90, -1.93) |                     \ntriangular~(Intercept)             | -1.61 (-2.29, -0.93) |                     \nother~pretty conditionimpasse      |  3.81 ( 1.72,  5.89) |                     \nangular~pretty conditionimpasse    |  2.86 ( 0.70,  5.03) |                     \ntriangular~pretty conditionimpasse |  1.56 ( 0.63,  2.49) |                     \npretty condition (impasse)         |                      |  3.81 ( 1.71,  5.91)\npretty_conditionimpasse            |                      |  2.86 ( 0.68,  5.04)\npretty_conditionimpasse            |                      |  1.56 ( 0.62,  2.49)\n--------------------------------------------------------------------------------\nObservations                       |                  126 |                  126\n\n\nCODE\n#::::::::: PRINT MODEL \npaste(\"MODEL SUMMARY\")\n\n\n[1] \"MODEL SUMMARY\"\n\n\nCODE\nsummary(m)\n\n\n\nCall:\nmblogit(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nEquation for other vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -3.91       1.01   -3.87  0.00011 ***\npretty_conditionimpasse     3.81       1.06    3.59  0.00033 ***\n\nEquation for angular vs orthogonal:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  -3.912      1.010   -3.87  0.00011 ***\ntri(Intercept)               -1.609      0.346   -4.65  3.4e-06 ***\npretty_conditionimpasse       2.862      1.101    2.60  0.00935 ** \ntripretty_conditionimpasse    1.558      0.472    3.30  0.00096 ***\n\nEquation for triangular vs orthogonal:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.609      0.346   -4.65  3.4e-06 ***\npretty_conditionimpasse    1.558      0.472    3.30  0.00096 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNull Deviance:     349 \nResidual Deviance: 244 \nNumber of Fisher Scoring iterations:  6 \nNumber of observations:  126 \n\n\nCODE\npaste(\"SIGNIFICANCE TEST\")\n\n\n[1] \"SIGNIFICANCE TEST\"\n\n\nCODE\n# car::Anova(mbl.C)\ncar::Anova(catm)\n\n\n# weights:  8 (3 variable)\ninitial  value 174.673090 \niter  10 value 141.745541\nfinal  value 141.745401 \nconverged\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     39.7  3    1.3e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n# (l <- describe_posterior(m))\n(tm <- tidy(m,   conf.int = TRUE))\n\n\nWarning: The `tidy()` method for objects of class mblogit is not maintained by\nthe broom team, and is only supported through the lm tidier method. Please be\ncautious in interpreting and reporting broom output.\n\n\n# A tibble: 6 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  <chr>                     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 other~(Intercept)         -3.91     1.01      -3.87 1.07e-4   -5.90     -1.93 \n2 angular~(Intercept)       -3.91     1.01      -3.87 1.07e-4   -5.90     -1.93 \n3 triangular~(Intercept)    -1.61     0.346     -4.65 3.38e-6   -2.29     -0.928\n4 other~pretty_conditio…     3.81     1.06       3.59 3.33e-4    1.72      5.89 \n5 angular~pretty_condit…     2.86     1.10       2.60 9.35e-3    0.697     5.03 \n6 triangular~pretty_con…     1.56     0.472      3.30 9.59e-4    0.630     2.49 \n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nParameter                          | Coefficient |    SE |         95% CI | Statistic |  df |      p\n----------------------------------------------------------------------------------------------------\nother~(Intercept)                  |        0.02 |  0.02 | [0.00,   0.15] |     -3.87 | 372 | < .001\nangular~(Intercept)                |        0.02 |  0.02 | [0.00,   0.15] |     -3.87 | 372 | < .001\ntriangular~(Intercept)             |        0.20 |  0.07 | [0.10,   0.40] |     -4.65 | 372 | < .001\nother~pretty conditionimpasse      |       45.00 | 47.74 | [5.59, 362.43] |      3.59 | 372 | < .001\nangular~pretty conditionimpasse    |       17.50 | 19.27 | [2.01, 152.59] |      2.60 | 372 | 0.010 \ntriangular~pretty conditionimpasse |        4.75 |  2.24 | [1.88,  12.01] |      3.30 | 372 | 0.001 \n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald distribution approximation.\n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\nnewdata <- df %>% dplyr::select(pretty_condition)\npreds <- predict(catm, newdata = newdata, type = \"probs\")\npreds <- cbind(newdata, preds)\n#LENGTHEN TO HANDLE MULTINOMIAL\npreds <- preds %>%\n  # dplyr::select(-subject, -q) %>% #marginalize over subject and q\n  pivot_longer(\n  cols = !pretty_condition,\n  values_to = \"preds\",\n  names_to = \"state\",\n)\n\n(p <- preds %>%\n  group_by(pretty_condition, state ) %>%\n  summarise(\n    median = median(preds),\n    se = sd(preds)/sqrt(n()),\n    lwr = median - 1.96*se,\n    upr = median + 1.96*se))\n\n\n# A tibble: 8 × 6\n# Groups:   pretty_condition [2]\n  pretty_condition state      median    se    lwr    upr\n  <fct>            <chr>       <dbl> <dbl>  <dbl>  <dbl>\n1 control          angular    0.0161     0 0.0161 0.0161\n2 control          orthogonal 0.806      0 0.806  0.806 \n3 control          other      0.0161     0 0.0161 0.0161\n4 control          triangular 0.161      0 0.161  0.161 \n5 impasse          angular    0.109      0 0.109  0.109 \n6 impasse          orthogonal 0.313      0 0.313  0.313 \n7 impasse          other      0.281      0 0.281  0.281 \n8 impasse          triangular 0.297      0 0.297  0.297 \n\n\n\n\nInference TODO\n\nBeing in the IMPASSE condition increases the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 45 (z = 3.81, p < 0.001) . Participants in the impasse condition were 45x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control.\nBeing in the IMPASSE condition increases the odds of giving ‘triangle-like’ response rather than an orthogonal (or satisficing) response by a factor of 17.5 (z = 2.60, p < 0.001 ). Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control.\nBeing in the IMPASSE condition increases the odds of giving ‘triangle-like’ response rather than an orthogonal (or satisficing) response by a factor of 4.8 (z = 3.30, p < 0.001 ). Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control.\nAs with the (binary) logistic regression on accuracy ~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 in the control condition. (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n[need to to double check interpretation, but I think that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the control condition. which makes sense. I think.?]\nIF I change reference category for condition… then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) [Yup! this works!]\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n\n\nWarning: Could not estimate a good default ROPE range. Using 'c(-0.1, 0.1)'.\n\n\nCODE\nplot(result)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n#TODO NEED FIX THIS\n# (d <- p %>%\n#   ggplot(aes(y = median,  x = state, fill = pretty_condition)) +\n#   geom_point() +\n#   geom_errorbar(aes(ymin = lwr, ymax = upr))\n#     # stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\")\n#   #   #normalize = all, panels, xy, groups, none\n#   # xlim(0,1) + labs(\n#   #   title = \"Model Predicted Probability of Correct Response\",\n#   #   x = \"probability of correct response\",\n#   #   y = \"Interpretation\"\n#   # ) +  theme_clean() #+ ggeasy::easy_remove_legend() +\n# )\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \nstate\n\n\nPredictors\nEstimates\nCI\np\n\n\nother~(Intercept)\n-3.91\n-5.90 – -1.93\n<0.001\n\n\nangular~(Intercept)\n-3.91\n-5.90 – -1.93\n<0.001\n\n\ntriangular~(Intercept)\n-1.61\n-2.29 – -0.93\n<0.001\n\n\nother~prettyconditionimpasse\n3.81\n1.72 – 5.89\n<0.001\n\n\nangular~prettyconditionimpasse\n2.86\n0.70 – 5.03\n0.010\n\n\ntriangular~prettyconditionimpasse\n1.56\n0.63 – 2.49\n0.001\n\n\nObservations\n126\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n\n\n\n\nDiagnostics\n\n\nCODE\n#EXAMINE PREDICTIONS\n# #create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(catm, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n\nprint(\"MODEL PERFORMANCE\")\n\n\n[1] \"MODEL PERFORMANCE\"\n\n\nCODE\nperformance(catm)\n\n\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n255.834 | 272.851 | 0.140 |     0.133 | 0.363 | 1.425\n\n\nCODE\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n\n\n  McFadden   CoxSnell Nagelkerke \n     0.140      0.270      0.302"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "",
    "text": "The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study (online replication, without OSPAN).\nResearch Questions\nIn SGC3A we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task?\nExperimental Hypothesis\nLearners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.\nNull Hypothesis\nNo significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#sample",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#sample",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData was collected (online, via SONA) in Fall 2021 and Winter 2022, for the purpose of verifying the use of the graph comprehension task for online, asynchronous data collection.\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    fall21 \n    3 \n    3 \n    6 \n  \n  \n    winter22 \n    28 \n    37 \n    65 \n  \n  \n    Sum \n    31 \n    40 \n    71 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.male \n    percent.female \n    percent.other \n  \n \n\n  \n     \n    18 \n    20 \n    20 \n    21 \n    27 \n    20.6 \n    1.61 \n    71 \n    0 \n    0.282 \n    0.676 \n    0.042 \n  \n\n\nNote:   Age in Years\n\n\n\n\nREPORTED\nOverall 71 participants (28 % male, 68 % female, 4 % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 27 years)."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1a-overall-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1a-overall-accuracy",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "H1A | OVERALL ACCURACY",
    "text": "H1A | OVERALL ACCURACY\n\n\n\n\n\n\n\nResearch Question\nDo Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?\n\n\n\n\nHypothesis\n(H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.\n\n\nData\ndata: df_items where q nin 6,9 (the 13 discriminating Qs ), df_subjects\noutcome:\n\n[at item level] : accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\n[subject level]: accuracy (number of test phase qs correct from total s_NABS)\n\npredictor: condition [between-subjects factor]\n\n\nAnalysis Strategy\n\nWilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (s_NABS)\nMixed Logistic Regression\naccuracy ~ condition + (1 | subject ) + (1 | question)\nmodel effect of condition on probability of correct response [during test phase] while accounting for subject (and item-level?) effects\n\n\n\nAlternatives\n\nOrdinal Mixed Logistic Regression on scaled_score\nOLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals\n\n\n\nNotes\nAlso exploring:\n\nHurdle model (mixture model w/ binomial + [poisson or negbinom count; 0s from 1 DGP)\nZero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)\nBeta regression hurdle model? (mixture with location and scale parameters [mean, variance] and hurdles for floor and ceiling effects)\nOther way to account for the severe bimodality?\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q)\n\ndf_s <- df_subjects %>% \n   dplyr::select(pretty_condition, task_percent)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 2))+\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n  # coord_flip() +\n  theme(legend.position=\"bottom\")+\n   labs(title = \"STUDY 3A (online replication) | DISTRIBUTION of Question Accuracy\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~q) +\n   labs(title = \"STUDY 3 (online replication) | DISTRIBUTION of Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n\n\n\n\n\nCODE\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  # gf_facet_grid(pretty_condition ~ pretty_mode) %>%\n  gf_facet_grid(~pretty_condition) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"DISTRIBUTION | Total Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nCODE\n#:::::::: RAINCLOUD WITH STATS\n  \ndf <- df_s %>% mutate(task_percent = task_percent*100)\n\np <-   ggbetweenstats(data = df, x = pretty_condition, y = task_percent,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               # package = \"RColorBrewer\",\n               # palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  # aes(color = pretty_condition, fill = pretty_condition),\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  theme(axis.text.x = element_text(angle = 90)))\n               ) +\n  ggdist::stat_halfeye(\n    alpha = 0.7, \n    point_colour = NA,\n    adjust = .5, \n    width = .5, .width = 0, \n    justification = -.5) +\n  geom_boxplot(\n    alpha = 0.1,\n    width = .2, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 2,\n    alpha = .5,\n    position = position_jitter(\n      seed = 1, width = .08, height = 1.5\n    )\n  )  +\ncoord_flip() + theme_clean() + theme(legend.position = \"blank\")\np$layers[[3]]=NULL #remove default boxplot\ne <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df,\n                                type = \"nonparametric\", alternative = \"less\",\n                                var.equal = FALSE)\n#labels are layer 4\np <- p + labs(title = \"STUDY 3A (Online Replication) | Distribution of Total Score\",\n         y = \"Percentage of correct responses across task\", x = \"\",\n         # caption=e$expression[[1]],\n         subtitle = \"Impasse condition yields greater variance and more high scores\")\n\np\n\n\n\n\n\nCODE\nggsave(p, filename = \"figures/SGC3A_REP_totalscore.png\", width = 6, height =4)\n\n\n\n\nDescribe\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0 \n    0 \n    0.077 \n    0.769 \n    1 \n    0.32 \n    0.392 \n    71 \n    0 \n  \n\n\n\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\n \n  \n    pretty_condition \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    control \n    0 \n    0.000 \n    0.000 \n    0.269 \n    1 \n    0.236 \n    0.372 \n    31 \n    0 \n  \n  \n    impasse \n    0 \n    0.058 \n    0.115 \n    0.846 \n    1 \n    0.385 \n    0.399 \n    40 \n    0 \n  \n\n\n\n\n\n\nWILCOXON RANK SUM (Mann-Whitney Test)\n\nNon parametric alternative to t-test; compares median rather than mean by ranking data\nDoes not assume normality\nDoes not assume equal variance of samples (homogeneity of variance)\n\n\nTest\n\n\nCODE\n(w <- wilcox.test(df_s$task_percent ~ df_s$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df_s$task_percent by df_s$pretty_condition\nW = 457, p-value = 0.03\nalternative hypothesis: true location shift is less than 0\n\n\nCODE\nreport(w)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_s$task_percent and df_s$pretty_condition suggests that the effect is negative, statistically significant, and medium (W = 457.00, p = 0.026; r (rank biserial) = -0.26, 95% CI [-1.00, -0.04])\n\n\n\n\nInference – DIRECTIONAL EFFECT\n\n\nVisualize\n\n\nCODE\nggbetweenstats( x = pretty_condition, y = task_percent, data = df_s,\n                type = \"nonparametric\", var.equal = FALSE)\n\n\n\n\n\n\n\n\nMIXED LOGISTIC REGRESSION\nFit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.\n\nFit Model\n\n\nCODE\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n\n\n[1] TRUE\n\n\nCODE\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n\n\n[1] TRUE\n\n\nCODE\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n\n\n[1] \"Empty fixed model\"\n\n\nCODE\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n\n\n[1] \"Subject intercept random model\"\n\n\nCODE\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  2 |       1 | 542.98 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  4.24706346098158e-120\"\n\n\nCODE\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n\n\n[1] \"Subject Intercept + Item intercept random model\"\n\n\nCODE\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.rSQ | glmerMod |  3 |       1 | 16.08 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0000608083810989485\"\n\n\nCODE\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n\n\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n\n\nCODE\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n#summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |      |      \nmm.CrSQ | glmerMod |  4 |       1 | 4.19 | 0.041\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0405529998876994\"\n\n\nCODE\n# control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n\n\nA likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.\n\n\nDescribe\n\n\nCODE\n#::::::::: SETUP\nm <- mm.CrSQ\nm %>% write_rds(file = \"analysis/SGC3A/models/sgc3a_glmer_acc_mm.CrSQ_REP.rds\")\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     601      621     -297      593      919 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-6.283 -0.231 -0.091  0.212  5.031 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 14.905   3.861   \n q       (Intercept)  0.545   0.738   \nNumber of obs: 923, groups:  subject, 71; q, 13\n\nFixed effects:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -3.542      0.944   -3.75  0.00018 ***\npretty_conditionimpasse    2.204      1.105    1.99  0.04619 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nprtty_cndtn -0.771\n\n\nCODE\nprint(\"SIGNIFICANCE TEST [non directional]\")\n\n\n[1] \"SIGNIFICANCE TEST [non directional]\"\n\n\nCODE\ncar::Anova(m)\n\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                 Chisq Df Pr(>Chisq)  \npretty_condition  3.97  1      0.046 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\npaste(\"MODEL INFO\")\n\n\n[1] \"MODEL INFO\"\n\n\nCODE\nglance(m)\n\n\n# A tibble: 1 × 7\n   nobs sigma logLik   AIC   BIC deviance df.residual\n  <int> <dbl>  <dbl> <dbl> <dbl>    <dbl>       <int>\n1   923     1  -297.  601.  621.     367.         919\n\n\nCODE\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n# se <- sqrt(diag(stats::vcov(m)))\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n\n\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   -3.54      0.944     -3.75  1.75e-4  -5.39       -1.69\n2 fixed    <NA>   pret…    2.20      1.11       1.99  4.62e-2   0.0373      4.37\n3 ran_pars subje… sd__…    3.86     NA         NA    NA        NA          NA   \n4 ran_pars q      sd__…    0.738    NA         NA    NA        NA          NA   \n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n# (e <- exp(tab))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n\n\n# A tibble: 4 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   0.0290    0.0273     -3.75  1.75e-4  0.00455     0.184\n2 fixed    <NA>   pret…   9.06     10.0         1.99  4.62e-2  1.04       79.1  \n3 ran_pars subje… sd__…   3.86     NA          NA    NA       NA          NA    \n4 ran_pars q      sd__…   0.738    NA          NA    NA       NA          NA    \n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\n#setup df \nnewdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(pretty_condition, fit, lwr, upr) %>% \n  group_by(pretty_condition) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n\n\n# A tibble: 2 × 4\n  pretty_condition median   lower upper\n  <fct>             <dbl>   <dbl> <dbl>\n1 control          0.0278 0.00474 0.147\n2 impasse          0.206  0.0516  0.555\n\n\n\n\nINFERENCE — SIGNIFICANT EFFECT\n\n\nPrint\n\n\nCODE\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n\nmodels <- list(\"odds ratios\" = m, \"(log odds)\" = m)\ntitle = \"Study 3A (Online Replication) | Question Accuracy | Mixed Logistic Regression\"\nnotes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n             paste(\"n = \",n_obs(m), \"R^2(Conditional) =\", round(r2(m)[[1]],2),\n                   \"R^2(Marginal) =\", round(r2(m)[[2]],2)),\n             \"Accuracy  ~ Condition + (1 | subject) + (1 | q)\")\n\nmodelsummary(models,\n             exponentiate = c(TRUE, FALSE),\n             shape = term ~ model + statistic,\n             fmt = 2, #two digits w/ trailing zero\n             estimate  = \"{estimate} {stars}\",\n             statistic = \"conf.int\",\n             gof_map = c(\"AIC\", \"sigma\"),\n             gof_omit = 'RMSE|ICC|BIC',\n             coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n             title = title,\n             notes = notes,\n             output = \"tables/SGC3A_REP_GLMER_OverallAccuracy.tex\")\n\n\nWarning: To compile a LaTeX document with this table, the following commands must be placed in the document preamble:\n\n\\usepackage{booktabs}\n\\usepackage{siunitx}\n\\newcolumntype{d}{S[input-symbols = ()]}\n\nTo disable `siunitx` and prevent `modelsummary` from wrapping numeric entries in `\\num{}`, call:\n\noptions(\"modelsummary_format_numeric_latex\" = \"plain\")\n This warning appears once per session.\n\n\nCODE\n# #              # coef_omit = \"Intercept\",\n\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n\n#SJPLOT | MODEL | lOG ODDS\nplot_model(m, transform = NULL,\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.06, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | LOG ODDS\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, transform = \"exp\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.06, #manually adjust to account for directional test\n           ci.lvl = 0.95 ) + #manually adjusted for directional test   \n  labs(title = \"Model ESTIMATE | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result) + labs(\n#     title = \"Model ESTIMATE | ODDS RATIO\"\n#   )\n\n## | PLOT TESTS\n# result <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n# plot(result)\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"pred\")[[1]]  +\n  ylim(0,1) +\n  labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"Impasse increases probability of correct response\",\n    y = \"Probability of Correct Response\", x = \"Condition\"\n  )\n\n\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n\n\n\n\n\nCODE\n#GGDIST | MODEL | PREDICTED PROBABILITIES\npreds %>% \n  ggplot(aes( x = fit, y = pretty_condition, fill = pretty_condition)) + \n  stat_halfeye(alpha = 0.5, normalize = \"xy\") + \n  xlim(0,0.3) + theme_clean() + labs(\n    title = \"Model PREDICTION | Probability of Accurate Response\",\n    subtitle = \"TODO check preds to see if fixed or includes random\"\n  )\n\n\n\n\n\nCODE\n# SIMULATE FIXED EFFECTS\n# simulate values of fixed effects \n# (feEx <- FEsim(m,  oddsRatio = FALSE, n.sims = 1000))\n# PLOT estimates of fixed effects\n# plotFEsim(feEx) +\n#   theme_bw() + labs(title = \"Coefficient Plot of InstEval Model\",\n#                     x = \"Median Effect Estimate\")\n\n# SIMULATE RANDOM EFFECTS\n# simulate values of random effects\n# reEx <- REsim(m)\n# PLOT estimates of random effects\n# plotREsim(reEx)\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n\n\n[1] \"DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)\n\n\n\n\n\n\n\nSanity Check :: Bayesian\n\n\nCODE\n# ## 0 | SETUP\n# #confirm 13 items [all discriminating items]\n# nrow(df_i) / nrow(df_s) == 13\n# #confirm all factors \n# is.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy)\n# \n#\n# \n# print(\"FIXED Condition + Subject & Item random intercepts\")\n# Bmm.CrSQ <- brm( accuracy ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"bernoulli\",\n#                  chains = 4, iter = 2000, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_acc_Bmm.CrSQ_REP.rds\")\n# \n# #get Priors \n# # describe_priors(Bmm.CrSQ)\n# \n# #GRAPHICAL POSTERIOR PREDICTION CHECKS\n# pp_check(Bmm.CrSQ)\n# \n# #DESCRIBE MODEL\n# (d <- describe_posterior(ci=.95, Bmm.CrSQ))\n# \n# #SEE MODEL\n# plot(pd(Bmm.CrSQ))\n# #convert to a pd value\n# (pds <- pd_to_p(d$pd))\n\n\nA likelihood ratio test indicates adding CONDITION as a fixed effect to a logistic regression model including a fixed effect random intercepts for SUBJECT and QUESTION explains more variance in the data than random-effects only model.\n\n\nCODE\n# #::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n# ##WORKING\n# ## VIS probability of correct response\n# #TAKES A REALLY LONG TIME\n# \n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(\"analysis/SGC3A/models/draws_BB.catCrSQ.rds\")\n# \n# #2| VISUALIZE PREDICTIONS | GGDIST\n# ##TODO figure out height normalization.\n# ##do it with much smaller number of draws \n# #TODO adjust bandwidth/smoothing? + put on same line + \n# #TAKES A REAAALY LONG TIME\n# # draws %>% sample_n(1000) %>% \n# #   ggplot(aes(x = .value,  y = 0, fill = pretty_condition)) +\n# #   stat_slab(width = c(.95), alpha = 1, normalize=\"xy\") +\n# #   #normalize = all, panels, xy, groups, none\n# #   xlim(0,1) + labs(\n# #     title = \"Model Predicted Probability of Correct Response\",\n# #     x = \"probability of correct response\",\n# #     y = \"Interpretation\"\n# #   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1a-overall-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1a-overall-interpretation-state",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "H1A | OVERALL INTERPRETATION STATE",
    "text": "H1A | OVERALL INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses across questions?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items\n\n\nData\n\ndata: df_items where q nin 6,9 (13 discriminant test phase items)\noutcome: state ( 3 level factor from high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMIXED Multinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nMIXED Ordinal regression on state (doesn’t meet proportional odds assumption-I think)\nMIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  # facet_wrap(~pretty_mode) + \n  theme(legend.position = \"bottom\")+\n   labs(title = \"Study 3A (online replication) | DISTRIBUTION of Interpretation\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  facet_wrap(~q) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. In the impasse condition, there are also more positive transition (i.e. triangle-like) and neutral (ie. blank or uncertain response types) than in the control condition.\n\n\nDescribe\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse    Sum\n  orthogonal  0.5682  0.3115 0.4236\n  other       0.1414  0.2308 0.1918\n  angular     0.0546  0.0731 0.0650\n  triangular  0.2357  0.3846 0.3196\n  Sum         1.0000  1.0000 1.0000\n\n\nCODE\n(t <- table(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n            \n             control impasse Sum\n  orthogonal     229     162 391\n  other           57     120 177\n  angular         22      38  60\n  triangular      95     200 295\n  Sum            403     520 923\n\n\n\n\nMIXED MULTINOMIAL REGRESSION\nDoes condition affect the response state of of items across the task?\nFit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\nFit Model [brms]\n\n\nCODE\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.rSQ_REP.rds\")\n\n\n#UNINFORMATIVE PRIOR BAYESIAN MIXED VERSION\n# flat_Bmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n#                  data = df_i, \n#                  family = \"categorical\",\n#                  chains = 4, iter = 2500, warmup = 1000,\n#                  cores = 4, seed = 1234,\n#                  save_pars = save_pars(all = TRUE),\n#                  # backend = \"cmdstanr\",\n#                  file =\"analysis/SGC3A/models/sgc3a_brms_state_FLAT_Bmm.cat.CrSQ_REP.rds\")\n\n\n# determine default priors \n# prior_summary(flat_Bmm.cat.CrSQ)\n\n#set priors [see justification, below]\ninf_priors <- c(\n  # too strong?\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muangular\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"muother\"),\n  # prior(normal(-6.91, 0.201),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\")\n)\n\n#INFORMATIVE PRIORS\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 prior = inf_priors,\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.CrSQ_REP.rds\"\n                 )\n\n#a bayes factor model comparison of the flat vs informative prior models suggest convicing evidence that \n#informative prior model is a better fit\n# bayesfactor(Bmm.cat.CrSQ, flat_Bmm.cat.CrSQ)\n\n# PRIORS LOGIC \n# https://www.bayesrulesbook.com/chapter-13.html#building-the-logistic-regression-model\n\n#expectation for probability of _better_ response [in control]?\n#very low probability center: 0.1% [very low]; as logodds = logit(0.001) = -6.91\n#range from 0 to 55%  logit(0.55) = 0.201\n#probability of 0.1 to 55% is equivalent to [logodds] -6.91 +/ 2* 0.201\n#therefore... prior for intercept => Normal(−6.91, 0)\n\n\n#expectation for probability of _better_ response [in impasse]?\n#increases probablity from 0 % \n# 0 [very low]; as OR  = exp(0) = 1\n#range from 0 to 90%  exp(0.9) = 2.46\n#probability of 0 to 90% is equivalent to [ODDS scale] 1 +/ 2* 2.42\n#on log odds scale ? [0, ]\n#therefore... prior for intercept => Normal(1, 2.42)\n                             # prior = normal(0.07, 0.035),\n\n\n\n\nDescribe\n\n\nCODE\n# best model\nm <- Bmm.cat.CrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ pretty_condition + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 923) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.53      0.40     0.93     2.50 1.00     2333\nsd(muangular_Intercept)        1.25      0.39     0.66     2.20 1.00     2334\nsd(mutriangular_Intercept)     0.96      0.30     0.50     1.64 1.00     2294\n                           Tail_ESS\nsd(muother_Intercept)          3830\nsd(muangular_Intercept)        3697\nsd(mutriangular_Intercept)     3092\n\n~subject (Number of levels: 71) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.06      0.20     0.70     1.49 1.00     2541\nsd(muangular_Intercept)        1.56      0.32     1.00     2.27 1.00     2374\nsd(mutriangular_Intercept)     4.40      0.61     3.36     5.77 1.00     1783\n                           Tail_ESS\nsd(muother_Intercept)          3759\nsd(muangular_Intercept)        3963\nsd(mutriangular_Intercept)     3493\n\nPopulation-Level Effects: \n                                     Estimate Est.Error l-95% CI u-95% CI Rhat\nmuother_Intercept                       -1.99      0.51    -2.99    -1.01 1.00\nmuangular_Intercept                     -3.25      0.57    -4.39    -2.16 1.00\nmutriangular_Intercept                  -2.74      0.91    -4.57    -1.02 1.00\nmuother_pretty_conditionimpasse          1.52      0.36     0.82     2.25 1.00\nmuangular_pretty_conditionimpasse        1.31      0.54     0.26     2.39 1.00\nmutriangular_pretty_conditionimpasse     2.19      1.08     0.04     4.31 1.00\n                                     Bulk_ESS Tail_ESS\nmuother_Intercept                        1577     3099\nmuangular_Intercept                      2984     4101\nmutriangular_Intercept                   1563     2547\nmuother_pretty_conditionimpasse          3924     4198\nmuangular_pretty_conditionimpasse        3980     4249\nmutriangular_pretty_conditionimpasse     1176     1865\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCODE\n(d <- describe_posterior(ci=.95, Bmm.cat.CrSQ))\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -2.00 | [-2.99, -1.01] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1612.00\nmuangular_Intercept                  |  -3.24 | [-4.39, -2.16] |   100% | [-0.18, 0.18] |        0% | 1.000 | 2912.00\nmutriangular_Intercept               |  -2.71 | [-4.57, -1.02] | 99.85% | [-0.18, 0.18] |        0% | 1.002 | 1529.00\nmuother_pretty_conditionimpasse      |   1.52 | [ 0.82,  2.25] |   100% | [-0.18, 0.18] |        0% | 1.000 | 3882.00\nmuangular_pretty_conditionimpasse    |   1.31 | [ 0.26,  2.39] | 99.28% | [-0.18, 0.18] |        0% | 1.000 | 3983.00\nmutriangular_pretty_conditionimpasse |   2.18 | [ 0.04,  4.31] | 97.62% | [-0.18, 0.18] |     0.56% | 1.002 | 1168.00\n\n\nCODE\nprint(\"BAYES FACTOR [comparison to null]\")\n\n\n[1] \"BAYES FACTOR [comparison to null]\"\n\n\nCODE\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(Bmm.cat.rSQ, m))\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n\n\nBayes Factors for Model Comparison\n\n    Model                                            BF\n[2] pretty_condition + (1 | subject) + (1 | q) 3.08e+04\n\n* Against Denominator: [1] 1 + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n\n\nCODE\nprint(\"DESCRIBE POSTERIOR\")\n\n\n[1] \"DESCRIBE POSTERIOR\"\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n(l <- describe_posterior(m))\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n---------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -2.00 | [-2.99, -1.01] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1612.00\nmuangular_Intercept                  |  -3.24 | [-4.39, -2.16] |   100% | [-0.18, 0.18] |        0% | 1.000 | 2912.00\nmutriangular_Intercept               |  -2.71 | [-4.57, -1.02] | 99.85% | [-0.18, 0.18] |        0% | 1.002 | 1529.00\nmuother_pretty_conditionimpasse      |   1.52 | [ 0.82,  2.25] |   100% | [-0.18, 0.18] |        0% | 1.000 | 3882.00\nmuangular_pretty_conditionimpasse    |   1.31 | [ 0.26,  2.39] | 99.28% | [-0.18, 0.18] |        0% | 1.000 | 3983.00\nmutriangular_pretty_conditionimpasse |   2.18 | [ 0.04,  4.31] | 97.62% | [-0.18, 0.18] |     0.56% | 1.002 | 1168.00\n\n\nCODE\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\nParameter                            | Median |        95% CI |     pd | % in ROPE |  Rhat |     ESS\n----------------------------------------------------------------------------------------------------\nmuother_Intercept                    |   0.14 | [0.05,  0.37] |   100% |        0% | 1.000 | 1612.00\nmuangular_Intercept                  |   0.04 | [0.01,  0.12] |   100% |        0% | 1.000 | 2912.00\nmutriangular_Intercept               |   0.07 | [0.01,  0.36] | 99.85% |        0% | 1.002 | 1529.00\nmuother_pretty_conditionimpasse      |   4.57 | [2.27,  9.52] |   100% |        0% | 1.000 | 3882.00\nmuangular_pretty_conditionimpasse    |   3.69 | [1.29, 10.91] | 99.28% |        0% | 1.000 | 3983.00\nmutriangular_pretty_conditionimpasse |   8.82 | [1.04, 74.73] | 97.62% |     0.56% | 1.002 | 1168.00\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nCODE\n# tidy(m,   conf.int = TRUE, exponentiate = TRUE)\n# tm %>% mutate(\n#   OR.est = exp(estimate),\n#   exp.low = exp(conf.low),\n#   exp.high = exp(conf.high)\n# ) %>% dplyr::select(effect, component, group, term, OR.est, exp.low, exp.high)\n\n# paste(\"PROBABILITIES\")\n# \n# #PREDICT METHOD\nnewdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\npreds <- predict(m, newdata = newdata, type = \"response\")\npreds <- cbind(newdata, preds)\n# #lengthen data frame to handle multinomial\npreds <- preds %>%\n  dplyr::select(-subject, -q) %>% #marginalize over subject and q\n  pivot_longer(\n  cols = !pretty_condition,\n  values_to = \"preds\",\n  names_to = \"state\",\n)\n# \n(p <- preds %>%\n  group_by(pretty_condition, state ) %>%\n  summarise(\n    median = median(preds),\n    se = sd(preds)/sqrt(n()),\n    lwr = median - 1.96*se,\n    upr = median + 1.96*se))\n\n\n# A tibble: 8 × 6\n# Groups:   pretty_condition [2]\n  pretty_condition state             median      se     lwr    upr\n  <fct>            <chr>              <dbl>   <dbl>   <dbl>  <dbl>\n1 control          P(Y = angular)    0.0275 0.00382 0.0200  0.0350\n2 control          P(Y = orthogonal) 0.635  0.0156  0.605   0.666 \n3 control          P(Y = other)      0.0867 0.00753 0.0719  0.101 \n4 control          P(Y = triangular) 0.036  0.0177  0.00137 0.0706\n5 impasse          P(Y = angular)    0.0427 0.00393 0.0350  0.0504\n6 impasse          P(Y = orthogonal) 0.247  0.0119  0.224   0.271 \n7 impasse          P(Y = other)      0.166  0.00906 0.148   0.184 \n8 impasse          P(Y = triangular) 0.154  0.0170  0.121   0.187 \n\n\nCODE\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n\n\n\n\nINFERENCE — EFFECT\n[REPORT POSTERIOR MEDIAN \\(\\exp_{beta}\\), 95 % credible interval, % probability of direction]\nWe fit a (bayesian) multinomial logistic regression model with random intercepts for subjects and questions. A Bayes Factor model comparison (against a random intercepts-only model) indicates extreme evidence for a main effect of CONDITION (BF = 4.09e+03). Consistent with our hypothesis, the impasse condition substantially increases the odds of transitional interpretations.\nAcross the entire task participants in the impasse condition were 5 times as likely to offer an ‘unknown’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 4.57, 95 \\% CI [2.27, 9.52], pd = 99.9\\%\\)). Participants in the impasse condition were 4 times more likely to offer an ‘angular’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 3.69, 95 \\% CI [1.29, 10.91], pd = 99.3\\%\\)), and 9 times more likely to offer an ‘triangular’ rather than orthogonal response compared with those in the control condition ( \\(e^{\\beta_1} = 8.82, 95 \\% CI [1.04, 74.73], pd = 97.6\\%\\)).\n\n\nPrint\n\n\nCODE\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n#model summary doesn't work for brms multinomial\n\n# DOESN'T WORK FOR BRMS\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n# \n# \n# # #GET MODEL ESTIMATES\n# t <- as.data.frame(model_parameters(m, exponentiate = TRUE))\n# \n# #REFORMAT\n# x <- t %>%\n#   mutate(\n#     Interpretation = word(Parameter, 2, sep = \"_\"),\n#     Interpretation = str_remove_all(Interpretation,\"mu\"),\n#     Interpretation = fct_relevel(Interpretation, levels = c(\"other\",\"angular\",\"triangular\")),\n# \n#     Parameter = as.factor(word(Parameter, 3, sep = \"_\")),\n#     Parameter = recode_factor(Parameter,\n#                          \"Intercept\" = \"(Intercept)\",\n#                          \"pretty\" = \"Condition[impasse]\"),\n#     Median = round(Median,2),\n#     CI_low = round(CI_low,2),\n#     CI_high = round(CI_high,2),\n#     pd = round(pd,2),\n#     ROPE_Percentage = round(ROPE_Percentage,2)\n#   ) %>%\n#   arrange(Interpretation) %>%\n#   dplyr::select(-CI, -Rhat, -ESS) %>%\n#   rename( \"%_in_ROPE\"=\"ROPE_Percentage\",\n#           \"(Odds Ratio)\" = \"Median\") %>%\n#   dplyr::select(Interpretation, Parameter, `(Odds Ratio)`, CI_low, CI_high, pd, `%_in_ROPE`)\n# \n# \n# \n# #KNIT\n# title = \"Study 3A (Online Replication) | Question Interpretation | Mixed Multinomial Regression\"\n# tab <- kbl(x, format = \"latex\", caption = title,\n#            booktabs = FALSE) %>% kable_classic() %>%\n# footnote(general = paste(\"Model Interpretation ~ \",b$Model[2], \"Bayes Factor \", format( exp(b$log_BF[2]), digits =2 ) ), footnote_as_chunk = T, general_title = \"\")\n# writeLines(tab, \"tables/SGC3A_REP_BRMS_state.tex\")\n\n\n\n\nCODE\n# ## POINT ESTIMATES IN PROBABILITY\n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #2 | SUMMARIZE draws \n# k <- kable(draws %>%\n#   select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 2, col.names = \n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>% \n#   kable_styling()\n# k\n\n#COMPARISONS\n# c <- draws %>% \n#   # dplyr::select(pretty_condition, .category, .value) %>%\n#   compare_levels(variable = .value, by = pretty_condition, \n#                  comparison = list(c(\"control\",\"impasse\"))) \n#                                    # c(\"adots\",\"interval\"),\n#                                    # c(\"adots\",\"mean\"),\n#                                    # c(\"adots\",\"text\"),\n#                                    # c(\"density\",\"interval\"),\n#                                    # c(\"density\",\"mean\"),\n#                                    # c(\"density\",\"text\"),\n#                                    # c(\"interval\",\"mean\"),\n#                                    # c(\"interval\",\"text\"),\n#                                    # c(\"mean\",\"text\")\n#                                    \n# c %>%\n#   ggplot(aes(x = .value, y = reorder(x =pretty_condition, X = .value)))+\n#   stat_interval(.width = .95, color = \"black\") +\n#   geom_vline(xintercept = 0)+\n#   theme_bw()+\n#   # coord_cartesian(xlim = c(-.5,1)) +\n#   theme_tidybayes() \n# comps\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n'bayes_R2' is not defined for unordered categorical models.\n\n\n\n\n \nstate: other\nstate: angular\nstate: triangular\nstate: other_pretty\nstate: angular_pretty\nstate: triangular_pretty\n\n\nPredictors\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\n\n\nIntercept\n0.04\n0.01 – 0.12\n\n\n0.14\n0.05 – 0.37\n\n\n0.07\n0.01 – 0.36\n\n\n\n\nconditionimpasse\n\n\n3.69\n1.29 – 10.91\n\n\n4.57\n2.27 – 9.52\n\n\n8.82\n1.04 – 74.73\n\n\nRandom Effects\n\n\n\nσ2\n0.43\n\n\n\nτ00\n1.26\n\n\nICC\n0.26\n\n\nN subject\n71\n\n\nN q\n13\n\nObservations\n923\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n# \n# \n# ## POINT ESTIMATES IN PROBABILITY\n# #1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>%\n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #2 | SUMMARIZE draws \n# k <- kable(draws %>%\n#   select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 2, col.names = \n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>% \n#   kable_styling()\n# k\n\n#COMPARISONS\n# c <- draws %>% \n#   # dplyr::select(pretty_condition, .category, .value) %>%\n#   compare_levels(variable = .value, by = pretty_condition, \n#                  comparison = list(c(\"control\",\"impasse\"))) \n#                                    # c(\"adots\",\"interval\"),\n#                                    # c(\"adots\",\"mean\"),\n#                                    # c(\"adots\",\"text\"),\n#                                    # c(\"density\",\"interval\"),\n#                                    # c(\"density\",\"mean\"),\n#                                    # c(\"density\",\"text\"),\n#                                    # c(\"interval\",\"mean\"),\n#                                    # c(\"interval\",\"text\"),\n#                                    # c(\"mean\",\"text\")\n#                                    \n# c %>%\n#   ggplot(aes(x = .value, y = reorder(x =pretty_condition, X = .value)))+\n#   stat_interval(.width = .95, color = \"black\") +\n#   geom_vline(xintercept = 0)+\n#   theme_bw()+\n#   # coord_cartesian(xlim = c(-.5,1)) +\n#   theme_tidybayes() \n# comps\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test\n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(Bmm.cat.CrSQ, exponentiate = TRUE, component = \"all\")\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\nCODE\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n\n\n\n\n\nCODE\n# + theme_clean()\n\n# \n# result <- estimate_density(m,exponentiate = TRUE)\n# plot(result,  stack = FALSE, priors = TRUE)\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?equivalence_test'.\n\n\nCODE\nplot(result)\n\n\nPicking joint bandwidth of 0.0835\n\n\nWarning: Removed 3600 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\nCODE\nresult <- rope(m)\n\n\nPossible multicollinearity between b_mutriangular_pretty_conditionimpasse and b_mutriangular_Intercept (r = 0.74). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\nCODE\nplot(result)\n\n\n\n\n\nCODE\n(result <- pd(m,exponentiate = TRUE))\n\n\nProbability of Direction\n\nParameter                            |     pd\n---------------------------------------------\nmuother_Intercept                    |   100%\nmuangular_Intercept                  |   100%\nmutriangular_Intercept               | 99.85%\nmuother_pretty_conditionimpasse      |   100%\nmuangular_pretty_conditionimpasse    | 99.28%\nmutriangular_pretty_conditionimpasse | 97.62%\n\n\nCODE\nplot(result, show_intercept = TRUE, show_labels = TRUE)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\n# plot_model(m, type=\"eff\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            title = \"Model Prediction | Probability of Accurate Response\",\n#            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# \n# #PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")\n\n\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n\n\n$pretty_condition\n\n\n\n\n\nCODE\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n\n\n\n\nCODE\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA) \n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\n# d <- draws %>%\n#   ggplot(aes(x = .value,  y = pretty_condition, fill = .category)) +\n#   stat_slab(width = c(.95), alpha = 1, normalize=\"xy\") +\n#   #   #normalize = all, panels, xy, groups, none\n#   xlim(0,1) + labs(\n#     title = \"Model Predicted Probability of Correct Response\",\n#     x = \"probability of correct response\",\n#     y = \"Interpretation\"\n#   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # \n# # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\n# d\n\n\n##FROM PREDS\npreds %>% \n    ggplot(aes(x = preds,  y = state, fill = pretty_condition)) +\n    stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\") \n\n\n\n\n\n\n\nDiagnostics\n\n\nCODE\n#CHECK Fit of posterior predictive to data\npp_check(Bmm.cat.CrSQ, ndraws=1000)\n\n\n\n\n\nCODE\n#CHECK posterior vs. priors\nresult <- estimate_density(Bmm.cat.CrSQ)\nplot(result, stack = FALSE, priors = TRUE)\n\n\n\n\n\nCODE\n#CHECK model\nplot(Bmm.cat.CrSQ)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFit Model [mblogit]\n\n\nCODE\n# \n# #https://www.elff.eu/software/mclogit/manual/mblogit/\n# #\"baseline category logit\" model matches multinom()\n# \n# #check reference level \n# print(\"Categories (first is reference)\")\n# levels(df_i$state)\n# \n# #FIT EMPTY MODEL\n# # print(\"EMPTY MODEL\")\n# mm.cat.rSQ <- mblogit(state ~ 1 , \n#                       random = list( ~ 1|subject, ~1|q), \n#                       data = df_i)\n# #summary(mm.cat.rSQ)\n# \n# #FIT PREDICTOR MODEL\n# # print(\"PREDICTOR MODEL\")\n# mm.cat.CrSQ <- mblogit(state ~ pretty_condition , \n#                   random = list( ~ 1|subject, ~1|q), \n#                   data = df_i)\n# # summary(mm.cat.CrSQ)\n# \n# #COMPARE MODEL FIT\n# paste(\"AIC wth predictor is lower than empty model?\", AIC(mm.cat.rSQ) > AIC(mm.cat.CrSQ))\n# test_lrt(mm.cat.rSQ, mm.cat.CrSQ)\n\n\n\n\nDescribe\n\n\nCODE\n# \n# m <- mm.cat.CrSQ\n# \n# #DESCRIBE MODEL\n# summary(m)\n# \n# #INTERPRET COEFFICIENTS\n# paste(\"LOG ODDS\")\n# tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n# paste(\"ODDS RATIOS\")\n# tidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n# \n# # paste(\"MODEL INFO\")\n# # glance(m)\n# \n# #PERFORMANCE\n# performance(m)\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes)\n#              # output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nVisualize\n\n\nCODE\n# \n# ## | PLOT PARAMETERS \n# \n# #SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, \n#            transform = \"exp\",\n#            vline.color = \"red\", \n#            show.intercept = TRUE, \n#            show.values = TRUE)\n# \n# \n# #TODO SEPARATE THIS BY EQUATION \n# # ms <- model_parameters(Bmm.cat.CrSQ, component = \"conditional\")\n# # m1 <- ms %>% filter(str_detect(Parameter, \"muother\"))\n# # plot(m1)\n# \n# #EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result, show_labels = TRUE, n_columns = 3)\n# \n# # result <- simulate_parameters(m)\n# # plot(result, stack = FALSE)\n# \n# ## | PLOT TESTS\n# result <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\n# plot(result)\n# \n# ## | PLOT PREDICTIONS\n# \n# #SJPLOT | MODEL | PROBABILITIES\n# # plot_model(m, type=\"eff\",\n# #            show.intercept = TRUE,\n# #            show.values = TRUE,\n# #            title = \"Model Prediction | Probability of Accurate Response\",\n# #            axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n# # \n# # #PLOT MODEL PREDICTION\n# # plot_model(m, type = \"pred\")[[1]] + \n# #   ylim(0,1) + labs(\n# #     title = \"Model Prediction | Probability of Accurate Response\",\n# #     subtitle = \"Impasse increases Probability of Correct Response\"\n# #   )\n# \n# #TODO EMMEANS for the estimated marginal means\n\n\n\n\nDiagnostics\n\n\nCODE\n# check_model(m)\n\n\n\n\nCOMPARE MBLOGIT to BRMS\n\n\nCODE\n# compare_models(mm.cat.CrSQ, Bmm.cat.CrSQ)\n\n\nThe predictions of the manual, frequentist mixed multinomial and bayesian mixed multinomial models are comparable."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1b-q1-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1b-q1-accuracy",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "H1B | Q1 ACCURACY",
    "text": "H1B | Q1 ACCURACY\nDo Ss in the IMPASSE condition have a higher likelihood of producing a correct response to the first question?\nThe graph comprehension task includes 15 questions completed in sequence. But the first question the reader encounters (Q1) is the most important, as it is their first exposure to the unconventional triangular coordinate system.\n\n\n\n\n\n\n\nResearch Question\nDoes the frequency of correct (vs) incorrect responses on the first question differ by condition? [Is response accuracy independent of condition?]\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of correctly responding to the first question than those in the CONTROL condition\n\n\nData\n\ndata: df_items where q == 1\noutcome: accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nLogistic Regression on accuracy predicted by condition\n\naccount for difference in odds of correct score by condition\n\n\nAlternatives:\n\nChi-Square test of independence on outcome accuracy by condition\n\n\n\nNotes\n\nCHIQ SQR is simplest method to examine independence of two categorical factors; LOGISTIC REGRESSION is recommended for binomial ~ continuous; though with regression we can quantify the size of the effect and overall model fit\nindependence assumption : (CHI SQR) as we only consider responses on the first question, each observation corresponds to an individual subject, and are thus independent\ncell frequency : (CHI SQR) expected frequency in each cell of the contingency table is greater than 5 (more than 5 correct , more than 5 incorrect responses)\n\n\n\n\n\nSetup\n\n\nCODE\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1)  %>% dplyr::select(accuracy, pretty_condition)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of incorrect (vs) correct responses in each condition for each data collection modality (left/right facet) reveals that the pattern of responses appear the same regardless of the data collection modality. In both data collection sessions, the proportion of incorrect responses is much greater than the proportion of correct responses, regardless of condition (marginal probability of incorrect). In the impasse condition, the difference in proportions is smaller than the control condition (conditional probability of success in impasse; (i.e) There are more correct responses in the impasse condition than the control condition).\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n\n\n[1] \"Proportions of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            control impasse   Sum\n  incorrect   0.839   0.650 0.732\n  correct     0.161   0.350 0.268\n  Sum         1.000   1.000 1.000\n\n\nCODE\npaste(\"Number of Correct Responses by Condition\")\n\n\n[1] \"Number of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            control impasse Sum\n  incorrect      26      26  52\n  correct         5      14  19\n  Sum            31      40  71\n\n\n\n\nLOGISTIC REGRESSION\nFit a logistic regression predicting accuracy (absolute score) (n = 71) by condition (k = 2).\n\n\nParameter estimate: \\(\\beta_{0}\\) = Log Odds of (correct) responses in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of correct response in CONTROL condition\nParameter estimate: \\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for correct response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\nNull hypothesis:\\(\\beta_{impasse} \\le 0\\) the odds for a correct response does not change, or decreases\nAlternative hypothesis: \\(\\beta_{impasse} \\gt 0\\) the odds of a correct response increases\n\n\nFit Model\nFirst, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.\n\n\nCODE\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm1 <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m1)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.928  -0.928  -0.593   1.449   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.488   -3.38  0.00074 ***\npretty_conditionimpasse    1.030      0.590    1.74  0.08107 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 82.483  on 70  degrees of freedom\nResidual deviance: 79.188  on 69  degrees of freedom\nAIC: 83.19\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\ncar::Anova(m1)\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.29  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m0$aic > m1$aic)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(m0,m1) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm0   |   glm |  1 |         |      |      \nm1   |   glm |  2 |       1 | 3.29 | 0.069\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,m1))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.069492127779542\"\n\n\nThe Condition predictor decreases AIC, but the Likelihood Ratio Test is marginal. We proceed to examine the predictor model, as we plan to do a 1-tailed NHST .\n\n\nDescribe\n\n\nCODE\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n\n\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n\n\nCODE\nsummary(m1)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.928  -0.928  -0.593   1.449   1.910  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -1.649      0.488   -3.38  0.00074 ***\npretty_conditionimpasse    1.030      0.590    1.74  0.08107 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 82.483  on 70  degrees of freedom\nResidual deviance: 79.188  on 69  degrees of freedom\nAIC: 83.19\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\ncar::Anova(m1)\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     3.29  1      0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\ntt <- 2*pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n\n\n[1] \"p value for two-tailed test, null B = 0 :  0.081\"\n\n\nCODE\not <- pnorm(summary(m1)$coefficients[2,3], lower.tail = F)\npaste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n\n\n[1] \"BUT we want a one tailed directional, null: B <= 0:  0.041\"\n\n\nCODE\npaste(\"adjusted confint for directional hypothesis\")\n\n\n[1] \"adjusted confint for directional hypothesis\"\n\n\nCODE\n(dcint <- confint(m1, level = 0.90)) # get 90% for right side))\n\n\nWaiting for profiling to be done...\n\n\n                           5 %   95 %\n(Intercept)             -2.538 -0.907\npretty_conditionimpasse  0.094  2.058\n\n\nCODE\n# https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients —- ODDS RATIOS\")\n\n\n[1] \"Coefficients —- ODDS RATIOS\"\n\n\nCODE\n# (e <- cbind( exp(coef(m1)), exp(confint(m1)))) #exponentiated, not adjusted\n(e <- cbind( exp(coef(m1)), exp(dcint))) #exponentiated, adjusted\n\n\n                                5 %  95 %\n(Intercept)             0.192 0.079 0.404\npretty_conditionimpasse 2.800 1.099 7.832\n\n\nCODE\nprint(\"MODEL PREDICTIONS\")\n\n\n[1] \"MODEL PREDICTIONS\"\n\n\nCODE\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\npred.control <- predict(m1,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\npaste(\"Probability of success in control,\", pred.control)\n\n\n[1] \"Probability of success in control, 0.161290322580645\"\n\n\nCODE\npred.impasse <- predict(m1,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\npaste(\"Probability of success in impasse,\", pred.impasse)\n\n\n[1] \"Probability of success in impasse, 0.350000000000014\"\n\n\n\n\nInference — DIRECTIONAL EFFECT\n\n\nVisualize\n\n\nCODE\n#SET MODEL\nm <- m1\n\n#GGSTATS | MODEL | LOG ODDS \n# ggcoefstats(m1, output = \"plot\", \n#               conf.level = 0.90) + \n#   labs(x = \"Log Odds Estimate\", \n#        title = \"LOGODDS | Q1 Accuracy ~ condition\",\n#        subtitle = \"(p is for two tailed test)\")\n\n\n#PARAMETERS | MODEL | SIMULATED PARAMETERS\n# similar to bayesian dist of estimate\n# result <- simulate_parameters(m1)\n# #rename params so intercept is plotted \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result) \n\n#EQUIVALENCE TEST [not sure if appropriate for log model?]\n# https://journals.sagepub.com/doi/10.1177/2515245918770963#:~:text=Consequently%2C%20when%20reporting%20an%20equivalence,values%20is%20smaller%20than%20alpha.\n# https://easystats.github.io/parameters/reference/equivalence_test.lm.html\n# (result <- equivalence_test(m1, rule = \"classic\", component = c(\"all\")))\n# plot(result,   show_intercept = TRUE) + \n#   scale_y_discrete(labels = c(\"impasse\", \"control\")) + \n#   labs( title = \"Equivalence Test for Model Parameter Estimates\")\n\n\n#PARAMETERS | MODEL | ODDS RATIO \n# result <- model_parameters(m1,exponentiate = TRUE)\n# #rename params \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result,   show_intercept = TRUE) +  labs(\n#   title = \"Model Parameter Estimates\"\n# ) + theme_clean() + theme(legend.position=\"blank\")\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  scale_y_continuous() + #remove to put on log scale x axis \n  scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"pred\")[[1]] +\n  ylim(0,1) + #scale y axis to actual range\n  labs(title = \"MODEL PREDICTION  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases probability of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.19\n0.07 – 0.46\n0.001\n\n\npretty condition[impasse]\n2.80\n0.92 – 9.70\n0.081\n\n\nObservations\n71\n\n\nR2 Tjur\n0.045\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\nprint(\"MODEL DIAGNOSTICS\")\n\n\n[1] \"MODEL DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m1)"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1b-q1-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_replication_hypotesting.html#h1b-q1-interpretation-state",
    "title": "8  SGC3A (Replication) Hypothesis Testing",
    "section": "H1B | Q1 INTERPRETATION STATE",
    "text": "H1B | Q1 INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses on the first question?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question\n\n\nData\n\ndata: df_items where q == 1\noutcome: state ( 4 level factor from 5 level high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMultinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nOrdinal regression on state; but model doesn’t satisfy proportional odds assumption (parallel slopes)\nMultinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can’t accurately estimate those comparisons\n\n\n\n\n\nSetup\n\n\nCODE\n#:::::::: PREP DATA\ndf <- df_items %>% filter(q==1) %>% dplyr::select(pretty_condition, state)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nA proportional bar chart visualizing the proportion of each interpretations type by condition for each data collection modality (left/right facet) reveals that the pattern of responses are similar regardless of the data collection modality, by differ by condition. In the impasse condition, there are more triangular responses than in control. We see that around half of the ‘incorrect’ (i.e. not triangular) responses in the impasse condition are not orthogonal-like, but “other/unknown”.\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse    Sum\n  orthogonal  0.8387  0.1750 0.4648\n  other       0.0000  0.4000 0.2254\n  angular     0.0000  0.0750 0.0423\n  triangular  0.1613  0.3500 0.2676\n  Sum         1.0000  1.0000 1.0000\n\n\nCODE\n(t <- table(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n            \n             control impasse Sum\n  orthogonal      26       7  33\n  other            0      16  16\n  angular          0       3   3\n  triangular       5      14  19\n  Sum             31      40  71\n\n\n\n\nMULTINOMIAL REGRESSION\nDoes condition affect the response state of Q1?\nFit a logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\n3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) [essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing [reference category] vs [this category])\nFor each equation:\n\n\\(\\beta_{0}\\) = Log Odds of [this category type vs. reference category type) response in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of [this category type vs. reference category type] response in CONTROL condition\n\\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for [this category] type response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of [this. vs reference category type] response in IMPASSE (vs) CONTROL\nTwo-tailed NHST Null hypothesis: \\(\\beta_{impasse} = 0\\) the odds for [this category of response vs. reference] are not different for IMPASSE condition\nAlternative hypothesis: \\(\\beta_{impasse} \\ne 0\\) the odds of [this category of response vs. reference] increases or decreases for IMPASSE condition\n\n\n\nFit Model\n\n\nCODE\n#check reference level \nprint(\"Categories (first is reference)\")\n\n\n[1] \"Categories (first is reference)\"\n\n\nCODE\nlevels(df$state)\n\n\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n\n\nCODE\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n\n\n# weights:  8 (3 variable)\ninitial  value 98.426900 \niter  10 value 83.663951\nfinal  value 83.663925 \nconverged\n\n\nCODE\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\n\n# weights:  12 (6 variable)\ninitial  value 98.426900 \niter  10 value 63.286429\niter  20 value 63.042636\niter  30 value 63.026275\nfinal  value 63.026272 \nconverged\n\n\nCODE\n# summary(catm)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm$AIC)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(catm.0, catm)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  3 |         |       |       \ncatm   | multinom |  6 |       3 | 41.28 | < .001\n\n\nCODE\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n\n\nAIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.\n\n\nDescribe\n\n\nCODE\n#set model\nm <- catm\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n\n\n[1] \"MODEL SUMMARY\"\n\n\nCODE\nsummary(m)\n\n\nCall:\nmultinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionimpasse\nother           -12.20                   13.02\nangular         -10.88                   10.03\ntriangular       -1.65                    2.34\n\nStd. Errors:\n           (Intercept) pretty_conditionimpasse\nother           87.342                  87.343\nangular         45.215                  45.221\ntriangular       0.488                   0.673\n\nResidual Deviance: 126 \nAIC: 138 \n\n\nCODE\ncar::Anova(m)\n\n\n# weights:  8 (3 variable)\ninitial  value 98.426900 \niter  10 value 83.663951\nfinal  value 83.663925 \nconverged\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     41.3  3    5.7e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n\n\n           p..Intercept. p.pretty_conditionimpasse\nother           0.888933                  0.881461\nangular         0.809829                  0.824406\ntriangular      0.000735                  0.000501\n\n\nCODE\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n\n\n           OR..Intercept. OR.pretty_conditionimpasse p..Intercept.\nother          0.00000504                   453336.0      0.888933\nangular        0.00001881                    22779.9      0.809829\ntriangular     0.19230417                       10.4      0.000735\n           p.pretty_conditionimpasse\nother                       0.881461\nangular                     0.824406\ntriangular                  0.000501\n\n\n\n\nInference — CAN’T MODEL, SPARSE CELLS\nsample size is too low to estimate this model. There are no participants in the control condition with ‘other’ or ‘angular’ answers.\n\n\nVisualize\n\n\nCODE\n#:::::::: PLOT\n\n#GGSTATS | MODEL | LOG ODDS \n# ggcoefstats(m, output = \"plot\", \n#               # conf.level = 0.90,\n#               exclude.intercept = FALSE) + \n#   labs(x = \"Log Odds Estimate\", \n#        title = \"LOGODDS | Q1 State ~ condition\",\n#        subtitle = \"(p is for two tailed test)\")\n#:::::::: PLOT\n\n#PARAMETERS | MODEL | SIMULATED PARAMETERS\n# similar to bayesian dist of estimate\n# result <- simulate_parameters(m)\n# plot(result, show_intercept = TRUE, stack=FALSE)\n\n#PARAMETERS | MODEL | ODDS RATIO \n# result <- model_parameters(m1,exponentiate = TRUE)\n# #rename params \n# result$Parameter[1] <- \"condition [control]\"\n# result$Parameter[2] <- \"condition [impasse]\"\n# plot(result,   show_intercept = TRUE) +  labs(\n#   title = \"Model Parameter Estimates\"\n# ) + theme_clean() + theme(legend.position=\"blank\")\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\nScale for 'x' is already present. Adding another scale for 'x', which will\nreplace the existing scale.\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"eff\", ci.lvl = 0.95)[[1]] +\n  ylim(0,1) +\n  labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n       subtitle = \"Impasse increases probability of more accurate response states Q1\",\n       x = \"Condition\") + theme_clean()\n\n\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n\n\n\n\n\nCODE\n#MANUALLY BUILD PREDICTION PLOT FACET BY CONDITION RATHER THAN STATE\np <-plot_model(m, type=\"eff\")[[1]]\nd <- ggplot_build(p)[[1]]  \npoints <- d[[2]]\npoints <- points %>% mutate(\n  state = recode(PANEL, \"1\" =\"orth\", \"2\"=\"other\", \"3\" = \"trilike\", \"4\"=\"tri\"),\n  condition = recode(x, \"1\"=\"control\",\"2\"=\"impasse\"),\n  prob = y\n)\ngf_point( prob ~ state, group = ~x, data = points) + \n  geom_errorbar(aes( x = state, ymin = ymin, ymax = ymax)) + facet_grid(~condition) +ylim(0,1)\n\n\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \nstate\n\n\nPredictors\nOdds Ratios\nCI\np\nResponse\n\n\n(Intercept)\n0.00\n0.00 – 28722943722689885056297507068099247428705629324489501913190908976693248.00\n0.889\nother\n\n\npretty condition[impasse]\n453336.04\n0.00 – 2588676395945885478672530837777748631114813950974385474275281551223317278062804992.00\n0.882\nother\n\n\n(Intercept)\n0.00\n0.00 – 31041424057090752611383649685733376.00\n0.811\nangular\n\n\npretty condition[impasse]\n22779.87\n0.00 – 37983240834656997126437600879159232069369856.00\n0.825\nangular\n\n\n(Intercept)\n0.19\n0.07 – 0.51\n0.001\ntriangular\n\n\npretty condition[impasse]\n10.40\n2.71 – 39.87\n0.001\ntriangular\n\n\nObservations\n71\n\n\nR2 / R2 adjusted\n0.247 / 0.235\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n\n\n\n\nDiagnostics\n\n\nCODE\n#EXAMINE PREDICTIONS\n#create sample data frame\ntest <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\npred <- predict(catm, newdata = test, \"probs\")\npaste(\"Predicted Probability of Being in Each State\")\n\n\n[1] \"Predicted Probability of Being in Each State\"\n\n\nCODE\n( x <- cbind(test, pred))\n\n\n  pretty_condition orthogonal      other   angular triangular\n1          control      0.839 0.00000423 0.0000158      0.161\n2          impasse      0.175 0.39999611 0.0750004      0.350\n\n\nCODE\nprint(\"MODEL PERFORMANCE\")\n\n\n[1] \"MODEL PERFORMANCE\"\n\n\nCODE\nperformance(catm)\n\n\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n138.053 | 151.629 | 0.247 |     0.235 | 0.354 | 1.393\n\n\nCODE\nDescTools::PseudoR2(catm, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n\n\n  McFadden   CoxSnell Nagelkerke \n     0.247      0.441      0.487 \n\n\nCODE\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\n# chisq.test(df$state, predict(catm)) #actual states VS predicted states\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "",
    "text": "The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study WITH OSPAN.\nTODO UPDATE Research Questions\nIn SGC3A-OSPAN we set out to answer the following question: Does posing a mental impasse improve performance on the interval graph comprehension task? Does WORKING MEMORY CAPACITY (as measured by the OSPAN task) explain performance on the graph comprehension task?\nExperimental Hypothesis\nLearners posed with scenario designed to evoke a mental impasse will be more likely to correct interpret the graph.\nWe had no specific hypotheses with respect to how the OSPAN task affects performance. It is plausible that higher working memory allows one to persist in interpreting the coordinate system. It is also plausibe that higher working memory capacity facilitates incorrect interpretations that are more taxing on working memory (for example: end-time questions that require multiple visual projections.)\nNull Hypothesis\nNo significant differences in performance will exist between learners in the IMPASSE and CONTROL conditions."
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#sample",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#sample",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData was collected (online, via SONA) in Fall 2021. Note that approximately 200 subjects were run in Fall 2021, but only 133 of them completed the OSPAN task. Therefore subjects who did not complete the task are discarded from analysis.\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    fall21 \n    65 \n    68 \n    133 \n  \n  \n    Sum \n    65 \n    68 \n    133 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.male \n    percent.female \n    percent.other \n  \n \n\n  \n     \n    18 \n    19 \n    20 \n    21 \n    31 \n    20.6 \n    2.18 \n    133 \n    0 \n    0.316 \n    0.669 \n    0.015 \n  \n\n\nNote:   Age in Years\n\n\n\n\nOverall 133 participants (32 % male, 67 % female, 2 % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 31 years).\n[230 subjects were recorded to study database in FA21 - 32 pilot sgc3b]\n\n\nOSPAN\n\n\nCODE\ntitle = \"Descriptive Statistics of OSPAN Task Accuracy\"\nospan.stats <- rbind(\n  \"MATH\" = df_subjects %>% dplyr::select(OSPAN.math_acc) %>% unlist() %>% favstats(),\n  \"ORDER\" = df_subjects %>%  dplyr::select(OSPAN.order_acc) %>% unlist() %>% favstats(),\n  \"WEIGHTED\" = df_subjects %>% dplyr::select(OSPAN.weighted) %>% unlist() %>% favstats()\n\n)\nospan.stats %>% kbl (caption = title) %>% kable_classic() %>%\n  footnote(general = \"MATH = %correct of all math questions;\n           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct\", general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nDescriptive Statistics of OSPAN Task Accuracy\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    MATH \n    0.517 \n    0.897 \n    0.931 \n    0.966 \n    1 \n    0.924 \n    0.085 \n    133 \n    0 \n  \n  \n    ORDER \n    0.000 \n    0.533 \n    0.733 \n    0.867 \n    1 \n    0.678 \n    0.253 \n    133 \n    0 \n  \n  \n    WEIGHTED \n    0.000 \n    13.448 \n    20.276 \n    24.828 \n    30 \n    19.082 \n    7.391 \n    133 \n    0 \n  \n\n\nNote:   MATH = %correct of all math questions;           ORDER = % correct of OSPAN ordering (out of 30); WEIGHTED = math*ospan number correct\n\n\n\n\n\n\nCODE\n# #GGFORMULA | DENSITY HISTOGRAM \n med = median(df_subjects$OSPAN.weighted)\n  gf_dhistogram(~OSPAN.weighted, data = df_subjects) %>% \n  gf_vline(xintercept = ~med, color = \"red\") +\n  labs(x = \"OSPAN (weighted) score\",\n       y = \"% of subjects\",\n       title = \"Distribution of OSPAN SCORE\",\n       subtitle = \"line indicates median split\")\n\n\n\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = ospan_split)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~ospan_split) + \n   labs(title = \"OSPAN SPLIT\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"After taking a median split, comparable high(vs) low in each condition\")"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1a-overall-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1a-overall-accuracy",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "H1A | OVERALL ACCURACY",
    "text": "H1A | OVERALL ACCURACY\n\n\n\n\n\n\n\nResearch Question\nDo Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?\n\n\n\n\nHypothesis\n(H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.\n\n\nData\ndata: df_items where q nin 6,9 (the 13 discriminating Qs ), df_subjects\noutcome:\n\n[at item level] : accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\n[subject level]: accuracy (number of test phase qs correct from total s_NABS)\n\npredictor: condition [between-subjects factor]\n\n\nAnalysis Strategy\n\nWilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (s_NABS)\nMixed Logistic Regression\naccuracy ~ condition + (1 | subject ) + (1 | question)\nmodel effect of condition on probability of correct response [during test phase] while accounting for subject (and item-level?) effects\n\n\n\nAlternatives\n\nOrdinal Mixed Logistic Regression on scaled_score\nOLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals\n\n\n\nNotes\nAlso exploring:\n\nHurdle model (mixture model w/ binomial + [poisson or negbinom count; 0s from 1 DGP)\nZero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)\nBeta regression hurdle model? (mixture with location and scale parameters [mean, variance] and hurdles for floor and ceiling effects)\nOther way to account for the severe bimodality?\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, accuracy, subject,q, ospan_split)\n\ndf_s <- df_subjects %>% \n  dplyr::select(pretty_condition, ospan_split, task_percent)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\", width = 0.75 ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"lisa::FridaKahlo\", 2))+\n  facet_wrap(~ospan_split)+\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::Jewel_Bright\", 2))+\n  # scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 2))+\n  # scale_fill_brewer(palette = \"Set1\")  +\n  # facet_wrap(~pretty_mode) + \n  # coord_flip() +\n  theme(legend.position=\"bottom\")+\n   labs(title = \"Study 3C | DISTRIBUTION of Question Accuracy\",\n       x = \"Condition\",\n       y = \"Proportion of Questions\",\n       fill = \"\",\n       subtitle=\"Impasse is particularly effective for subjects with high-working memory\")\n\n\n\n\n\nCODE\n#:::::::: LABELLED \n\ntemp <- df_i %>% mutate(\n  accuracy = fct_rev(accuracy)\n)  \n\n#CREATE PLOT WITH LABELS\np <- grouped_ggbarstats(data = temp, x = accuracy, y = pretty_condition,\n               grouping.var = ospan_split,\n               results.subtitle = FALSE,\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  scale_fill_manual(values = paletteer::paletteer_d(\"lisa::FridaKahlo\", 2))\n                  # theme(axis.text.x = element_text(angle = 90)))\n               ))  + theme_clean() \n\n\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\n\n\nCODE\n#FIX LABELS\np1 <- p[[1]] +  labs(\n  subtitle = \"Impasse is particularly effective for subjects with high-working memory\",\n    x = \"Condition\", y = \"Probability of Response\"\n  ) + theme_clean() + theme(legend.position = \"blank\") \n \np2 <-   p[[2]] + labs(\n    x = \"Condition\", y = \"Probability of Response\",\n    subtitle = \"   \"\n  ) + theme_clean() + theme(legend.position = \"blank\") +\n  ggeasy::easy_remove_axes(which=\"y\", what=c(\"text\",\"title\"))\n  # ggeasy::easy_remove_axes(which=\"y\", what= \"\"))\n\n#CREATE ROW\n\nplot_row <- plot_grid(p1,p2, rel_widths = c(1,0.85))\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Medium' not found in PostScript font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Barlow Semi Condensed' not found in PostScript font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'BarlowSemiCondensed-Bold' not found in PostScript font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\n\nCODE\ntitle <- ggdraw() + \n  draw_label(\n    \"DISTRIBUTION | Question Accuracy\",\n    fontface = 'bold',\n    x = 0,\n    hjust = 0\n  ) +\n  theme(\n    # add margin on the left of the drawing canvas,\n    # so title is aligned with left edge of first plot\n    plot.margin = margin(0, 0, 0, 7)\n  )\n\n\npg <- plot_grid(\n  title,\n  plot_row,\n  ncol = 1,\n  # rel_heights values control vertical title margins\n  rel_heights = c(0.1, 1)\n) + theme_clean()\n  \npg\n\n\n\n\n\nCODE\n# ggsave(pg, filename = \"figures/SGC3A_OSPAN_Accuracy.png\", width = 6, height =4)\n\n\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) + \n   labs(title = \"Overall Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses for HIGH WM\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap( q ~ ospan_split) +\n   labs(title = \"Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n\n\n\n\n\nCODE\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(pretty_condition) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  gf_facet_grid(pretty_condition ~ ospan_split) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Overall Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nDescribe\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0 \n    0 \n    0.077 \n    0.462 \n    1 \n    0.252 \n    0.37 \n    133 \n    0 \n  \n\n\n\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\n \n  \n    pretty_condition \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    control \n    0 \n    0 \n    0.000 \n    0.154 \n    1 \n    0.155 \n    0.303 \n    65 \n    0 \n  \n  \n    impasse \n    0 \n    0 \n    0.077 \n    0.788 \n    1 \n    0.345 \n    0.405 \n    68 \n    0 \n  \n\n\n\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT\"\ntbl2 <- mosaic::favstats(task_percent ~ ospan_split, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct) BY OSPAN SPLIT\n \n  \n    ospan_split \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    low-memory \n    0 \n    0 \n    0.077 \n    0.192 \n    1 \n    0.195 \n    0.314 \n    67 \n    0 \n  \n  \n    high-memory \n    0 \n    0 \n    0.077 \n    0.769 \n    1 \n    0.310 \n    0.413 \n    66 \n    0 \n  \n\n\n\n\n\nAcross both conditions, overall accuracy on the task ranges from 0 to 100 with a mean of 25.217. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.\nTask level accuracy on the graph comprehension task follows the same pattern of behaviour observed in Study 3A: the distribution is bimodal. Total scores were higher in the impasse condition (M = 35%, SD = 41%) than control condition (M = 15%, SD = 30%), implying a likely main effect of scaffold condition. Comparing total scores across the median split on the OSPAN task (high working memory (vs) low working memory), we see readers with high working memory (M = 31 %, SD = 41%) performed better than readers with low working memory (M = 19 %, SD = 31%). In Figure \\(\\ref{fig_3C_ospan_raw_accuracy}\\) we see that while readers in the impasse condition performed consistently better than those in the control condition, the effect is particularly pronounced for readers with high-working memory, implying a potential interaction between condition and working memory.\n\nWILCOXON RANK SUM (Mann-Whitney Test)\n\nNon parametric alternative to t-test; compares median rather than mean by ranking data\nDoes not assume normality\nDoes not assume equal variance of samples (homogeneity of variance)\n\n\nTest\n\n\nCODE\n#WILCOXON ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY\ndf_low <- df_s %>% filter(ospan_split == \"low-memory\")\n(w <- wilcox.test(df_low$task_percent ~ df_low$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df_low$task_percent by df_low$pretty_condition\nW = 458, p-value = 0.09\nalternative hypothesis: true location shift is less than 0\n\n\nCODE\n#WILCOXON ON ACCURACY X OSPAN-SPLIT in HIGH\ndf_high <- df_s %>% filter(ospan_split == \"high-memory\")\n(w <- wilcox.test(df_high$task_percent ~ df_high$pretty_condition,\n                 paired = FALSE, alternative = \"less\")) #less, greater\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df_high$task_percent by df_high$pretty_condition\nW = 304, p-value = 0.0005\nalternative hypothesis: true location shift is less than 0\n\n\nCODE\ngrouped_ggbetweenstats( data = df_s, type = \"nonparametric\",\n                        y = task_percent, x = pretty_condition, grouping.var = ospan_split)\n\n\n\n\n\n\n\nInference — EFFECT\nA Wilcoxon-Rank sum test on task accuracy x condition for the low-memory participants indicate that impasse is not significantly higher. A Wilcoxon rank sum test on task accuracy x condition for high-memory participants indicate that impasse IS higher. Taken together, this indiates there may be an interaction between working memory and condition.\n\n\nVisualize\n\n\nCODE\n#TODO   \np <- grouped_ggbetweenstats(data = df_s,\n                       y = task_percent, x = pretty_condition, grouping.var = ospan_split,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               results.subtitle = FALSE,\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               # point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  labs(y = \"Percentage of correct responses across task\", x = \"\"),\n                  aes(color = pretty_condition, fill = pretty_condition),\n                  scale_fill_grey(), scale_color_grey()\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3))\n                  # theme(axis.text.x = element_text(angle = 90)\n                )) \n\n\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\nScale for 'colour' is already present. Adding another scale for 'colour',\nwhich will replace the existing scale.\n\n\nCODE\np1 <- p[[1]] + coord_flip() + theme_clean() +\n   ggeasy::easy_remove_legend()\n\np2 <- p[[2]] + coord_flip() + \n  labs(\n       subtitle = \"High working memory yields higher scores and greater variance in impasse condition\") + \n  theme_clean() + ggeasy::easy_remove_axes(which = \"x\") + ggeasy::easy_remove_legend()\n\n\npg <- plot_grid(p2, p1, ncol=1)\npg\n\n\n\n\n\n\n\n\nMIXED LOGISTIC REGRESSION [IXN!!]\nFit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.\n\nFit Model\n\n\nCODE\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n\n\n[1] TRUE\n\n\nCODE\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy) && is.factor(df_i$ospan_split)\n\n\n[1] FALSE\n\n\nCODE\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n\n\n[1] \"Empty fixed model\"\n\n\nCODE\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n\n\n[1] \"Subject intercept random model\"\n\n\nCODE\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |   Chi2 |      p\n-------------------------------------------------\nm0    |      glm |  1 |         |        |       \nmm.rS | glmerMod |  2 |       1 | 995.86 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  1.42843406321987e-218\"\n\n\nCODE\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n\n\n[1] \"Subject Intercept + Item intercept random model\"\n\n\nCODE\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\nmm.rS  | glmerMod |  2 |         |       |       \nmm.rSQ | glmerMod |  3 |       1 | 71.77 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n[1] \"Likelihood Ratio test is significant? p =  2.4238269730051e-17\"\n\n\nCODE\n## 2 | ADD FIXED EFFECT CONDITION\n\nprint(\"FIXED Condition + Subject & Item random intercepts\")\n\n\n[1] \"FIXED Condition + Subject & Item random intercepts\"\n\n\nCODE\nmm.CrSQ <- glmer(accuracy ~ pretty_condition + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n#summary(mm.CrSQ)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.CrSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.rSQ,mm.CrSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------\nmm.rSQ  | glmerMod |  3 |         |       |       \nmm.CrSQ | glmerMod |  4 |       1 | 17.23 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.CrSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0000330410023284755\"\n\n\nCODE\n## 3 | ADD INTERACTION OSPAN\n\nprint(\"FIXED Condition * FIXED OSPAN + Subject & Item random intercepts\")\n\n\n[1] \"FIXED Condition * FIXED OSPAN + Subject & Item random intercepts\"\n\n\nCODE\nmm.COrSQ <- glmer(accuracy ~ pretty_condition *ospan_split + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\nsummary(mm.COrSQ)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition * ospan_split + (1 | subject) + (1 |  \n    q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     873      906     -430      861     1723 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-7.040 -0.129 -0.031  0.024 11.797 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 31.30    5.59    \n q       (Intercept)  1.18    1.09    \nNumber of obs: 1729, groups:  subject, 133; q, 13\n\nFixed effects:\n                                               Estimate Std. Error z value\n(Intercept)                                      -6.832      1.463   -4.67\npretty_conditionimpasse                           2.348      1.599    1.47\nospan_splithigh-memory                           -0.669      1.432   -0.47\npretty_conditionimpasse:ospan_splithigh-memory    4.845      2.255    2.15\n                                               Pr(>|z|)    \n(Intercept)                                       3e-06 ***\npretty_conditionimpasse                           0.142    \nospan_splithigh-memory                            0.640    \npretty_conditionimpasse:ospan_splithigh-memory    0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prtty_ ospn_-\nprtty_cndtn -0.602              \nospn_splth- -0.594  0.531       \nprtty_cn:_-  0.183 -0.657 -0.625\n\n\nCODE\ncar::Anova(mm.COrSQ)\n\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: accuracy\n                             Chisq Df Pr(>Chisq)    \npretty_condition             14.59  1    0.00013 ***\nospan_split                   1.25  1    0.26284    \npretty_condition:ospan_split  4.62  1    0.03167 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.CrSQ)) > AIC(logLik(mm.COrSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.CrSQ,mm.COrSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\nmm.CrSQ  | glmerMod |  4 |         |      |      \nmm.COrSQ | glmerMod |  6 |       2 | 6.93 | 0.031\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.CrSQ,mm.COrSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0312599524800637\"\n\n\nA likelihood ratio test indicates adding OSPAN as a fixed effect to a logistic regression model including a fixed effect for CONDITION and random intercepts for SUBJECT and QUESTION explains more variance in the data than the CONDITION + random-effects only model.\n\\(chi^2(4,6) = 6.93, p < 0.05\\)\n\n\nDescribe\n\n\nCODE\n# best model\nm <- mm.COrSQ\nm %>% write_rds(file = \"analysis/SGC3A/models/sgc3a_glmer_acc_mm.COrSQ_OSPAN.rds\")\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ pretty_condition * ospan_split + (1 | subject) + (1 |  \n    q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n     873      906     -430      861     1723 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-7.040 -0.129 -0.031  0.024 11.797 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 31.30    5.59    \n q       (Intercept)  1.18    1.09    \nNumber of obs: 1729, groups:  subject, 133; q, 13\n\nFixed effects:\n                                               Estimate Std. Error z value\n(Intercept)                                      -6.832      1.463   -4.67\npretty_conditionimpasse                           2.348      1.599    1.47\nospan_splithigh-memory                           -0.669      1.432   -0.47\npretty_conditionimpasse:ospan_splithigh-memory    4.845      2.255    2.15\n                                               Pr(>|z|)    \n(Intercept)                                       3e-06 ***\npretty_conditionimpasse                           0.142    \nospan_splithigh-memory                            0.640    \npretty_conditionimpasse:ospan_splithigh-memory    0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) prtty_ ospn_-\nprtty_cndtn -0.602              \nospn_splth- -0.594  0.531       \nprtty_cn:_-  0.183 -0.657 -0.625\n\n\nCODE\nprint(\"SIGNIFICANCE TEST [non directional]\")\n\n\n[1] \"SIGNIFICANCE TEST [non directional]\"\n\n\nCODE\ncar::Anova(m, type=3) #TYPE 3 SS FOR IXNS\n\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: accuracy\n                             Chisq Df Pr(>Chisq)    \n(Intercept)                  21.80  1      3e-06 ***\npretty_condition              2.15  1      0.142    \nospan_split                   0.22  1      0.640    \npretty_condition:ospan_split  4.62  1      0.032 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#:::::::: MANUAL ONE-SIDED SIGTEST \n#note: anova and chi square are always one-tailed, but that is independent of being one-sided\n#https://www.ibm.com/support/pages/can-one-get-one-tailed-tests-logistic-regression-dividing-significance-levels-half\n\n# one-sided (right tail) z test for B COEFFICIENT\n#SANITY CHECK 2-tailed test should match the model output\n#NOTE ... NEED TO DO THIS FOR _EACH_ COEFFICIENT\n# tt <- 2*pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,5))\n# ot <- pnorm(summary(m)$coefficients[2,3], lower.tail = F)\n# paste(\"BUT we want a one  directional, null: B <= 0: \",round(ot,5))\n\n#:::::::: INTERPRET COEFFICIENTS\n# \n# se <- sqrt(diag(stats::vcov(m)))\n# # table of estimates with 95% CI\n# paste(\"LOG ODDS\")\n# (tab <- cbind(Est = fixef(m), LL = fixef(m) - 1.96 * se, UL = fixef(m) + 1.96 *\n#     se))\n# paste(\"ODDS RATIOS\")\n# (e <- exp(tab))\n\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n# se <- sqrt(diag(stats::vcov(m)))\n# (tab <- cbind(Est = fixef(m),\n#               LL = fixef(m) - 1.96 * se,\n#               UL = fixef(m) + 1.96 * se))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n\n\n# A tibble: 6 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…   -6.83       1.46    -4.67   3.03e-6   -9.70      -3.96\n2 fixed    <NA>   pret…    2.35       1.60     1.47   1.42e-1   -0.787      5.48\n3 fixed    <NA>   ospa…   -0.669      1.43    -0.467  6.40e-1   -3.47       2.14\n4 fixed    <NA>   pret…    4.84       2.25     2.15   3.17e-2    0.425      9.26\n5 ran_pars subje… sd__…    5.59      NA       NA     NA         NA         NA   \n6 ran_pars q      sd__…    1.09      NA       NA     NA         NA         NA   \n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n# (e <- exp(tab))\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n\n\n# A tibble: 6 × 9\n  effect   group  term  estimate std.error statistic  p.value conf.low conf.high\n  <chr>    <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 fixed    <NA>   (Int…  1.08e-3   0.00158    -4.67   3.03e-6  6.13e-5   1.90e-2\n2 fixed    <NA>   pret…  1.05e+1  16.7         1.47   1.42e-1  4.55e-1   2.40e+2\n3 fixed    <NA>   ospa…  5.12e-1   0.733      -0.467  6.40e-1  3.10e-2   8.47e+0\n4 fixed    <NA>   pret…  1.27e+2 286.          2.15   3.17e-2  1.53e+0   1.05e+4\n5 ran_pars subje… sd__…  5.59e+0  NA          NA     NA       NA        NA      \n6 ran_pars q      sd__…  1.09e+0  NA          NA     NA       NA        NA      \n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\n#setup df \nnewdata <- df_i %>% dplyr::select(pretty_condition, ospan_split, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n\n\nWarning: executing %dopar% sequentially: no parallel backend registered\n\n\nCODE\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(pretty_condition, ospan_split, fit, lwr, upr) %>% \n  group_by(pretty_condition, ospan_split) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n\n\n# A tibble: 4 × 5\n# Groups:   pretty_condition [2]\n  pretty_condition ospan_split   median     lower   upper\n  <fct>            <fct>          <dbl>     <dbl>   <dbl>\n1 control          low-memory  0.00106  0.000113  0.0101 \n2 control          high-memory 0.000551 0.0000682 0.00477\n3 impasse          low-memory  0.0114   0.00130   0.0876 \n4 impasse          high-memory 0.417    0.0896    0.839  \n\n\n\n\nInference TODO UPDATE\n(TODO Dissertation)\nTo explore the effect of working memory capacity on ACCURACY, we fit a mixed effects logistic regression model with random intercepts for subjects and questions, with CONDITION, WORKING MEMORY and their interaction term as fixed effects. A likelihood ratio test indicates that a model including the fixed effect of CONDITION explains significantly more variance in the data than an intercepts-only baseline model (\\(\\chi^2 (3,4) = 17.23, p < 0.001\\)). The final model including fixed effects and interaction term of OSPAN is a significantly better fit than the CONDITION-only model (\\(\\chi^2(4,6) = 6.93, p < 0.05\\)). The explanatory power of the entire model is substantial (\\(conditional \\ R^2 = 0.92\\)) and the part related to the fixed effects CONDITION and WORKING MEMORY (\\(marginal \\ R^2\\)) explains 18% of variance.\nThe model includes no significant main effects, but a significant interaction between CONDITION and OSPAN, ( \\(e^{\\beta_1} = 127, p < 0.05\\), \\(95 \\% \\  CI \\ [1.53, 1.05e4]\\)).\nThe model predicts that, in the control condition, the probability of a correct response for a participant with high vs. low working memory increases from (0.1 to 0.5%) a negligible difference. In the impasse condition, however, the probability of a correct response increases from only 1% for participants with low working memory, to 42% for participants with high working memory. These results are consistent with the intuition we develop from Figure TODO. Participants with high working memory capacity are most able to take advantage of the impasse scaffold.\n\n\nPrint\n\n\nCODE\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# title = \"Study 3C (OSPAN) | Question Accuracy | Mixed Logistic Regression\"\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              paste(\"n = \",n_obs(m), \"R^2(Conditional) =\", round(r2(m)[[1]],2),\n#                    \"R^2(Marginal) =\", round(r2(m)[[2]],2)),\n#              \"Accuracy  ~ Condition * OSPAN +  (1 | subject) + (1 | q)\")\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = title,\n#              notes = notes,\n#              output = \"tables/SGC3C_OSPAN_GLMER_OverallAccuracy.tex\")\n#              # coef_omit = \"Intercept\",\n\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n\n\n$pretty_condition\n\n\n\n\n\n\n$ospan_split\n\n\n\n\n\nCODE\nplot_model(m, type = \"eff\")  \n\n\n$pretty_condition\n\n\n\n\n\n\n$ospan_split\n\n\n\n\n\nCODE\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.00\n0.00 – 0.02\n<0.001\n\n\npretty condition[impasse]\n10.46\n0.46 – 240.44\n0.142\n\n\nospan split [high-memory]\n0.51\n0.03 – 8.47\n0.640\n\n\npretty condition[impasse] * ospan split[high-memory]\n127.05\n1.53 – 10549.66\n0.032\n\n\nRandom Effects\n\n\n\nσ2\n3.29\n\n\n\nτ00 subject\n31.30\n\n\nτ00 q\n1.18\n\n\nICC\n0.91\n\n\nN subject\n133\n\n\nN q\n13\n\nObservations\n1729\n\n\nMarginal R2 / Conditional R2\n0.177 / 0.924\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list('\"* p < 0.05, ** p < 0.01, *** p < 0.001\"',\n#                'N(subject) = 133 $\\tau_{00}$(subject) = 34.85',\n#              'N(question) = 13 $\\tau_{00}$(question) = 1.14')\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex\")\n# # #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n\n\n[1] \"DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1a-overall-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1a-overall-interpretation-state",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "H1A | OVERALL INTERPRETATION STATE",
    "text": "H1A | OVERALL INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses across questions?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items\n\n\nData\n\ndata: df_items where q nin 6,9 (13 discriminant test phase items)\noutcome: state ( 3 level factor from high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMIXED Multinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nMIXED Ordinal regression on state (doesn’t meet proportional odds assumption-I think)\nMIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(q,subject,state,pretty_condition, ospan_split) %>% droplevels()\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  facet_wrap(~ospan_split) +\n   labs(title = \"Interpretation across all Questions\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))+\n  # scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(q ~ ospan_split) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\n\n\nCODE\n#:::::::: LABELLED \n\n# temp <- df_i %>% mutate(\n#   state = fct_rev(state)\n# )  \n# \n# p <-   grouped_ggbarstats(data = temp, x = state, y = pretty_condition,\n#                           grouping.var = ospan_split,\n#                results.subtitle = FALSE,\n#                ggplot.component = ## modify further with `{ggplot2}` functions\n#                 list(\n#                   scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))\n#                   # theme(axis.text.x = element_text(angle = 90)))\n#                ))  + theme_clean() + theme(legend.position = \"bottom\")\n# \n# p <- p + labs(title = \"DISTRIBUTION | Question Accuracy\",\n#          y = \"Proportion of Questions\", x = \"Condition\",\n#          subtitle = \"Impasse condition yields more correct responses\")\n# \n# p\n# # ggsave(p, filename = \"figures/SGC3A_LAB_Accuracy.png\", width = 6, height =4)\n\n\n#:::::::: LABELLED \n\ntemp <- df_i \n# %>% mutate(\n#   accuracy = fct_rev(accuracy)\n# )\n\n#CREATE PLOT WITH LABELS\np <- grouped_ggbarstats(data = temp, x = state, y = pretty_condition,\n               grouping.var = ospan_split,\n               results.subtitle = FALSE,\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  scale_fill_manual(values = paletteer::paletteer_d(\"ggthemes::calc\", 4))\n                  # theme(axis.text.x = element_text(angle = 90)))\n               )) \n\n\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\nScale for 'fill' is already present. Adding another scale for 'fill', which\nwill replace the existing scale.\n\n\nCODE\n#FIX LABELS\np1 <- p[[1]] +  labs(\n  subtitle = \"Impasse is particularly effective for subjects with high-working memory\",\n    x = \"Condition\", y = \"Probability of Response\"\n  ) + theme_clean() + theme(legend.position = \"blank\") \n \np2 <-   p[[2]] + labs(\n    x = \"Condition\", y = \"Probability of Response\",\n    subtitle = \"   \"\n  ) + theme_clean() + theme(legend.position = \"blank\") +\n  ggeasy::easy_remove_axes(which=\"y\", what=c(\"text\",\"title\"))\n  # ggeasy::easy_remove_axes(which=\"y\", what= \"\"))\n\n#CREATE ROW\n\nplot_row <- plot_grid(p1,p2, rel_widths = c(1,0.85))\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily 'Barlow Semi Condensed' not found in PostScript font database\n\n\nCODE\ntitle <- ggdraw() + \n  draw_label(\n    \"DISTRIBUTION | Question Accuracy\",\n    fontface = 'bold',\n    x = 0,\n    hjust = 0\n  ) +\n  theme(\n    # add margin on the left of the drawing canvas,\n    # so title is aligned with left edge of first plot\n    plot.margin = margin(0, 0, 0, 7)\n  )\n\n\npg <- plot_grid(\n  title,\n  plot_row,\n  ncol = 1,\n  # rel_heights values control vertical title margins\n  rel_heights = c(0.1, 1)\n) + theme_clean()\n  \npg\n\n\n\n\n\nCODE\n# ggsave(pg, filename = \"figures/SGC3A_OSPAN_Accuracy.png\", width = 6, height =4)\n\n\n\n\nDescribe\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse    Sum\n  orthogonal  0.6686  0.3224 0.4916\n  other       0.1361  0.2704 0.2047\n  angular     0.0402  0.0622 0.0515\n  triangular  0.1550  0.3450 0.2522\n  Sum         1.0000  1.0000 1.0000\n\n\nCODE\n(t <- table(df_i$state, df_i$pretty_condition, df_i$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n, ,  = low-memory\n\n            \n             control impasse Sum\n  orthogonal     269     171 440\n  other           58     151 209\n  angular         16      36  52\n  triangular      60     110 170\n  Sum            403     468 871\n\n, ,  = high-memory\n\n            \n             control impasse Sum\n  orthogonal     296     114 410\n  other           57      88 145\n  angular         18      19  37\n  triangular      71     195 266\n  Sum            442     416 858\n\n\n\n\nMIXED MULTINOMIAL REGRESSION\nDoes condition affect the response state of of items across the task?\nFit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\nmblogit version wouldn’t coverge, so using brms\n\n\nFit Model [brms]\n\n\nCODE\ninf_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\")\n)\n\nixn_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  #prior on CONDITION COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse\", dpar = \"mutriangular\"),\n  #prior on OSPAN COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"ospan_splithighMmemory\", dpar = \"mutriangular\"),\n  #prior on IXN COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimpasse:ospan_splithighMmemory\", dpar = \"mutriangular\")\n)\n\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.rSQ_OSPAN.rds\")\n\n\n# CONDITION ONLY MODEL\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = inf_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.CrSQ_OSPAN.rds\")\n\n\n##MODEL COMPARISON\n# print(\"MODEL COMPARISON: random effects (vs) CONDITION\")\n# bayesfactor(Bmm.cat.rSQ, Bmm.cat.CrSQ)\n#substantial evidence in favor of conditon model over random only BF 1.64e+16\n\n# CONDITION + OSPAN MODEL\nBmm.cat.COrSQ <- brm( state ~ pretty_condition*ospan_split + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = ixn_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3A/models/sgc3a_brms_state_Bmm.cat.COrSQ_OSPAN.rds\")\n# summary(mm.cat.COrSQ)\n\n##MODEL COMPARISON\nprint(\"MODEL COMPARISON: COND*OSPAN (vs) CONDITION\")\n\n\n[1] \"MODEL COMPARISON: COND*OSPAN (vs) CONDITION\"\n\n\nCODE\nbayesfactor(Bmm.cat.COrSQ, Bmm.cat.CrSQ)\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nRecompiling the model with 'rstan'\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nclang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:88:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include <complex>\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\nRecompilation done\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nBayes Factors for Model Comparison\n\n    Model                                         BF\n[2] pretty_condition + (1 | subject) + (1 | q) 0.061\n\n* Against Denominator: [1] pretty_condition * ospan_split + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n\n\nCODE\n#which model is better?\ncompare_models(Bmm.cat.CrSQ, Bmm.cat.COrSQ)\n\n\nParameter                                                   |         Bmm.cat.CrSQ |        Bmm.cat.COrSQ\n---------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           | -2.03 (-2.82, -1.27) | -1.95 (-2.80, -1.18)\nmuangular_Intercept                                         | -3.94 (-5.19, -2.71) | -4.10 (-5.53, -2.72)\nmutriangular_Intercept                                      | -4.70 (-6.43, -3.14) | -4.82 (-6.86, -2.93)\nmuother_pretty_conditionimpasse                             |  1.80 ( 1.37,  2.25) |  1.81 ( 1.23,  2.45)\nmuangular_pretty_conditionimpasse                           |  1.67 ( 0.90,  2.50) |  1.85 ( 0.79,  3.00)\nmutriangular_pretty_conditionimpasse                        |  3.56 ( 1.61,  5.54) |  2.45 ( 0.24,  4.68)\nmuother_ospan_splithighMmemory                              |                      | -0.18 (-0.81,  0.45)\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |                      | -0.08 (-0.98,  0.81)\nmutriangular_ospan_splithighMmemory                         |                      |  0.07 (-2.25,  2.28)\nmuangular_ospan_splithighMmemory                            |                      |  0.16 (-1.01,  1.32)\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |                      | -0.33 (-1.84,  1.23)\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |                      |  2.76 (-0.12,  5.52)\n---------------------------------------------------------------------------------------------------------\nObservations                                                |                 1729 |                 1729\n\n\nCODE\n# compare_performance(Bmm.cat.CrSQ, Bmm.cat.COrSQ)\n# car::Anova(mm.cat.CrSQ, mm.cat.COrSQ)\n# car::Anova(mm.cat.COrSQ)\n\n\n\n\nDescribe\n\n\nCODE\n# best model\nm <- Bmm.cat.COrSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ pretty_condition * ospan_split + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 1729) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.28      0.32     0.81     2.07 1.00     1338\nsd(muangular_Intercept)        1.97      0.56     1.18     3.36 1.00     1556\nsd(mutriangular_Intercept)     1.50      0.37     0.95     2.37 1.00     1924\n                           Tail_ESS\nsd(muother_Intercept)          2804\nsd(muangular_Intercept)        2534\nsd(mutriangular_Intercept)     3273\n\n~subject (Number of levels: 133) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          0.90      0.13     0.66     1.17 1.00     2005\nsd(muangular_Intercept)        1.65      0.28     1.15     2.24 1.00     1800\nsd(mutriangular_Intercept)     5.33      0.62     4.25     6.65 1.00     1149\n                           Tail_ESS\nsd(muother_Intercept)          3045\nsd(muangular_Intercept)        3459\nsd(mutriangular_Intercept)     2307\n\nPopulation-Level Effects: \n                                                            Estimate Est.Error\nmuother_Intercept                                              -1.96      0.42\nmuangular_Intercept                                            -4.11      0.71\nmutriangular_Intercept                                         -4.85      1.00\nmuother_pretty_conditionimpasse                                 1.82      0.31\nmuother_ospan_splithighMmemory                                 -0.18      0.32\nmuother_pretty_conditionimpasse:ospan_splithighMmemory         -0.07      0.45\nmuangular_pretty_conditionimpasse                               1.86      0.56\nmuangular_ospan_splithighMmemory                                0.16      0.59\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory       -0.32      0.78\nmutriangular_pretty_conditionimpasse                            2.47      1.12\nmutriangular_ospan_splithighMmemory                             0.05      1.17\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory     2.74      1.46\n                                                            l-95% CI u-95% CI\nmuother_Intercept                                              -2.80    -1.18\nmuangular_Intercept                                            -5.53    -2.72\nmutriangular_Intercept                                         -6.86    -2.93\nmuother_pretty_conditionimpasse                                 1.23     2.45\nmuother_ospan_splithighMmemory                                 -0.81     0.45\nmuother_pretty_conditionimpasse:ospan_splithighMmemory         -0.98     0.81\nmuangular_pretty_conditionimpasse                               0.79     3.00\nmuangular_ospan_splithighMmemory                               -1.01     1.32\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory       -1.84     1.23\nmutriangular_pretty_conditionimpasse                            0.24     4.68\nmutriangular_ospan_splithighMmemory                            -2.25     2.28\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory    -0.12     5.52\n                                                            Rhat Bulk_ESS\nmuother_Intercept                                           1.00     1051\nmuangular_Intercept                                         1.00     1411\nmutriangular_Intercept                                      1.00     1109\nmuother_pretty_conditionimpasse                             1.00     2022\nmuother_ospan_splithighMmemory                              1.00     2358\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      1.00     1927\nmuangular_pretty_conditionimpasse                           1.00     1894\nmuangular_ospan_splithighMmemory                            1.00     1947\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    1.00     1990\nmutriangular_pretty_conditionimpasse                        1.00      819\nmutriangular_ospan_splithighMmemory                         1.01     1166\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory 1.00     1281\n                                                            Tail_ESS\nmuother_Intercept                                               2068\nmuangular_Intercept                                             2534\nmutriangular_Intercept                                          1663\nmuother_pretty_conditionimpasse                                 2940\nmuother_ospan_splithighMmemory                                  3218\nmuother_pretty_conditionimpasse:ospan_splithighMmemory          3157\nmuangular_pretty_conditionimpasse                               2465\nmuangular_ospan_splithighMmemory                                3299\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory        2629\nmutriangular_pretty_conditionimpasse                            1699\nmutriangular_ospan_splithighMmemory                             2366\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory     2310\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCODE\n(d <- describe_posterior(ci=.95, Bmm.cat.CrSQ))\n\n\nSummary of Posterior Distribution\n\nParameter                            | Median |         95% CI |   pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                    |  -2.03 | [-2.82, -1.27] | 100% | [-0.18, 0.18] |        0% | 1.000 |  888.00\nmuangular_Intercept                  |  -3.94 | [-5.19, -2.71] | 100% | [-0.18, 0.18] |        0% | 1.000 | 1132.00\nmutriangular_Intercept               |  -4.70 | [-6.43, -3.14] | 100% | [-0.18, 0.18] |        0% | 1.007 |  719.00\nmuother_pretty_conditionimpasse      |   1.80 | [ 1.37,  2.25] | 100% | [-0.18, 0.18] |        0% | 1.002 | 2160.00\nmuangular_pretty_conditionimpasse    |   1.67 | [ 0.90,  2.50] | 100% | [-0.18, 0.18] |        0% | 1.000 | 1771.00\nmutriangular_pretty_conditionimpasse |   3.56 | [ 1.61,  5.54] | 100% | [-0.18, 0.18] |        0% | 1.010 |  572.00\n\n\nCODE\nprint(\"BAYES FACTOR [comparison to CONDITION only]\")\n\n\n[1] \"BAYES FACTOR [comparison to CONDITION only]\"\n\n\nCODE\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(Bmm.cat.CrSQ, m))\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n\n\nRecompiling the model with 'rstan'\n\n\nRecompilation done\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nWarning: logml could not be estimated within maxiter, rerunning with adjusted starting value. \nEstimate might be more variable than usual.\n\n\nBayes Factors for Model Comparison\n\n    Model                                                       BF\n[2] pretty_condition * ospan_split + (1 | subject) + (1 | q) 0.677\n\n* Against Denominator: [1] pretty_condition + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n\n\nCODE\nprint(\"DESCRIBE POSTERIOR\")\n\n\n[1] \"DESCRIBE POSTERIOR\"\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n(l <- describe_posterior(m))\n\n\nSummary of Posterior Distribution\n\nParameter                                                   | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n--------------------------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           |  -1.95 | [-2.80, -1.18] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1040.00\nmuangular_Intercept                                         |  -4.10 | [-5.53, -2.72] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1378.00\nmutriangular_Intercept                                      |  -4.82 | [-6.86, -2.93] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1102.00\nmuother_pretty_conditionimpasse                             |   1.81 | [ 1.23,  2.45] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1993.00\nmuother_ospan_splithighMmemory                              |  -0.18 | [-0.81,  0.45] | 71.52% | [-0.18, 0.18] |    38.68% | 1.001 | 2323.00\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |  -0.08 | [-0.98,  0.81] | 56.37% | [-0.18, 0.18] |    32.33% | 1.001 | 1907.00\nmuangular_pretty_conditionimpasse                           |   1.85 | [ 0.79,  3.00] | 99.98% | [-0.18, 0.18] |        0% | 1.001 | 1900.00\nmuangular_ospan_splithighMmemory                            |   0.16 | [-1.01,  1.32] | 60.73% | [-0.18, 0.18] |    25.18% | 1.002 | 1892.00\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |  -0.33 | [-1.84,  1.23] | 66.37% | [-0.18, 0.18] |    17.42% | 1.000 | 1986.00\nmutriangular_pretty_conditionimpasse                        |   2.45 | [ 0.24,  4.68] | 98.75% | [-0.18, 0.18] |        0% | 1.002 |  824.00\nmutriangular_ospan_splithighMmemory                         |   0.07 | [-2.25,  2.28] | 52.40% | [-0.18, 0.18] |    12.63% | 1.005 | 1164.00\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |   2.76 | [-0.12,  5.52] | 97.03% | [-0.18, 0.18] |     1.37% | 1.001 | 1268.00\n\n\nCODE\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nParameter                                                   |   Median |         95% CI |     pd | % in ROPE |  Rhat |     ESS\n------------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                                           |     0.14 | [0.06,   0.31] |   100% |        0% | 1.001 | 1040.00\nmuangular_Intercept                                         |     0.02 | [0.00,   0.07] |   100% |        0% | 1.000 | 1378.00\nmutriangular_Intercept                                      | 8.07e-03 | [0.00,   0.05] |   100% |        0% | 1.000 | 1102.00\nmuother_pretty_conditionimpasse                             |     6.13 | [3.42,  11.53] |   100% |        0% | 1.001 | 1993.00\nmuother_ospan_splithighMmemory                              |     0.83 | [0.44,   1.56] | 71.52% |    38.68% | 1.001 | 2323.00\nmuother_pretty_conditionimpasse:ospan_splithighMmemory      |     0.93 | [0.38,   2.25] | 56.37% |    32.33% | 1.001 | 1907.00\nmuangular_pretty_conditionimpasse                           |     6.39 | [2.21,  20.08] | 99.98% |        0% | 1.001 | 1900.00\nmuangular_ospan_splithighMmemory                            |     1.18 | [0.37,   3.74] | 60.73% |    25.18% | 1.002 | 1892.00\nmuangular_pretty_conditionimpasse:ospan_splithighMmemory    |     0.72 | [0.16,   3.41] | 66.37% |    17.42% | 1.000 | 1986.00\nmutriangular_pretty_conditionimpasse                        |    11.64 | [1.27, 107.34] | 98.75% |        0% | 1.002 |  824.00\nmutriangular_ospan_splithighMmemory                         |     1.07 | [0.11,   9.76] | 52.40% |    12.63% | 1.005 | 1164.00\nmutriangular_pretty_conditionimpasse:ospan_splithighMmemory |    15.73 | [0.89, 249.91] | 97.03% |     1.37% | 1.001 | 1268.00\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#PREDICT METHOD\nnewdata <- df_i %>% dplyr::select(pretty_condition, ospan_split, subject, q)\npreds <- predict(m, newdata = newdata, type = \"response\")\npreds <- cbind(newdata, preds)\n#lengthen data frame to handle multinomial\n# preds <- preds %>% \n#   dplyr::select(-subject, -q) %>% #marginalize over subject and q\n#   pivot_longer(\n#   cols = !pretty_condition,\n#   values_to = \"preds\",\n#   names_to = \"state\",\n# ) \n# \n# (p <- preds %>% \n#   group_by(pretty_condition, state ) %>%\n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se))\n\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n\n\n\n\nINFERENCE\n\n\nPrint\n\n\nCODE\n#SJPLOT | MODEL | TABLE\n# tab_model(m)\n\n# #MODEL SUMMARY | save latex table\n#model summary doesn't work for brms multinomial\n\n# DOESN'T WORK FOR BRMS\n# extract_eq(m, use_coefs = TRUE, wrap = TRUE)\n# \n# \n# #GET MODEL ESTIMATES\n# t <- as.data.frame(model_parameters(m, exponentiate = TRUE))\n# # \n# # #REFORMAT\n# x <- t %>%\n#   mutate(\n#     Parameter = str_remove_all(Parameter,\"_pretty\"),\n#     Parameter = str_remove_all(Parameter,\"b_mu\"),\n#     Interpretation = word(Parameter, 1, sep = \"_\"),\n#     Interpretation = fct_relevel(Interpretation, levels = c(\"other\",\"angular\",\"triangular\")),\n#     Factor = word(Parameter, 2, sep = \"_\"),\n#     Factor = recode_factor(Factor,\n#                          \"Intercept\" = \"(Intercept)\",\n#                          \"conditionimpasse\" = \"Condition[impasse]\",\n#                          \"ospan\" = \"OSPAN[high-memory]\",\n#                          \"conditionimpasse:ospan\" = \"Condition:OSPAN\"),\n#     Median = round(Median,2),\n#     CI_low = round(CI_low,2),\n#     CI_high = round(CI_high,2),\n#     pd = round(pd,2),\n#     ROPE_Percentage = round(ROPE_Percentage,2)) %>%\n#   arrange(Interpretation) %>%\n#   dplyr::select(-CI, -Rhat, -ESS) %>%\n#   rename( \"%_in_ROPE\"=\"ROPE_Percentage\",\n#   \"(Odds Ratio)\" = \"Median\") %>%\n#   dplyr::select(Interpretation, Factor, `(Odds Ratio)`, CI_low, CI_high, pd, `%_in_ROPE`)\n# \n# # #KNIT\n# title = \"Study 3C (OSPAN) | Question Interpretation | Mixed Multinomial Regression\"\n# tab <- kbl(x, format = \"latex\", caption = title,\n#            booktabs = FALSE) %>% kable_classic() %>%\n# footnote(general = paste(\"Model Interpretation ~ \",b$Model[2], \"Bayes Factor \", format( exp(b$log_BF[2]), digits =2 ) ), footnote_as_chunk = T, general_title = \"\")\n# writeLines(tab, \"tables/SGC3C_OSPAN_BRMS_state.tex\")\n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\", \n#            show.intercept = TRUE, \n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test   \n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n\n\n\n\n\nCODE\n# + theme_clean()\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\nPicking joint bandwidth of 0.0938\n\n\nWarning: Removed 7200 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\nCODE\nresult <- rope(m)\nplot(result)\n\n\n\n\n\nCODE\nresult <- pd(m) \nplot(result)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")  \n# plot_model(m, type = \"eff\")  \n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n\n\nCODE\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\ndraws <- df_i %>%\n  data_grid(pretty_condition, ospan_split, subject, q) %>%\n  add_epred_draws(m,\n                   # ndraws = 100, # n = 100,\n                   # dpar = TRUE,\n                   transform = TRUE, #gives prob%, otherwise OR\n                   re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\n# d <- \n\nd <- draws %>% sample_n(10) %>% \n  ggplot(aes(x = .epred,  y = pretty_condition, fill = ospan_split)) +\n  stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\") +\n  facet_wrap(~.category) +\n  #   #normalize = all, panels, xy, groups, none\n  xlim(0,1) + labs(\n    title = \"Model Predicted Probability of Correct Response\",\n    x = \"probability of correct response\",\n    y = \"Interpretation\"\n  ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # \n# # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\nd\n\n\n\n\n\n\n\nCODE\n#DISPLAY MODEL AS TABLE\ntab_model(m)\n\n\n'bayes_R2' is not defined for unordered categorical models.\n\n\n\n\n \nstate: other\nstate: angular\nstate: triangular\nstate: other_pretty\nstate: other_ospan\nstate: other_pretty_conditionimpasse:ospan\nstate: angular_pretty\nstate: angular_ospan\nstate: angular_pretty_conditionimpasse:ospan\nstate: triangular_pretty\nstate: triangular_ospan\nstate: triangular_pretty_conditionimpasse:ospan\n\n\nPredictors\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\n\n\nIntercept\n0.02\n0.00 – 0.07\n\n\n\n\n\n\n0.14\n0.06 – 0.31\n\n\n\n\n\n\n0.01\n0.00 – 0.05\n\n\n\n\n\n\n\n\nsplithighMmemory\n\n\n1.18\n0.37 – 3.74\n\n\n0.72\n0.16 – 3.41\n\n\n0.83\n0.44 – 1.56\n\n\n0.93\n0.38 – 2.25\n\n\n1.07\n0.11 – 9.76\n\n\n15.73\n0.89 – 249.91\n\n\nconditionimpasse\n\n\n\n\n6.39\n2.21 – 20.08\n\n\n\n\n\n\n6.13\n3.42 – 11.53\n\n\n\n\n\n\n11.64\n1.27 – 107.34\n\n\n\n\nRandom Effects\n\n\n\nσ2\n0.48\n\n\n\nτ00\n1.07\n\n\nICC\n0.31\n\n\nN subject\n133\n\n\nN q\n13\n\nObservations\n1729\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list('\"* p < 0.05, ** p < 0.01, *** p < 0.001\"',\n#                'N(subject) = 133 $\\tau_{00}$(subject) = 34.85',\n#              'N(question) = 13 $\\tau_{00}$(question) = 1.14')\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex\")\n# # #              # coef_omit = \"Intercept\",\n#TODO OUTPUT TABLE \n\n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n\n\n\n\nDiagnostics\n\n\nCODE\n#CHECK Fit of posterior predictive to data\npp_check(m, ndraws=1000)\n\n\n\n\n\nCODE\n#CHECK posterior vs. priors\nresult <- estimate_density(m)\nplot(result, stack = FALSE, priors= TRUE)\n\n\n\n\n\nCODE\n#CHECK model\nplot(m)"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1b-q1-accuracy",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1b-q1-accuracy",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "H1B | Q1 ACCURACY",
    "text": "H1B | Q1 ACCURACY\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1) %>% dplyr::select(accuracy, pretty_condition, ospan_split)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses\")\n\n\n\n\n\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n\n\n[1] \"Proportions of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            control impasse   Sum\n  incorrect   0.892   0.765 0.827\n  correct     0.108   0.235 0.173\n  Sum         1.000   1.000 1.000\n\n\nCODE\npaste(\"Number of Correct Responses by Condition\")\n\n\n[1] \"Number of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n\n\n, ,  = low-memory\n\n           \n            control impasse Sum\n  incorrect      28      31  59\n  correct         3       5   8\n  Sum            31      36  67\n\n, ,  = high-memory\n\n           \n            control impasse Sum\n  incorrect      30      21  51\n  correct         4      11  15\n  Sum            34      32  66\n\n\n\n\nCHI SQUARE [YES]\n\n\nCODE\n#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY\ndf_low <- df %>% filter(ospan_split == \"low-memory\")\n# table(df_low$pretty_condition, df_low$accuracy)\nchisq.test( x = df_low$pretty_condition, y = df_low$accuracy, correct = TRUE)\n\n\nWarning in chisq.test(x = df_low$pretty_condition, y = df_low$accuracy, : Chi-\nsquared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  df_low$pretty_condition and df_low$accuracy\nX-squared = 0.02, df = 1, p-value = 0.9\n\n\nCODE\n#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in HIGH WORKING MEMORY\ndf_high <- df %>% filter(ospan_split == \"high-memory\")\n#table(df_high$pretty_condition, df_high$accuracy)\nchisq.test( x = df_high$pretty_condition, y = df_high$accuracy,correct = TRUE)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  df_high$pretty_condition and df_high$accuracy\nX-squared = 4, df = 1, p-value = 0.06\n\n\nCODE\n#significant if correct = FALSE\n\n\nTODO why do these chisqrs not match the grouped bar stats? ::: {.cell}\n\nCODE\n# INTERACTION (OSPAN X CONDITION)\ngrouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, \n                    grouping.var = ospan_split,\n                    type = \"nonparametric\")\n\n\n\n\n\nCODE\n# MAIN EFFECT CONDITION (yes)\n# ggbarstats( data = df, x = accuracy, y = pretty_condition, \n#                     type = \"nonparametric\")\n\n# MAIN EFFECT OSPAN (none)\n# ggbarstats( data = df, x = accuracy, y = ospan_split, \n#                     type = \"nonparametric\")\n\n:::\nThere is no non-parametric version of two-way ANOVA, so we perform individual CHI-SQR tests. We split the data into two groups (low memory, and high memory, based on the median split). For each, we run a CHI SQR test of independence testing the null hypothesis that Q1 ACCURACY is independent of CONDITION. In the low-working memory group, we cannot reject the null hypothesis, suggesting that accuracy does not differ by condition. But in the HIGH working memory group we do reject the null hypothesis. The proportion of correct responses in IMPASSE is much higher than in CONTROL, but only in the HIGH WORKING MEMORY group.\n\n\nLOGISTIC REGRESSION (MAIN EFFECT CONDITION)\nTODO:: consider weighted(centered) continuous vs ospan split\nFit a logistic regression predicting accuracy (absolute score) (n = 133) by condition (k = 2).\n\n\nParameter estimate: \\(\\beta_{0}\\) = Log Odds of (correct) responses in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of correct response in CONTROL condition\nParameter estimate: \\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for correct response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\nNull hypothesis:\\(\\beta_{impasse} \\le 0\\) the odds for a correct response does not change, or decreases\nAlternative hypothesis: \\(\\beta_{impasse} \\gt 0\\) the odds of a correct response increases\n\n\nFit CONDITION Model\nFirst, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.\n\n\nCODE\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm.0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm.C <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 2 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m.0$aic > m.C$aic)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(m.0,m.C) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.0  |   glm |  1 |         |      |      \nm.C  |   glm |  2 |       1 | 3.88 | 0.049\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m.0,m.C))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0489409367734944\"\n\n\nCODE\nsummary(m.C)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.733  -0.733  -0.477  -0.477   2.111  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.115      0.400   -5.28  1.3e-07 ***\npretty_conditionimpasse    0.936      0.492    1.90    0.057 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 118.62  on 131  degrees of freedom\nAIC: 122.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\n##### Fit OSPAN Models\n\n#: 3 OSPAN ONLY MODEL \nm.O = glm(accuracy ~ ospan_split, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 3 TEST SUPERIOR FIT\npaste(\"AIC OSPAN predictor is lower than CONDITION model?\", m.C$aic > m.O$aic)\n\n\n[1] \"AIC OSPAN predictor is lower than CONDITION model? FALSE\"\n\n\nCODE\n#: 4 OSPAN + CONDITION model\nm.CO <- glm( accuracy ~ pretty_condition + ospan_split, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\nsummary(m.CO)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition + ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.870  -0.599  -0.559  -0.373   2.323  \n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               -2.629      0.523   -5.03    5e-07 ***\npretty_conditionimpasse    1.002      0.499    2.01    0.045 *  \nospan_splithigh-memory     0.851      0.487    1.75    0.081 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 115.42  on 130  degrees of freedom\nAIC: 121.4\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\ncar::Anova(m.CO, type=3)\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: accuracy\n                 LR Chisq Df Pr(>Chisq)  \npretty_condition     4.33  1      0.037 *\nospan_split          3.19  1      0.074 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#: 4 TEST SUPERIOR FIT\npaste(\"AIC wth OSPAN is lower than CONDITION only model?\", m.C$aic > m.CO$aic)\n\n\n[1] \"AIC wth OSPAN is lower than CONDITION only model? TRUE\"\n\n\nCODE\ntest_lrt(m.C,m.CO) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff | Chi2 |     p\n------------------------------------------\nm.C  |   glm |  2 |         |      |      \nm.CO |   glm |  3 |       1 | 3.19 | 0.074\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m.C,m.CO))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0739762476630023\"\n\n\nCODE\n##Adding OSPAN as a predictor (no interaction) decreases AIC, but does not improve fit (LRT)\n\n\n#: 5 OSPAN + CONDITION INTERACTION model\nm.C.O <- glm( accuracy ~ pretty_condition * ospan_split, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m.C.O)\n# car::Anova(m.C.O, type =3)\n\n#: 5 TEST SUPERIOR FIT\npaste(\"AIC wth OSPAN IXN lower than CONDITION + OSPAN only model?\", m.CO$aic > m.C.O$aic)\n\n\n[1] \"AIC wth OSPAN IXN lower than CONDITION + OSPAN only model? FALSE\"\n\n\nCODE\ntest_lrt(m.CO,m.C.O) \n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.CO  |   glm |  3 |         |      |      \nm.C.O |   glm |  4 |       1 | 0.89 | 0.346\n\n\nCODE\npaste(\"AIC wth OSPAN IXN is lower than CONDITION only model?\", m.C$aic > m.C.O$aic)\n\n\n[1] \"AIC wth OSPAN IXN is lower than CONDITION only model? TRUE\"\n\n\nCODE\ntest_lrt(m.C,m.C.O) \n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  | Model | df | df_diff | Chi2 |     p\n-------------------------------------------\nm.C   |   glm |  2 |         |      |      \nm.C.O |   glm |  4 |       2 | 4.08 | 0.130\n\n\nAdding OSPAN interaction does not improve model fit over condition-only model, or main effects only model.\n\n\nDescribe\n\n\nCODE\n#set model\nm <- m.C.O\n\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n\n\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n\n\nCODE\nsummary(m)\n\n\n\nCall:\nglm(formula = accuracy ~ pretty_condition * ospan_split, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-0.918  -0.547  -0.500  -0.451   2.161  \n\nCoefficients:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.234      0.607   -3.68\npretty_conditionimpasse                           0.409      0.775    0.53\nospan_splithigh-memory                            0.219      0.808    0.27\npretty_conditionimpasse:ospan_splithigh-memory    0.959      1.011    0.95\n                                               Pr(>|z|)    \n(Intercept)                                     0.00024 ***\npretty_conditionimpasse                         0.59782    \nospan_splithigh-memory                          0.78656    \npretty_conditionimpasse:ospan_splithigh-memory  0.34295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 122.49  on 132  degrees of freedom\nResidual deviance: 114.54  on 129  degrees of freedom\nAIC: 122.5\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\nprint(\"SIGNIFIGANCE TEST\")\n\n\n[1] \"SIGNIFIGANCE TEST\"\n\n\nCODE\ncar::Anova(m, type=3)\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: accuracy\n                             LR Chisq Df Pr(>Chisq)\npretty_condition                0.284  1       0.59\nospan_split                     0.074  1       0.79\npretty_condition:ospan_split    0.887  1       0.35\n\n\nCODE\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m, level = 0.90)) # get 90% for right side))\n# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\nprint(\"Coefficients —- ODDS RATIOS\")\n\n\n[1] \"Coefficients —- ODDS RATIOS\"\n\n\nCODE\n(e <- cbind( exp(coef(m)), exp(confint(m)))) #exponentiated, not adjusted\n\n\nWaiting for profiling to be done...\n\n\n                                                      2.5 % 97.5 %\n(Intercept)                                    0.107 0.0256  0.302\npretty_conditionimpasse                        1.505 0.3380  7.881\nospan_splithigh-memory                         1.244 0.2528  6.786\npretty_conditionimpasse:ospan_splithigh-memory 2.610 0.3409 19.436\n\n\nCODE\n# (e <- cbind( exp(coef(m)), exp(dcint))) #exponentiated, adjusted\n\n#TODO INTERACTIONS & ESTIMATED MARGINAL MEANS \n# print(\"MODEL PREDICTIONS\")\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\n# pred.control <- predict(m,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\n# paste(\"Probability of success in control,\", pred.control)\n# pred.impasse <- predict(m,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\n# paste(\"Probability of success in impasse,\", pred.impasse)\n\n\n\n\nInference\nTODO double check chisqrs vs grouped_barstats. Why is the tests not the same. Otherwise report mm.C as ospan didn’t improve fit\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n\n\n$pretty_condition\n\n\n\n\n\n\n$ospan_split\n\n\n\n\n\nCODE\nplot_model(m, type = \"eff\")  \n\n\n$pretty_condition\n\n\n\n\n\n\n$ospan_split\n\n\n\n\n\nCODE\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.11\n0.03 – 0.30\n<0.001\n\n\npretty condition[impasse]\n1.51\n0.34 – 7.88\n0.598\n\n\nospan split [high-memory]\n1.24\n0.25 – 6.79\n0.787\n\n\npretty condition[impasse] * ospan split[high-memory]\n2.61\n0.34 – 19.44\n0.343\n\n\nObservations\n133\n\n\nR2 Tjur\n0.066\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report::report(m)\n\n#print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"MODEL DIAGNOSTICS\")\n\n\n[1] \"MODEL DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1b-q1-interpretation-state",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#h1b-q1-interpretation-state",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "H1B | Q1 INTERPRETATION STATE",
    "text": "H1B | Q1 INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations on first question?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category derived response variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses on the first question?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question\n\n\nData\n\ndata: df_items where q == 1\noutcome: state ( 4 level factor from 5 level high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMultinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nOrdinal regression on state; but model doesn’t satisfy proportional odds assumption (parallel slopes)\nMultinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can’t accurately estimate those comparisons\n\n\n\n\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1) %>% \n  dplyr::select(pretty_condition, ospan_split, state)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ospan_split) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             control impasse    Sum\n  orthogonal  0.8154  0.2647 0.5338\n  other       0.0462  0.3824 0.2180\n  angular     0.0308  0.1176 0.0752\n  triangular  0.1077  0.2353 0.1729\n  Sum         1.0000  1.0000 1.0000\n\n\nCODE\n(t <- table(df$state, df$pretty_condition, df$ospan_split) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n, ,  = low-memory\n\n            \n             control impasse Sum\n  orthogonal      26      15  41\n  other            1      13  14\n  angular          1       3   4\n  triangular       3       5   8\n  Sum             31      36  67\n\n, ,  = high-memory\n\n            \n             control impasse Sum\n  orthogonal      27       3  30\n  other            2      13  15\n  angular          1       5   6\n  triangular       4      11  15\n  Sum             34      32  66\n\n\n\n\nMULTINOMIAL REGRESSION\nTODO:: USE MBLOGIT VERSION WITH P VALUES IN MODEL\nDoes condition affect the response state of Q1?\nFit a logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\n3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) [essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing [reference category] vs [this category])\nFor each equation:\n\n\\(\\beta_{0}\\) = Log Odds of [this category type vs. reference category type) response in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of [this category type vs. reference category type] response in CONTROL condition\n\\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for [this category] type response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of [this. vs reference category type] response in IMPASSE (vs) CONTROL\nTwo-tailed NHST Null hypothesis: \\(\\beta_{impasse} = 0\\) the odds for [this category of response vs. reference] are not different for IMPASSE condition\nAlternative hypothesis: \\(\\beta_{impasse} \\ne 0\\) the odds of [this category of response vs. reference] increases or decreases for IMPASSE condition\n\n\n\nFit CONDITION Model\n\n\nCODE\n#check reference level \nprint(\"Categories (first is reference)\")\n\n\n[1] \"Categories (first is reference)\"\n\n\nCODE\nlevels(df$state)\n\n\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n\n\nCODE\n#FIT EMPTY MODEL\n# print(\"EMPTY MODEL\")\ncatm.0 <- multinom(state ~ 1, data = df)\n\n\n# weights:  8 (3 variable)\ninitial  value 184.377150 \niter  10 value 155.544397\nfinal  value 154.972366 \nconverged\n\n\nCODE\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\n# print(\"PREDICTOR MODEL\")\ncatm.C <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\n\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 131.798993\nfinal  value 131.798569 \nconverged\n\n\nCODE\n# summary(catm.C)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth predictor is lower than empty model?\", catm.0$AIC > catm.C$AIC)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(catm.0, catm.C)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |  Chi2 |      p\n-------------------------------------------------\ncatm.0 | multinom |  3 |         |       |       \ncatm.C | multinom |  6 |       3 | 46.35 | < .001\n\n\nCODE\n##compare bayesian version\n#library(brms)\n# b.cat <- brm( state2 ~ pretty_condition, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat)\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\n# blm1 <- mblogit(state2 ~ pretty_condition , data = df)\n# summary(blm1)\n#identical to catm. super cool!\n\n\nAIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.\n\n\nFit OSPAN Model\n\n\nCODE\n#FIT OSPAN only MODEL\n# print(\"OSPAN ONLY MODEL\")\ncatm.O <- multinom(state ~ ospan_split, data = df)\n\n\n# weights:  12 (6 variable)\ninitial  value 184.377150 \niter  10 value 152.820024\nfinal  value 152.819667 \nconverged\n\n\nCODE\n# summary(catm.O) \n# car::Anova(catm.O) \nprint(\"OSPAN ONLY better than empty?\")\n\n\n[1] \"OSPAN ONLY better than empty?\"\n\n\nCODE\ntest_lrt(catm.0, catm.O)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff | Chi2 |     p\n-----------------------------------------------\ncatm.0 | multinom |  3 |         |      |      \ncatm.O | multinom |  6 |       3 | 4.31 | 0.230\n\n\nCODE\n#FIT OSPAN + CONDITION\n# print(\"OSPAN + CONDITION MODEL\")\ncatm.CO <- multinom(formula = state ~ pretty_condition + ospan_split, data = df, model = TRUE)\n\n\n# weights:  16 (9 variable)\ninitial  value 184.377150 \niter  10 value 128.125771\nfinal  value 128.076360 \nconverged\n\n\nCODE\n# summary(catm.CO)\ncar::Anova(catm.CO) #MainEff condition, marginal ospan\n\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: state\n                 LR Chisq Df Pr(>Chisq)    \npretty_condition     49.5  3      1e-10 ***\nospan_split           7.4  3      0.059 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#COMPARE MODEL FIT\npaste(\"Adding OSPAN to CONDITION lowers AIC?\", catm.C$AIC > catm.CO$AIC)\n\n\n[1] \"Adding OSPAN to CONDITION lowers AIC? TRUE\"\n\n\nCODE\ntest_lrt(catm.C, catm.CO)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff | Chi2 |     p\n------------------------------------------------\ncatm.C  | multinom |  6 |         |      |      \ncatm.CO | multinom |  9 |       3 | 7.44 | 0.059\n\n\nAdding (main effect) predictor of OSPAN decreases AIC and is a marginally better fit. In this model, there is still only a main effect of condition. OSPAN is not a significant main effect.\n\n\nCODE\n#FIT OSPAN * CONDITION\n# print(\"OSPAN * CONDITION MODEL\")\ncatm.C.O <- multinom(formula = state ~ pretty_condition * ospan_split, data = df, model = TRUE)\n\n\n# weights:  20 (12 variable)\ninitial  value 184.377150 \niter  10 value 126.168657\niter  20 value 125.962345\nfinal  value 125.962341 \nconverged\n\n\nCODE\ncar::Anova(catm.C.O, type = 3)\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                             LR Chisq Df Pr(>Chisq)    \npretty_condition                16.37  3    0.00095 ***\nospan_split                      0.36  3    0.94767    \npretty_condition:ospan_split     4.23  3    0.23787    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# summary(catm.C.O)\n# car::Anova(catm.C.O) #MainEff condition, marginal ospan\n#COMPARE MODEL FIT\npaste(\"Adding INTERACTION lowers AIC?\", catm.CO$AIC > catm.C.O$AIC)\n\n\n[1] \"Adding INTERACTION lowers AIC? FALSE\"\n\n\nCODE\ntest_lrt(catm.CO, catm.C.O)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff | Chi2 |     p\n-------------------------------------------------\ncatm.CO  | multinom |  9 |         |      |      \ncatm.C.O | multinom | 12 |       3 | 4.23 | 0.238\n\n\nAdding interaction of OSPAN does not improve fit and does not lower AIC. In the IXN model, only the main effect of condition is significant.\n\n\nCODE\n##compare bayesian version\n# library(brms)\n# b.cat <- brm( state ~ pretty_condition*ospan_split, data = df, family = \"categorical\", backend = \"cmdstanr\")\n# summary(b.cat)\n# plot_model(b.cat) \n# plot(equivalence_test(b.cat))\n# plot(rope(b.cat))\n# report(b.cat)\n# coefficient estimates are very simliar to catm. super cool!\n\n##compare mclogit version\n#\"baseline-category logit model\n# https://www.elff.eu/software/mclogit/manual/mblogit/\nblm1 <- mblogit(state ~ pretty_condition *ospan_split , data = df)\n\n\n\nIteration 1 - deviance = 253 - criterion = 0.272\nIteration 2 - deviance = 252 - criterion = 0.00566\nIteration 3 - deviance = 252 - criterion = 0.000157\nIteration 4 - deviance = 252 - criterion = 2.98e-07\nIteration 5 - deviance = 252 - criterion = 2.53e-12\nconverged\n\n\nCODE\nsummary(blm1)\n\n\n\nCall:\nmblogit(formula = state ~ pretty_condition * ospan_split, data = df)\n\nEquation for other vs orthogonal:\n                                               Estimate Std. Error z value\n(Intercept)                                      -3.258      1.019   -3.20\npretty_conditionimpasse                           3.115      1.087    2.87\nospan_splithigh-memory                            0.655      1.255    0.52\npretty_conditionimpasse:ospan_splithigh-memory    0.954      1.459    0.65\n                                               Pr(>|z|)   \n(Intercept)                                      0.0014 **\npretty_conditionimpasse                          0.0042 **\nospan_splithigh-memory                           0.6016   \npretty_conditionimpasse:ospan_splithigh-memory   0.5132   \n\nEquation for angular vs orthogonal:\n                                                  Estimate Std. Error z value\n(Intercept)                                        -3.2581     1.0190   -3.20\ntri(Intercept)                                     -2.1595     0.6097   -3.54\npretty_conditionimpasse                             1.6487     1.1994    1.37\ntripretty_conditionimpasse                          1.0609     0.7990    1.33\nospan_splithigh-memory                             -0.0377     1.4407   -0.03\ntriospan_splithigh-memory                           0.2499     0.8117    0.31\npretty_conditionimpasse:ospan_splithigh-memory      2.1580     1.7346    1.24\ntripretty_conditionimpasse:ospan_splithigh-memory   2.1480     1.1618    1.85\n                                                  Pr(>|z|)    \n(Intercept)                                         0.0014 ** \ntri(Intercept)                                      0.0004 ***\npretty_conditionimpasse                             0.1693    \ntripretty_conditionimpasse                          0.1843    \nospan_splithigh-memory                              0.9791    \ntriospan_splithigh-memory                           0.7581    \npretty_conditionimpasse:ospan_splithigh-memory      0.2135    \ntripretty_conditionimpasse:ospan_splithigh-memory   0.0645 .  \n\nEquation for triangular vs orthogonal:\n                                               Estimate Std. Error z value\n(Intercept)                                      -2.159      0.610   -3.54\npretty_conditionimpasse                           1.061      0.799    1.33\nospan_splithigh-memory                            0.250      0.812    0.31\npretty_conditionimpasse:ospan_splithigh-memory    2.148      1.162    1.85\n                                               Pr(>|z|)    \n(Intercept)                                      0.0004 ***\npretty_conditionimpasse                          0.1843    \nospan_splithigh-memory                           0.7581    \npretty_conditionimpasse:ospan_splithigh-memory   0.0645 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNull Deviance:     369 \nResidual Deviance: 252 \nNumber of Fisher Scoring iterations:  5 \nNumber of observations:  133 \n\n\nCODE\n# car::Anova(blm1) #todo need to separate by individual equation\n#identical to catm. super cool!\n\n\nAIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.\n\n\nDescribe\n\n\nCODE\n#set model\nm <- catm.C.O\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n\n\n[1] \"MODEL SUMMARY\"\n\n\nCODE\nsummary(m)\n\n\nCall:\nmultinom(formula = state ~ pretty_condition * ospan_split, data = df, \n    model = TRUE)\n\nCoefficients:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother            -3.26                    3.11                 0.6553\nangular          -3.26                    1.65                -0.0377\ntriangular       -2.16                    1.06                 0.2500\n           pretty_conditionimpasse:ospan_splithigh-memory\nother                                               0.954\nangular                                             2.158\ntriangular                                          2.148\n\nStd. Errors:\n           (Intercept) pretty_conditionimpasse ospan_splithigh-memory\nother             1.02                   1.087                  1.255\nangular           1.02                   1.199                  1.441\ntriangular        0.61                   0.799                  0.812\n           pretty_conditionimpasse:ospan_splithigh-memory\nother                                                1.46\nangular                                              1.73\ntriangular                                           1.16\n\nResidual Deviance: 252 \nAIC: 276 \n\n\nCODE\ncar::Anova(m, type =3) #always type 3 for ixns \n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                             LR Chisq Df Pr(>Chisq)    \npretty_condition                16.37  3    0.00095 ***\nospan_split                      0.36  3    0.94767    \npretty_condition:ospan_split     4.23  3    0.23787    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# calculate z-statistics of coefficients\nz_stats <- summary(m)$coefficients/summary(m)$standard.errors\n# convert to p-values\np_values <- (1 - pnorm(abs(z_stats)))*2\n# display p-values in transposed data frame\n(p_values <- data.frame(p = (p_values)))\n\n\n           p..Intercept. p.pretty_conditionimpasse p.ospan_splithigh.memory\nother           0.001388                   0.00417                    0.602\nangular         0.001387                   0.16927                    0.979\ntriangular      0.000398                   0.18428                    0.758\n           p.pretty_conditionimpasse.ospan_splithigh.memory\nother                                                0.5132\nangular                                              0.2134\ntriangular                                           0.0645\n\n\nCODE\n# display odds ratios in transposed data frame\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\nodds_ratios <- data.frame(OR = exp(summary(m)$coefficients))\noptions(scipen = 2)\n(results <- cbind(odds_ratios, p_values))\n\n\n           OR..Intercept. OR.pretty_conditionimpasse OR.ospan_splithigh.memory\nother              0.0385                      22.53                     1.926\nangular            0.0385                       5.20                     0.963\ntriangular         0.1154                       2.89                     1.284\n           OR.pretty_conditionimpasse.ospan_splithigh.memory p..Intercept.\nother                                                   2.60      0.001388\nangular                                                 8.65      0.001387\ntriangular                                              8.57      0.000398\n           p.pretty_conditionimpasse p.ospan_splithigh.memory\nother                        0.00417                    0.602\nangular                      0.16927                    0.979\ntriangular                   0.18428                    0.758\n           p.pretty_conditionimpasse.ospan_splithigh.memory\nother                                                0.5132\nangular                                              0.2134\ntriangular                                           0.0645\n\n\n\n\nInference\nlooking at detailed p values\n… OTHER: only main effect of condition TRI-LIKE: no effects TRI: IXN condition * impasse\nTODO\n\nBeing in the IMPASSE condition increases the odds of giving an unknown (potentially nonsense) or blank/uncertain response rather than an orthogonal (or satisficing) response by a factor of 45 (z = 3.81, p < 0.001) . Participants in the impasse condition were 45x as likely to give an unknown/uncertain response rather than an orthogonal response compared to participants in control.\nBeing in the IMPASSE condition increases the odds of giving ‘triangle-like’ response rather than an orthogonal (or satisficing) response by a factor of 17.5 (z = 2.60, p < 0.001 ). Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control.\nBeing in the IMPASSE condition increases the odds of giving ‘triangle-like’ response rather than an orthogonal (or satisficing) response by a factor of 4.8 (z = 3.30, p < 0.001 ). Participants in the impasse condition were almost 6x as likely to give an a triangular response rather than an orthogonal response compared to participants in control.\nAs with the (binary) logistic regression on accuracy ~ condition, significant model intercepts indicate that the odds of being in any particular response state (vs) orthogonal are significantly different than 1 in the control condition. (i.e. not 1:1 odds or 50% chance of being in that response state. Orthogonal is a much more probable response state in control)\n[need to to double check interpretation, but I think that the OR intercepts converted to probabilities equate to the marginal probability of being in each state in the control condition. which makes sense. I think.?]\nIF I change reference category for condition… then the intercepts should no longer be significant. The b1 coefficients should still be significant, but with changed sign (much less likely) [Yup! this works!]\n\n\n\nVisualize\n\n\nCODE\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"int\", ci.lvl = 0.95) \n\n\n\n\n\nCODE\nplot_model(m, type=\"eff\", ci.lvl = 0.95) \n\n\n$pretty_condition\n\n\n\n\n\n\n$ospan_split\n\n\n\n\n\nCODE\n# +  ylim(0,1) +\n#   labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n#        subtitle = \"Impasse increases probability of more accurate response states Q1\",\n#        x = \"Condition\") + theme_clean()\n\n#TODO ESTIMAED MARGINALS AND IXN PLOTS \n# https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \nstate\n\n\nPredictors\nOdds Ratios\nCI\np\nResponse\n\n\n(Intercept)\n0.04\n0.01 – 0.29\n0.002\nother\n\n\npretty condition[impasse]\n22.53\n2.62 – 193.88\n0.005\nother\n\n\nospan split [high-memory]\n1.93\n0.16 – 23.11\n0.603\nother\n\n\npretty condition[impasse] * ospan split[high-memory]\n2.60\n0.14 – 46.67\n0.514\nother\n\n\n(Intercept)\n0.04\n0.01 – 0.29\n0.002\nangular\n\n\npretty condition[impasse]\n5.20\n0.48 – 55.86\n0.172\nangular\n\n\nospan split [high-memory]\n0.96\n0.06 – 16.68\n0.979\nangular\n\n\npretty condition[impasse] * ospan split[high-memory]\n8.65\n0.28 – 268.24\n0.216\nangular\n\n\n(Intercept)\n0.12\n0.03 – 0.39\n0.001\ntriangular\n\n\npretty condition[impasse]\n2.89\n0.59 – 14.05\n0.187\ntriangular\n\n\nospan split [high-memory]\n1.28\n0.26 – 6.40\n0.759\ntriangular\n\n\npretty condition[impasse] * ospan split[high-memory]\n8.57\n0.86 – 85.46\n0.067\ntriangular\n\n\nObservations\n133\n\n\nR2 / R2 adjusted\n0.187 / 0.181\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n\n\n\n\nDiagnostics\n\n\nCODE\n#EXAMINE PREDICTIONS\n#create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(m, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n\nprint(\"MODEL PERFORMANCE\")\n\n\n[1] \"MODEL PERFORMANCE\"\n\n\nCODE\nperformance(m)\n\n\nCan't calculate log-loss.\nCan't calculate proper scoring rules for ordinal, multinomial or cumulative link models.\n\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n275.925 | 310.609 | 0.187 |     0.181 | 0.354 | 1.443\n\n\nCODE\nDescTools::PseudoR2(m, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))\n\n\n  McFadden   CoxSnell Nagelkerke \n     0.187      0.354      0.392 \n\n\nCODE\n#General Goodness of Fit\n#library(generalhoslem)\n#logitgof(df$state, catm$fitted.values, g = 3)\n#A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).\n#don't fret! this version of the hoslem-lem test is problematic with fewer than 10 input variables\nchisq.test(df$state,predict(m)) #actual states VS predicted states\n\n\nWarning in chisq.test(df$state, predict(m)): Chi-squared approximation may be\nincorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  df$state and predict(m)\nX-squared = 33, df = 3, p-value = 3e-07\n\n\nCODE\n# The chi-square test tests the decrease in unexplained variance from the baseline model to the final model\n\n# print(\"MODEL DIAGNOSTICS\")\n# check_model(m) can't do overall diagnostics, have to do them on individual model equations"
  },
  {
    "objectID": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#explore-specific-question",
    "href": "analysis/SGC3A/4_sgc3A_ospan_hypotesting.html#explore-specific-question",
    "title": "9  SGC3 (OSPAN) Hypothesis Testing",
    "section": "EXPLORE specific question",
    "text": "EXPLORE specific question\n\n\nCODE\ndf <- df_items %>% filter(q==10)\ngrouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, grouping.var = ospan_split)"
  },
  {
    "objectID": "analysis/SGC3B/1_sgc3B_introduction.html",
    "href": "analysis/SGC3B/1_sgc3B_introduction.html",
    "title": "10  Introduction",
    "section": "",
    "text": "TODO UPDATE ALL\nIn Study 3B we compare the efficacy of the explicit [interaction] scaffold and the implicit [impasse] scaffold."
  },
  {
    "objectID": "analysis/SGC3B/1_sgc3B_introduction.html#methods",
    "href": "analysis/SGC3B/1_sgc3B_introduction.html#methods",
    "title": "10  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Scaffold: control,impasse)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 17.1. The list of questions can be found here.\n\n\n\nFigure 10.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\nThe green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line. We hypothesize that this presents the reader with an obstacle, at which point they are forced to confront their interpretation of the coordinate system and (ideally) develop a new strategy.\n\n\n\nFigure 10.2: Sample Question (Q=1) graphs for each condition\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items.\n(3B) The first five items in the task are defined as the SCAFFOLDING block. In the IMPASSE condition, the first five questions included an IMPASSE problem state. For participants in the CONTROL condition, the dataset was structure such that there was always an available ‘orthogonal answer’ for the first 5 questions.\n(3B) The remaining 10 items are defined as the TESTING block. In both conditions, these questions were not structured as impasse (i.e. contained an available orthogonal answer)\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData was collected by convenience sample of a university subject pool. Initial data (Fall 2017, Spring 2018) were collected in-person, with large groups of students simultaneously completing the study (independently) in a computer lab. In Fall 2021 and Winter 2022 we collected additional data to replicate results in a remote format (students completing the study asynchronously on their own computers)."
  },
  {
    "objectID": "analysis/SGC3B/1_sgc3B_introduction.html#analysis",
    "href": "analysis/SGC3B/1_sgc3B_introduction.html#analysis",
    "title": "10  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\nBefore analysis, data files from individual data collection periods are harmonized into a common data format.\n\n\n\n\n\n\n\nPre-Requisite\nFollowed By\n\n\n\n\nspring17_clean_data.Rmd  spring18_clean_data.Rmd  fall21_clean_data.Rmd  winter2022_clean_sgc3b.Rmd\n2_sgc3B_scoring.qmd\n\n\n\nData for study SGC_3B were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n\n\nPeriod\nModality\n\n\n\n\nFall 2017\nin person, SONA groups in computer lab\n\n\nSpring 2018\nin person, SONA groups in computer lab\n\n\nFall 2021\nasynchronous, online, SONA\n\n\nSummer 2022\nasynchronous, online, SONA\n\n\n\nData collected in Fall 2017, Spring 2018 constitute the original SGC_3B study, conducted in person. Data collected in Fall 2021 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application.\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3B/data/0-session-level/fall17_sgc3b_participants.csv\"\nspring18 <- \"analysis/SGC3B/data/0-session-level/spring18_sgc3b_participants.csv\"\nfall21 <- \"analysis/SGC3B/data/0-session-level/fall21_sgc3b_participants.csv\"\nsummer22 <- \"analysis/SGC3B/data/0-session-level/su22_sgc3b_participants.rds\"\n\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_subjects_summer22 <- read_rds(summer22) %>% mutate(mode = \"asynch\", term = \"summer22\")\n\n\n#SAVE METADATA FROM SGC3A, but no rows \ndf_subjects <- df_subjects_summer22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#COMPARE COLS\n# janitor::compare_df_cols(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21,meta)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_summer22 <- df_subjects_summer22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_before, df_subjects_summer22) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_condition = recode_factor(condition, \n                                     \"111\" = \"none-control\", \"121\" =  \"none-impasse\",\n                                     \"211\" = \"img-control\", \"221\" =  \"img-impasse\",\n                                     \"311\" = \"ixv-control\", \"321\" =  \"ixv-impasse\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\",\"su22\", \"summer22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_before, df_subjects_summer22)\nrm(fall17,fall21,spring18,summer22)\n\n\n\n\n## TO EVEN COLUMNS, DROP FA21 DATA FOR 111 AND 112 [the sgc3a online replication study]\ndf_subjects <- df_subjects %>% filter(\n  !(condition %in% c(111,121) & term == \"fall21\")\n)\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC3B/data/0-session-level/fall17_sgc3b_blocks.csv\"\nspring18 <- \"analysis/SGC3B/data/0-session-level/spring18_sgc3b_blocks.csv\"\nfall21 <- \"analysis/SGC3B/data/0-session-level/fall21_sgc3b_blocks.csv\"\nsummer22 <- \"analysis/SGC3B/data/0-session-level/su22_sgc3b_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read_csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_items_summer22 <- read_rds(summer22) %>%  mutate(mode = \"asynch\", term = \"summer21\")#use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_summer22 %>% group_by(q) %>% dplyr::select(q,relation) %>% unique()\n\n#SAVE METADATA FROM SUMMER, but no rows \ndf_items <- df_items_summer22 %>% filter(condition=='X') %>% dplyr::select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n\n#COMPARE COLS\njanitor::compare_df_cols(df_items_before, df_items)\n\n\n  column_name df_items_before  df_items\n1      answer       character character\n2   condition         numeric character\n3     correct         logical    factor\n4        mode       character character\n5           q         numeric    factor\n6    question       character character\n7        rt_s         numeric   numeric\n8     subject       character character\n9        term       character character\n\n\nCODE\n#reduce data collected using new webapp\ndf_items_summer22 <- df_items_summer22 %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_before, df_items_summer22) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% dplyr::select(-question,-correct,-rt_s,-num_o)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n  question = \"Please describe how to determine what event(s) start at 12pm?\",\n  response = as.character(response) #doesn't need to be factor\n)\n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#add back pretty condition \ndf_items <- df_items %>% mutate(\n  pretty_condition = recode_factor(condition, \n                                     \"111\" = \"none-control\", \"121\" =  \"none-impasse\",\n                                     \"211\" = \"img-control\", \"221\" =  \"img-impasse\",\n                                     \"311\" = \"ixv-control\", \"321\" =  \"ixv-impasse\"),\n  pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_before, df_items_summer22)\nrm(fall17,fall21,spring18,summer22, map_relations)\n\n##ONLY INCLUDE ITEMS FOR INCLUDED SUBJECTS\n##SEE CONDITION LEVELLING IN PARTICIPANTS BLOCK\ndf_items <- df_items %>% filter(subject %in% df_subjects$subject)\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC3B/data/1-study-level/sgc3b_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC3B/data/1-study-level/sgc3b_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC3B/data/1-study-level/sgc3b_freeresponse.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC3B/data/1-study-level/sgc3b_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC3B/data/1-study-level/sgc3b_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC3B/1_sgc3B_introduction.html#resources",
    "href": "analysis/SGC3B/1_sgc3B_introduction.html#resources",
    "title": "10  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9     \n [5] purrr_0.3.4      readr_2.1.2      tidyr_1.2.0      tibble_3.1.7    \n [9] ggplot2_3.3.6    tidyverse_1.3.1  codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.3        bit64_4.0.5       vroom_1.5.7       jsonlite_1.8.0   \n [5] viridisLite_0.4.0 modelr_0.1.8      assertthat_0.2.1  highr_0.9        \n [9] cellranger_1.1.0  yaml_2.3.5        pillar_1.7.0      backports_1.4.1  \n[13] glue_1.6.2        digest_0.6.29     rvest_1.0.2       snakecase_0.11.0 \n[17] colorspace_2.0-3  htmltools_0.5.2   pkgconfig_2.0.3   broom_0.8.0      \n[21] labelled_2.9.1    haven_2.5.0       scales_1.2.0      webshot_0.5.3    \n[25] svglite_2.1.0     openxlsx_4.2.5    rio_0.5.29        tzdb_0.3.0       \n[29] generics_0.1.2    ellipsis_0.3.2    withr_2.5.0       janitor_2.1.0    \n[33] cli_3.3.0         magrittr_2.0.3    crayon_1.5.1      readxl_1.4.0     \n[37] evaluate_0.15     fs_1.5.2          fansi_1.0.3       xml2_1.3.3       \n[41] foreign_0.8-82    tools_4.2.1       data.table_1.14.2 hms_1.1.1        \n[45] lifecycle_1.0.1   munsell_0.5.0     reprex_2.0.1      zip_2.2.0        \n[49] compiler_4.2.1    systemfonts_1.0.4 rlang_1.0.3       grid_4.2.1       \n[53] rstudioapi_0.13   htmlwidgets_1.5.4 rmarkdown_2.14    gtable_0.3.0     \n[57] DBI_1.1.3         curl_4.3.2        R6_2.5.1          lubridate_1.8.0  \n[61] knitr_1.39        fastmap_1.1.0     bit_4.0.4         utf8_1.2.2       \n[65] stringi_1.7.6     parallel_4.2.1    Rcpp_1.0.8.3      vctrs_0.4.1      \n[69] dbplyr_2.2.1      tidyselect_1.1.2  xfun_0.31"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html",
    "title": "11  Response Scoring",
    "section": "",
    "text": "TODO\nThe purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC3B study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#score-sgc-data",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#score-sgc-data",
    "title": "11  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_both <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_both\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC3B/data/1-study-level/sgc3b_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC3B/data/1-study-level/sgc3b_items.rds')\n\n#ADD TEMP IMPASSE COLUMN\ndf_items <- df_items %>% mutate(\n  IMPASSE = substr(condition,2,2),\n  IMPASSE = recode_factor(IMPASSE, \"1\"=\"none\", \"2\"=\"IMPASSE\")\n)\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#TROUBLESHOOTING\n# backup <- df_items\n# df_items <- backup %>% sample_n(20)\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tri))\n\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_BOTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_both))\n\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\n\n#OLD score_BOTH... new one is above (explicitly in key)\n# df_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items #%>% head(16) %>% tail(1)\ntemp <- derive_interpretation(temp)\n\n\n[1] \"DERIVING INTERPRETATION\"\n\n\nCODE\ndf_items <- temp\n\n\n\n\n? SPECIAL EXCEPTIONS\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nALSO reconciles issues when interpetation == triangular but scoreniceabs = 0 ::: {.cell}\n\nCODE\n# #temp setup for protection\n# backup <- df_items\ntemp <- df_items %>% mutate(\n  override = \"\"\n)\n\n## CONTROL. Q==1. \"FK\" derives as 'TRI', should be tversky start\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==1) & (IMPASSE ==\"none\") & (response == \"FK\"),\n  tv_type = \"score_TV_start\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"TRI\"\n)\n\n## IMPASS Q==2. \"EK\" derives as 'TRI', should be tversky MAX\ntemp <- temp %>% mutate_when(\n  (q==2) & (IMPASSE ==\"IMPASSE\") & (response == \"EK\"),\n  tv_type = \"score_TV_max\",\n  int2 = \"Tversky\", #override from TRI\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n## CONTROL. Q==3. \"A\" derives as 'unknown', should be tversky duration\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"A\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n\n## CONTROL  Q==3 \"AF\" derives as TRI. hardcode as \"both\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"AF\"),\n  int2 = \"both tri + orth\", #override from TRI\n  interpretation = \"both tri + orth\", #override from TRI\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## CONTROL  Q==3 \"EFK\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"EFK\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL  Q==3 \"FG\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"FG\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASS  Q==3 \"AF\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE  Q==3 \"AFG\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE  Q==3 \"AH\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AH\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n## IMPASSE  Q==3 \"AO\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE  Q==3 \"AOU\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AOU\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## CONTROL Q==4 AH Derives as TRI RECODE as TVERSKY\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response %in% c(\"AH\",\"HK\")),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 HJ DERIVES as TRI Recode as ?\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"HJ\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 DEU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 DEOU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEOU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 KU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"KU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## IMPASSE Q==4 BD Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BD\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 BDEG Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BDEG\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 AFG Derives as SATISFICE RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from Satisfice\n  interpretation = \"?\", #override from Satisfice\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE Q==4 DH Derives as TRI RECODE as BOTH\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"DH\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AU Derives as TRI RECODE as satisfice\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AU\"),\n  int2 = \"Satisfice\", #override from Triangular\n  interpretation = \"Satisfice\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AZ Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AZ\"),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AFG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n\n## IMPASSE Q==5 AF Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5  Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"FO\",\"JO\") ),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 FO, HO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"HO\",\"FO\",\"DJO\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 KO Derives as TRI RECODE as tversky_duration\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response == \"KO\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n##  Q==7 HOX, OX Derives as TRI but incorrect\n#includes H which is at rather than under 5 hours.\n#give credit \ntemp <- temp %>% mutate_when(\n  (q==7)  & (response %in% c(\"HOX\", \"OX\")),\n  score_niceABS = 1\n)\n\n##  Q==7 AX, MO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MO\",\"AX\",\"FJOX\")) ,\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==7 MOX, MX  Derives as TRI RECODE as tversky\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MOX\", \"MX\", \"DX\",\"O\",\"X\",\"JX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8) & (response %in% c(\"CFGO\",\"BFG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AGK Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AGK\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 FG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response %in% c(\"FG\",\"CG\",\"CFG\",\"CGM\",\"CM\",\"ACGP\",\"GM\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==11 M Derives as TRI MISSING RESPONSE\n##LEAVE AS TRI + OVERRIDE SCORENABS\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"M\",\"L\") ),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==11 BLM Derives as TRI set at both\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response == \"BLM\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at ORTH\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"AGM\")),\n  int2 = \"Orthogonal\",\n  interpretation = \"Orthogonal\", \n  high_interpretation = \"orthogonal\", \n  override = \"Triangular\"\n)\n##  Q==11 EKM Derives as TRI set at other\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"EKM\",\"JM\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at Angular\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"KL\",\"MOX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==12 Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==12)  & (response %in% c(\"GP\", \"EG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 E Derives as TRI but incorrect\n##LEAVE AS TRI + OVERRIDE SCORENABS\n##one of two correct answers\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response == \"E\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==13 CE Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"CE\",\"EH\")),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 EO Derives as TRI set at ?\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"EO\")),\n  int2 = \"?\", \n  interpretation = \"?\", \n  high_interpretation = \"neg.trans\", \n  override = \"Triangular\"\n)\n\n##  Q==14  Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response %in% c(\"FX\",\"CX\",\"EFX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 OX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"OX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 EX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"EX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 CX Derives as TRI but incorrect \n#within visual margin... give credit\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"CX\",\"KO\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n#  Q==15  Derives as TRI but incorrect \n#missing 1 right answer or within 0.5hr visual error \ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"X\",\"CK\",\"K\",\"GKX\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==15 DJNX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"DJNX\", \"OX\", \"AK\",\"DNX\")),\n  # tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 AKPX Derives as TRI set at OTHER\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"AKPX\",\"GK\",\"JX\",\"LX\",\"BK\",\"HK\",\"HNX\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n#SET BACK\ndf_items <- temp\n\n:::\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#summarize-by-subject",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#summarize-by-subject",
    "title": "11  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC3B/data/1-study-level/sgc3b_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#explore-distributions",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#explore-distributions",
    "title": "11  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_wrap(~pretty_condition)+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE TEST PHASE\ngf_props(~item_test_NABS, fill = ~pretty_condition, \n             data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Absolute Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE TEST PHASE\ngf_histogram(~item_test_SCALED, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Scaled Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Scaled Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\nggbarstats( data = df, x = score_STATE, y = pretty_condition)\n\n\n\n\n\nCODE\nggbarstats( data = df, x = high_interpretation, y = pretty_condition)\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ndf_scaled_progress <- df_scaled_progress %>% \n  mutate(\n    implicit = recode_factor(pretty_condition,\n                            \"none-control\"=\"none\",\n                            \"none-impasse\"=\"impasse\",\n                            \"img-control\"=\"none\",\n                            \"img-impasse\"=\"impasse\",\n                            \"ixv-control\"=\"none\",\n                            \"ixv-impasse\"=\"impasse\"),\n    explicit = recode_factor(pretty_condition,\n                            \"none-control\"=\"none\",\n                            \"none-impasse\"=\"none\",\n                            \"img-control\"=\"img\",\n                            \"img-impasse\"=\"img\",\n                            \"ixv-control\"=\"ixv\",\n                            \"ixv-impasse\"=\"ixv\")\n  )\n\n\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_grid(explicit~implicit) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"Impasse shifts density toward higher Triagular scores\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#explore-responses",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#explore-responses",
    "title": "11  Response Scoring",
    "section": "EXPLORE RESPONSES",
    "text": "EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n\nCODE\ngf_props(~ score_niceABS, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Item Absolute Score\", title = \"Distribution of Accuracy  | ALL ITEMS \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | ALL ITEMS \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nSCAFFOLD PHASE\nThe first five questions constitute the ‘scaffold’ (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\nQuestion #1\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ1. Control Condition\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\n\n\n\nFigure 11.1: Question 1 — Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Control Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    A \n    OI \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    CF \n    Z \n  \n  \n    Tversky [start diagonal] \n    F \n    Z \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nHere we summarize the distinct response options given by participants on this item. Each letter in response indicates a checkbox selected by the participant (See Figure 17.1 ). n indicates the number of participants who gave this response, while interpretation indicates the graph interpretation most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\nNotice that for this Question, the Triangular answer is the same as the Tversky [start diagonal] answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 2) %>% \n  # pack_rows(\"Orthogonal\", 3, 3) %>% \n  # pack_rows(\"Other\", 4, 4)  %>% \n  # pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    10 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    CF \n    1 \n    Tversky \n    0 \n    0.923 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    A \n    50 \n    Orthogonal \n    0 \n    -0.077 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AF \n    1 \n    both tri + orth \n    0 \n    0.923 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as ? .\n\n\n\n\n\n\n\nWhich shifts start at 11am?\n\n\n\n\n\n\nResponse: A\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, projecting an invisible orthogonal line upward, and locating data point A.\n\n\n\n\nResponse: F\n\nindicates the triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point F.\n\n\n\n\nResponse: C, F\n\nindicates a maximal-Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following both the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C.\n\n\n\n\nResponse: A , F\n\nThe reader selects both triangular and orthogonal-consistent data points\nPossibly indicates uncertainty or confusion\n\n\n\n\nThree responses were given that were not consistent with any of the identified interpretations. Note that options highlighted in light grey are considered within the range of ‘visual error’, defined by 0.5hr offset from the interpretation-specific projection.\n\n\n\n\n\n\n\n\nD I J\nX\nZ\n[found this subject F86ZM, thought maybe this was a missed ‘F’, but they have a series of other unknown answers]\n\n\n\n\n\n\n\n\n\n\n\n\nQ1. Impasse Condition\n\n\n\nFigure 11.2: Question 1 — Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Impasse Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    O \n     \n  \n  \n    Satisficing [right] \n    AI \n     \n  \n  \n    Tversky [maximal] \n    CF \n     \n  \n  \n    Tversky [start diagonal] \n    F \n     \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nNotice that there is no orthogonal answer for this question. This is the purpose of the impasse condition, to remove the possibility of selecting the orthogonal answer, we expect learners will be more likely to restructure their understanding of the coordinate system, and arrive at a correct (triangular) interpretation.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 4) %>% \n  # pack_rows(\"Satisfice\", 5, 9) %>% \n  # pack_rows(\"Other\", 10, 10) %>% \n  # pack_rows(\"Unknown\", 11, 12) %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    19 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.071 \n    NA \n    1.0 \n  \n  \n    CF \n    6 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    -0.143 \n    NA \n    0.5 \n  \n  \n    C \n    1 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    -0.071 \n    NA \n    0.5 \n  \n  \n    O \n    14 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    AI \n    3 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    A \n    1 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    AO \n    1 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    0.929 \n    NA \n    -1.0 \n  \n  \n    I \n    1 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n     \n    18 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nWe see that nearly all of the subjects selected a response consistent with one of the identified interpretations. Responses that do not accord with any interpretation are indicated as ? .\nTODO ADJUST ‘both’ to select for both tri/satisfice or both tri/orth\n\n\n\n\n\n\n\nWhich shifts start at 11am?\n\n\n\n\n\n\nResponse: F\n\nindicates the triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following the right-diagonal gridline, identifying data point F.\n\n\n\n\nResponse: [C, F]\n\nindicates a maximal-Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (11am) on the x-axis, and following both the right-diagonal and left-diagonal gridlines, identifying both datapoints F and C gridline.\n\n\n\n\nResponses: [AOI]\n\nindicates a satisficing strategy\nConsistent with the reader identifying the datapoints nearest to the orthogonal projection from the reference point point\n\n\n\n\nTwo responses were given that were not consistent with any of the identified interpretations.\n\n\n\n\n\n\n[E],[X]\n\n\n\n\n\n\n\n\n\n\n\nQuestion #2\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ2. Control Condition\n\n\n\nFigure 11.3: Q2—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==2)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n    E \n    G \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AKJX \n    Z \n  \n  \n    Tversky [start diagonal] \n    AK \n    Z \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 4) %>% \n  # pack_rows(\"Orthogonal\", 5, 7) %>%\n  # pack_rows(\"Other\", 8, 8)  %>% \n  # pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    10 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    DK \n    1 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    AK \n    1 \n    Tversky \n    0 \n    0.917 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    E \n    45 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DE \n    2 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EG \n    1 \n    Orthogonal \n    0 \n    -0.167 \n    -0.154 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    D \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\nWhich shift(s) start at the same time as D?\n\n\n\n\nReponse: E (also EG, DE)\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (D) on the graph, projecting an invisible orthogonal line through it, and locating data point E.\n\n\n\n\nResponse: K (also KD)\n\nindicates an triangular (correct) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (D) on the graph, and following its descending-leftward diagonal gridline, and locating data point K.\n\n\n\n\nResponse: AK\n\nindicates an Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (D) on the graph, and following its descending-leftward diagonal gridline, and locating data point K then continuing along the connecting ascending leftward diagonal locating data point A.\n\n\n\n\nResponse: J\n\nindicates an Tversky strategy following connecting lines\nConsistent with the reader identifying the reference point (D) on the graph, and following its horizontal gridline to the y-axis, locating data point J.\n\n\n\n\nResponse: D\n\nthe reader selected only the reference point\nConsistent with the reader identifying the reference point (D) on the graph\nPossibly indicates uncertainty or confusion\n\n\n\n\n\n\n\n\n\n\n\nB\nC\n\n\n\n\n\n\n\n\n\n\n\nQ2. Impasse Condition\n\n\n\nFigure 11.4: Q2—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==2)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Impasse Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n    G \n     \n  \n  \n    Tversky [maximal] \n    JKEX \n    Z \n  \n  \n    Tversky [start diagonal] \n    K \n    Z \n  \n  \n    Tversky [end diagonal] \n    EX \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 10) %>% \n  # pack_rows(\"Satisfice\", 11, 12) %>%\n  # pack_rows(\"Other\", 13, 16)  %>% \n  # pack_rows(\"Unknown\", 17, 18)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    31 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    DK \n    1 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    EX \n    2 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    J \n    2 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    E \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    EK \n    1 \n    Tversky \n    0 \n    0.917 \n    0.917 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    EKX \n    1 \n    Tversky \n    0 \n    0.833 \n    0.917 \n    -0.231 \n    NA \n    0.5 \n  \n  \n    JK \n    1 \n    Tversky \n    0 \n    0.917 \n    0.923 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    G \n    5 \n    Satisfice \n    0 \n    -0.083 \n    -0.077 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    BG \n    1 \n    Satisfice \n    0 \n    -0.167 \n    -0.154 \n    0.923 \n    NA \n    -1.0 \n  \n  \n    D \n    5 \n    reference \n    0 \n    0.000 \n    NA \n    0.000 \n    NA \n    0.0 \n  \n  \n     \n    10 \n    blank \n    0 \n    0.000 \n    NA \n    0.000 \n    NA \n    0.0 \n  \n  \n    ACDFHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.250 \n    0.250 \n    -0.846 \n    NA \n    -0.5 \n  \n  \n    BEGKUZ \n    1 \n    frenzy \n    0 \n    0.667 \n    0.667 \n    0.615 \n    NA \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.167 \n    -0.154 \n    -0.154 \n    NA \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\n\nQuestion #3\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ3. Control Condition\n\n\n\nFigure 11.5: Q3—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==3)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Control Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    Z \n    FIO \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AUBFOJ \n     \n  \n  \n    Tversky [start diagonal] \n    OJ \n     \n  \n  \n    Tversky [end diagonal] \n    F \n    Z \n  \n  \n    Tversky [duration line] \n    AUB \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    12 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    0.0 \n    1.0 \n  \n  \n    A \n    5 \n    Tversky \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    DJO \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.917 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    Z \n    40 \n    Orthogonal \n    0 \n    0.000 \n    0.000 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    EFK \n    1 \n    ? \n    0 \n    0.833 \n    0.833 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    EU \n    1 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 17)  \n\n\nTODO\n\naddress RESPONSE FKE which is classified as Triangular but doesn’t seem to fit this interpretation?\nShould O,K be considered Tvresky ?\nconsider adding trapdoor on n_q, such that score is penalized (OR interpretation is not predicted?) if the Ss selects more than 1 extra options, or is missing more than 2 options?\nLEFT OFF HERE\n\n\n\n\n\n\n\n\nWhat shift(s) begin when C ends?\n\n\n\n\n\n\nResponse: Z\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\nConsistent with the reader identifying the reference point (C) then using the duration encoded on the y-axis (2) , project along the horizontal gridline by two hours, and then project an invisible orthogonal line through that time (12PM) locating data point Z.\n\n\n\n\nResponse: F\n\nindicates a (correct) triangular interpretation of the coordinate system\nConsistent with the reader identifying the reference point (C) on the graph, and following the descending gridline to the x-axis to identify the end-time (11AM) and then following the ascending gridline to identify datapoints starting at 11AM and locating data point F.\n\n\n\n\nResponse: AUB (also A)\n\nindicates a Tversky strategy following connecting lines (duration)\nConsistent with the reader identifying the reference point (C) on the graph, and following the horizontal y-axis gridline and locating data points A U B.\n\n\n\n\nResponse: OJ\n\nindicates a Tversky strategy following connecting lines (start-time)\nConsistent with the reader identifying the reference point (C) on the graph, and following the ascending diagonal gridline and locating data points O J.\n\n\n\n\nResponse: C\n\nthe participant selected the point referenced in the question\npossibly indicates confusion or uncertainty\n\n\n\n\nResponse: AIOZFHJXKUDEGB\n\nthe participant selects all (or nearly all) the data points\npossibly indicates confusion or uncertainty\n\n\n\n\nSix responses (from 9 participants) appear inconsistent with any interpretation.\n\n\n\n\n\n\n\n\nK (n=3)\nAH (n=1)\nDE (n=1)\n\n\n\n\n\n\n\n\n\nUE (n=1)\nU (n=1)\nE (n=1)\n\n\n\n\n\n\n\n\n\n\nQ3. Impasse Condition\n\n\n\nFigure 11.6: Q3—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==3)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Impasse Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    AI \n     \n  \n  \n    Satisficing [right] \n    F \n     \n  \n  \n    Tversky [maximal] \n    BJ \n     \n  \n  \n    Tversky [start diagonal] \n    J \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    B \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nTODO investigate these responses 17 at O?\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    26 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    1.000 \n    NA \n    1.0 \n  \n  \n    AOU \n    3 \n    Tversky \n    0 \n    -0.231 \n    -0.231 \n    0.333 \n    NA \n    0.5 \n  \n  \n    AF \n    2 \n    Tversky \n    0 \n    0.923 \n    -0.154 \n    0.923 \n    NA \n    0.5 \n  \n  \n    AH \n    2 \n    Tversky \n    0 \n    -0.154 \n    -0.154 \n    0.417 \n    NA \n    0.5 \n  \n  \n    B \n    2 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    AO \n    1 \n    Tversky \n    0 \n    -0.154 \n    -0.154 \n    0.417 \n    NA \n    0.5 \n  \n  \n    BE \n    1 \n    Tversky \n    0 \n    -0.154 \n    0.923 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    J \n    1 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    A \n    3 \n    Satisfice \n    0 \n    -0.077 \n    -0.077 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    AFI \n    2 \n    Satisfice \n    0 \n    0.846 \n    -0.231 \n    0.917 \n    NA \n    -1.0 \n  \n  \n    AI \n    2 \n    Satisfice \n    0 \n    -0.154 \n    -0.154 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    AIO \n    1 \n    Satisfice \n    0 \n    -0.231 \n    -0.231 \n    0.917 \n    NA \n    -1.0 \n  \n  \n     \n    8 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n    ABDEFGHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    -0.5 \n  \n  \n    BDEFGHJKUXZ \n    1 \n    frenzy \n    0 \n    0.231 \n    0.250 \n    0.231 \n    NA \n    -0.5 \n  \n  \n    O \n    6 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.154 \n    -0.154 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    U \n    1 \n    ? \n    0 \n    -0.077 \n    -0.077 \n    -0.077 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>% \n#   pack_rows(\"Lines-Connect\", 3, 5) %>% \n#   pack_rows(\"Satisfice\", 6, 15) %>% \n#   pack_rows(\"Other\", 16, 21) %>% \n#   pack_rows(\"Unknown\", 22, 29) \n\n\n\n\n\nQuestion #4\n[PLACEHOLDER — NOT YET CONSIDERED THIS QUESTION]\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ4. Control Condition\n\n\n\nFigure 11.7: Q4—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==4)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n    U \n    OF \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    13 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    AH \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    B \n    1 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    U \n    37 \n    Orthogonal \n    0 \n    -0.071 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    1 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    E \n    4 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DE \n    2 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    DEOU \n    1 \n    ? \n    0 \n    -0.286 \n    -0.286 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 3) %>% \n#   pack_rows(\"Orthogonal\", 4, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 16) \n\n\n\nTBL4 test\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n |\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\nQ4. Impasse Condition\n\n\n\nFigure 11.8: Q4—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==4)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Impasse Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    FO \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nTODO investigate D? add to tversky or orth?\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Impasse Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Impasse Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    28 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    B \n    1 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    BH \n    1 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    O \n    4 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    FO \n    3 \n    Satisfice \n    0 \n    -0.143 \n    -0.143 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    F \n    2 \n    Satisfice \n    0 \n    -0.071 \n    -0.071 \n    0.500 \n    NA \n    -1.0 \n  \n  \n    DH \n    1 \n    both tri + orth \n    0 \n    0.929 \n    0.929 \n    -0.154 \n    NA \n    0.5 \n  \n  \n     \n    6 \n    blank \n    0 \n    0.000 \n    0.000 \n    0.000 \n    NA \n    0.0 \n  \n  \n    D \n    10 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    A \n    3 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    -0.077 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 6) %>% \n#   pack_rows(\"Satisfice\", 7, 10) %>% \n#   pack_rows(\"Other\", 11, 12) %>% \n#   pack_rows(\"Unknown\", 13, 19) \n\n\n\n\n\nQuestion #5\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nQ5. Control Condition\n\n\n\nFigure 11.9: Q5—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==5)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    O \n    AZ \n  \n  \n    Orthgonal \n    U \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    UGX \n    AZKD \n  \n  \n    Tversky [start diagonal] \n    X \n     \n  \n  \n    Tversky [end diagonal] \n    UG \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    O \n    17 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    U \n    33 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    HU \n    1 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    I \n    1 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DEHJ \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>% \n#   pack_rows(\"Lines-Connect\", 5, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 9) %>% \n#   pack_rows(\"Other\", 10, 11) %>% \n#   pack_rows(\"Unknown\", 12, 22) \n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\nQ5. Impasse Condition\n\n\n\nFigure 11.10: Q5—Impasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"impasse\") %>% filter(Q==5)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Impasse Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Impasse Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    A \n     \n  \n  \n    Orthgonal \n     \n     \n  \n  \n    Satisficing [left] \n    FUZ \n     \n  \n  \n    Satisficing [right] \n    H \n     \n  \n  \n    Tversky [maximal] \n    OX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & condition == 121) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    A \n    31 \n    Triangular \n    1 \n    1.000 \n    -0.083 \n    -0.077 \n    NA \n    1.0 \n  \n  \n    AF \n    4 \n    Tversky \n    0 \n    0.923 \n    -0.167 \n    0.242 \n    NA \n    0.5 \n  \n  \n    O \n    3 \n    Tversky \n    0 \n    -0.077 \n    0.500 \n    -0.077 \n    NA \n    0.5 \n  \n  \n    AO \n    1 \n    Tversky \n    0 \n    0.923 \n    0.417 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    OX \n    1 \n    Tversky \n    0 \n    -0.154 \n    1.000 \n    -0.154 \n    NA \n    0.5 \n  \n  \n    H \n    6 \n    Satisfice \n    0 \n    -0.077 \n    -0.083 \n    1.000 \n    NA \n    -1.0 \n  \n  \n    FHZ \n    1 \n    Satisfice \n    0 \n    -0.231 \n    -0.250 \n    0.846 \n    NA \n    -1.0 \n  \n  \n    FU \n    1 \n    Satisfice \n    0 \n    -0.154 \n    -0.167 \n    0.667 \n    NA \n    -1.0 \n  \n  \n    HK \n    1 \n    Satisfice \n    0 \n    -0.154 \n    -0.167 \n    0.923 \n    NA \n    -1.0 \n  \n  \n    HKUZ \n    1 \n    Satisfice \n    0 \n    -0.308 \n    -0.333 \n    0.769 \n    NA \n    -1.0 \n  \n  \n    I \n    1 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n     \n    4 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    NA \n    0.0 \n  \n  \n    ABCFGUZ \n    1 \n    frenzy \n    0 \n    0.538 \n    -0.583 \n    0.636 \n    NA \n    -0.5 \n  \n  \n    FHJKX \n    1 \n    frenzy \n    0 \n    -0.385 \n    0.167 \n    0.692 \n    NA \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    -0.077 \n    NA \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    0.333 \n    NA \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.154 \n    -0.167 \n    -0.154 \n    NA \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.077 \n    -0.083 \n    -0.077 \n    NA \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 7) %>% \n#   pack_rows(\"Lines-Connect\", 8, 13) %>% \n#   pack_rows(\"Orthogonal\", 14, 16) %>% \n#   pack_rows(\"Other\", 17, 21) %>% \n#   pack_rows(\"Unknown\", 22, 31) \n\n\n\n\n\n\nTESTING PHASE\nThe following 10 questions were the same for both conditions.\n\nQuestion #7\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 11.11: Q7-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    OX \n     \n  \n  \n    Orthgonal \n    BF \n    M \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    IJZNCHOX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n    IJZN \n     \n  \n  \n    Tversky [duration line] \n    CH \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #7\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    OX \n    206 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    HOX \n    2 \n    Triangular \n    1 \n    0.938 \n    0.938 \n    NA \n    -0.200 \n    1.0 \n  \n  \n    CH \n    3 \n    Tversky \n    0 \n    -0.125 \n    1.000 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    IJ \n    2 \n    Tversky \n    0 \n    -0.125 \n    0.500 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    DX \n    1 \n    Tversky \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    JX \n    1 \n    Tversky \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    BF \n    131 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FZ \n    14 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BJ \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    F \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    FG \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    BDFIJNOXZ \n    1 \n    frenzy \n    0 \n    0.562 \n    0.643 \n    NA \n    0.533 \n    -0.5 \n  \n  \n    BDIJMNOX \n    1 \n    frenzy \n    0 \n    0.625 \n    0.625 \n    NA \n    0.100 \n    -0.5 \n  \n  \n    BIO \n    1 \n    ? \n    0 \n    0.375 \n    0.375 \n    NA \n    0.367 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    DN \n    1 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    KM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>%\n#   pack_rows(\"Lines-Connect\", 6, 9) %>%\n#   pack_rows(\"Orthogonal\", 10, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 17)\n\n\n\n\nQuestion #8\n\n\n\nFigure 11.12: Q8-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    E \n    F \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #8\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    187 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    AGK \n    5 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    AG \n    2 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    CFGO \n    2 \n    Tversky \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    CG \n    2 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    FG \n    2 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.071 \n    0.5 \n  \n  \n    CM \n    1 \n    Tversky \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    E \n    94 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EIJ \n    4 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EFIJ \n    3 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EF \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EFI \n    1 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EI \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EG \n    1 \n    both tri + orth \n    0 \n    0.933 \n    NA \n    NA \n    0.929 \n    0.5 \n  \n  \n     \n    9 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJNOZ \n    2 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    EFGIJ \n    2 \n    frenzy \n    0 \n    0.733 \n    NA \n    NA \n    0.786 \n    -0.5 \n  \n  \n    CDEFGHIJNOZ \n    1 \n    frenzy \n    0 \n    0.333 \n    NA \n    NA \n    0.357 \n    -0.5 \n  \n  \n    CDHIJNOZ \n    1 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    -0.571 \n    -0.5 \n  \n  \n    J \n    8 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    M \n    6 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    F \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    IJ \n    5 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    A \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    I \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    C \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AK \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    JM \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AJN \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    DHNZ \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DIJN \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DJN \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    EFGI \n    1 \n    ? \n    0 \n    0.800 \n    NA \n    NA \n    0.857 \n    -0.5 \n  \n  \n    IJM \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    JO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Orthogonal\", 11, 16) %>%\n#   pack_rows(\"Other\", 17, 21) %>%\n#   pack_rows(\"Unknown\", 22, 45)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #10\n\n\n\nFigure 11.13: Q10-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    E \n     \n  \n  \n    Orthgonal \n    X \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    EGZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n    E \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #10\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    E \n    250 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    EF \n    2 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    11 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    G \n    3 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    XZ \n    2 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n    BZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    X \n    71 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FX \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    2 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    B \n    12 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    5 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    M \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    BCO \n    1 \n    ? \n    0 \n    -0.188 \n    -0.188 \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    BIJM \n    1 \n    ? \n    0 \n    -0.250 \n    -0.250 \n    NA \n    -0.250 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>%\n#   pack_rows(\"Lines-Connect\", 3, 7) %>%\n#   pack_rows(\"Orthogonal\", 8, 11) %>%\n#   pack_rows(\"Other\", 12, 14) %>%\n#   pack_rows(\"Unknown\", 15, 27)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #11\n\n\n\nFigure 11.14: Q11-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at 12pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    ML \n     \n  \n  \n    Orthgonal \n    FB \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #11\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    LM \n    234 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.125 \n    1.0 \n  \n  \n    M \n    10 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    L \n    1 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    BF \n    115 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BGO \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    NA \n    NA \n    0.375 \n    -1.0 \n  \n  \n    BLM \n    2 \n    both tri + orth \n    0 \n    0.938 \n    NA \n    NA \n    0.375 \n    0.5 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACDGHKLMNOPXZ \n    1 \n    frenzy \n    0 \n    0.312 \n    NA \n    NA \n    -0.812 \n    -0.5 \n  \n  \n    DHLMNOXZ \n    1 \n    frenzy \n    0 \n    0.625 \n    NA \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    EKM \n    1 \n    ? \n    0 \n    0.375 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    0.438 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 9) %>%\n#   pack_rows(\"Other\", 10, 12) %>%\n#   pack_rows(\"Unknown\", 13, 17)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #12\n\n\n\nFigure 11.15: Q12-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    GZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #12\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    231 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    FG \n    13 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    GP \n    4 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    Z \n    3 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    B \n    113 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BCO \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    -0.188 \n    NA \n    0.875 \n    -1.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    E \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    LM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Lines-Connect\", 4, 6) %>%\n#   pack_rows(\"Orthogonal\", 7, 8) %>%\n#   pack_rows(\"Other\", 9, 10) %>%\n#   pack_rows(\"Unknown\", 11, 14)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #13\n\n\n\nFigure 11.16: Q13-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts end when Z begins?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EF \n     \n  \n  \n    Orthgonal \n    FX \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #13\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EF \n    235 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    0.433 \n    1.0 \n  \n  \n    E \n    1 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.067 \n    1.0 \n  \n  \n    FX \n    75 \n    Orthogonal \n    0 \n    0.433 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    X \n    4 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    CX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    KX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    OX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    BX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    GX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    HNX \n    1 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.367 \n    -1.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    HN \n    19 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HL \n    5 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    3 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HLP \n    3 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    BF \n    2 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    EX \n    2 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    AH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    AJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CGO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    DKM \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    EH \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HZ \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    JK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    LM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Orthogonal\", 4, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 36)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #14\n\n\n\nFigure 11.17: Q14-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at 3pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    X \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XJND \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    JND \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #14\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    X \n    259 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.059 \n    1.0 \n  \n  \n    FX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    OX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    B \n    73 \n    Orthogonal \n    0 \n    -0.059 \n    -0.059 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    6 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BGO \n    1 \n    Orthogonal \n    0 \n    -0.176 \n    -0.176 \n    NA \n    0.882 \n    -1.0 \n  \n  \n    BO \n    1 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BX \n    1 \n    both tri + orth \n    0 \n    0.941 \n    0.941 \n    NA \n    0.941 \n    0.5 \n  \n  \n     \n    9 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    O \n    7 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    D \n    2 \n    ? \n    0 \n    -0.059 \n    0.333 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    AH \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    HLP \n    1 \n    ? \n    0 \n    -0.176 \n    -0.176 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 7) %>%\n#   pack_rows(\"Other\", 8, 9) %>%\n#   pack_rows(\"Unknown\", 10, 22)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #15\n\n\n\nFigure 11.18: Q15-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Coffee breaks happen halfway through a shift. Which shifts share a break at 2pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    XK \n     \n  \n  \n    Orthgonal \n    EF \n    B \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XKZ \n     \n  \n  \n    Tversky [start diagonal] \n    Z \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #15\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    KX \n    240 \n    Triangular \n    1 \n    1.000 \n    0.667 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    CX \n    4 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    X \n    4 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    CK \n    2 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    GKX \n    1 \n    Triangular \n    1 \n    0.938 \n    0.600 \n    NA \n    -0.200 \n    1.0 \n  \n  \n    FZ \n    4 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    0.433 \n    0.5 \n  \n  \n    OX \n    2 \n    Tversky \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    DNX \n    1 \n    Tversky \n    0 \n    0.375 \n    0.200 \n    NA \n    -0.200 \n    0.5 \n  \n  \n    HZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    EF \n    62 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    12 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    4 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    E \n    3 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    CF \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EG \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EFZ \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    0.882 \n    NA \n    0.933 \n    -1.0 \n  \n  \n     \n    6 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    AG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    ACG \n    1 \n    ? \n    0 \n    -0.188 \n    -0.176 \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    BG \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    BM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    GM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HNX \n    1 \n    ? \n    0 \n    0.375 \n    0.200 \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    LM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Lines-Connect\", 11, 13) %>%\n#   pack_rows(\"Orthogonal\", 14, 22) %>%\n#   pack_rows(\"Other\", 23, 23) %>%\n#   pack_rows(\"Unknown\", 24, 44)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nNON-DISCRIMINANT QUESTIONS\n\nQuestion #6 NONDISCRIM\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 11.19: Q6-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) are six hours long?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EG \n     \n  \n  \n    Orthgonal \n    EG \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\nTODO discuss non discriminant\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #6\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EG \n    367 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n    C \n    2 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    CH \n    2 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    BDI \n    1 \n    ? \n    0 \n    -0.188 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    BE \n    1 \n    ? \n    0 \n    0.438 \n    NA \n    NA \n    0.438 \n    -0.5 \n  \n\n\n\n\n\n\n\nQuestion #9 NONDISCRIM\n\n\n\nFigure 11.20: Q9-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% select(\"REF_POINT\")\nanswers <- q %>% select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% select(\"OPTIONS\")\nquestion = q %>%  select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) begins before J begins and ends during B?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    I \n     \n  \n  \n    Orthgonal \n    I \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #9\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    I \n    244 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    20 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    E \n    79 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    9 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    EI \n    2 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    FI \n    2 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    G \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IJ \n    2 \n    ? \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    -0.5 \n  \n  \n    IM \n    2 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    BEI \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    EIJ \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Other\", 1, 2) %>%\n#   pack_rows(\"Unknown\", 3, 19)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#export",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#export",
    "title": "11  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\n\n\nCODE\ntable(df_subjects$mode, df_subjects$condition) %>% addmargins()\n\n\n           \n            111 121 211 221 311 321 Sum\n  lab-synch  62  64  45  30  59  30 290\n  asynch      0   0  17  32   3  31  83\n  Sum        62  64  62  62  62  61 373\n\n\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC3B/data/2-scored-data/sgc3b_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC3B/data/2-scored-data/sgc3b_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC3B/data/2-scored-data/sgc3b_absolute_progressL.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC3B/data/2-scored-data/sgc3b_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC3B/data/2-scored-data/sgc3b_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC3B/data/2-scored-data/sgc3b_scored_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#resources",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#resources",
    "title": "11  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\nset operations\nhttps://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html\nkableExtra tables\nhttps://haozhu233.github.io/kableExtra/awesome_table_in_html.html#grouped_columns__rows\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1          stringr_1.4.0          dplyr_1.0.9           \n [4] purrr_0.3.4            readr_2.1.2            tidyr_1.2.0           \n [7] tibble_3.1.7           tidyverse_1.3.1        tidyfst_1.6.5         \n[10] statsExpressions_1.3.2 ggstatsplot_0.9.3      Hmisc_4.7-0           \n[13] Formula_1.2-4          survival_3.3-1         lattice_0.20-45       \n[16] pbapply_1.5-0          ggformula_0.10.1       ggridges_0.5.3        \n[19] scales_1.2.0           ggstance_0.3.5         ggplot2_3.3.6         \n[22] kableExtra_1.3.4      \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.4.0           backports_1.4.1        systemfonts_1.0.4     \n  [4] plyr_1.8.7             splines_4.2.1          gmp_0.6-5             \n  [7] kSamples_1.2-9         TH.data_1.1-1          SuppDists_1.1-9.7     \n [10] digest_0.6.29          htmltools_0.5.2        fansi_1.0.3           \n [13] magrittr_2.0.3         checkmate_2.1.0        memoise_2.0.1         \n [16] paletteer_1.4.0        cluster_2.1.3          openxlsx_4.2.5        \n [19] tzdb_0.3.0             mosaicCore_0.9.0       modelr_0.1.8          \n [22] vroom_1.5.7            sandwich_3.0-2         svglite_2.1.0         \n [25] jpeg_0.1-9             colorspace_2.0-3       rvest_1.0.2           \n [28] ggrepel_0.9.1          haven_2.5.0            xfun_0.31             \n [31] crayon_1.5.1           prismatic_1.1.0        jsonlite_1.8.0        \n [34] zeallot_0.1.0          zoo_1.8-10             glue_1.6.2            \n [37] polyclip_1.10-0        gtable_0.3.0           emmeans_1.7.5         \n [40] webshot_0.5.3          MatrixModels_0.5-0     Rmpfr_0.8-9           \n [43] mvtnorm_1.1-3          DBI_1.1.3              PMCMRplus_1.9.5       \n [46] Rcpp_1.0.8.3           viridisLite_0.4.0      xtable_1.8-4          \n [49] performance_0.9.1      htmlTable_2.4.0        foreign_0.8-82        \n [52] bit_4.0.4              datawizard_0.4.1       htmlwidgets_1.5.4     \n [55] httr_1.4.3             fstcore_0.9.12         RColorBrewer_1.1-3    \n [58] ellipsis_0.3.2         pkgconfig_2.0.3        farver_2.1.0          \n [61] multcompView_0.1-8     nnet_7.3-17            dbplyr_2.2.1          \n [64] utf8_1.2.2             tidyselect_1.1.2       labeling_0.4.2        \n [67] rlang_1.0.3            effectsize_0.7.0       munsell_0.5.0         \n [70] cellranger_1.1.0       tools_4.2.1            cachem_1.0.6          \n [73] cli_3.3.0              generics_0.1.2         broom_0.8.0           \n [76] evaluate_0.15          fastmap_1.1.0          BWStest_0.2.2         \n [79] yaml_2.3.5             rematch2_2.1.2         knitr_1.39            \n [82] bit64_4.0.5            fs_1.5.2               zip_2.2.0             \n [85] xml2_1.3.3             correlation_0.8.1      compiler_4.2.1        \n [88] rstudioapi_0.13        curl_4.3.2             png_0.1-7             \n [91] ggsignif_0.6.3         reprex_2.0.1           tweenr_1.0.2          \n [94] stringi_1.7.6          highr_0.9              parameters_0.18.1     \n [97] Matrix_1.4-1           vctrs_0.4.1            pillar_1.7.0          \n[100] lifecycle_1.0.1        estimability_1.4       data.table_1.14.2     \n[103] insight_0.18.0         patchwork_1.1.1        R6_2.5.1              \n[106] latticeExtra_0.6-29    rio_0.5.29             gridExtra_2.3         \n[109] BayesFactor_0.9.12-4.4 codetools_0.2-18       boot_1.3-28           \n[112] MASS_7.3-57            assertthat_0.2.1       withr_2.5.0           \n[115] multcomp_1.4-19        bayestestR_0.12.1      parallel_4.2.1        \n[118] hms_1.1.1              fst_0.9.8              grid_4.2.1            \n[121] rpart_4.1.16           labelled_2.9.1         coda_0.19-4           \n[124] rmarkdown_2.14         ggforce_0.3.3          lubridate_1.8.0       \n[127] base64enc_0.1-3"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "",
    "text": "The purpose of this notebook is test the hypotheses that determined the design of the SGC3A study WITH OSPAN.\nTODO UPDATE Research Questions\nExperimental Hypothesis\nNull Hypothesis"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#sample",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#sample",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData was collected …\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\", \"Control+Img\", \"Impasse + Img\", \"Control + IXN\", \"Impasse + IXN\", \"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$pretty_condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Control+Img \n    Impasse + Img \n    Control + IXN \n    Impasse + IXN \n    Total for Period \n  \n \n\n  \n    fall17 \n    27 \n    27 \n    30 \n    30 \n    30 \n    30 \n    174 \n  \n  \n    spring18 \n    35 \n    37 \n    15 \n    0 \n    29 \n    0 \n    116 \n  \n  \n    fall21 \n    0 \n    0 \n    5 \n    12 \n    3 \n    11 \n    31 \n  \n  \n    Sum \n    62 \n    64 \n    50 \n    42 \n    62 \n    41 \n    321 \n  \n\n\n\n\n\nCODE\ntable(df_subjects$IMPLICIT, df_subjects$EXPLICIT)\n\n\n         \n          none img ixn\n  control   62  50  62\n  impasse   64  42  41\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.male <- ((df_subjects %>% filter(gender==\"Male\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.female <- ((df_subjects %>% filter(gender==\"Female\") %>% count())/count(df_subjects))$n\nsubject.stats$percent.other <- ((df_subjects %>% filter(gender %nin% c(\"Female\",\"Male\")) %>% count())/count(df_subjects))$n\n\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.male \n    percent.female \n    percent.other \n  \n \n\n  \n     \n    18 \n    19 \n    20 \n    21 \n    33 \n    20.3 \n    1.82 \n    321 \n    0 \n    0.386 \n    0.611 \n    0.003 \n  \n\n\nNote:   Age in Years\n\n\n\n\nOverall 321 participants (39 % male, 61 % female, 0 % other) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 33 years)."
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1a-overall-accuracy",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1a-overall-accuracy",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "H1A | OVERALL ACCURACY",
    "text": "H1A | OVERALL ACCURACY\n\n\n\n\n\n\n\nResearch Question\nDo Ss in the IMPASSE condition score higher across the entire task than those in the CONTROL group?\n\n\n\n\nHypothesis\n(H1) Participants in the IMPASSE condition will be more likely to correctly interpret the graph than those in the CONTROL condition.\n\n\nData\ndata: df_items where q nin 6,9 (the 13 discriminating Qs ), df_subjects\noutcome:\n\n[at item level] : accuracy ( factor(incorrect/correct) from score_niceABS [absolute score]\n[subject level]: accuracy (number of test phase qs correct from total s_NABS)\n\npredictor: condition [between-subjects factor]\n\n\nAnalysis Strategy\n\nWilcoxon-Rank Sum (Mann-Whitney) test on subject-level total accuracy of test phase (s_NABS)\nMixed Logistic Regression\naccuracy ~ condition + (1 | subject ) + (1 | question)\nmodel effect of condition on probability of correct response [during test phase] while accounting for subject (and item-level?) effects\n\n\n\nAlternatives\n\nOrdinal Mixed Logistic Regression on scaled_score\nOLS Linear Regression: bimodal distribution at tails makes the mean a poor predictor; LMs violate assumptions of normally distributed residuals; both absolute and scaled scores yield non-normal residuals; no transformation of the outcome variables yield normal residuals\n\n\n\nNotes\nAlso exploring:\n\nHurdle model (mixture model w/ binomial + [poisson or negbinom count; 0s from 1 DGP)\nZero Inflated model (mixture model w/ binomial + poisson or negbinom count; 0s from 2 DGPs)\nBeta regression hurdle model? (mixture with location and scale parameters [mean, variance] and hurdles for floor and ceiling effects)\nOther way to account for the severe bimodality?\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% \n  dplyr::select(pretty_condition, condition, accuracy, subject,q, IMPLICIT, EXPLICIT)\n\ndf_s <- df_subjects %>% \n  dplyr::select(pretty_condition, condition, task_percent, IMPLICIT, EXPLICIT)\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STACKED PROPORTIONAL BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = IMPLICIT,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  facet_grid(~EXPLICIT) + \n  scale_fill_brewer(palette = \"Set1\")  +\n   labs(title = \"Overall Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Impasse Condition yields a greater proportion of correct responses for HIGH WM\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART BY QUESTION\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~ q ) +\n   labs(title = \"Accuracy by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"Q6 and Q9 are non-discriminative\")\n\n\n\n\n\nCODE\n#:::::::: FACETED HISTOGRAM\nstats = df_s %>% group_by(IMPLICIT, EXPLICIT) %>% dplyr::summarise(mean = mean(task_percent))\ngf_props(~task_percent,\n         fill = ~pretty_condition, data = df_s) %>%\n  gf_facet_grid(IMPLICIT~EXPLICIT) %>%\n  gf_vline(data = stats, xintercept = ~mean, color = \"red\") +\n  labs(x = \"% Correct\",\n       y = \"proportion of subjects\",\n       title = \"Overall Absolute Score (% Correct)\",\n       subtitle = \"\") + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nCODE\n#TODO   \np <- grouped_ggbetweenstats(data = df_s,\n                       y = task_percent, x = IMPLICIT, grouping.var = EXPLICIT,\n               plot.type = \"box\", type = \"nonparametric\", var.equal = FALSE,\n               centrality.type = \"parametric\",\n               package = \"RColorBrewer\",\n               palette = \"PRGn\",\n               centrality.point.args = list(color=\"black\", size = 3, shape = 1),\n               # point.args = list(alpha=0), #suppress points\n               ggplot.component = ## modify further with `{ggplot2}` functions\n                list(\n                  # aes(color = IMPLICIT, fill = IMPLICIT),\n                  # scale_colour_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3)),\n                  # scale_fill_manual(values = paletteer::paletteer_c(\"viridis::viridis\", 3))\n                  # theme(axis.text.x = element_text(angle = 90)\n                )) \n\np[[1]] + coord_flip() + p[[2]] + coord_flip() + p[[3]] + coord_flip()\n\n\n\n\n\nCODE\n# # ggplot(data = df_s, aes( x = pretty_condition, y = task_percent)) + \n#   ggdist::stat_halfeye(\n#     alpha = 0.7,\n#     point_colour = NA,\n#     adjust = .5,\n#     width = .5, .width = 0,\n#     justification = -.5) +\n#   geom_boxplot(\n#     alpha = 0.1,\n#     width = .2,\n#     outlier.shape = NA\n#   ) +\n#   geom_point(\n#     size = 2,\n#     alpha = .5,\n#     position = position_jitter(\n#       seed = 1, width = .05, height = .02\n#     )\n#   ) \n# coord_flip() + theme_clean() + theme(legend.position = \"blank\")\n# p$layers[[3]]=NULL #remove default boxplot\n# e <- statsExpressions::two_sample_test(y = task_percent, x = pretty_condition, data = df_s,\n#                                 type = \"nonparametric\", alternative = \"less\",\n#                                 var.equal = FALSE)\n# #labels are layer 4\n# p + labs(title = \"Distribution of Total Accuracy\",\n#          y = \"Proportion of correct responses across task\", x = \"\",\n#          subtitle = \"Impasse condition yields higher scores and greater variance\",\n#          caption=e$expression[[1]])\n\n\n\n\nDescribe\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct)\"\ntbl1 <- mosaic::favstats(~task_percent, data = df_s) \ntbl1 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0 \n    0.077 \n    0.769 \n    0.923 \n    1 \n    0.585 \n    0.392 \n    321 \n    0 \n  \n\n\n\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\"\ntbl2 <- mosaic::favstats(task_percent ~ pretty_condition, data = df_s) \ntbl2 %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Total % Correct) BY CONDITION\n \n  \n    pretty_condition \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    none-control \n    0.000 \n    0.000 \n    0.000 \n    0.154 \n    1.000 \n    0.210 \n    0.370 \n    62 \n    0 \n  \n  \n    none-impasse \n    0.000 \n    0.058 \n    0.346 \n    0.846 \n    1.000 \n    0.419 \n    0.387 \n    64 \n    0 \n  \n  \n    img-control \n    0.000 \n    0.404 \n    0.769 \n    0.923 \n    1.000 \n    0.637 \n    0.359 \n    50 \n    0 \n  \n  \n    img-impasse \n    0.000 \n    0.692 \n    0.846 \n    0.846 \n    0.923 \n    0.755 \n    0.218 \n    42 \n    0 \n  \n  \n    ixv-control \n    0.000 \n    0.769 \n    0.923 \n    1.000 \n    1.000 \n    0.816 \n    0.276 \n    62 \n    0 \n  \n  \n    ixv-impasse \n    0.154 \n    0.769 \n    0.846 \n    0.923 \n    1.000 \n    0.827 \n    0.157 \n    41 \n    0 \n  \n\n\n\n\n\nAcross conditions, overall accuracy on the task ranges from 0 to 100 with a mean of 58.543. We see that the distribution of this outcome variable is clearly bimodal: with modes near the floor (0% correct) and ceiling (100% correct) of the scale. This bimodality is sensical considering the nature of the task, where each item in the task indexes a different information extraction operation over the same coordinate system.\nA score of 100% indicates that the participant correctly interpreted the interval-coordinate system throughout the task, starting at the first question. A score of 0% indicates the individual never correctly interpreted the coordinate system. A score somewhere inbetween indicates that an individual deciphered the coordinate system sometime over the course the task.\n\nTESTS\n\nAligned Ranks Transformation\n\n\n\nCODE\nm.art = art(task_percent ~ IMPLICIT*EXPLICIT, data = df_s)\nanova(m.art)\n\n\nAnalysis of Variance of Aligned Rank Transformed Data\n\nTable Type: Anova Table (Type III tests) \nModel: No Repeated Measures (lm)\nResponse: art(task_percent)\n\n                    Df Df.res F value Pr(>F)    \n1 IMPLICIT           1    315  2.0192  0.156    \n2 EXPLICIT           2    315 63.0761 <2e-16 ***\n3 IMPLICIT:EXPLICIT  2    315  5.9096  0.003  **\n---\nSignif. codes:   0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\n\n\n\nKruskal Wallis Test\n\n\nCODE\n(k <- kruskal.test(df_s$task_percent ~ df_s$pretty_condition))\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  df_s$task_percent by df_s$pretty_condition\nKruskal-Wallis chi-squared = 93, df = 5, p-value <2e-16\n\n\n\n\nVisualize\n\n\nCODE\n#:::::::: STATSPLOT | VIOLIN\ngrouped_ggbetweenstats(y = task_percent, x = EXPLICIT, grouping.var = IMPLICIT,  \n               data = df_s, type = \"nonparametric\")\n\n\n\n\n\nCODE\ngrouped_ggbetweenstats(y = task_percent, x = IMPLICIT, grouping.var = EXPLICIT,  \n               data = df_s, type = \"nonparametric\")\n\n\n\n\n\n\n\n\nMIXED LOGISTIC REGRESSION\nFit a mixed logistic regression (at the item level), predicting accuracy (absolute score) on all discriminating questions by condition; accounting for random effects of subject and item.\n\nFit Model\n\n\nCODE\n## 0 | SETUP\n#confirm 13 items [all discriminating items]\nnrow(df_i) / nrow(df_s) == 13\n\n\n[1] FALSE\n\n\nCODE\n#confirm all factors \nis.factor(df_i$q) && is.factor(df_i$subject) && is.factor(df_i$pretty_condition) && is.factor(df_i$accuracy) && is.factor(df_i$ospan_split)\n\n\nWarning: Unknown or uninitialised column: `ospan_split`.\n\n\n[1] FALSE\n\n\nCODE\n## 1 | SETUP RANDOM INTERCEPT SUBJECT\n\n#:: EMPTY MODEL (baseline, no random effect)\nprint(\"Empty fixed model\")\n\n\n[1] \"Empty fixed model\"\n\n\nCODE\nm0 = glm(accuracy ~ 1, family = \"binomial\", data = df_i) \n# summary(m0)\n\n#:: RANDOM INTERCEPT SUBJECT\nprint(\"Subject intercept random model\")\n\n\n[1] \"Subject intercept random model\"\n\n\nCODE\nmm.rS <- glmer(accuracy ~ (1|subject), data = df_i, family = \"binomial\")\n# summary(mm.rS)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", m0$aic > AIC(logLik(mm.rS)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(m0,mm.rS) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName  |    Model | df | df_diff |    Chi2 |      p\n--------------------------------------------------\nm0    |      glm |  1 |         |         |       \nmm.rS | glmerMod |  2 |       1 | 3812.12 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m0,mm.rS))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0\"\n\n\nCODE\n#:: RANDOM INTERCEPT SUBJECT + ITEM\nprint(\"Subject Intercept + Item intercept random model\")\n\n\n[1] \"Subject Intercept + Item intercept random model\"\n\n\nCODE\nmm.rSQ <- glmer(accuracy ~ (1|subject) + (1|q), data = df_i, family = \"binomial\")\n#summary(mm.rSQ)\n\n# :: TEST random effect\npaste(\"AIC decreases w/ new model?\", AIC(logLik(mm.rS)) > AIC(logLik(mm.rSQ)))\n\n\n[1] \"AIC decreases w/ new model? TRUE\"\n\n\nCODE\ntest_lrt(mm.rS, mm.rSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |   Chi2 |      p\n--------------------------------------------------\nmm.rS  | glmerMod |  2 |         |        |       \nmm.rSQ | glmerMod |  3 |       1 | 156.57 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rS, mm.rSQ))$p[2])\n\n\nSome of the nested models seem to be identical and probably only vary in\n  their random effects.\n\n\n[1] \"Likelihood Ratio test is significant? p =  6.36605414566804e-36\"\n\n\nCODE\n## 2 | ADD MAIN EFFECTS \n\nprint(\"MAIN FIXED  implicit*explicit + Subject & Item random intercepts\")\n\n\n[1] \"MAIN FIXED  implicit*explicit + Subject & Item random intercepts\"\n\n\nCODE\nmm.IErSQ <- glmer(accuracy ~ IMPLICIT + EXPLICIT + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\n# car::Anova(mm.IErSQ, type = 3)\n\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.rSQ)) > AIC(logLik(mm.IErSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.rSQ,mm.IErSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName     |    Model | df | df_diff |   Chi2 |      p\n----------------------------------------------------\nmm.rSQ   | glmerMod |  3 |         |        |       \nmm.IErSQ | glmerMod |  6 |       3 | 191.22 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.rSQ,mm.IErSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  3.32771194302262e-41\"\n\n\nCODE\n## 2 | ADD IXN FIXED EFFECT\n\nprint(\"MAIN IXN implicit*explicit + Subject & Item random intercepts\")\n\n\n[1] \"MAIN IXN implicit*explicit + Subject & Item random intercepts\"\n\n\nCODE\nmm.I.ErSQ <- glmer(accuracy ~ IMPLICIT*EXPLICIT + (1|subject) + (1|q) ,\n                data = df_i, family = \"binomial\")\ncar::Anova(mm.I.ErSQ, type = 3)\n\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: accuracy\n                  Chisq Df Pr(>Chisq)    \n(Intercept)        94.4  1    < 2e-16 ***\nIMPLICIT           33.2  1    8.4e-09 ***\nEXPLICIT          147.2  2    < 2e-16 ***\nIMPLICIT:EXPLICIT  19.4  2    6.0e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\npaste(\"AIC decreases w/ new model\", AIC(logLik(mm.IErSQ)) > AIC(logLik(mm.I.ErSQ)) )\n\n\n[1] \"AIC decreases w/ new model TRUE\"\n\n\nCODE\ntest_lrt(mm.I.ErSQ,mm.IErSQ) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName      |    Model | df | df_diff |  Chi2 |      p\n----------------------------------------------------\nmm.I.ErSQ | glmerMod |  8 |         |       |       \nmm.IErSQ  | glmerMod |  6 |      -2 | 20.41 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(mm.I.ErSQ,mm.IErSQ))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  0.0000370366553860735\"\n\n\n\n\nDescribe\n\n\nCODE\n# best model\nm <- mm.I.ErSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: accuracy ~ IMPLICIT * EXPLICIT + (1 | subject) + (1 | q)\n   Data: df_i\n\n     AIC      BIC   logLik deviance df.resid \n    4118     4172    -2051     4102     5972 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.300 -0.170 -0.054  0.315  6.208 \n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 9.437    3.072   \n q       (Intercept) 0.405    0.636   \nNumber of obs: 5980, groups:  subject, 460; q, 13\n\nFixed effects:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   -4.014      0.413   -9.72  < 2e-16 ***\nIMPLICITimpasse                2.670      0.464    5.76  8.4e-09 ***\nEXPLICITimg                    4.960      0.603    8.22  < 2e-16 ***\nEXPLICITixn                    7.046      0.610   11.55  < 2e-16 ***\nIMPLICITimpasse:EXPLICITimg   -2.096      0.824   -2.54    0.011 *  \nIMPLICITimpasse:EXPLICITixn   -3.517      0.831   -4.23  2.3e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n                       (Intr) IMPLICITm EXPLICITm EXPLICITx\nIMPLICITmps            -0.693                              \nEXPLICITimg            -0.566  0.477                       \nEXPLICITixn            -0.604  0.502     0.420             \nIMPLICITmpss:EXPLICITm  0.391 -0.562    -0.714    -0.284   \nIMPLICITmpss:EXPLICITx  0.417 -0.577    -0.288    -0.706   \n                       IMPLICITmpss:EXPLICITm\nIMPLICITmps                                  \nEXPLICITimg                                  \nEXPLICITixn                                  \nIMPLICITmpss:EXPLICITm                       \nIMPLICITmpss:EXPLICITx  0.325                \n\n\nCODE\nprint(\"SIGNIFICANCE TEST [non directional]\")\n\n\n[1] \"SIGNIFICANCE TEST [non directional]\"\n\n\nCODE\ncar::Anova(m, type=3) #TYPE 3 SS FOR IXNS\n\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: accuracy\n                  Chisq Df Pr(>Chisq)    \n(Intercept)        94.4  1    < 2e-16 ***\nIMPLICIT           33.2  1    8.4e-09 ***\nEXPLICIT          147.2  2    < 2e-16 ***\nIMPLICIT:EXPLICIT  19.4  2    6.0e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\")\n\n\n# A tibble: 8 × 9\n  effect   group term  estimate std.error statistic   p.value conf.low conf.high\n  <chr>    <chr> <chr>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>  (Int…   -4.01      0.413     -9.72  2.59e-22    -4.82    -3.20 \n2 fixed    <NA>  IMPL…    2.67      0.464      5.76  8.43e- 9     1.76     3.58 \n3 fixed    <NA>  EXPL…    4.96      0.603      8.22  2.02e-16     3.78     6.14 \n4 fixed    <NA>  EXPL…    7.05      0.610     11.5   7.40e-31     5.85     8.24 \n5 fixed    <NA>  IMPL…   -2.10      0.824     -2.54  1.10e- 2    -3.71    -0.480\n6 fixed    <NA>  IMPL…   -3.52      0.831     -4.23  2.31e- 5    -5.15    -1.89 \n7 ran_pars subj… sd__…    3.07     NA         NA    NA           NA       NA    \n8 ran_pars q     sd__…    0.636    NA         NA    NA           NA       NA    \n\n\nCODE\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\ntidy(m,   conf.int = TRUE, conf.level = 0.95, conf.method = \"Wald\", exponentiate = TRUE)\n\n\n# A tibble: 8 × 9\n  effect   group term  estimate std.error statistic   p.value conf.low conf.high\n  <chr>    <chr> <chr>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n1 fixed    <NA>  (Int…  1.81e-2   0.00746     -9.72  2.59e-22  8.04e-3    0.0406\n2 fixed    <NA>  IMPL…  1.44e+1   6.70         5.76  8.43e- 9  5.82e+0   35.8   \n3 fixed    <NA>  EXPL…  1.43e+2  86.0          8.22  2.02e-16  4.37e+1  465.    \n4 fixed    <NA>  EXPL…  1.15e+3 700.          11.5   7.40e-31  3.47e+2 3795.    \n5 fixed    <NA>  IMPL…  1.23e-1   0.101       -2.54  1.10e- 2  2.44e-2    0.619 \n6 fixed    <NA>  IMPL…  2.97e-2   0.0247      -4.23  2.31e- 5  5.83e-3    0.151 \n7 ran_pars subj… sd__…  3.07e+0  NA           NA    NA        NA         NA     \n8 ran_pars q     sd__…  6.36e-1  NA           NA    NA        NA         NA     \n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#probability control = plogis(intercept)\n#probability impasse = plogis(intercept + coefficient)\n\n#FROM predict()\n# newdata <- df_i %>% dplyr::select(pretty_condition, subject, q)\n# preds <- predict(m, newdata = newdata, type = \"response\")\n# preds <- cbind(newdata, preds)\n# p <- preds %>% \n#   dplyr::select(pretty_condition, preds) %>% \n#   group_by(pretty_condition) %>% \n#   summarise(\n#     median = median(preds),\n#     se = sd(preds)/sqrt(n()),\n#     lwr = median - 1.96*se,\n#     upr = median + 1.96*se)\n    \n  \n#FROM merTools\n#setup df \nnewdata <- df_i %>% dplyr::select(IMPLICIT, EXPLICIT, subject, q)\n#make predictions\npreds <- predictInterval(m, newdata = newdata,\n                              which = \"fixed\", #full, fixed or random for those only\n                              type = \"probability\", #linear.prediction\n                              stat = \"median\",\n                              n.sims = 1000,\n                              level = 0.80) #width of prediction interval\n\n\nWarning in predictInterval(m, newdata = newdata, which = \"fixed\", type = \"probability\", : newdata is tbl_df or tbl object from dplyr package and has been\n              coerced to a data.frame\n\n\nWarning: executing %dopar% sequentially: no parallel backend registered\n\n\nCODE\n#join predictions to the new dataframe\npreds <- cbind(newdata, preds)\n#summarize\n(summ_preds <- preds %>% \n  dplyr::select(IMPLICIT, EXPLICIT, fit, lwr, upr) %>% \n  group_by(IMPLICIT,EXPLICIT) %>% \n  summarise(\n    median = median(fit),\n    lower = median(lwr),\n    upper = median(upr)\n  )) \n\n\n# A tibble: 6 × 5\n# Groups:   IMPLICIT [2]\n  IMPLICIT EXPLICIT median   lower  upper\n  <fct>    <fct>     <dbl>   <dbl>  <dbl>\n1 control  none     0.0178 0.00454 0.0673\n2 control  img      0.724  0.387   0.916 \n3 control  ixn      0.954  0.834   0.989 \n4 impasse  none     0.209  0.0642  0.506 \n5 impasse  img      0.821  0.518   0.951 \n6 impasse  ixn      0.902  0.682   0.975 \n\n\n\n\nInference TODO UPDATE\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.02\n0.01 – 0.04\n<0.001\n\n\nIMPLICIT: impasse\n14.44\n5.82 – 35.84\n<0.001\n\n\nEXPLICIT: img\n142.56\n43.70 – 465.09\n<0.001\n\n\nEXPLICIT: ixn\n1147.91\n347.26 – 3794.59\n<0.001\n\n\nIMPLICITimpasse:EXPLICITimg\n0.12\n0.02 – 0.62\n0.011\n\n\nIMPLICITimpasse:EXPLICITixn\n0.03\n0.01 – 0.15\n<0.001\n\n\nRandom Effects\n\n\n\nσ2\n3.29\n\n\n\nτ00 subject\n9.44\n\n\nτ00 q\n0.40\n\n\nICC\n0.75\n\n\nN subject\n460\n\n\nN q\n13\n\nObservations\n5980\n\n\nMarginal R2 / Conditional R2\n0.334 / 0.833\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n# \n# \n# \n\n\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result)\n\n\n\n\n\nCODE\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n\n\n$IMPLICIT\n\n\n\n\n\n\n$EXPLICIT\n\n\n\n\n\nCODE\nplot_model(m, type = \"eff\")  \n\n\n$IMPLICIT\n\n\n\n\n\n\n$EXPLICIT\n\n\n\n\n\nCODE\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n#TODO EMMEANS for the estimated marginal means OR USE IXN PLOT\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.02\n0.01 – 0.04\n<0.001\n\n\nIMPLICIT: impasse\n14.44\n5.82 – 35.84\n<0.001\n\n\nEXPLICIT: img\n142.56\n43.70 – 465.09\n<0.001\n\n\nEXPLICIT: ixn\n1147.91\n347.26 – 3794.59\n<0.001\n\n\nIMPLICITimpasse:EXPLICITimg\n0.12\n0.02 – 0.62\n0.011\n\n\nIMPLICITimpasse:EXPLICITixn\n0.03\n0.01 – 0.15\n<0.001\n\n\nRandom Effects\n\n\n\nσ2\n3.29\n\n\n\nτ00 subject\n9.44\n\n\nτ00 q\n0.40\n\n\nICC\n0.75\n\n\nN subject\n460\n\n\nN q\n13\n\nObservations\n5980\n\n\nMarginal R2 / Conditional R2\n0.334 / 0.833\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list('\"* p < 0.05, ** p < 0.01, *** p < 0.001\"',\n#                'N(subject) = 133 $\\tau_{00}$(subject) = 34.85',\n#              'N(question) = 13 $\\tau_{00}$(question) = 1.14')\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex\")\n# # #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report(m)\n\n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"DIAGNOSTICS\")\n\n\n[1] \"DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1a-overall-interpretation-state",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1a-overall-interpretation-state",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "H1A | OVERALL INTERPRETATION STATE",
    "text": "H1A | OVERALL INTERPRETATION STATE\nDo Ss in the IMPASSE condition offer less-orthogonal interpretations across the test phase questions?\nWhile absolute accuracy score tells us whether a participant successfully interpreted the coordinate system, it doesn’t allow us to differentiate between different kinds of incorrect interpretations. Here we examine the (categorical) interpretation state type based on the nature of subject’s response, and determine if these interpretations differ by experimental condition. State is a 3-category variable that groups the following interpretations:\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses across questions?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and triangle-like response states across all items\n\n\nData\n\ndata: df_items where q nin 6,9 (13 discriminant test phase items)\noutcome: state ( 3 level factor from high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMIXED Multinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nMIXED Ordinal regression on state (doesn’t meet proportional odds assumption-I think)\nMIXED Multinomial or Ordinal regression on high_interpretation (some cells are 0, produces problems)\n\n\n\n\n\nSetup\n\n\nCODE\ndf_i = df_items %>% filter(q %nin% c(6,9)) %>% dplyr::select(pretty_condition, q,subject,state,IMPLICIT, EXPLICIT) %>% droplevels()\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = EXPLICIT,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~IMPLICIT) +\n   labs(title = \"Interpretation across all Questions\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = IMPLICIT,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~EXPLICIT) +\n   labs(title = \"Interpretation across all Questions\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf_i %>% \n  ggplot(data = .,\n         mapping = aes(x = EXPLICIT,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(q ~ IMPLICIT) +\n   labs(title = \"Interpretation by Question\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df_i$state, df_i$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             none-control none-impasse img-control img-impasse ixv-control\n  orthogonal       0.6811       0.3305      0.2292      0.0531      0.1129\n  other            0.1059       0.2302      0.0969      0.1447      0.0496\n  angular          0.0189       0.0456      0.0185      0.0238      0.0149\n  triangular       0.1941       0.3937      0.6554      0.7784      0.8226\n  Sum              1.0000       1.0000      1.0000      1.0000      1.0000\n            \n             ixv-impasse    Sum\n  orthogonal      0.0338 0.3375\n  other           0.1051 0.1373\n  angular         0.0150 0.0263\n  triangular      0.8462 0.4990\n  Sum             1.0000 1.0000\n\n\nCODE\n(t <- table(df_i$state, df_i$EXPLICIT, df_i$IMPLICIT) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n, ,  = control\n\n            \n             none  img  ixn  Sum\n  orthogonal 1151  149   91 1391\n  other       179   63   40  282\n  angular      32   12   12   56\n  triangular  328  426  663 1417\n  Sum        1690  650  806 3146\n\n, ,  = impasse\n\n            \n             none  img  ixn  Sum\n  orthogonal  580   29   18  627\n  other       404   79   56  539\n  angular      80   13    8  101\n  triangular  691  425  451 1567\n  Sum        1755  546  533 2834\n\n\n\n\nMIXED MULTINOMIAL REGRESSION\nDoes condition affect the response state of of items across the task?\nFit a MIXED logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\nFit Model [brms]\n\n\nCODE\n# to set priors... create model with default priors\n# then run prior_summary to see what the defaults are and syntax for coefficients\n# prior_summary(flat)\n# then create lists with the new priors, and create a new model with the priors \n\ninf_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  \n  #prior on CONDITION COEFFICIENT\n  #likely to change odds between 0 and 2.4\n    \n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMcontrol\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMcontrol\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionnoneMimpasse\", dpar = \"muother\"),\n  \n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMcontrol\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMcontrol\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionnoneMimpasse\", dpar = \"muangular\"),\n  \n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMcontrol\", dpar = \"mutriangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionimgMimpasse\", dpar = \"mutriangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMcontrol\", dpar = \"mutriangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionixvMimpasse\", dpar = \"mutriangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"pretty_conditionnoneMimpasse\", dpar = \"mutriangular\")\n)\n\nme_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  \n  #prior on IMPLICIT COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"mutriangular\"),\n  \n  #prior on EXPLICIT COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"mutriangular\"),\n  \n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"mutriangular\")\n)\n\nixn_priors <- c(\n  #prior on INTERCEPTS \n  #25% chance of each answer in control, scale = from 0.01 to 62%\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muangular\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"muother\"),\n  prior(normal(-1.1, 1.5),  class = \"Intercept\", dpar = \"mutriangular\"),\n  \n  #prior on IMPLICIT COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse\", dpar = \"mutriangular\"),\n  \n  #prior on EXPLICIT COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITimg\", dpar = \"mutriangular\"),\n  \n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"EXPLICITixn\", dpar = \"mutriangular\"),\n  \n  #prior on IXN COEFFICIENT\n  #likely to change odds between 0 and 2.4\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITimg\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITimg\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITimg\", dpar = \"mutriangular\"),\n  \n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITixn\", dpar = \"muangular\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITixn\", dpar = \"muother\"),\n  prior(normal(0, 2.42), class = b, coef=\"IMPLICITimpasse:EXPLICITixn\", dpar = \"mutriangular\")\n)\n\n#BAYESIAN RANDOM ONLY\nBmm.cat.rSQ <- brm( state ~ 1 + (1|subject) + (1|q), \n                 data = df_i, \n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3B/models/sgc3b_brms_state_Bmm.cat.rSQ.rds\")\n\n# CONDITION (unravelled, not fatorial) EQUAL ONLY MODEL\nBmm.cat.CrSQ <- brm( state ~ pretty_condition + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = inf_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 backend = \"cmdstanr\",\n                 file =\"analysis/SGC3B/models/sgc3b_brms_state_Bmm.cat.CrSQ.rds\")\n\n##MODEL COMPARISON\n# print(\"MODEL COMPARISON: random effects (vs) CONDITION\")\n# bayesfactor(Bmm.cat.rSQ, Bmm.cat.CrSQ)\n#substantial evidence in favor of conditon model over random only BF 1.64e+16\n\n# CONDITION * OSPAN MODEL\nBmm.cat.IErSQ  <- brm( state ~ IMPLICIT + EXPLICIT + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = me_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2000, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3B/models/sgc3b_brms_state_Bmm.cat.IErSQ.rds\")\n\n\n\n# CONDITION * OSPAN MODEL\nBmm.cat.I.ErSQ  <- brm( state ~ IMPLICIT*EXPLICIT + (1|subject) + (1|q), \n                 data = df_i, \n                 prior = ixn_priors,\n                 family = \"categorical\",\n                 chains = 4, iter = 2500, warmup = 1000,\n                 cores = 4, seed = 1234,\n                 save_pars = save_pars(all = TRUE),\n                 control = list(adapt_delta = 0.98),  # to deal with divergent transitions\n                 # backend = \"cmdstanr\",\n                 file =\"analysis/SGC3B/models/sgc3b_brms_state_Bmm.cat.I.ErSQ.rds\")\n\n\n##MODEL COMPARISON\nprint(\"IS FACTORIAL better than MAIN EFFECTS model?\")\n\n\n[1] \"IS FACTORIAL better than MAIN EFFECTS model?\"\n\n\nCODE\nbayesfactor(Bmm.cat.I.ErSQ, Bmm.cat.IErSQ)\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nComputation of Bayes factors: estimating marginal likelihood, please wait...\n\n\nWarning: Infinite value in iterative scheme, returning NA.\n Try rerunning with more samples.\n\n\nWarning: Infinite value in iterative scheme, returning NA.\n Try rerunning with more samples.\n\n\nBayes Factors for Model Comparison\n\n    Model                                         BF\n[2] IMPLICIT + EXPLICIT + (1 | subject) + (1 | q)   \n\n* Against Denominator: [1] IMPLICIT * EXPLICIT + (1 | subject) + (1 | q)\n*   Bayes Factor Type: marginal likelihoods (bridgesampling)\n\n\nCODE\ncompare_models(Bmm.cat.I.ErSQ, Bmm.cat.IErSQ)\n\n\nParameter                                |       Bmm.cat.I.ErSQ |        Bmm.cat.IErSQ\n--------------------------------------------------------------------------------------\nmuother_Intercept                        | -2.63 (-3.54, -1.81) | -2.74 (-3.66, -1.89)\nmuangular_Intercept                      | -5.21 (-6.64, -3.63) | -5.09 (-6.53, -3.54)\nmutriangular_Intercept                   | -3.08 (-3.92, -2.28) | -2.80 (-3.60, -2.03)\nmuother_IMPLICITimpasse                  |  2.05 ( 1.69,  2.44) |  2.25 ( 1.92,  2.60)\nmuother_EXPLICITimg                      |  1.39 ( 0.84,  1.99) |  1.67 ( 1.24,  2.10)\nmuother_EXPLICITixn                      |  1.41 ( 0.79,  2.01) |  1.74 ( 1.27,  2.24)\nmuangular_IMPLICITimpasse                |  2.20 ( 1.55,  2.90) |  2.04 ( 1.51,  2.61)\nmuangular_EXPLICITimg                    |  1.28 ( 0.25,  2.27) |  1.12 ( 0.31,  1.85)\nmuangular_EXPLICITixn                    |  1.73 ( 0.62,  2.74) |  1.39 ( 0.56,  2.20)\nmutriangular_IMPLICITimpasse             |  2.77 ( 1.89,  3.63) |  2.26 ( 1.58,  2.92)\nmutriangular_EXPLICITimg                 |  4.62 ( 3.48,  5.74) |  4.22 ( 3.37,  5.10)\nmutriangular_EXPLICITixn                 |  6.39 ( 5.33,  7.50) |  5.68 ( 4.86,  6.52)\nmuangular_IMPLICITimpasse:EXPLICITixn    | -0.71 (-2.29,  0.88) |                     \nmutriangular_IMPLICITimpasse:EXPLICITixn | -1.56 (-3.15,  0.08) |                     \nmuother_IMPLICITimpasse:EXPLICITimg      |  0.59 (-0.27,  1.43) |                     \nmuother_IMPLICITimpasse:EXPLICITixn      |  0.62 (-0.30,  1.62) |                     \nmutriangular_IMPLICITimpasse:EXPLICITimg | -0.55 (-2.14,  1.06) |                     \nmuangular_IMPLICITimpasse:EXPLICITimg    | -0.24 (-1.70,  1.22) |                     \n--------------------------------------------------------------------------------------\nObservations                             |                 5980 |                 5980\n\n\n\n\nDescribe\n\n\nCODE\n# best model\nm <- Bmm.cat.I.ErSQ\n\n#::::::::: PRINT MODEL \n\nprint(\"PREDICTOR MODEL\")\n\n\n[1] \"PREDICTOR MODEL\"\n\n\nCODE\nsummary(m)\n\n\n Family: categorical \n  Links: muother = logit; muangular = logit; mutriangular = logit \nFormula: state ~ IMPLICIT * EXPLICIT + (1 | subject) + (1 | q) \n   Data: df_i (Number of observations: 5980) \n  Draws: 4 chains, each with iter = 2500; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nGroup-Level Effects: \n~q (Number of levels: 13) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.54      0.36     1.01     2.40 1.00     1934\nsd(muangular_Intercept)        2.73      0.86     1.54     4.81 1.00     1748\nsd(mutriangular_Intercept)     0.94      0.23     0.61     1.48 1.00     2098\n                           Tail_ESS\nsd(muother_Intercept)          2778\nsd(muangular_Intercept)        2712\nsd(mutriangular_Intercept)     3393\n\n~subject (Number of levels: 460) \n                           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(muother_Intercept)          1.04      0.09     0.88     1.22 1.00     2203\nsd(muangular_Intercept)        1.61      0.19     1.26     2.02 1.00     2011\nsd(mutriangular_Intercept)     3.27      0.18     2.95     3.64 1.00     1767\n                           Tail_ESS\nsd(muother_Intercept)          3615\nsd(muangular_Intercept)        2953\nsd(mutriangular_Intercept)     3019\n\nPopulation-Level Effects: \n                                         Estimate Est.Error l-95% CI u-95% CI\nmuother_Intercept                           -2.64      0.44    -3.54    -1.81\nmuangular_Intercept                         -5.18      0.76    -6.64    -3.63\nmutriangular_Intercept                      -3.08      0.42    -3.92    -2.28\nmuother_IMPLICITimpasse                      2.05      0.19     1.69     2.44\nmuother_EXPLICITimg                          1.39      0.29     0.84     1.99\nmuother_EXPLICITixn                          1.40      0.32     0.79     2.01\nmuother_IMPLICITimpasse:EXPLICITimg          0.58      0.44    -0.27     1.43\nmuother_IMPLICITimpasse:EXPLICITixn          0.63      0.49    -0.30     1.62\nmuangular_IMPLICITimpasse                    2.21      0.34     1.55     2.90\nmuangular_EXPLICITimg                        1.27      0.52     0.25     2.27\nmuangular_EXPLICITixn                        1.72      0.54     0.62     2.74\nmuangular_IMPLICITimpasse:EXPLICITimg       -0.24      0.74    -1.70     1.22\nmuangular_IMPLICITimpasse:EXPLICITixn       -0.72      0.80    -2.29     0.88\nmutriangular_IMPLICITimpasse                 2.76      0.44     1.89     3.63\nmutriangular_EXPLICITimg                     4.61      0.58     3.48     5.74\nmutriangular_EXPLICITixn                     6.40      0.56     5.33     7.50\nmutriangular_IMPLICITimpasse:EXPLICITimg    -0.56      0.82    -2.14     1.06\nmutriangular_IMPLICITimpasse:EXPLICITixn    -1.55      0.82    -3.15     0.08\n                                         Rhat Bulk_ESS Tail_ESS\nmuother_Intercept                        1.00     1219     2337\nmuangular_Intercept                      1.00     1681     2407\nmutriangular_Intercept                   1.00     1420     2462\nmuother_IMPLICITimpasse                  1.00     3207     3724\nmuother_EXPLICITimg                      1.00     3489     4476\nmuother_EXPLICITixn                      1.00     3800     4483\nmuother_IMPLICITimpasse:EXPLICITimg      1.00     3838     4353\nmuother_IMPLICITimpasse:EXPLICITixn      1.00     4029     4276\nmuangular_IMPLICITimpasse                1.00     3593     4391\nmuangular_EXPLICITimg                    1.00     4109     4387\nmuangular_EXPLICITixn                    1.00     4188     4523\nmuangular_IMPLICITimpasse:EXPLICITimg    1.00     3943     4315\nmuangular_IMPLICITimpasse:EXPLICITixn    1.00     4283     4708\nmutriangular_IMPLICITimpasse             1.00      851     2412\nmutriangular_EXPLICITimg                 1.00      900     1932\nmutriangular_EXPLICITixn                 1.00     1352     2466\nmutriangular_IMPLICITimpasse:EXPLICITimg 1.00     1055     1527\nmutriangular_IMPLICITimpasse:EXPLICITixn 1.00     1275     1924\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCODE\n(d <- describe_posterior(ci=.95, m))\n\n\nSummary of Posterior Distribution\n\nParameter                                | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                        |  -2.63 | [-3.54, -1.81] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1214.00\nmuangular_Intercept                      |  -5.21 | [-6.64, -3.63] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1663.00\nmutriangular_Intercept                   |  -3.08 | [-3.92, -2.28] |   100% | [-0.18, 0.18] |        0% | 1.002 | 1400.00\nmuother_IMPLICITimpasse                  |   2.05 | [ 1.69,  2.44] |   100% | [-0.18, 0.18] |        0% | 1.000 | 3149.00\nmuother_EXPLICITimg                      |   1.39 | [ 0.84,  1.99] |   100% | [-0.18, 0.18] |        0% | 1.002 | 3493.00\nmuother_EXPLICITixn                      |   1.41 | [ 0.79,  2.01] |   100% | [-0.18, 0.18] |        0% | 1.001 | 3790.00\nmuother_IMPLICITimpasse:EXPLICITimg      |   0.59 | [-0.27,  1.43] | 90.47% | [-0.18, 0.18] |    15.02% | 1.001 | 3836.00\nmuother_IMPLICITimpasse:EXPLICITixn      |   0.62 | [-0.30,  1.62] | 90.35% | [-0.18, 0.18] |    13.96% | 1.000 | 4032.00\nmuangular_IMPLICITimpasse                |   2.20 | [ 1.55,  2.90] |   100% | [-0.18, 0.18] |        0% | 1.001 | 3566.00\nmuangular_EXPLICITimg                    |   1.28 | [ 0.25,  2.27] | 99.10% | [-0.18, 0.18] |        0% | 1.000 | 4093.00\nmuangular_EXPLICITixn                    |   1.73 | [ 0.62,  2.74] | 99.88% | [-0.18, 0.18] |        0% | 1.000 | 4173.00\nmuangular_IMPLICITimpasse:EXPLICITimg    |  -0.24 | [-1.70,  1.22] | 62.05% | [-0.18, 0.18] |    19.32% | 1.002 | 3934.00\nmuangular_IMPLICITimpasse:EXPLICITixn    |  -0.71 | [-2.29,  0.88] | 81.42% | [-0.18, 0.18] |    12.84% | 1.000 | 4285.00\nmutriangular_IMPLICITimpasse             |   2.77 | [ 1.89,  3.63] |   100% | [-0.18, 0.18] |        0% | 1.002 |  810.00\nmutriangular_EXPLICITimg                 |   4.62 | [ 3.48,  5.74] |   100% | [-0.18, 0.18] |        0% | 1.005 |  807.00\nmutriangular_EXPLICITixn                 |   6.39 | [ 5.33,  7.50] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1344.00\nmutriangular_IMPLICITimpasse:EXPLICITimg |  -0.55 | [-2.14,  1.06] | 74.97% | [-0.18, 0.18] |    14.91% | 1.003 | 1023.00\nmutriangular_IMPLICITimpasse:EXPLICITixn |  -1.56 | [-3.15,  0.08] | 97.05% | [-0.18, 0.18] |     2.51% | 1.002 | 1233.00\n\n\nCODE\nprint(\"BAYES FACTOR [SIGNIFICANCE TEST]\")\n\n\n[1] \"BAYES FACTOR [SIGNIFICANCE TEST]\"\n\n\nCODE\n#think of this like the anova(model) to get p values for each predictor\n#has to recompile the models with rstan. total drag\n(b <- bayesfactor(m))\n\n\nSampling priors, please wait...\n\n\nWarning: Bayes factors might not be precise.\nFor precise Bayes factors, sampling at least 40,000 posterior samples is recommended.\n\n\nBayes Factor (Savage-Dickey density ratio)\n\nParameter                                |       BF\n---------------------------------------------------\nmuother_Intercept                        | 4.19e+04\nmuangular_Intercept                      | 1.33e+04\nmutriangular_Intercept                   | 6.12e+07\nmuother_IMPLICITimpasse                  | 8.00e+09\nmuother_EXPLICITimg                      | 1.80e+03\nmuother_EXPLICITixn                      |   259.57\nmuother_IMPLICITimpasse:EXPLICITimg      |    0.418\nmuother_IMPLICITimpasse:EXPLICITixn      |    0.454\nmuangular_IMPLICITimpasse                | 1.51e+05\nmuangular_EXPLICITimg                    |     4.36\nmuangular_EXPLICITixn                    |    21.42\nmuangular_IMPLICITimpasse:EXPLICITimg    |    0.309\nmuangular_IMPLICITimpasse:EXPLICITixn    |    0.499\nmutriangular_IMPLICITimpasse             | 4.37e+04\nmutriangular_EXPLICITimg                 | 2.71e+10\nmutriangular_EXPLICITixn                 | 2.03e+15\nmutriangular_IMPLICITimpasse:EXPLICITimg |    0.435\nmutriangular_IMPLICITimpasse:EXPLICITixn |     1.88\n\n* Evidence Against The Null: 0\n\n\nCODE\nprint(\"DESCRIBE POSTERIOR\")\n\n\n[1] \"DESCRIBE POSTERIOR\"\n\n\nCODE\n#:::::::: INTERPRET COEFFICIENTS\n\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\n(l <- describe_posterior(m))\n\n\nSummary of Posterior Distribution\n\nParameter                                | Median |         95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS\n-------------------------------------------------------------------------------------------------------------------------\nmuother_Intercept                        |  -2.63 | [-3.54, -1.81] |   100% | [-0.18, 0.18] |        0% | 1.000 | 1214.00\nmuangular_Intercept                      |  -5.21 | [-6.64, -3.63] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1663.00\nmutriangular_Intercept                   |  -3.08 | [-3.92, -2.28] |   100% | [-0.18, 0.18] |        0% | 1.002 | 1400.00\nmuother_IMPLICITimpasse                  |   2.05 | [ 1.69,  2.44] |   100% | [-0.18, 0.18] |        0% | 1.000 | 3149.00\nmuother_EXPLICITimg                      |   1.39 | [ 0.84,  1.99] |   100% | [-0.18, 0.18] |        0% | 1.002 | 3493.00\nmuother_EXPLICITixn                      |   1.41 | [ 0.79,  2.01] |   100% | [-0.18, 0.18] |        0% | 1.001 | 3790.00\nmuother_IMPLICITimpasse:EXPLICITimg      |   0.59 | [-0.27,  1.43] | 90.47% | [-0.18, 0.18] |    15.02% | 1.001 | 3836.00\nmuother_IMPLICITimpasse:EXPLICITixn      |   0.62 | [-0.30,  1.62] | 90.35% | [-0.18, 0.18] |    13.96% | 1.000 | 4032.00\nmuangular_IMPLICITimpasse                |   2.20 | [ 1.55,  2.90] |   100% | [-0.18, 0.18] |        0% | 1.001 | 3566.00\nmuangular_EXPLICITimg                    |   1.28 | [ 0.25,  2.27] | 99.10% | [-0.18, 0.18] |        0% | 1.000 | 4093.00\nmuangular_EXPLICITixn                    |   1.73 | [ 0.62,  2.74] | 99.88% | [-0.18, 0.18] |        0% | 1.000 | 4173.00\nmuangular_IMPLICITimpasse:EXPLICITimg    |  -0.24 | [-1.70,  1.22] | 62.05% | [-0.18, 0.18] |    19.32% | 1.002 | 3934.00\nmuangular_IMPLICITimpasse:EXPLICITixn    |  -0.71 | [-2.29,  0.88] | 81.42% | [-0.18, 0.18] |    12.84% | 1.000 | 4285.00\nmutriangular_IMPLICITimpasse             |   2.77 | [ 1.89,  3.63] |   100% | [-0.18, 0.18] |        0% | 1.002 |  810.00\nmutriangular_EXPLICITimg                 |   4.62 | [ 3.48,  5.74] |   100% | [-0.18, 0.18] |        0% | 1.005 |  807.00\nmutriangular_EXPLICITixn                 |   6.39 | [ 5.33,  7.50] |   100% | [-0.18, 0.18] |        0% | 1.001 | 1344.00\nmutriangular_IMPLICITimpasse:EXPLICITimg |  -0.55 | [-2.14,  1.06] | 74.97% | [-0.18, 0.18] |    14.91% | 1.003 | 1023.00\nmutriangular_IMPLICITimpasse:EXPLICITixn |  -1.56 | [-3.15,  0.08] | 97.05% | [-0.18, 0.18] |     2.51% | 1.002 | 1233.00\n\n\nCODE\n# (tm <- tidy(m,   conf.int = TRUE))\n\npaste(\"ODDS RATIOS\")\n\n\n[1] \"ODDS RATIOS\"\n\n\nCODE\n(e <- model_parameters(m, exponentiate = TRUE))\n\n\nParameter                                |   Median |            95% CI |     pd | % in ROPE |  Rhat |     ESS\n--------------------------------------------------------------------------------------------------------------\nmuother_Intercept                        |     0.07 | [  0.03,    0.16] |   100% |        0% | 1.000 | 1214.00\nmuangular_Intercept                      | 5.48e-03 | [  0.00,    0.03] |   100% |        0% | 1.001 | 1663.00\nmutriangular_Intercept                   |     0.05 | [  0.02,    0.10] |   100% |        0% | 1.002 | 1400.00\nmuother_IMPLICITimpasse                  |     7.78 | [  5.44,   11.50] |   100% |        0% | 1.000 | 3149.00\nmuother_EXPLICITimg                      |     4.00 | [  2.31,    7.30] |   100% |        0% | 1.002 | 3493.00\nmuother_EXPLICITixn                      |     4.08 | [  2.20,    7.47] |   100% |        0% | 1.001 | 3790.00\nmuother_IMPLICITimpasse:EXPLICITimg      |     1.80 | [  0.76,    4.19] | 90.47% |    15.02% | 1.001 | 3836.00\nmuother_IMPLICITimpasse:EXPLICITixn      |     1.85 | [  0.74,    5.06] | 90.35% |    13.96% | 1.000 | 4032.00\nmuangular_IMPLICITimpasse                |     8.99 | [  4.71,   18.19] |   100% |        0% | 1.001 | 3566.00\nmuangular_EXPLICITimg                    |     3.60 | [  1.28,    9.65] | 99.10% |        0% | 1.000 | 4093.00\nmuangular_EXPLICITixn                    |     5.62 | [  1.86,   15.47] | 99.88% |        0% | 1.000 | 4173.00\nmuangular_IMPLICITimpasse:EXPLICITimg    |     0.79 | [  0.18,    3.39] | 62.05% |    19.32% | 1.002 | 3934.00\nmuangular_IMPLICITimpasse:EXPLICITixn    |     0.49 | [  0.10,    2.42] | 81.42% |    12.84% | 1.000 | 4285.00\nmutriangular_IMPLICITimpasse             |    15.93 | [  6.63,   37.61] |   100% |        0% | 1.002 |  810.00\nmutriangular_EXPLICITimg                 |   101.32 | [ 32.45,  310.15] |   100% |        0% | 1.005 |  807.00\nmutriangular_EXPLICITixn                 |   598.22 | [206.84, 1815.96] |   100% |        0% | 1.001 | 1344.00\nmutriangular_IMPLICITimpasse:EXPLICITimg |     0.57 | [  0.12,    2.88] | 74.97% |    14.91% | 1.003 | 1023.00\nmutriangular_IMPLICITimpasse:EXPLICITixn |     0.21 | [  0.04,    1.09] | 97.05% |     2.51% | 1.002 | 1233.00\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a MCMC distribution approximation.\n\n\nCODE\npaste(\"PROBABILITIES\")\n\n\n[1] \"PROBABILITIES\"\n\n\nCODE\n#PREDICT METHOD\nnewdata <- df_i %>% dplyr::select(IMPLICIT, EXPLICIT, subject, q)\npreds <- predict(m, newdata = newdata, type = \"response\")\npreds <- cbind(newdata, preds)\n# lengthen data frame to handle multinomial\npreds <- preds %>%\n  dplyr::select(-subject, -q) %>% #marginalize over subject and q\n  pivot_longer(\n  cols = ! IMPLICIT & !EXPLICIT,\n  values_to = \"preds\",\n  names_to = \"state\",\n)\n\n(p <- preds %>%\n  group_by(IMPLICIT, EXPLICIT , state ) %>%\n  summarise(\n    median = median(preds),\n    se = sd(preds)/sqrt(n()),\n    lwr = median - 1.96*se,\n    upr = median + 1.96*se))\n\n\n# A tibble: 24 × 7\n# Groups:   IMPLICIT, EXPLICIT [6]\n   IMPLICIT EXPLICIT state              median       se       lwr     upr\n   <fct>    <fct>    <chr>               <dbl>    <dbl>     <dbl>   <dbl>\n 1 control  none     P(Y = angular)    0.00417 0.000968  0.00227  0.00606\n 2 control  none     P(Y = orthogonal) 0.830   0.00777   0.814    0.845  \n 3 control  none     P(Y = other)      0.0597  0.00311   0.0536   0.0658 \n 4 control  none     P(Y = triangular) 0.0277  0.00797   0.0120   0.0433 \n 5 control  img      P(Y = angular)    0.00383 0.00148   0.000930 0.00674\n 6 control  img      P(Y = orthogonal) 0.109   0.0105    0.0887   0.130  \n 7 control  img      P(Y = other)      0.0399  0.00534   0.0294   0.0504 \n 8 control  img      P(Y = triangular) 0.813   0.0136    0.787    0.840  \n 9 control  ixn      P(Y = angular)    0.00233 0.00128  -0.000177 0.00484\n10 control  ixn      P(Y = orthogonal) 0.0379  0.00675   0.0247   0.0511 \n# … with 14 more rows\n\n\nCODE\n##DRAWS METHOD\n# GENERATE draws from model\n# draws <- df_i %>%\n#   data_grid(pretty_condition, subject, q) %>% \n#   add_fitted_draws(Bmm.cat.CrSQ,\n#                    # n = 100,\n#                    # dpar = TRUE,\n#                    # transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# # draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# #OR load from file\n# # draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_BB.catCrSQ.rds\")\n# \n# # SUMMARIZE draws from model\n# (k <- kable(draws %>%\n#   dplyr::select(pretty_condition, .category, .value) %>%\n#   group_by(pretty_condition, .category) %>%\n#   median_hdci(.value), digits = 4, col.names =\n#     c(\"Condition\",\"Category\", \"Probability\",\"Lower Cred.I\",\"Upper Cred.I\", \"CI Width\", \"Point Type\", \"Interval Type\")) %>%\n#   kable_styling())\n\n\n\n\nINFERENCE\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\n# plot_model(m, vline.color = \"red\",\n#            show.intercept = TRUE,\n#            show.values = TRUE,\n#            p.threshold = 0.1, #manually adjust to account for directional test\n#            ci.lvl = 0.90 ) + #manually adjusted for directional test\n#   labs(title = \"Model Estimate | Odds Ratio\",\n#        subtitle = \"\",\n#        x = \"Condition\")\n\n\n#EASYSTATS | MODEL | LOG ODDS RATIO\nresult <- model_parameters(m, exponentiate = FALSE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\nresult <- model_parameters(m, exponentiate = TRUE, component = \"all\")\nplot(result, show_intercept = TRUE, show_labels = TRUE) \n\n\n\n\n\nCODE\n# + theme_clean()\n\n## | PLOT TESTS\n\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\nPicking joint bandwidth of 0.0673\n\n\nWarning: Removed 10800 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\nCODE\nresult <- rope(m)\nplot(result)\n\n\n\n\n\nCODE\nresult <- pd(m) \nplot(result)\n\n\n\n\n\nCODE\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\nNote: uncertainty of error terms are not taken into account. You may want to use `rstantools::posterior_predict()`.\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\n# plot_model(m, type = \"pred\")  \n# plot_model(m, type = \"eff\")  \n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n\n\nCODE\n#::::: GGDIST POSTERIOR PROBABILITY OF RESPONSE\n##WORKING\n# https://mjskay.github.io/ggdist/reference/stat_slab.html\n## VIS probability of correct response\n#TAKES A REALLY LONG TIME\n\n#1 | get draws\n# draws <- df_i %>%\n#   data_grid(pretty_condition, ospan_split, subject, q) %>%\n#   add_epred_draws(m,\n#                    # ndraws = 100, # n = 100,\n#                    # dpar = TRUE,\n#                    transform = TRUE, #gives prob%, otherwise OR\n#                    re_formula = NA)\n# draws %>% write_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#OR load from file\n# draws <- read_rds(file = \"analysis/SGC3A/models/draws/draws_Bmm.catCOrSQ_OPSAN.rds\")\n\n#2| VISUALIZE PREDICTIONS | GGDIST\n##TODO figure out height normalization.\n##do it with much smaller number of draws \n#TODO adjust bandwidth/smoothing? + put on same line + \n#TAKES A REAAALY LONG TIME\n# d <- \n\n# d <- draws %>% sample_n(10) %>% \n#   ggplot(aes(x = .epred,  y = pretty_condition, fill = ospan_split)) +\n#   stat_slab(width = c(.95), alpha = 0.5, normalize=\"xy\") +\n#   facet_wrap(~.category) +\n#   #   #normalize = all, panels, xy, groups, none\n#   xlim(0,1) + labs(\n#     title = \"Model Predicted Probability of Correct Response\",\n#     x = \"probability of correct response\",\n#     y = \"Interpretation\"\n#   ) +  theme_clean() #+ ggeasy::easy_remove_legend() + ggeasy::easy_remove_y_axis()\n# # # #TO PLOT ON THE SAME LINE, INCLUDE Y = 0 in aes and ggeasy::remove_y_axis()\n# # # \n# # # ggsave(d, filename = \"figures/sgc3a_BBm.cat.CrSQ_lab_posterior.svg\", width = 6, height =4)\n# d\n\n\n#USING PREDS\n\npreds %>% \n  ggplot(aes (x = preds, y = EXPLICIT, fill = IMPLICIT)) +\n  stat_slab( normalize = \"xy\", alpha = 0.5) +\n  facet_grid(~ state)\n\n\n\n\n\n\n\nCODE\n#DISPLAY MODEL AS TABLE\ntab_model(m)\n\n\n'bayes_R2' is not defined for unordered categorical models.\n\n\n\n\n \nstate: other\nstate: angular\nstate: triangular\n\n\nPredictors\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\nOdds Ratios\nCI (95%)\n\n\nIntercept\n0.01\n0.00 – 0.03\n0.07\n0.03 – 0.16\n0.05\n0.02 – 0.10\n\n\nIMPLICIT: impasse\n8.99\n4.71 – 18.19\n7.78\n5.44 – 11.50\n15.93\n6.63 – 37.61\n\n\nEXPLICIT: img\n3.60\n1.28 – 9.65\n4.00\n2.31 – 7.30\n101.32\n32.45 – 310.15\n\n\nEXPLICIT: ixn\n5.62\n1.86 – 15.47\n4.08\n2.20 – 7.47\n598.22\n206.84 – 1815.96\n\n\nIMPLICITimpasse:EXPLICITimg\n0.79\n0.18 – 3.39\n1.80\n0.76 – 4.19\n0.57\n0.12 – 2.88\n\n\nIMPLICITimpasse:EXPLICITixn\n0.49\n0.10 – 2.42\n1.85\n0.74 – 5.06\n0.21\n0.04 – 1.09\n\n\nRandom Effects\n\n\n\nσ2\n-0.11\n\n\n\nτ00\n2.00\n\n\nICC\n-0.06\n\n\nN subject\n460\n\n\nN q\n13\n\nObservations\n5980\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m, \"(log odds)\" = m)\n# notes = list('\"* p < 0.05, ** p < 0.01, *** p < 0.001\"',\n#                'N(subject) = 133 $\\tau_{00}$(subject) = 34.85',\n#              'N(question) = 13 $\\tau_{00}$(question) = 1.14')\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)',\n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_online.tex\")\n# # #              # coef_omit = \"Intercept\",\n#TODO OUTPUT TABLE \n\n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n# modelsummary(m)\n\n\n\n\nDiagnostics\n\n\nCODE\n#CHECK Fit of posterior predictive to data\npp_check(m, ndraws=1000)\n\n\n\n\n\nCODE\n#CHECK posterior vs. priors\nresult <- estimate_density(m)\nplot(result, stack = FALSE, priors= TRUE)\n\n\n\n\n\nCODE\n#CHECK model\nplot(m)"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1b-q1-accuracy",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1b-q1-accuracy",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "H1B | Q1 ACCURACY",
    "text": "H1B | Q1 ACCURACY\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1) %>% dplyr::select(accuracy, pretty_condition, IMPLICIT, EXPLICIT)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = IMPLICIT,\n                       fill = accuracy)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~EXPLICIT) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Accuracy\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\npaste(\"Proportions of Correct Responses by Condition\")\n\n\n[1] \"Proportions of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n           \n            none-control none-impasse img-control img-impasse ixv-control\n  incorrect        0.862        0.741       0.660       0.357       0.355\n  correct          0.138        0.259       0.340       0.643       0.645\n  Sum              1.000        1.000       1.000       1.000       1.000\n           \n            ixv-impasse   Sum\n  incorrect       0.171 0.628\n  correct         0.829 0.372\n  Sum             1.000 1.000\n\n\nCODE\npaste(\"Number of Correct Responses by Condition\")\n\n\n[1] \"Number of Correct Responses by Condition\"\n\n\nCODE\ntable(df$accuracy, df$IMPLICIT, df$EXPLICIT) %>% addmargins(2) %>% #display sum for row\n      addmargins(1) #sanity check sum of columns\n\n\n, ,  = none\n\n           \n            control impasse Sum\n  incorrect     112     100 212\n  correct        18      35  53\n  Sum           130     135 265\n\n, ,  = img\n\n           \n            control impasse Sum\n  incorrect      33      15  48\n  correct        17      27  44\n  Sum            50      42  92\n\n, ,  = ixn\n\n           \n            control impasse Sum\n  incorrect      22       7  29\n  correct        40      34  74\n  Sum            62      41 103\n\n\n\n\nTESTS\n\n\nCODE\n#CHI SQUARE ON ACCURACY X OSPAN-SPLIT in LOW WORKING MEMORY\n# df_low <- df %>% filter(ospan_split == \"low-memory\")\n# # table(df_low$pretty_condition, df_low$accuracy)\n# chisq.test( x = df_low$pretty_condition, y = df_low$accuracy, correct = TRUE)\n# \n# #CHI SQUARE ON ACCURACY X OSPAN-SPLIT in HIGH WORKING MEMORY\n# df_high <- df %>% filter(ospan_split == \"high-memory\")\n# #table(df_high$pretty_condition, df_high$accuracy)\n# chisq.test( x = df_high$pretty_condition, y = df_high$accuracy,correct = TRUE)\n# #significant if correct = FALSE\n\n\n\n\nCODE\n# INTERACTION (IMPLICIT (VS) EXPLICIT)\ngrouped_ggbarstats( data = df, x = IMPLICIT, y = accuracy, \n                    grouping.var = EXPLICIT,\n                    type = \"nonparametric\")\n\n\n\n\n\nCODE\n# MAIN EFFECT CONDITION (yes)\nggbarstats( data = df, x = accuracy, y = pretty_condition,\n                    type = \"nonparametric\")\n\n\n\n\n\nCODE\n# MAIN EFFECT OSPAN (none)\n# ggbarstats( data = df, x = accuracy, y = ospan_split, \n#                     type = \"nonparametric\")\n\n\n\n\nLOGISTIC REGRESSION (MAIN EFFECT CONDITION)\nFit a logistic regression predicting accuracy (absolute score) (n = 460) by condition (k = 2).\n\n\nParameter estimate: \\(\\beta_{0}\\) = Log Odds of (correct) responses in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of correct response in CONTROL condition\nParameter estimate: \\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for correct response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of correct response in IMPASSE (vs) CONTROL\nNull hypothesis:\\(\\beta_{impasse} \\le 0\\) the odds for a correct response does not change, or decreases\nAlternative hypothesis: \\(\\beta_{impasse} \\gt 0\\) the odds of a correct response increases\n\n\nFit CONDITION Model\nFirst, we fit a logistic regression with condition as predictor, and compare its fit to an empty (intercept-only) model.\n\n\nCODE\n# MODEL FITTING ::::::::\n\n#: 1 EMPTY MODEL baseline glm model intercept only\nm.0 = glm(accuracy ~ 1, data = df, family = \"binomial\")\n# print(\"EMPTY MODEL\")\n# summary(m0)\n\n#: 2 CONDITION model\nm.C <- glm( accuracy ~ pretty_condition, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m1)\n\n#: 2 TEST SUPERIOR FIT\npaste(\"AIC wth predictor is lower than empty model?\", m.0$aic > m.C$aic)\n\n\n[1] \"AIC wth predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(m.0,m.C) #same as anova(m0, m1, test = \"Chi\")\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName | Model | df | df_diff |   Chi2 |      p\n---------------------------------------------\nm.0  |   glm |  1 |         |        |       \nm.C  |   glm |  6 |       5 | 111.03 | < .001\n\n\nCODE\npaste(\"Likelihood Ratio test is significant? p = \",(test_lrt(m.0,m.C))$p[2])\n\n\n[1] \"Likelihood Ratio test is significant? p =  2.48199746205697e-22\"\n\n\nCODE\n# summary(m.C)\n\n\n#: 4 FACTORIAL model\nm.IE <- glm( accuracy ~ IMPLICIT*EXPLICIT, data = df, family = \"binomial\")\n# print(\"PREDICTOR MODEL\")\n# summary(m.IE)\n# car::Anova(m.IE, type=3)\n\n#: 4 TEST SUPERIOR FIT\npaste(\"AIC with FACTORIAL lower than FLAT CONDITION only model?\", m.C$aic > m.IE$aic)\n\n\n[1] \"AIC with FACTORIAL lower than FLAT CONDITION only model? FALSE\"\n\n\nCODE\n#can't do lrt ... not nested models\n\n\n\n\nDescribe\n\n\nCODE\n#set model\nm <- m.IE\n\n# DESCRIBE MODEL ::::::::::::::::::::::::::::::::::::: \n\nprint(\"PREDICTOR MODEL [default two-tailed sig test]\")\n\n\n[1] \"PREDICTOR MODEL [default two-tailed sig test]\"\n\n\nCODE\nsummary(m)\n\n\n\nCall:\nglm(formula = accuracy ~ IMPLICIT * EXPLICIT, family = \"binomial\", \n    data = df)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.880  -0.775  -0.546   0.936   1.988  \n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   -1.828      0.254   -7.20  6.1e-13 ***\nIMPLICITimpasse                0.778      0.321    2.42    0.015 *  \nEXPLICITimg                    1.165      0.392    2.97    0.003 ** \nEXPLICITixn                    2.426      0.367    6.60  4.0e-11 ***\nIMPLICITimpasse:EXPLICITimg    0.473      0.544    0.87    0.385    \nIMPLICITimpasse:EXPLICITixn    0.204      0.588    0.35    0.728    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 607.08  on 459  degrees of freedom\nResidual deviance: 496.05  on 454  degrees of freedom\nAIC: 508.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nCODE\nprint(\"SIGNIFIGANCE TEST\")\n\n\n[1] \"SIGNIFIGANCE TEST\"\n\n\nCODE\ncar::Anova(m, type=3)\n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: accuracy\n                  LR Chisq Df Pr(>Chisq)    \nIMPLICIT               6.1  1      0.013 *  \nEXPLICIT              50.3  2    1.2e-11 ***\nIMPLICIT:EXPLICIT      0.8  2      0.683    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\n# MANUAL ONE-SIDED SIGTEST ::::::::::::::::::::::::::: \n\n# one-sided (right tail) z test for B COEFFICIENT\n#https://stats.stackexchange.com/questions/330655/strategy-for-a-one-sided-test-of-glms-coefficients\n\n#SANITY CHECK 2-tailed test should match the model output\n# tt <- 2*pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"p value for two-tailed test, null B = 0 : \",round(tt,3))\n# ot <- pnorm(summary(m)$coefficients[2:4], lower.tail = F)\n# paste(\"BUT we want a one tailed directional, null: B <= 0: \",round(ot,3))\n# paste(\"adjusted confint for directional hypothesis\")\n# (dcint <- confint(m, level = 0.90)) # get 90% for right side))\n# # https://stats.stackexchange.com/questions/20734/is-a-1-sided-90-prediction-interval-equivalent-to-a-2-sided-95-prediction-inte\n\n#:::::::: INTERPRET COEFFICIENTS\n\n# print(\"Confidence Interval —- LOG ODDS\")\n# confint(m1) #not adjusted for 1-tailed\n# print(\"Coefficients —- ODDS RATIOS\")\n# (e <- cbind( exp(coef(m)), exp(confint(m)))) #exponentiated, not adjusted\n# (e <- cbind( exp(coef(m)), exp(dcint))) #exponentiated, adjusted\n\n#TODO INTERACTIONS & ESTIMATED MARGINAL MEANS \n# print(\"MODEL PREDICTIONS\")\n# Retrieve predictions as probabilities \n# (for each level of the predictor)\n# pred.control <- predict(m,data.frame(pretty_condition=\"control\"),type=\"response\")\n#this should match : plogis(intercept coefficient)\n# paste(\"Probability of success in control,\", pred.control)\n# pred.impasse <- predict(m,data.frame(pretty_condition=\"impasse\"),type=\"response\")\n#this should match : plogis(intercept coefficient + predictor coeff)\n# paste(\"Probability of success in impasse,\", pred.impasse)\n\n\n\n\nInference\n\n\nVisualize\n\n\nCODE\n## | PLOT PARAMETERS \n\n#SJPLOT | MODEL | ODDS RATIO\nplot_model(m, vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) + #manually adjusted for directional test   \n  labs(title = \"Model Estimate | Odds Ratio\",\n       subtitle = \"\",\n       x = \"Condition\")\n\n\n\n\n\nCODE\n#EASYSTATS | MODEL | ODDS RATIO\n# result <- model_parameters(m, exponentiate = TRUE, component = \"all\")\n# plot(result)\n\n\n\n## | PLOT TESTS\nresult <- equivalence_test(m, rule = \"classic\", ci=0.9) #classic[tost], , bayes\nplot(result)\n\n\n\n\n\nCODE\n#ONLY FOR BAYESIAN VERSION\n# result <- rope(m)\n# plot(result)\n# \n# result <- pd(m)\n# plot(result)\n\n\n## | PLOT PREDICTIONS\n\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type=\"int\",\n           show.intercept = TRUE,\n           show.values = TRUE,\n           title = \"Model Prediction | Probability of Accurate Response\",\n           axis.title = c(\"Condition\",\"Probability of Accurate Response\"))\n\n\n\n\n\nCODE\n#PLOT MODEL PREDICTION\nplot_model(m, type = \"pred\")  \n\n\n$IMPLICIT\n\n\n\n\n\n\n$EXPLICIT\n\n\n\n\n\nCODE\nplot_model(m, type = \"eff\")  \n\n\n$IMPLICIT\n\n\n\n\n\n\n$EXPLICIT\n\n\n\n\n\nCODE\n  # ylim(0,1) + \n  # labs(\n  #   title = \"Model Prediction | Probability of Accurate Response\",\n  #   subtitle = \"Impasse increases Probability of Correct Response\"\n  # )\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \naccuracy\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.16\n0.09 – 0.26\n<0.001\n\n\nIMPLICIT [impasse]\n2.18\n1.17 – 4.16\n0.015\n\n\nEXPLICIT [img]\n3.21\n1.48 – 6.95\n0.003\n\n\nEXPLICIT [ixn]\n11.31\n5.61 – 23.79\n<0.001\n\n\nIMPLICIT [impasse] *EXPLICIT [img]\n1.60\n0.55 – 4.71\n0.385\n\n\nIMPLICIT [impasse] *EXPLICIT [ixn]\n1.23\n0.40 – 4.04\n0.728\n\n\nObservations\n460\n\n\nR2 Tjur\n0.234\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n\n\n\nDiagnostics\n\n\nCODE\n# print(\"SANITY CHECK REPORTING\")\n# report::report(m)\n\n#print(\"MODEL PERFORMANCE\")\n# performance(m)\n\nprint(\"MODEL DIAGNOSTICS\")\n\n\n[1] \"MODEL DIAGNOSTICS\"\n\n\nCODE\ncheck_model(m)"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1b-q1-interpretation-state",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#h1b-q1-interpretation-state",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "H1B | Q1 INTERPRETATION STATE",
    "text": "H1B | Q1 INTERPRETATION STATE\n\n“orthogonal” [reference category] includes orthogonal and satisficing responses ==> indicates a primarily orthogonal state of coordinate system understanding\n“other” includes: blank, reference point, responses that can’t be classified (including selecting all datapoints), => indicates an uncertain or unidentifiable state of coordinate system understanding, but one that is distinctly not orthogonal nor triangular\n“angular” includes ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n“triangular” includes correct triangular and ‘lines connecting’ responses as well as responses that include both orthogonal and triangular answers => indicates some degree of angular/triangular coordinate understanding\n\n\n\n\n\n\n\n\nResearch Question\nDoes Ss in the impasse condition produce less orthogonal responses on the first question?\n\n\n\n\nHypothesis\nH1A | Ss in the IMPASSE condition will have a higher likelihood of producing unknown and and triangle-like response states, relative to orthogonal response states, on the first question\n\n\nData\n\ndata: df_items where q == 1\noutcome: state ( 4 level factor from 5 level high_interpretation )\npredictor: condition [between-subjects factor]\n\n\n\nAnalysis Strategy\n\nMultinomial (Logistic) Regression on state predicted by condition\n\nAlternative:\n\nOrdinal regression on state; but model doesn’t satisfy proportional odds assumption (parallel slopes)\nMultinomial or Ordinal regression on high_interpretation (5 category interpretation state which distinguishes between uncertain (blank, reference) unclassifiable, triangle-like and true triangular.) There are some cells with zeros, however (no uncertain responses in control) which means the model can’t accurately estimate those comparisons\n\n\n\n\n\nSetup\n\n\nCODE\ndf <- df_items %>% filter(q==1) %>% \n  dplyr::select(pretty_condition, IMPLICIT, EXPLICIT, state)\n\n\n\n\nDescribe\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#:::::::: STACKED BAR CHART\ndf %>% \n  ggplot(data = .,\n         mapping = aes(x = IMPLICIT,\n                       fill = state)) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  facet_wrap(~EXPLICIT) +\n   labs(#y = \"Correct Response on Q 1\",\n       title = \"Q1 Interpretation\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\n\n\nCODE\n#::::::::::::DESCRIPTIVES\n\ntable(df$state, df$pretty_condition) %>% addmargins(2) %>% #display sum for row\n      prop.table(margin=2) %>%  #return proportion (of column)\n      addmargins(1) #sanity check sum of columns\n\n\n            \n             none-control none-impasse img-control img-impasse ixv-control\n  orthogonal       0.8077       0.2963      0.6200      0.0476      0.2581\n  other            0.0308       0.3333      0.0200      0.2381      0.0000\n  angular          0.0231       0.1111      0.0200      0.0714      0.0968\n  triangular       0.1385       0.2593      0.3400      0.6429      0.6452\n  Sum              1.0000       1.0000      1.0000      1.0000      1.0000\n            \n             ixv-impasse    Sum\n  orthogonal      0.0244 0.4239\n  other           0.0732 0.1370\n  angular         0.0732 0.0674\n  triangular      0.8293 0.3717\n  Sum             1.0000 1.0000\n\n\nCODE\n(t <- table(df$state, df$IMPLICIT, df$EXPLICIT) %>% addmargins(2) %>% #display sum for row\n      addmargins(1)) #sanity check sum of columns\n\n\n, ,  = none\n\n            \n             control impasse Sum\n  orthogonal     105      40 145\n  other            4      45  49\n  angular          3      15  18\n  triangular      18      35  53\n  Sum            130     135 265\n\n, ,  = img\n\n            \n             control impasse Sum\n  orthogonal      31       2  33\n  other            1      10  11\n  angular          1       3   4\n  triangular      17      27  44\n  Sum             50      42  92\n\n, ,  = ixn\n\n            \n             control impasse Sum\n  orthogonal      16       1  17\n  other            0       3   3\n  angular          6       3   9\n  triangular      40      34  74\n  Sum             62      41 103\n\n\n\n\nMULTINOMIAL REGRESSION\nDoes condition affect the response state of Q1?\nFit a logistic regression predicting interpretation state (k=3) by condition(k = 2).\n\n3 equations will be estimated (# categories - 1); each representing the odds of answering in that particular interpretation (vs) the reference category (orthogonal answer) [essentially a series of binary logistic regressions, but instead of incorrect/correct, comparing [reference category] vs [this category])\nFor each equation:\n\n\\(\\beta_{0}\\) = Log Odds of [this category type vs. reference category type) response in CONTROL condition\n\\(e^{\\beta_{0}}\\) = ODDS of [this category type vs. reference category type] response in CONTROL condition\n\\(\\beta_{1}\\) = \\(\\beta_{1impasse}\\) Log Odds (Log OR; change in odds for [this category] type response in impasse (vs) control [log scale])\n\\(e^{\\beta_{1}}\\) = ODDS RATIO of [this. vs reference category type] response in IMPASSE (vs) CONTROL\nTwo-tailed NHST Null hypothesis: \\(\\beta_{impasse} = 0\\) the odds for [this category of response vs. reference] are not different for IMPASSE condition\nAlternative hypothesis: \\(\\beta_{impasse} \\ne 0\\) the odds of [this category of response vs. reference] increases or decreases for IMPASSE condition\n\n\n\nFit CONDITION Model\n\n\nCODE\n#check reference level \nprint(\"Categories (first is reference)\")\n\n\n[1] \"Categories (first is reference)\"\n\n\nCODE\nlevels(df$state)\n\n\n[1] \"orthogonal\" \"other\"      \"angular\"    \"triangular\"\n\n\nCODE\n#FIT EMPTY MODEL\nprint(\"EMPTY MODEL\")\n\n\n[1] \"EMPTY MODEL\"\n\n\nCODE\ncatm.0 <- multinom(state ~ 1, data = df)\n\n\n# weights:  8 (3 variable)\ninitial  value 637.695406 \niter  10 value 545.433715\niter  10 value 545.433715\niter  10 value 545.433713\nfinal  value 545.433713 \nconverged\n\n\nCODE\n# summary(catm.0)\n\n#FIT PREDICTOR MODEL\nprint(\"CONDITION MODEL\")\n\n\n[1] \"CONDITION MODEL\"\n\n\nCODE\ncatm.C <- multinom(formula = state ~ pretty_condition, data = df, model = TRUE)\n\n\n# weights:  28 (18 variable)\ninitial  value 637.695406 \niter  10 value 430.703794\niter  20 value 421.878998\niter  30 value 421.798906\nfinal  value 421.798277 \nconverged\n\n\nCODE\n# summary(catm.C)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth CONDITION predictor is lower than empty model?\", catm.0$AIC > catm.C$AIC)\n\n\n[1] \"AIC wth CONDITION predictor is lower than empty model? TRUE\"\n\n\nCODE\ntest_lrt(catm.0, catm.C)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |    Model | df | df_diff |   Chi2 |      p\n--------------------------------------------------\ncatm.0 | multinom |  3 |         |        |       \ncatm.C | multinom | 18 |      15 | 247.27 | < .001\n\n\nCODE\n#FIT PREDICTOR MODEL\nprint(\"FACTORIAL MODEL\")\n\n\n[1] \"FACTORIAL MODEL\"\n\n\nCODE\ncatm.IE <- multinom(formula = state ~ IMPLICIT*EXPLICIT, data = df, model = TRUE)\n\n\n# weights:  28 (18 variable)\ninitial  value 637.695406 \niter  10 value 429.000996\niter  20 value 421.941225\niter  30 value 421.799294\nfinal  value 421.798289 \nconverged\n\n\nCODE\n# summary(catm.IE)\n# car::Anova(catm.IE)\n\n#COMPARE MODEL FIT\npaste(\"AIC wth FACTORIAL predictor is lower than empty model?\", catm.IE$AIC > catm.0$AIC)\n\n\n[1] \"AIC wth FACTORIAL predictor is lower than empty model? FALSE\"\n\n\nCODE\ntest_lrt(catm.0, catm.IE)\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName    |    Model | df | df_diff |   Chi2 |      p\n---------------------------------------------------\ncatm.0  | multinom |  3 |         |        |       \ncatm.IE | multinom | 18 |      15 | 247.27 | < .001\n\n\nAIC in predictor model is less than empty model, and likelihood ratio test indicates predictor model is significantly better fit to the sample data than the empty (intercept only) model.\n\n\nDescribe\n\n\nCODE\n#set model\nm <- catm.IE\n\n#::::::::INTERPRETATION\npaste(\"MODEL SUMMARY\")\n\n\n[1] \"MODEL SUMMARY\"\n\n\nCODE\nsummary(m)\n\n\nCall:\nmultinom(formula = state ~ IMPLICIT * EXPLICIT, data = df, model = TRUE)\n\nCoefficients:\n           (Intercept) IMPLICITimpasse EXPLICITimg EXPLICITixn\nother            -3.27            3.39      -0.165      -10.63\nangular          -3.56            2.58       0.122        2.57\ntriangular       -1.76            1.63       1.163        2.68\n           IMPLICITimpasse:EXPLICITimg IMPLICITimpasse:EXPLICITixn\nother                             1.66                      11.608\nangular                           1.26                      -0.495\ntriangular                        1.57                       0.981\n\nStd. Errors:\n           (Intercept) IMPLICITimpasse EXPLICITimg EXPLICITixn\nother            0.510           0.554       1.137     260.146\nangular          0.586           0.659       1.173       0.756\ntriangular       0.255           0.344       0.395       0.391\n           IMPLICITimpasse:EXPLICITimg IMPLICITimpasse:EXPLICITixn\nother                            1.392                      260.15\nangular                          1.517                        1.41\ntriangular                       0.864                        1.11\n\nResidual Deviance: 844 \nAIC: 880 \n\n\nCODE\ncar::Anova(m, type =3) #always type 3 for ixns \n\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: state\n                  LR Chisq Df Pr(>Chisq)    \nIMPLICIT              84.6  3    < 2e-16 ***\nEXPLICIT              64.7  6    4.9e-12 ***\nIMPLICIT:EXPLICIT      7.8  6       0.25    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\npaste(\"LOG ODDS\")\n\n\n[1] \"LOG ODDS\"\n\n\nCODE\ntidy(m)\n\n\n# A tibble: 18 × 6\n   y.level    term                        estimate std.error statistic  p.value\n   <chr>      <chr>                          <dbl>     <dbl>     <dbl>    <dbl>\n 1 other      (Intercept)                   -3.27      0.510   -6.41   1.42e-10\n 2 other      IMPLICITimpasse                3.39      0.554    6.11   9.82e-10\n 3 other      EXPLICITimg                   -0.165     1.14    -0.145  8.84e- 1\n 4 other      EXPLICITixn                  -10.6     260.      -0.0408 9.67e- 1\n 5 other      IMPLICITimpasse:EXPLICITimg    1.66      1.39     1.19   2.34e- 1\n 6 other      IMPLICITimpasse:EXPLICITixn   11.6     260.       0.0446 9.64e- 1\n 7 angular    (Intercept)                   -3.56      0.586   -6.07   1.27e- 9\n 8 angular    IMPLICITimpasse                2.58      0.659    3.91   9.39e- 5\n 9 angular    EXPLICITimg                    0.122     1.17     0.104  9.17e- 1\n10 angular    EXPLICITixn                    2.57      0.756    3.40   6.64e- 4\n11 angular    IMPLICITimpasse:EXPLICITimg    1.26      1.52     0.834  4.04e- 1\n12 angular    IMPLICITimpasse:EXPLICITixn   -0.495     1.41    -0.350  7.26e- 1\n13 triangular (Intercept)                   -1.76      0.255   -6.91   4.73e-12\n14 triangular IMPLICITimpasse                1.63      0.344    4.73   2.22e- 6\n15 triangular EXPLICITimg                    1.16      0.395    2.94   3.25e- 3\n16 triangular EXPLICITixn                    2.68      0.391    6.86   6.85e-12\n17 triangular IMPLICITimpasse:EXPLICITimg    1.57      0.864    1.82   6.87e- 2\n18 triangular IMPLICITimpasse:EXPLICITixn    0.981     1.11     0.882  3.78e- 1\n\n\nCODE\npaste(\"ODDS RATIO\")\n\n\n[1] \"ODDS RATIO\"\n\n\nCODE\ntidy(m, exponentiate = TRUE)\n\n\n# A tibble: 18 × 6\n   y.level    term                        estimate std.error statistic  p.value\n   <chr>      <chr>                          <dbl>     <dbl>     <dbl>    <dbl>\n 1 other      (Intercept)                  3.81e-2     0.510   -6.41   1.42e-10\n 2 other      IMPLICITimpasse              2.96e+1     0.554    6.11   9.82e-10\n 3 other      EXPLICITimg                  8.48e-1     1.14    -0.145  8.84e- 1\n 4 other      EXPLICITixn                  2.43e-5   260.      -0.0408 9.67e- 1\n 5 other      IMPLICITimpasse:EXPLICITimg  5.24e+0     1.39     1.19   2.34e- 1\n 6 other      IMPLICITimpasse:EXPLICITixn  1.10e+5   260.       0.0446 9.64e- 1\n 7 angular    (Intercept)                  2.86e-2     0.586   -6.07   1.27e- 9\n 8 angular    IMPLICITimpasse              1.31e+1     0.659    3.91   9.39e- 5\n 9 angular    EXPLICITimg                  1.13e+0     1.17     0.104  9.17e- 1\n10 angular    EXPLICITixn                  1.31e+1     0.756    3.40   6.64e- 4\n11 angular    IMPLICITimpasse:EXPLICITimg  3.54e+0     1.52     0.834  4.04e- 1\n12 angular    IMPLICITimpasse:EXPLICITixn  6.10e-1     1.41    -0.350  7.26e- 1\n13 triangular (Intercept)                  1.71e-1     0.255   -6.91   4.73e-12\n14 triangular IMPLICITimpasse              5.10e+0     0.344    4.73   2.22e- 6\n15 triangular EXPLICITimg                  3.20e+0     0.395    2.94   3.25e- 3\n16 triangular EXPLICITixn                  1.46e+1     0.391    6.86   6.85e-12\n17 triangular IMPLICITimpasse:EXPLICITimg  4.82e+0     0.864    1.82   6.87e- 2\n18 triangular IMPLICITimpasse:EXPLICITixn  2.67e+0     1.11     0.882  3.78e- 1\n\n\n\n\nINFERENCE\n\n\nVisualize\n\n\nCODE\n#:::::::: PLOT\n\n#SJPLOT | MODEL | ODDS RATIO\n#library(sjPlot)\nplot_model(m, type = \"est\",\n           vline.color = \"red\", \n           show.intercept = TRUE, \n           show.values = TRUE,\n           p.threshold = 0.1, #manually adjust to account for directional test\n           ci.lvl = 0.90 ) +  #manually adjusted for directional test   \n  # scale_y_continuous() + #remove to put on log scale x axis \n  # scale_x_discrete(labels=c(\"control\",\"impasse\"))+\n  labs(title = \"MODEL ESTIMATE  | Q1 Accuracy ~ condition\",\n       subtitle = \"Impasse increases odds of correct response on Q1\",\n       x = \"Condition\") + theme_clean()\n\n\n\n\n\nCODE\n#SJPLOT | MODEL | PROBABILITIES\nplot_model(m, type = \"int\") \n\n\n\n\n\nCODE\nplot_model(m, type=\"eff\", ci.lvl = 0.95) \n\n\n$IMPLICIT\n\n\n\n\n\n\n$EXPLICIT\n\n\n\n\n\nCODE\n# +  ylim(0,1) +\n#   labs(title = \"MODEL PREDICTION  | Q1 State ~ condition\",\n#        subtitle = \"Impasse increases probability of more accurate response states Q1\",\n#        x = \"Condition\") + theme_clean()\n\n#TODO ESTIMAED MARGINALS AND IXN PLOTS \n# https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html\n\n\n\n\nCODE\n#SJPLOT | MODEL | TABLE\ntab_model(m)\n\n\n\n\n \nstate\n\n\nPredictors\nOdds Ratios\nCI\np\nResponse\n\n\n(Intercept)\n0.04\n0.01 – 0.10\n<0.001\nother\n\n\nIMPLICIT [impasse]\n29.56\n9.95 – 87.81\n<0.001\nother\n\n\nEXPLICIT [img]\n0.85\n0.09 – 7.91\n0.884\nother\n\n\nEXPLICIT [ixn]\n0.00\n0.00 – 26890237206676851180659357231474401586319581534496059759925304797703258003531172558751853555730764093288464456003813246375993529953405397154597503190438627303676892440581086232580628533964212091366079345127455920750592.00\n0.967\nother\n\n\nIMPLICIT [impasse] *EXPLICIT [img]\n5.24\n0.34 – 80.93\n0.235\nother\n\n\nIMPLICIT [impasse] *EXPLICIT [ixn]\n109951.22\n0.00 – 122503716766342913005856662309396962294807819254143349107684749616859499401894725824666072930757279077555234659963245699512125516689553378572634612498458224596411002868095396480828924069285855879174390479243492606106887727874048.00\n0.964\nother\n\n\n(Intercept)\n0.03\n0.01 – 0.09\n<0.001\nangular\n\n\nIMPLICIT [impasse]\n13.13\n3.59 – 47.98\n<0.001\nangular\n\n\nEXPLICIT [img]\n1.13\n0.11 – 11.32\n0.917\nangular\n\n\nEXPLICIT [ixn]\n13.13\n2.97 – 58.07\n0.001\nangular\n\n\nIMPLICIT [impasse] *EXPLICIT [img]\n3.54\n0.18 – 69.76\n0.405\nangular\n\n\nIMPLICIT [impasse] *EXPLICIT [ixn]\n0.61\n0.04 – 9.80\n0.726\nangular\n\n\n(Intercept)\n0.17\n0.10 – 0.28\n<0.001\ntriangular\n\n\nIMPLICIT [impasse]\n5.10\n2.59 – 10.05\n<0.001\ntriangular\n\n\nEXPLICIT [img]\n3.20\n1.47 – 6.96\n0.003\ntriangular\n\n\nEXPLICIT [ixn]\n14.58\n6.77 – 31.43\n<0.001\ntriangular\n\n\nIMPLICIT [impasse] *EXPLICIT [img]\n4.82\n0.88 – 26.36\n0.069\ntriangular\n\n\nIMPLICIT [impasse] *EXPLICIT [ixn]\n2.67\n0.30 – 23.70\n0.378\ntriangular\n\n\nObservations\n460\n\n\nR2 / R2 adjusted\n0.227 / 0.225\n\n\n\n\n\n\nCODE\n# #MODEL SUMMARY | save latex table\n# models <- list(\"odds ratios\" = m1, \"(log odds)\" = m1)\n# notes = list(\"* p < 0.05, ** p < 0.01, *** p < 0.001\",\n#              '$sigma^{2}$ = 3.29\" N(subject) = 126 $\\tau_{00}$(subject) = 22.22 N(question) = 13 $\\tau_{00}$(question) = 0.31'\n#                )\n# \n# modelsummary(models,\n#              exponentiate = c(TRUE, FALSE),\n#              shape = term ~ model + statistic,\n#              fmt = 2, #two digits w/ trailing zero\n#              estimate  = \"{estimate} {stars}\",\n#              statistic = \"conf.int\",\n#              gof_map = c(\"AIC\", \"sigma\"),\n#              gof_omit = 'RMSE|ICC|BIC',\n#              coef_rename = c(\"pretty_conditionimpasse\" = \"Condition[impasse]\"),\n#              title = 'Accuracy ~ Condition (Mixed Logistic Regression)', \n#              notes = notes,\n#              output = \"analysis/SGC3A/models/tables/GLMER_OverallAccuracy_lab.tex\")\n# #              # coef_omit = \"Intercept\",\n\n# modelsummary(mixcat.1, s)\n#TODO OUTPUT TABLE \n#https://arelbundock.com/posts/modelsummary_multinomial_logit/\n\n\n\n\nDiagnostics\n\n\nCODE\n#EXAMINE PREDICTIONS\n#create sample data frame\n# test <- data.frame(pretty_condition = c(\"control\", \"impasse\"))\n# pred <- predict(m, newdata = test, \"probs\")\n# paste(\"Predicted Probability of Being in Each State\")\n# ( x <- cbind(test, pred))\n# \n# print(\"MODEL PERFORMANCE\")\n# performance(m)\n# DescTools::PseudoR2(m, which = c(\"McFadden\", \"CoxSnell\", \"Nagelkerke\"))"
  },
  {
    "objectID": "analysis/SGC3B/4_sgc3B_hypotesting.html#explore-specific-question",
    "href": "analysis/SGC3B/4_sgc3B_hypotesting.html#explore-specific-question",
    "title": "11  SGC3B (Impasse * Explicit) Hypothesis Testing",
    "section": "EXPLORE specific question",
    "text": "EXPLORE specific question\n\n\nCODE\n# \n# df <- df_items %>% filter(q==10)\n# grouped_ggbarstats( data = df, x = accuracy, y = pretty_condition, grouping.var = ospan_split)"
  },
  {
    "objectID": "analysis/SGC4A/1_sgc4A_introduction.html",
    "href": "analysis/SGC4A/1_sgc4A_introduction.html",
    "title": "12  Introduction",
    "section": "",
    "text": "In Study 4A we explore the extent to which the design of the axes and gridlines of the graph influence how a reader interprets its underlying coordinate system.\nExperimental Hypothesis:\nWe hypothesize that the design of the major axes (specifically orthogonal) axes establish for the learner the basis of the coordinate system. Differently oriented axes should lead the reader to be more open to alternative coordinate systems.\nExploratory Questions"
  },
  {
    "objectID": "analysis/SGC4A/1_sgc4A_introduction.html#methods",
    "href": "analysis/SGC4A/1_sgc4A_introduction.html#methods",
    "title": "12  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 4 levels (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 19.1. The list of questions can be found here.\n\n\n\nFigure 12.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items : the Graph Comprehension Task\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData were collected by convenience sample of a university subject pool during the winter of 2022. Participants accessed the study via a web browser (asynchronously). The stimulus application required the participant stay in full-screen mode for the entirety of the study."
  },
  {
    "objectID": "analysis/SGC4A/1_sgc4A_introduction.html#analysis",
    "href": "analysis/SGC4A/1_sgc4A_introduction.html#analysis",
    "title": "12  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\n\n\n\nPre-Requisite\nFollowed By\n\n\n\n\nwinter2022_clean_sgc4a.Rmd\n2_sgc4A_scoring.qmd\n\n\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC4A/data/0-session-level/fall17_sgc4a_participants.csv\"\nspring18 <- \"analysis/SGC4A/data/0-session-level/spring18_sgc4a_participants.csv\"\nwinter22 <- \"analysis/SGC4A/data/0-session-level/winter22_sgc4a_participants.rds\"\nsummer22 <- \"analysis/SGC4A/data/0-session-level/su22_sgc4a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\ndf_subjects_summer22 <- read_rds(summer22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,pretty_condition, term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    condition = as.factor(condition),\n    pretty_condition = \"NULL\",\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, pretty_condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  dplyr::select(subject, condition, pretty_condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\ndf_subjects_summer22 <- df_subjects_summer22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#compare dataframe columns\n# janitor::compare_df_cols(df_subjects, df_subjects_winter22, df_subjects_before)\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_summer22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\",\"summer22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#REFACTOR CONDITIONS\ndf_subjects <- df_subjects %>% mutate(\n    condition = recode_factor(condition, \"11111\" = \"111\", \"112\" = \"112\", \"111\" = \"111\", \"113\" = \"113\", \"114\" = \"114\", \"115\"=\"115\"),\n    pretty_condition = recode_factor(condition, \"111\" = \"Orth-Full\", \"114\" =  \"Orth-Sparse\", \"115\"=\"Orth-Grid\",\"113\"=\"Tri-Sparse\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_subjects_fall17, df_subjects_spring18, df_subjects_winter22,df_subjects_before, df_subjects_summer22)\nrm(fall17,spring18,winter22, summer22)\n\n#FINALLY DROP CONDITION 112 (partial orthog with y axis lines extending only to right end of triangle)\n#this was an incomplete [pilot only] condition collected in FA17 SP18 for pilot purposes\ndf_subjects <- df_subjects %>% filter(condition != \"112\") %>% \n  mutate(\n    condition = droplevels(condition),\n    pretty_condition = droplevels(pretty_condition)\n  )\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC4A/data/0-session-level/fall17_sgc4a_blocks.csv\"\nspring18 <- \"analysis/SGC4A/data/0-session-level/spring18_sgc4a_blocks.csv\"\nwinter22 <- \"analysis/SGC4A/data/0-session-level/winter22_sgc4a_items.rds\"\nsummer22 <- \"analysis/SGC4A/data/0-session-level/su22_sgc4a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\ndf_items_summer22 <- read_rds(summer22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% select(q,relation) %>% unique()\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n\n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\ndf_items_summer22 <- df_items_summer22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22, df_items_summer22, df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\",\"summer22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_winter22_q16 <- df_winter22_q16 %>% dplyr::select(-pretty_condition)\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#REFACTOR CONDITIONS\ndf_items <- df_items %>% mutate(\n    condition = recode_factor(condition, \"11111\" = \"111\", \"112\" = \"112\", \"111\" = \"111\", \"113\" = \"113\", \"114\" = \"114\", \"115\"=\"115\"),\n    pretty_condition = recode_factor(condition, \"111\" = \"Orth-Full\", \"114\" =  \"Orth-Sparse\", \"115\"=\"Orth-Grid\",\"113\"=\"Tri-Sparse\"),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16, df_items_summer22)\nrm(fall17,spring18,winter22, map_relations, summer22)\n\n#FINALLY DROP CONDITION 112 (partial orthog with y axis lines extending only to right end of triangle)\n#this was an incomplete [pilot only] condition collected in FA17 SP18 for pilot purposes\ndf_items <- df_items %>% filter(condition != \"112\") %>% \n  mutate(\n    condition = droplevels(condition),\n    pretty_condition = droplevels(pretty_condition)\n  )\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4A/data/1-study-level/sgc4a_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4A/data/1-study-level/sgc4a_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC4A/data/1-study-level/sgc4a_freeresponse.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4A/data/1-study-level/sgc4a_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4A/data/1-study-level/sgc4a_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4A/1_sgc4A_introduction.html#resources",
    "href": "analysis/SGC4A/1_sgc4A_introduction.html#resources",
    "title": "12  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9      purrr_0.3.4     \n [5] readr_2.1.2      tidyr_1.2.0      tibble_3.1.7     ggplot2_3.3.6   \n [9] tidyverse_1.3.1  kableExtra_1.3.4 codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.8.3      svglite_2.1.0     lubridate_1.8.0   assertthat_0.2.1 \n [5] digest_0.6.29     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n [9] backports_1.4.1   reprex_2.0.1      labelled_2.9.1    evaluate_0.15    \n[13] httr_1.4.3        highr_0.9         pillar_1.7.0      rlang_1.0.3      \n[17] curl_4.3.2        readxl_1.4.0      data.table_1.14.2 rstudioapi_0.13  \n[21] rmarkdown_2.14    webshot_0.5.3     foreign_0.8-82    htmlwidgets_1.5.4\n[25] bit_4.0.4         munsell_0.5.0     broom_0.8.0       compiler_4.2.1   \n[29] modelr_0.1.8      xfun_0.31         pkgconfig_2.0.3   systemfonts_1.0.4\n[33] htmltools_0.5.2   tidyselect_1.1.2  rio_0.5.29        fansi_1.0.3      \n[37] viridisLite_0.4.0 crayon_1.5.1      tzdb_0.3.0        dbplyr_2.2.1     \n[41] withr_2.5.0       grid_4.2.1        jsonlite_1.8.0    gtable_0.3.0     \n[45] lifecycle_1.0.1   DBI_1.1.3         magrittr_2.0.3    scales_1.2.0     \n[49] zip_2.2.0         cli_3.3.0         stringi_1.7.6     vroom_1.5.7      \n[53] fs_1.5.2          xml2_1.3.3        ellipsis_0.3.2    generics_0.1.2   \n[57] vctrs_0.4.1       openxlsx_4.2.5    tools_4.2.1       bit64_4.0.5      \n[61] glue_1.6.2        hms_1.1.1         parallel_4.2.1    fastmap_1.1.0    \n[65] yaml_2.3.5        colorspace_2.0-3  rvest_1.0.2       knitr_1.39       \n[69] haven_2.5.0"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html",
    "title": "13  Response Scoring",
    "section": "",
    "text": "The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC4A study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#score-sgc-data",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#score-sgc-data",
    "title": "14  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_both <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_both\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_items.rds')\n\n#ADD TEMP IMPASSE COLUMN\ndf_items <- df_items %>% mutate(\n  IMPASSE = substr(condition,2,2),\n  IMPASSE = recode_factor(IMPASSE, \"1\"=\"none\", \"2\"=\"IMPASSE\")\n)\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n# backup <- df_items\n# df_items <- backup %>%  sample_n(200)\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tri))\n\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response,  MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_BOTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_both))\n\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\n\n#OLD score_BOTH... new one is above (explicitly in key)\n# df_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items #%>% head(16) %>% tail(1)\ntemp <- derive_interpretation(temp)\n\n\n[1] \"DERIVING INTERPRETATION\"\n\n\nCODE\ndf_items <- temp\n\n\n\n\n? SPECIAL EXCEPTIONS\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nALSO reconciles issues when interpetation == triangular but scoreniceabs = 0 ::: {.cell}\n\nCODE\n# #temp setup for protection\n# backup <- df_items\ntemp <- df_items %>% mutate(\n  override = \"\"\n)\n\n## CONTROL. Q==1. \"FK\" derives as 'TRI', should be tversky start\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==1) & (IMPASSE ==\"none\") & (response == \"FK\"),\n  tv_type = \"score_TV_start\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"TRI\"\n)\n\n## IMPASS Q==2. \"EK\" derives as 'TRI', should be tversky MAX\ntemp <- temp %>% mutate_when(\n  (q==2) & (IMPASSE ==\"IMPASSE\") & (response == \"EK\"),\n  tv_type = \"score_TV_max\",\n  int2 = \"Tversky\", #override from TRI\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n## CONTROL. Q==3. \"A\" derives as 'unknown', should be tversky duration\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"A\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n\n## CONTROL  Q==3 \"AF\" derives as TRI. hardcode as \"both\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"AF\"),\n  int2 = \"both tri + orth\", #override from TRI\n  interpretation = \"both tri + orth\", #override from TRI\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## CONTROL  Q==3 \"EFK\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"EFK\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL  Q==3 \"FG\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"FG\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASS  Q==3 \"AF\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE  Q==3 \"AFG\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE  Q==3 \"AH\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AH\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n## IMPASSE  Q==3 \"AO\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE  Q==3 \"AOU\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AOU\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## CONTROL Q==4 AH Derives as TRI RECODE as TVERSKY\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response %in% c(\"AH\",\"HK\")),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 HJ DERIVES as TRI Recode as ?\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"HJ\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 DEU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 DEOU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEOU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 KU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"KU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## IMPASSE Q==4 BD Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BD\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 BDEG Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BDEG\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 AFG Derives as SATISFICE RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from Satisfice\n  interpretation = \"?\", #override from Satisfice\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE Q==4 DH Derives as TRI RECODE as BOTH\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"DH\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AU Derives as TRI RECODE as satisfice\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AU\"),\n  int2 = \"Satisfice\", #override from Triangular\n  interpretation = \"Satisfice\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AZ Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AZ\"),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AFG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n\n## IMPASSE Q==5 AF Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5  Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"FO\",\"JO\") ),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 FO, HO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"HO\",\"FO\",\"DJO\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 KO Derives as TRI RECODE as tversky_duration\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response == \"KO\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n##  Q==7 HOX, OX Derives as TRI but incorrect\n#includes H which is at rather than under 5 hours.\n#give credit \ntemp <- temp %>% mutate_when(\n  (q==7)  & (response %in% c(\"HOX\", \"OX\")),\n  score_niceABS = 1\n)\n\n##  Q==7 AX, MO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MO\",\"AX\",\"FJOX\")) ,\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==7 MOX, MX  Derives as TRI RECODE as tversky\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MOX\", \"MX\", \"DX\",\"O\",\"X\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8) & (response %in% c(\"CFGO\",\"BFG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AGK Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AGK\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 FG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response %in% c(\"FG\",\"CG\",\"CFG\",\"CGM\",\"CM\",\"ACGP\",\"GM\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==11 M Derives as TRI MISSING RESPONSE\n##LEAVE AS TRI + OVERRIDE SCORENABS\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"M\",\"L\") ),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==11 BLM Derives as TRI set at both\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response == \"BLM\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at ORTH\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"AGM\")),\n  int2 = \"Orthogonal\",\n  interpretation = \"Orthogonal\", \n  high_interpretation = \"orthogonal\", \n  override = \"Triangular\"\n)\n##  Q==11 EKM Derives as TRI set at other\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"EKM\",\"JM\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at Angular\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"KL\",\"MOX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==12 Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==12)  & (response %in% c(\"GP\", \"EG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 E Derives as TRI but incorrect\n##LEAVE AS TRI + OVERRIDE SCORENABS\n##one of two correct answers\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response == \"E\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==13 CE Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"CE\",\"EH\")),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 EO Derives as TRI set at ?\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"EO\")),\n  int2 = \"?\", \n  interpretation = \"?\", \n  high_interpretation = \"neg.trans\", \n  override = \"Triangular\"\n)\n\n##  Q==14  Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response %in% c(\"FX\",\"CX\",\"EFX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 OX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"OX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 EX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"EX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 CX Derives as TRI but incorrect \n#within visual margin... give credit\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"CX\",\"KO\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n#  Q==15  Derives as TRI but incorrect \n#missing 1 right answer or within 0.5hr visual error \ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"X\",\"CK\",\"K\",\"GKX\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==15 DJNX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"DJNX\", \"OX\", \"AK\",\"DNX\")),\n  # tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 AKPX Derives as TRI set at OTHER\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"AKPX\",\"GK\",\"JX\",\"LX\",\"BK\",\"HK\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n#SET BACK\ndf_items <- temp\n\n:::\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#summarize-by-subject",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#summarize-by-subject",
    "title": "14  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC4A/data/1-study-level/sgc4a_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#explore-distributions",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#explore-distributions",
    "title": "14  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_wrap(~pretty_condition)+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE TEST PHASE\ngf_props(~item_test_NABS, fill = ~pretty_condition, \n             data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Absolute Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE TEST PHASE\ngf_histogram(~item_test_SCALED, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Scaled Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Scaled Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_SCALED,\n                type = \"non-parametric\",\n                title = \"Total Scaled Score [directional test]\")\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\nggbarstats( data = df, x = score_STATE, y = pretty_condition)\n\n\n\n\n\nCODE\nggbarstats( data = df, x = high_interpretation, y = pretty_condition)\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"Impasse shifts density toward higher Triagular scores\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#peeking",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#peeking",
    "title": "13  Response Scoring",
    "section": "PEEKING",
    "text": "PEEKING\n\n\nCODE\nlibrary(performance)\nlibrary(report)\n# m1 <- lm(s_SCALED ~ pretty_condition, data = df_subjects)\n# summary(m1)\n# anova(m1)\n# report(m1)"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#export",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#export",
    "title": "14  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects), as well as cumulative progress dataframes (df_absolute_progress, df_scaled_progress)\n\n\nCODE\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4A/data/2-scored-data/sgc4a_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4A/data/2-scored-data/sgc4a_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4A/data/2-scored-data/sgc4a_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4A/data/2-scored-data/sgc4a_scored_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#resources",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#resources",
    "title": "13  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      performance_0.9.1 forcats_0.5.1     stringr_1.4.0    \n [5] dplyr_1.0.9       purrr_0.3.4       readr_2.1.2       tidyr_1.2.0      \n [9] tibble_3.1.7      tidyverse_1.3.1   Hmisc_4.7-0       Formula_1.2-4    \n[13] survival_3.3-1    lattice_0.20-45   pbapply_1.5-0     ggformula_0.10.1 \n[17] ggridges_0.5.3    scales_1.2.0      ggstance_0.3.5    ggplot2_3.3.6    \n[21] kableExtra_1.3.4 \n\nloaded via a namespace (and not attached):\n [1] fs_1.5.2            bit64_4.0.5         lubridate_1.8.0    \n [4] insight_0.18.0      webshot_0.5.3       RColorBrewer_1.1-3 \n [7] httr_1.4.3          tools_4.2.1         backports_1.4.1    \n[10] utf8_1.2.2          R6_2.5.1            rpart_4.1.16       \n[13] DBI_1.1.3           colorspace_2.0-3    nnet_7.3-17        \n[16] withr_2.5.0         tidyselect_1.1.2    gridExtra_2.3      \n[19] curl_4.3.2          bit_4.0.4           compiler_4.2.1     \n[22] cli_3.3.0           rvest_1.0.2         htmlTable_2.4.0    \n[25] xml2_1.3.3          labeling_0.4.2      mosaicCore_0.9.0   \n[28] checkmate_2.1.0     systemfonts_1.0.4   digest_0.6.29      \n[31] foreign_0.8-82      rmarkdown_2.14      svglite_2.1.0      \n[34] rio_0.5.29          base64enc_0.1-3     jpeg_0.1-9         \n[37] pkgconfig_2.0.3     htmltools_0.5.2     labelled_2.9.1     \n[40] dbplyr_2.2.1        fastmap_1.1.0       readxl_1.4.0       \n[43] htmlwidgets_1.5.4   rlang_1.0.3         rstudioapi_0.13    \n[46] farver_2.1.0        generics_0.1.2      jsonlite_1.8.0     \n[49] vroom_1.5.7         zip_2.2.0           magrittr_2.0.3     \n[52] Matrix_1.4-1        Rcpp_1.0.8.3        munsell_0.5.0      \n[55] fansi_1.0.3         lifecycle_1.0.1     stringi_1.7.6      \n[58] yaml_2.3.5          MASS_7.3-57         plyr_1.8.7         \n[61] grid_4.2.1          parallel_4.2.1      crayon_1.5.1       \n[64] haven_2.5.0         splines_4.2.1       hms_1.1.1          \n[67] knitr_1.39          pillar_1.7.0        reprex_2.0.1       \n[70] glue_1.6.2          evaluate_0.15       latticeExtra_0.6-29\n[73] data.table_1.14.2   modelr_0.1.8        tzdb_0.3.0         \n[76] png_0.1-7           vctrs_0.4.1         tweenr_1.0.2       \n[79] cellranger_1.1.0    gtable_0.3.0        polyclip_1.10-0    \n[82] datawizard_0.4.1    assertthat_0.2.1    openxlsx_4.2.5     \n[85] xfun_0.31           ggforce_0.3.3       broom_0.8.0        \n[88] viridisLite_0.4.0   cluster_2.1.3       ellipsis_0.3.2"
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html",
    "href": "analysis/SGC4A/3_sgc4A_description.html",
    "title": "14  Description",
    "section": "",
    "text": "TODO check term cell counts and decide if data is pilot or included ? The purpose of this notebook is describe the distributions of dependent variables for Study SGC4A.\nTEMP REMOVE IN PERSON DATA ::: {.cell}\n:::"
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html#sample",
    "href": "analysis/SGC4A/3_sgc4A_description.html#sample",
    "title": "14  Description",
    "section": "SAMPLE",
    "text": "SAMPLE\n\nData Collection\nData were collected online in Winter 2022.\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Orth-Full\", \"Orth-Sparse\",\"Orth-Grid\", \"Tri-Sparse\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Orth-Full \n    Orth-Sparse \n    Orth-Grid \n    Tri-Sparse \n    Total for Period \n  \n \n\n  \n    winter22 \n    88 \n    86 \n    88 \n    98 \n    360 \n  \n  \n    Sum \n    88 \n    86 \n    88 \n    98 \n    360 \n  \n\n\n\n\n\n\n\nParticipants\n\n\nCODE\n#Describe participants\nsubject.stats <-df_subjects %>% dplyr::select(age) %>% unlist() %>% favstats()\nsubject.stats$percent.female <- df_subjects %>% filter(gender==\"Female\") %>% count() %>% unlist()/nrow(df_subjects)\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()%>% \n  footnote(general = \"Age in Years\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    percent.female \n  \n \n\n  \n     \n    18 \n    19 \n    20 \n    21 \n    37 \n    20.5 \n    2.29 \n    360 \n    0 \n    0.722 \n  \n\n\nNote:   Age in Years\n\n\n\n\n360 participants (72 % female ) undergraduate STEM majors at a public American University participated in exchange for course credit (age: 18 - 37 years)."
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html#response-accuracy",
    "href": "analysis/SGC4A/3_sgc4A_description.html#response-accuracy",
    "title": "14  Description",
    "section": "RESPONSE ACCURACY",
    "text": "RESPONSE ACCURACY\n\nSubject Level Scores\nSubject level scores summarize the the response accuracy by a particular participant across all discriminant items in the graph comprehension task.\n\nTask Absolute Score\nRecall from ?sec-absolute-scoring that the absolute score (following the dichotomous scoring approach) s_NABS indicates if the subject’s response for a particular item was perfectly correct: whether they selected all correct answer options and no others (excluding certain allowed exceptions, such as also selecting the data point referenced in the question). Across the entire task, there ae 13 strategy discriminating questions.\n\n\nCODE\ntitle = \"Descriptive Statistics of Task Response Accuracy (Total Absolute Score)\"\nabs.stats <- df_subjects %>% dplyr::select(s_NABS) %>% unlist() %>% favstats()\nabs.stats %>% kbl (caption = title) %>% kable_classic() %>% \n  footnote(general = \"# questions correct [0,13]\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nDescriptive Statistics of Task Response Accuracy (Total Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0 \n    0 \n    0 \n    2 \n    13 \n    2.22 \n    4.02 \n    360 \n    0 \n  \n\n\nNote:   # questions correct [0,13]\n\n\n\n\nWhen combined overall, total absolute accuracy scores in the TEST phase (n = 360) range from 0 to 13 with a slightly lower mean score of (M = 2.22, SD = 4.02).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL ABSOLUTE\n  gf_props(~s_NABS, data = df_subjects) + \n  labs(x = \"number of correct responses\",\n       y = \"% of subjects\",\n       title = \"Distribution of Task Absolute Score \",\n       subtitle = \"\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"s_NABS\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\")) +\n  labs( title = \"Distribution of Task Absolute Score\",\n        subtitle =\"\",\n        x = \"Total Absolute Score\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = s_NABS,\n                        fill = pretty_condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = s_NABS),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = s_NABS, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of Task Absolute Score \",\n    x = \"Condition\", y = \"Total Absolute Score \") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbetweenstats(y = s_NABS, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\nCODE\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(s_NABS)) + \n  stat_ecdf(geom = \"step\") +\n  facet_grid(pretty_condition~pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — Task Absolute Score \",\n        x = \"Total Absolute Score [0,13]\", \n        y = \"Cumulative Probability\")\n\n\n\n\n\nVisual inspection of this distribution suggests it is not normal, and perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).\n\n\nCODE\nmultimode::modetest(df_subjects$s_NABS)\n\n\nWarning in multimode::modetest(df_subjects$s_NABS): A modification of the data\nwas made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$s_NABS\nExcess mass = 0.06, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\n# n_modes = multimode::nmodes(df_subjects$s_NABS, bw=2) #bw = 2questions/15 = 0.15%\n# l_modes = multimode::locmodes(df_subjects$s_NABS,mod0 =  n_modes, display = TRUE)\n\n\nThe excess mass test for multimodality suggests there is not enough mass at the positive end of the score distribution to be considered multimodal.\n\n\nTask Scaled Scores\nThe total scaled score s_SCALED summarizes the scaled score on the 13 strategy-discriminant questions, for each subject. This score ranges from from -13 (all orthogonal) to 13 (all triangular). Recall that the s_SCALED score for an item is a numeric representation of the strategy-consistent response, scaled from -1 to +1 (see Section 4.1.4)\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy\"\nscaled.stats <- df_subjects %>% dplyr::select(s_SCALED) %>% unlist() %>% favstats()\nscaled.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    -13 \n    -12.5 \n    -10.5 \n    -5 \n    13 \n    -6.58 \n    8.23 \n    360 \n    0 \n  \n\n\n\n\n\nOverall, task scaled scores (n = 360) range from -13 to 13 with a slightly lower mean score of (M = -6.58, SD = 8.23).\n\n\nCODE\n#GGFORMULA | DENSITY HISTOGRAM SUBJECT TOTAL SCALED\ngf_props(~item_test_SCALED, data = df_subjects) +\n  labs(x = \"total scaled score\",\n       y = \"% of subjects\",\n       title = \"Distribution of Scaled Score \",\n       subtitle = \"Modes at high and low ends of scale suggest concentration of high (vs) low understanding\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"s_SCALED\",binwidth=1,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE) \nfacet(p, facet.by=c(\"pretty_condition\")) + \n  labs( title = \"Distribution of Scaled Score\",\n        subtitle =\"\",\n        x = \"total scaled score\", y = \"number of participants\") + \n theme_minimal() + theme(legend.position = \"blank\") \n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = s_SCALED,\n                        fill = pretty_condition) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.1,\n    width = 1, \n    point_colour = NA\n   ) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = s_SCALED),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = s_SCALED, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  )) + labs( \n    title = \"Distribution of Task Scaled Score\",\n    x = \"Condition\", y = \"Total Scaled \") +\n  theme(legend.position = \"blank\") + \n  coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbetweenstats(y = s_SCALED, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\nCODE\n#PLOT EMPIRICIAL CUMULATIVE DISTRIBUTION FUNCTION\nggplot(data = df_subjects, aes(s_SCALED)) + \n  stat_ecdf(geom = \"step\") + \n  facet_grid(pretty_condition ~ pretty_mode) + \n  labs( title = \"Empirical Cumulative Density Function — Task Scaled Score\",\n        x = \"Test Phase Scaled Score [-13,13]\", \n        y = \"Cumulative Probability\") \n\n\n\n\n\nVisual inspection of this distribution suggests it is not normal, and perhaps perhaps bimodal. We verify this via an excess mass test (Ameijeiras-Alsonso et. al 2018).\n\n\nCODE\nmultimode::modetest(df_subjects$s_SCALED)\n\n\nWarning in multimode::modetest(df_subjects$s_SCALED): A modification of the data\nwas made in order to compute the excess mass or the dip statistic\n\n\n\n    Ameijeiras-Alonso et al. (2019) excess mass test\n\ndata:  df_subjects$s_SCALED\nExcess mass = 0.07, p-value <2e-16\nalternative hypothesis: true number of modes is greater than 1\n\n\nCODE\n# n_modes = multimode::nmodes(df_subjects$s_SCALED, bw=2) #bw = 2questions/15 = 0.15%\n# l_modes = multimode::locmodes(df_subjects$s_SCALED,mod0 =  n_modes, display = TRUE)\n\n\nThe excess mass test for multimodality suggests there is not enough mass at the positive end of the score distribution to be considered multimodal.\n\n\n\nFirst Item Scores\nNext we consider the response accuracy on just the first question of the graph comprehension task: a subject’s first exposure to the TM graph.\n\nFirst Item Absolute Score\n\n\nCODE\ntitle = \"Proportion of Correct Response on First Item (Combined)\"\nitem.contingency <- df_subjects %>%  dplyr::select(item_q1_NABS, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Correct Response on First Item (Combined)\n \n  \n      \n    Orth-Full \n    Orth-Sparse \n    Orth-Grid \n    Tri-Sparse \n    Sum \n  \n \n\n  \n    0 \n    0.943 \n    0.886 \n    0.959 \n    0.86 \n    0.914 \n  \n  \n    1 \n    0.057 \n    0.114 \n    0.041 \n    0.14 \n    0.086 \n  \n  \n    Sum \n    1.000 \n    1.000 \n    1.000 \n    1.00 \n    1.000 \n  \n\n\n\n\n\nAcross data collection sessions, first-item accuracy is consistent across experimental conditions. Incorrect answers are far more frequent (91%) than correct answers (9%). Highest accuracy is achieved in the Triangular gridlines condition, with roughly 14% correct response rate, compared to only 6% in the orthogonal axis control.\n\n\nCODE\n#PROPORTIONAL BAR CHART\ngf_props(~item_q1_NABS, data = df_subjects) +\n  labs(x = \"response accuracy\",\n       y = \"% subjects\",\n       title = \"Proportion of Correct Responses on First Item\",\n       subtitle=\"\")+\n  theme(legend.position = \"none\")+theme_ggdist()\n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(item_q1_NABS))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  labs(x = \"response accuracy\",\n       title = \"Proportion of Correct Responses on First Item\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#MOSAIC PLOT\nvcd::mosaic(main=\"Proportion of Correct Responses on First Item\",\n            data = df_subjects, item_q1_NABS ~ pretty_condition, rot_labels=c(0,90,0,0), \n            offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n            spacing = spacing_dimequal(unit(1:2, \"lines\"))) \n\n\n\n\n\nCODE\n#STATSPLOT\nggbarstats(\n  x = item_q1_NABS,\n  y = pretty_condition, \n  data = df_subjects\n)\n\n\n\n\n\n\n\nFirst Item Scaled Score\nAt the item level, the scaled score gives us a numeric measure of correctness of interpretation, ranging from -1 to 1. (note: we evaluate scaled_score on the first item rather than interpretation, because no orthogonal interpretation is available in the impasse condition)\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (First Item Scaled Score)\"\nfirstscaled.stats <- df_subjects %>% dplyr::select(item_q1_SCALED) %>% unlist() %>% favstats()\nfirstscaled.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (First Item Scaled Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    -1 \n    -1 \n    -1 \n    -1 \n    1 \n    -0.751 \n    0.621 \n    360 \n    0 \n  \n\n\n\n\n\nWhen combined overall, first item scaled scores (n = 360) range from -1 to 1 with a slightly lower mean score of (M = -0.75, SD = 0.62).\n\n\nCODE\n#GGFORMULA | PROPORTIONAL HISTOGRAM SUBJECT FIRST SCALED\ngf_props(~item_q1_SCALED, data = df_subjects) +\n  labs(x = \"scaled score (first item)\",\n       y = \"% of subjects\",\n       title = \"Distribution of First Item Scaled Score\",\n       subtitle = \"\") \n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_q1_SCALED\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE) \nfacet(p, facet.by=c(\"pretty_condition\")) + \n  labs( title = \"Distribution of First Item Scaled Score (by Mode and Condition)\",\n        subtitle =\"\",\n        x = \"scaled score (firt item) \", y = \"number of participants\") + \n  theme_minimal() + theme(legend.position = \"blank\") \n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_subjects %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(item_q1_SCALED))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  labs(x = \"response accuracy\",\n       title = \"Type of Responses on First Item (by Modality and Condition)\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#STATSPLOT\nggbarstats(\n  x = item_q1_SCALED,\n  y = pretty_condition, \n  data = df_subjects\n)\n\n\n\n\n\n\n\n\nInterpretation Scores\nNext we consider the the interpretations assigned to each response. For each response given by a participant to a question, we assign an interpretation label based on the interpretation the response most closely matches (see ?sec-scoring-interpretation).\n\n\nCODE\ntitle = \"Proportion of Interpretations Across Items Items By Condition\"\nitem.contingency <- df_items %>%  dplyr::select(interpretation, pretty_condition) %>% table() %>%  addmargins(2) %>% prop.table(margin=2) %>% addmargins(1)\nitem.contingency %>% kbl (caption = title) %>% kable_classic()\n\n\n\nProportion of Interpretations Across Items Items By Condition\n \n  \n      \n    Orth-Full \n    Orth-Sparse \n    Tri-Sparse \n    Orth-Grid \n    Sum \n  \n \n\n  \n    Orthogonal \n    0.568 \n    0.558 \n    0.484 \n    0.608 \n    0.556 \n  \n  \n    frenzy \n    0.005 \n    0.008 \n    0.004 \n    0.005 \n    0.006 \n  \n  \n    ? \n    0.125 \n    0.089 \n    0.114 \n    0.114 \n    0.111 \n  \n  \n    reference \n    0.000 \n    0.002 \n    0.001 \n    0.003 \n    0.001 \n  \n  \n    blank \n    0.018 \n    0.023 \n    0.025 \n    0.035 \n    0.026 \n  \n  \n    both tri + orth \n    0.120 \n    0.119 \n    0.115 \n    0.120 \n    0.118 \n  \n  \n    Tversky \n    0.025 \n    0.018 \n    0.031 \n    0.020 \n    0.024 \n  \n  \n    Triangular \n    0.139 \n    0.183 \n    0.227 \n    0.094 \n    0.158 \n  \n  \n    Sum \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n    1.000 \n  \n\n\n\n\n\n\n\nCODE\n#PROPORTIONAL BAR CHART\ngf_propsh(~interpretation, data = df_items, fill = ~pretty_condition) %>% \n  gf_facet_grid(pretty_condition~pretty_mode) +\n  labs(x = \"% of items\",\n       title = \"Proportion of Interpretations Across Items\",\n       subtitle=\"\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\nCODE\n#STACKED BAR CHART\ndf_items %>% \n  ggplot(data = .,\n         mapping = aes(x = pretty_condition,\n                       fill = as.factor(interpretation))) +\n  geom_bar(position = \"fill\" ) + #,color = \"black\") +\n  scale_fill_brewer(palette = \"Set1\")  +\n  labs(x = \"response accuracy\",\n       title = \"Response Types on All Items (by Condition)\",\n       x = \"Condition\",\n       fill = \"\",\n       subtitle=\"\")\n\n\n\n\n\nCODE\n#MOSAIC PLOT\n# vcd::mosaic(main=\"Proportion of Interpretations across Conditions\",\n#             data = df_items, pretty_condition ~ interpretation, rot_labels=c(0,90,0,0), \n#             offset_varnames = c(left = 4.5), offset_labels = c(left = -0.5),just_labels = \"right\",\n#             spacing = spacing_dimequal(unit(1:2, \"lines\"))) \n\n#STATSPLOT\nggbarstats(\n  x = interpretation,\n  y = pretty_condition, \n  data = df_items\n)\n\n\n\n\n\n\n\nCumulative Task Performance\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html#response-latency",
    "href": "analysis/SGC4A/3_sgc4A_description.html#response-latency",
    "title": "14  Description",
    "section": "RESPONSE LATENCY",
    "text": "RESPONSE LATENCY\n\nTime on First Item\nHere we consider the time spent on just the first individual item (first exposure to graph).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- df_subjects %>% dplyr::select(item_q1_rt) %>% unlist() %>% favstats()\ntitle = \"Descriptive Statistics of First Response Time (seconds)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of First Response Time (seconds)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    5.6 \n    13.8 \n    21.6 \n    35.6 \n    536 \n    31.1 \n    39.1 \n    360 \n    0 \n  \n\n\n\n\n\nResponse time on the first item for subjects (n = 360) ranged from 5.6 to 536.39 minutes with a mean duration of (M = 31.08, SD = 39.13).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~item_q1_rt, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of First Item Response Time (seconds)\", subtitle = \"fit by gamma distribution\", x = \"First Item Response Time (seconds)\", y = \"% items\")\n\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\n\nWarning: Removed 360 rows containing missing values (geom_vline).\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"item_q1_rt\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\")) +\n  labs( title = \"Distribution of First Item Response Time (seconds)\",\n        subtitle =\"\",\n        x = \"First Item Response Time (seconds)\", y = \"number of items\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#recode as boolean correct\ndf_subjects <- df_subjects %>% mutate(\n  item_q1_NABS = as.logical(item_q1_NABS)\n)\n\n##RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = item_q1_rt, color = item_q1_NABS) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.2, \n    adjust = .5, \n    width = .6, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .1\n  )) + \n  labs( title = \"Distribution of First Item Response Time (seconds)\",\n        subtitle =\"\",\n        y = \"First Item Response Time (s)\", x = \"Condition\") +\n  theme_ggdist() \n\n\n\n\n\nCODE\n# + theme(legend.position = \"blank\")\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n\n\n#TEMP REMOVE OUTLIERS\ndf <- df_subjects %>% filter(item_q1_rt < 300)\n\n#STATSPLOT\nggbetweenstats(y = item_q1_rt, x = pretty_condition, data = df,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\n\n\nTime on Item\nHere we consider the time spent on an individual item (across all items).\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- df_items %>%   dplyr::select(rt_s) %>% unlist() %>% favstats()\ntitle = \"Descriptive Statistics of Item Response Latency (seconds)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Item Response Latency (seconds)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    0.785 \n    12.1 \n    21.8 \n    40.6 \n    536 \n    33.1 \n    36 \n    5400 \n    0 \n  \n\n\n\n\n\nTime on an individual item for subjects (n = 5400) ranged from 0.78 to 536.39 minutes with a mean duration of (M = 33.13, SD = 35.95).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~rt_s, data = df_items) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of Item Response Time (seconds)\", \n       subtitle = \"fit by gamma distribution\", x = \"Item Response Time (seconds)\", y = \"% items\") \n\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\nWarning in densfun(x, parm[1], parm[2], ...): NaNs produced\n\n\nWarning: Removed 5400 rows containing missing values (geom_vline).\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_items, x = \"rt_s\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\")) +\n  labs( title = \"Distribution of Item Response Time (seconds)\",\n        subtitle =\"\",\n        x = \"Item Response Time (seconds)\", y = \"number of items\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#recode as boolean correct\ndf_items <- df_items %>% mutate(\n  score_niceABS = as.logical(score_niceABS)\n)\n\n##RAINCLOUD USING GGDISTR\nggplot(df_items, aes(x = pretty_condition, y = rt_s, color = score_niceABS) ) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    # position = position_dodgejust(),\n    justification = 1.5, \n    # adjust = .5, \n    width = .5, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    width = .15, \n    outlier.shape = NA,\n    position = position_dodge2()\n  ) +\n  geom_point(\n    size = 1.3,\n    alpha = .3,\n    position = position_jitterdodge(\n      # seed = 1,\n      dodge.width = 0.5,\n      jitter.width = 0.075\n  )) +\n  labs( title = \"Distribution of Item Response Time (seconds)\",\n        subtitle =\"\",\n        y = \"Item Response Time (s)\", x = \"Condition\") +\n  theme_ggdist() \n\n\n\n\n\nCODE\n# + theme(legend.position = \"blank\")\n# + coord_cartesian(xlim = c(1.2, NA), clip = \"off\")\n                \n#STATSPLOT\nggbetweenstats(y = rt_s, x = pretty_condition, data = df_items,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )\n\n\n\n\n\n\n\nTime on Task\nHere we consider the time spent on the entire experimental task.\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- df_subjects %>% dplyr::select(rt_m) %>% unlist() %>% favstats()\ntitle = \"Descriptive Statistics of Total Task Response Latency (minutes)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Total Task Response Latency (minutes)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n     \n    1.19 \n    5.08 \n    6.85 \n    9.1 \n    26.8 \n    7.48 \n    3.52 \n    360 \n    0 \n  \n\n\n\n\n\nTotal time on task for subjects (n = 360) ranged from 1.19 to 26.82 minutes with a mean duration of (M = 7.48, SD = 3.52).\n\n\nCODE\n#HISTOGRAM\ngf_dhistogram(~rt_m, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Distribution of Total Response Time (minutes)\", subtitle = \"fit by gamma distribution\", x = \"Total Response Time (minutes)\", y = \"% subjects\") \n\n\nWarning: Removed 360 rows containing missing values (geom_vline).\n\n\n\n\n\nCODE\n##GGPUBR | HIST+DENSITY SCORE BY CONDITION/MODE\np <- gghistogram(df_subjects, x = \"rt_m\", binwidth = 0.5,\n   add = \"mean\", rug = TRUE,\n   fill = \"pretty_condition\", #, palette = c(\"#00AFBB\", \"#E7B800\"),\n   add_density = TRUE)\nfacet(p, facet.by=c(\"pretty_condition\")) +\n  labs( title = \"Distribution of Total Response Time (minutes)\",\n        subtitle =\"\",\n        x = \"Scaffold Phase Time (minutes)\", y = \"number of subjects\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n##VERTICAL RAINCLOUD USING GGDISTR\nggplot(df_subjects, aes(x = pretty_condition, y = rt_m, fill = pretty_condition)) + \n  ggdist::stat_halfeye(\n    side = \"left\",\n    justification = 1.2, \n    adjust = .5, \n    width = .6, \n    .width = 0, \n    point_colour = NA) + \n  geom_boxplot(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = rt_m),\n    width = .15, \n    outlier.shape = NA\n  ) + \n  geom_point(\n    inherit.aes = FALSE, #supress fill\n    mapping = aes(x=pretty_condition, y = rt_m, color = pretty_condition),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter( \n      seed = 1, width = .05\n  ))+ labs( title = \"Distribution of Total Response Time (minutes)\",\n        subtitle =\"\",\n        y = \"Total Response Time (minutes)\", x = \"Condition\") +\n  theme_ggdist() + theme(legend.position = \"blank\") #+\n\n\n\n\n\nCODE\n  # coord_cartesian(xlim = c(0.5, NA), clip = \"off\")\n\n#STATSPLOT\nggbetweenstats(y = rt_m, x = pretty_condition, data = df_subjects,\n               type = \"nonparametric\", var.equal = FALSE,\n               pairwide.display = \"significant\", )"
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html#exploring-relationships",
    "href": "analysis/SGC4A/3_sgc4A_description.html#exploring-relationships",
    "title": "14  Description",
    "section": "EXPLORING RELATIONSHIPS",
    "text": "EXPLORING RELATIONSHIPS\n\nACCURACY (VS) LATENCY\n\nTotal Task\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ rt_m, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by TOTAL Item Response Time\",\n    subtitle = \"\", \n    x = \"Total Item Response Time (minutes)\", y = \"Total Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ item_avg_rt, data = df_subjects, alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by MEAN Item Response Time\",\n    subtitle = \"\", \n    x = \"Average Item Response Time (seconds)\", y = \"Total Scaled Score\"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#SCATTERPLOT [SCORE X ITEM RESPONSE TIME]\ngf_jitter( s_SCALED ~ item_max_rt, data = df_subjects %>% filter(item_max_rt < 400), alpha = 0.5, color=~pretty_condition) %>% \n  gf_facet_wrap(~pretty_condition) + labs(\n    title = \"Total (Scaled) Score by MAX Item Response Time\",\n    subtitle = \"\", \n    x = \"MAX Item Response Time (s)\", y = \"Total Scaled Score \"\n  ) + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#NOTE: LOG transforms of the RT do not yield linear relationships\n\n\n\n\nAverage Item RT by Accuracy\n\n\nCODE\nq.stats <- df_items %>% filter(q != 6) %>% dplyr::group_by(q, pretty_condition, score_niceABS) %>% dplyr::summarise(\n  m = mean(rt_s),\n  sd = sd(rt_s),\n  sd = tidyr::replace_na(sd,0),\n  lo = m-sd/2,\n  hi = m+sd/2,\n  group = paste(pretty_condition,\"-\",score_niceABS)\n)\n\ngf_line( m ~ q, group = ~group,  color = ~as.factor(score_niceABS),data = q.stats) %>% \n  gf_point() %>% \n  gf_ribbon(lo+hi~q) %>% \n  gf_facet_wrap(~pretty_condition) + scale_color_manual(values=c(\"red\",\"green\")) + \n  labs(title = \"Average Item Response Time by Absolute Score\",\n       subtitle = \"Correct responses are generally faster [computational efficiency] except on Q1 [learning]\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Correct Response\")\n\n\n\n\n\nCODE\n#GGDIST LINERIBBON\n# df_items %>%\n#   ggplot(aes(y = rt_s, x = q,  fill = pretty_condition)) +\n#   stat_lineribbon(alpha = 1/4, point_interval = \"mean_qi\") + facet_wrap(~pretty_condition)\n\n\n\n\nCODE\nq.stats <- df_items %>% filter(q %nin% c(6,9)) %>% dplyr::group_by(q, pretty_condition, interpretation) %>% dplyr::summarise(\n  m = mean(rt_s),\n  sd = sd(rt_s),\n  sd = tidyr::replace_na(sd,0),\n  lo = m-sd/2,\n  hi = m+sd/2,\n  group = paste(pretty_condition,\"-\",score_SCALED)\n)\n\ngf_line( m ~ as.factor(q), group = ~group,  color = ~interpretation,data = q.stats) %>% \n  gf_point() %>% \n  gf_ribbon(lo+hi~as.factor(q)) %>% \n  gf_facet_grid(interpretation~pretty_condition) + #+ scale_color_manual(values=c(\"red\",\"green\")) + \n  labs(title = \"Average Item Response Time by Interpretation\",\n       subtitle = \"Correct responses are generally faster [computational efficiency] except on Q1 [learning]\",\n       caption=\"NOTE: Points with no ribbon indicate singular response\",\n       x = \"Question\", y = \"Averate Item Response Time\", color=\"Interpretation\")\n\n\ngeom_path: Each group consists of only one observation. Do you need to adjust\nthe group aesthetic?\n\n\n\n\n\nCODE\n#GGDIST LINERIBBON\ndf_items %>% filter(q %nin% c(6,9)) %>% mutate( interpretation = recode(interpretation, \"reference\" = \"blank\", \"frenzy\" = \"?\")) %>% \n  ggplot(aes(y = rt_s, x = q,  fill = interpretation)) +\n  stat_lineribbon(alpha = 1/4, point_interval = \"mean_qi\") + \n  facet_grid(interpretation ~ pretty_condition) + \n  labs( title = \"Average Response Time by Question Interpretation\", x = \"Question\", y=\"Averate Item Response Time (s)\")"
  },
  {
    "objectID": "analysis/SGC4A/3_sgc4A_description.html#resources",
    "href": "analysis/SGC4A/3_sgc4A_description.html#resources",
    "title": "14  Description",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] forcats_0.5.1      stringr_1.4.0      purrr_0.3.4        readr_2.1.2       \n [5] tidyr_1.2.0        tibble_3.1.7       tidyverse_1.3.1    performance_0.9.1 \n [9] fitdistrplus_1.1-8 MASS_7.3-57        multimode_1.5      ggeasy_0.1.3      \n[13] ggstatsplot_0.9.3  ggdist_3.1.1       ggpubr_0.4.0       vcd_1.4-10        \n[17] kableExtra_1.3.4   mosaic_1.8.3       ggridges_0.5.3     mosaicData_0.20.2 \n[21] ggformula_0.10.1   ggstance_0.3.5     dplyr_1.0.9        Matrix_1.4-1      \n[25] Hmisc_4.7-0        ggplot2_3.3.6      Formula_1.2-4      survival_3.3-1    \n[29] lattice_0.20-45   \n\nloaded via a namespace (and not attached):\n  [1] utf8_1.2.2             ks_1.13.5              tidyselect_1.1.2      \n  [4] htmlwidgets_1.5.4      gmp_0.6-5              munsell_0.5.0         \n  [7] codetools_0.2-18       effectsize_0.7.0       withr_2.5.0           \n [10] colorspace_2.0-3       highr_0.9              knitr_1.39            \n [13] rstudioapi_0.13        ggsignif_0.6.3         labeling_0.4.2        \n [16] emmeans_1.7.5          polyclip_1.10-0        bit64_4.0.5           \n [19] farver_2.1.0           datawizard_0.4.1       coda_0.19-4           \n [22] vctrs_0.4.1            generics_0.1.2         TH.data_1.1-1         \n [25] xfun_0.31              BWStest_0.2.2          diptest_0.76-0        \n [28] R6_2.5.1               BayesFactor_0.9.12-4.4 cachem_1.0.6          \n [31] assertthat_0.2.1       scales_1.2.0           vroom_1.5.7           \n [34] multcomp_1.4-19        nnet_7.3-17            rootSolve_1.8.2.3     \n [37] gtable_0.3.0           multcompView_0.1-8     sandwich_3.0-2        \n [40] MatrixModels_0.5-0     rlang_1.0.3            zeallot_0.1.0         \n [43] systemfonts_1.0.4      PMCMRplus_1.9.5        splines_4.2.1         \n [46] rstatix_0.7.0          broom_0.8.0            prismatic_1.1.0       \n [49] mosaicCore_0.9.0       checkmate_2.1.0        yaml_2.3.5            \n [52] abind_1.4-5            modelr_0.1.8           crosstalk_1.2.0       \n [55] backports_1.4.1        tools_4.2.1            ellipsis_0.3.2        \n [58] RColorBrewer_1.1-3     ggdendro_0.1.23        Rcpp_1.0.8.3          \n [61] plyr_1.8.7             base64enc_0.1-3        rpart_4.1.16          \n [64] pbapply_1.5-0          correlation_0.8.1      zoo_1.8-10            \n [67] haven_2.5.0            ggrepel_0.9.1          cluster_2.1.3         \n [70] fs_1.5.2               magrittr_2.0.3         data.table_1.14.2     \n [73] lmtest_0.9-40          reprex_2.0.1           mvtnorm_1.1-3         \n [76] hms_1.1.1              patchwork_1.1.1        evaluate_0.15         \n [79] xtable_1.8-4           leaflet_2.1.1          jpeg_0.1-9            \n [82] mclust_5.4.10          readxl_1.4.0           gridExtra_2.3         \n [85] compiler_4.2.1         KernSmooth_2.23-20     crayon_1.5.1          \n [88] htmltools_0.5.2        tzdb_0.3.0             lubridate_1.8.0       \n [91] DBI_1.1.3              SuppDists_1.1-9.7      kSamples_1.2-9        \n [94] tweenr_1.0.2           dbplyr_2.2.1           boot_1.3-28           \n [97] car_3.1-0              cli_3.3.0              parallel_4.2.1        \n[100] insight_0.18.0         pkgconfig_2.0.3        statsExpressions_1.3.2\n[103] foreign_0.8-82         xml2_1.3.3             paletteer_1.4.0       \n[106] svglite_2.1.0          webshot_0.5.3          estimability_1.4      \n[109] rvest_1.0.2            distributional_0.3.0   digest_0.6.29         \n[112] parameters_0.18.1      pracma_2.3.8           rmarkdown_2.14        \n[115] cellranger_1.1.0       htmlTable_2.4.0        lifecycle_1.0.1       \n[118] jsonlite_1.8.0         carData_3.0-5          viridisLite_0.4.0     \n[121] fansi_1.0.3            labelled_2.9.1         pillar_1.7.0          \n[124] fastmap_1.1.0          httr_1.4.3             glue_1.6.2            \n[127] bayestestR_0.12.1      png_0.1-7              bit_4.0.4             \n[130] ggforce_0.3.3          stringi_1.7.6          rematch2_2.1.2        \n[133] latticeExtra_0.6-29    memoise_2.0.1          Rmpfr_0.8-9"
  },
  {
    "objectID": "analysis/SGC4B/1_sgc4B_introduction.html",
    "href": "analysis/SGC4B/1_sgc4B_introduction.html",
    "title": "15  Introduction",
    "section": "",
    "text": "In Study 4B we explore the extent to which the design of the marks indicating data points influence how a reader interprets its underlying coordinate system."
  },
  {
    "objectID": "analysis/SGC4B/1_sgc4B_introduction.html#methods",
    "href": "analysis/SGC4B/1_sgc4B_introduction.html#methods",
    "title": "15  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 3 levels (Mark: POINT, CROSS, ARROW) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Mark Design: Point, Arrow, Cross )\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 19.1. The list of questions can be found here.\n\n\n\nFigure 15.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\nIn each experimental\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a Triangular Model (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items: The Graph Comprehension Task.\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData were collected by convenience sample of a university subject pool during the winter of 2022. Participants accessed the study via a web browser (asynchronously). The stimulus application required the participant stay in full-screen mode for the entirety of the study."
  },
  {
    "objectID": "analysis/SGC4B/1_sgc4B_introduction.html#analysis",
    "href": "analysis/SGC4B/1_sgc4B_introduction.html#analysis",
    "title": "15  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\n\n\n\nPre-Requisite\nFollowed By\n\n\n\n\nwinter2022_clean_sgc4b.Rmd\n2_sgc4B_scoring.qmd\n\n\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#import file\ndf_subjects <- read_rds(\"analysis/SGC4B/data/0-session-level/sgc4b_participants.rds\") #use RDS file as it contains metadata\n\n#NO EXPLANATION COLUMN IN SGC4B DATASET; TRIAL NOT COLLECTED \n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\n# df_q16 <- df_subjects %>% \n#   select(subject, condition, term , mode, explanation) %>% \n#   mutate(\n#     q = 16,\n#     response = explanation\n#   ) %>% select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\n#drop absolute score because we rescore in 2_scoring\ndf_subjects <- df_subjects %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, study, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m,\n                 #exploratory factors\n                 violations, browser, width, height\n                 )\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#set factors\ndf_subjects <- df_subjects %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#read datafiles\ndf_items <- read_rds(\"analysis/SGC4B/data/0-session-level/sgc4b_items.rds\") #use RDS file as it contains metadata\n\n#reduce data collected using new webapp\ndf_items <- df_items %>% \n  select(subject, condition, pretty_condition, study, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  ) %>% \n  mutate(\n    response = str_remove_all(as.character(answer), \",\"),\n    num_o = str_length(response)\n  )%>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4B/data/1-study-level/sgc4b_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4B/data/1-study-level/sgc4b_items.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4B/data/1-study-level/sgc4b_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4B/data/1-study-level/sgc4b_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4B/1_sgc4B_introduction.html#resources",
    "href": "analysis/SGC4B/1_sgc4B_introduction.html#resources",
    "title": "15  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9     \n [5] purrr_0.3.4      readr_2.1.2      tidyr_1.2.0      tibble_3.1.7    \n [9] ggplot2_3.3.6    tidyverse_1.3.1  codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.8.3      svglite_2.1.0     lubridate_1.8.0   assertthat_0.2.1 \n [5] digest_0.6.29     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n [9] backports_1.4.1   reprex_2.0.1      labelled_2.9.1    evaluate_0.15    \n[13] highr_0.9         httr_1.4.3        pillar_1.7.0      rlang_1.0.3      \n[17] curl_4.3.2        readxl_1.4.0      data.table_1.14.2 rstudioapi_0.13  \n[21] rmarkdown_2.14    webshot_0.5.3     foreign_0.8-82    htmlwidgets_1.5.4\n[25] munsell_0.5.0     broom_0.8.0       compiler_4.2.1    modelr_0.1.8     \n[29] xfun_0.31         pkgconfig_2.0.3   systemfonts_1.0.4 htmltools_0.5.2  \n[33] tidyselect_1.1.2  rio_0.5.29        fansi_1.0.3       viridisLite_0.4.0\n[37] crayon_1.5.1      tzdb_0.3.0        dbplyr_2.2.1      withr_2.5.0      \n[41] grid_4.2.1        jsonlite_1.8.0    gtable_0.3.0      lifecycle_1.0.1  \n[45] DBI_1.1.3         magrittr_2.0.3    scales_1.2.0      zip_2.2.0        \n[49] cli_3.3.0         stringi_1.7.6     fs_1.5.2          xml2_1.3.3       \n[53] ellipsis_0.3.2    generics_0.1.2    vctrs_0.4.1       openxlsx_4.2.5   \n[57] tools_4.2.1       glue_1.6.2        hms_1.1.1         fastmap_1.1.0    \n[61] yaml_2.3.5        colorspace_2.0-3  rvest_1.0.2       knitr_1.39       \n[65] haven_2.5.0"
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html",
    "title": "16  Response Scoring",
    "section": "",
    "text": "The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC4B study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#score-sgc-data",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#score-sgc-data",
    "title": "17  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section Section 3.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_both <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_both\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_items.rds')\n\n#ADD TEMP IMPASSE COLUMN\ndf_items <- df_items %>% mutate(\n  IMPASSE = substr(condition,2,2),\n  IMPASSE = recode_factor(IMPASSE, \"1\"=\"none\", \"2\"=\"IMPASSE\")\n)\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n# backup <- df_items\n# df_items <- backup %>%  sample_n(200)\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tri))\n\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response,  MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_BOTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_both))\n\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\n\n#OLD score_BOTH... new one is above (explicitly in key)\n# df_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items #%>% head(16) %>% tail(1)\ntemp <- derive_interpretation(temp)\n\n\n[1] \"DERIVING INTERPRETATION\"\n\n\nCODE\ndf_items <- temp\n\n\n\n\n? SPECIAL EXCEPTIONS\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\n\n\nCODE\n# #temp setup for protection\n# temp <- df_items %>% mutate(\n#   override = \"\"\n# )\n# \n# \n# ## CONTROL. Q==3. \"A\" derives as 'unknown', should be tversky duration\n# #codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"none\") & (response == \"A\"),\n#   tv_type = \"score_TV_duration\",\n#   int2 = \"Tversky\", #override from ?\n#   interpretation = \"Tversky\", #override from ?\n#   high_interpretation = \"pos.trans\",\n#   override = \"?\"\n# )\n# \n# ## CONTROL  Q==3 \"EFK\" derives as TRI. hardcode as \"unknown\"\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"none\") & (response == \"EFK\"),\n#   int2 = \"?\", #override from TRI\n#   interpretation = \"?\", #override from TRI\n#   high_interpretation = \"neg.trans\", #override from triangular\n#   override = \"Triangular\"\n# )\n# \n# ## IMPASSE  Q==3 \"AFG\" derives as TRI. hardcode as \"unknown\"\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n#   int2 = \"?\", #override from TRI\n#   interpretation = \"?\", #override from TRI\n#   high_interpretation = \"neg.trans\", #override from triangular\n#   override = \"Triangular\"\n# )\n# \n# \n# ## IMPASSE  Q==3 \"AH\" derives as SATISFICE hardcode as \"angular\"\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AH\"),\n#   int2 = \"Tversky\", #override from Satisfice\n#   interpretation = \"Tversky\", #override from Satisfice\n#   high_interpretation = \"pos.trans\", #override from orthogonal\n#   override = \"Satisfice\"\n# )\n# \n# ## IMPASSE  Q==3 \"AO\" derives as SATISFICE hardcode as \"angular\"\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n#   int2 = \"Tversky\", #override from Satisfice\n#   interpretation = \"Tversky\", #override from Satisfice\n#   high_interpretation = \"pos.trans\", #override from orthogonal\n#   override = \"Satisfice\"\n# )\n# \n# \n# ## IMPASSE  Q==3 \"AOU\" derives as SATISFICE hardcode as \"angular\"\n# temp <- temp %>% mutate_when(\n#   (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AOU\"),\n#   int2 = \"Tversky\", #override from Satisfice\n#   interpretation = \"Tversky\", #override from Satisfice\n#   high_interpretation = \"pos.trans\", #override from orthogonal\n#   override = \"Satisfice\"\n# )\n# \n# ## CONTROL Q==4 DEU DERIVES as ORTH Recode as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"none\") & (response == \"DEU\"),\n#   int2 = \"?\", #override from Orthogonal\n#   interpretation = \"?\", #override from Orthogonal\n#   high_interpretation = \"neg.trans\", #override from orthogonal\n#   override = \"Orthogonal\"\n# )\n# \n# ## CONTROL Q==4 DEOU DERIVES as ORTH Recode as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"none\") & (response == \"DEOU\"),\n#   int2 = \"?\", #override from Orthogonal\n#   interpretation = \"?\", #override from Orthogonal\n#   high_interpretation = \"neg.trans\", #override from orthogonal\n#   override = \"Orthogonal\"\n# )\n# \n# ## CONTROL Q==4 KU DERIVES as ORTH Recode as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"none\") & (response == \"KU\"),\n#   int2 = \"?\", #override from Orthogonal\n#   interpretation = \"?\", #override from Orthogonal\n#   high_interpretation = \"neg.trans\", #override from orthogonal\n#   override = \"Orthogonal\"\n# )\n# \n# ## IMPASSE Q==4 BD Derives as TVERSKY RECODE as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BD\"),\n#   int2 = \"?\", #override from Tversky\n#   interpretation = \"?\", #override from Tversky\n#   high_interpretation = \"neg.trans\", #override from pos.trans\n#   override = \"Tversky\"\n# )\n# \n# ## IMPASSE Q==4 BDEG Derives as TVERSKY RECODE as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BDEG\"),\n#   int2 = \"?\", #override from Tversky\n#   interpretation = \"?\", #override from Tversky\n#   high_interpretation = \"neg.trans\", #override from pos.trans\n#   override = \"Tversky\"\n# )\n# \n# ## IMPASSE Q==4 AFG Derives as SATISFICE RECODE as OTHER\n# temp <- temp %>% mutate_when(\n#   (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n#   int2 = \"?\", #override from Satisfice\n#   interpretation = \"?\", #override from Satisfice\n#   high_interpretation = \"neg.trans\", #override from orthogonal\n#   override = \"Satisfice\"\n# )\n# \n# ## IMPASSE Q==5 AFG Derives as TRI RECODE as angular\n# temp <- temp %>% mutate_when(\n#   (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n#   int2 = \"Tversky\", #override from Triangular\n#   interpretation = \"Tversky\", #override from Triangular\n#   high_interpretation = \"pos.trans\", #override from triangular\n#   override = \"Triangular\"\n# )\n# \n# \n# #SET BACK\n# df_items <- temp\n\n\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#summarize-by-subject",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#summarize-by-subject",
    "title": "17  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC4B/data/1-study-level/sgc4b_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#explore-distributions",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#explore-distributions",
    "title": "17  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_wrap(~pretty_condition)+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE TEST PHASE\ngf_props(~item_test_NABS, fill = ~pretty_condition, \n             data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Absolute Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\n# result <- two_sample_test(data = df_subjects, x = pretty_condition, y = s_NABS,\n#                           type = \"nonparametric\", var.equal = FALSE,alternative = \"less\",\n#                           k = 2L, conf.level = 0.89, effsize.type = \"g\",\n#                           bf.prior = 0.707, tr = 0.2, nboot = 100L)\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE TEST PHASE\ngf_histogram(~item_test_SCALED, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Scaled Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Scaled Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_SCALED,\n                type = \"non-parametric\",\n                title = \"Total Scaled Score [directional test]\")\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\nggbarstats( data = df, x = score_STATE, y = pretty_condition)\n\n\n\n\n\nCODE\nggbarstats( data = df, x = high_interpretation, y = pretty_condition)\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"Impasse shifts density toward higher Triagular scores\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#peeking",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#peeking",
    "title": "16  Response Scoring",
    "section": "PEEKING",
    "text": "PEEKING\n\n\nCODE\nlibrary(performance)\nlibrary(report)\nm1 <- lm(s_SCALED ~ pretty_condition, data = df_subjects)\nsummary(m1)\n\n\n\nCall:\nlm(formula = s_SCALED ~ pretty_condition, data = df_subjects)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -8.55  -5.55  -3.72   1.78  20.62 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             -7.621      0.891   -8.55  9.2e-16 ***\npretty_conditioncross    1.344      1.290    1.04    0.299    \npretty_conditionarrow    3.172      1.237    2.56    0.011 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.5 on 269 degrees of freedom\nMultiple R-squared:  0.0241,    Adjusted R-squared:  0.0168 \nF-statistic: 3.32 on 2 and 269 DF,  p-value: 0.0376\n\n\nCODE\nanova(m1)\n\n\nAnalysis of Variance Table\n\nResponse: s_SCALED\n                  Df Sum Sq Mean Sq F value Pr(>F)  \npretty_condition   2    480   240.0    3.32  0.038 *\nResiduals        269  19434    72.2                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\nreport(m1)\n\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\n\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with pretty_condition (formula: s_SCALED ~ pretty_condition). The model explains a statistically significant and weak proportion of variance (R2 = 0.02, F(2, 269) = 3.32, p = 0.038, adj. R2 = 0.02). The model's intercept, corresponding to pretty_condition = point, is at -7.62 (95% CI [-9.38, -5.87], t(269) = -8.55, p < .001). Within this model:\n\n  - The effect of pretty condition [cross] is statistically non-significant and positive (beta = 1.34, 95% CI [-1.20, 3.88], t(269) = 1.04, p = 0.299; Std. beta = 0.16, 95% CI [-0.14, 0.45])\n  - The effect of pretty condition [arrow] is statistically significant and positive (beta = 3.17, 95% CI [0.74, 5.61], t(269) = 2.56, p = 0.011; Std. beta = 0.37, 95% CI [0.09, 0.65])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation."
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#export",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#export",
    "title": "17  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects), as well as cumulative progress dataframes (df_absolute_progress, df_scaled_progress)\n\n\nCODE\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4B/data/2-scored-data/sgc4b_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4B/data/2-scored-data/sgc4b_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4B/data/2-scored-data/sgc4b_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4B/data/2-scored-data/sgc4b_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4B/data/2-scored-data/sgc4b_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4B/data/2-scored-data/sgc4b_scored_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#resources",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#resources",
    "title": "16  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      performance_0.9.1 forcats_0.5.1     stringr_1.4.0    \n [5] dplyr_1.0.9       purrr_0.3.4       readr_2.1.2       tidyr_1.2.0      \n [9] tibble_3.1.7      tidyverse_1.3.1   Hmisc_4.7-0       Formula_1.2-4    \n[13] survival_3.3-1    lattice_0.20-45   pbapply_1.5-0     ggformula_0.10.1 \n[17] ggridges_0.5.3    scales_1.2.0      ggstance_0.3.5    ggplot2_3.3.6    \n[21] kableExtra_1.3.4 \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.1-1       colorspace_2.0-3    rio_0.5.29         \n  [4] ellipsis_0.3.2      estimability_1.4    htmlTable_2.4.0    \n  [7] parameters_0.18.1   base64enc_0.1-3     fs_1.5.2           \n [10] rstudioapi_0.13     farver_2.1.0        bit64_4.0.5        \n [13] fansi_1.0.3         mvtnorm_1.1-3       lubridate_1.8.0    \n [16] xml2_1.3.3          codetools_0.2-18    splines_4.2.1      \n [19] knitr_1.39          polyclip_1.10-0     jsonlite_1.8.0     \n [22] broom_0.8.0         cluster_2.1.3       dbplyr_2.2.1       \n [25] png_0.1-7           effectsize_0.7.0    ggforce_0.3.3      \n [28] compiler_4.2.1      httr_1.4.3          emmeans_1.7.5      \n [31] backports_1.4.1     assertthat_0.2.1    Matrix_1.4-1       \n [34] fastmap_1.1.0       cli_3.3.0           tweenr_1.0.2       \n [37] htmltools_0.5.2     tools_4.2.1         coda_0.19-4        \n [40] gtable_0.3.0        glue_1.6.2          Rcpp_1.0.8.3       \n [43] cellranger_1.1.0    vctrs_0.4.1         svglite_2.1.0      \n [46] insight_0.18.0      xfun_0.31           openxlsx_4.2.5     \n [49] rvest_1.0.2         lifecycle_1.0.1     mosaicCore_0.9.0   \n [52] zoo_1.8-10          MASS_7.3-57         vroom_1.5.7        \n [55] hms_1.1.1           sandwich_3.0-2      parallel_4.2.1     \n [58] RColorBrewer_1.1-3  curl_4.3.2          yaml_2.3.5         \n [61] gridExtra_2.3       labelled_2.9.1      rpart_4.1.16       \n [64] latticeExtra_0.6-29 stringi_1.7.6       bayestestR_0.12.1  \n [67] checkmate_2.1.0     zip_2.2.0           rlang_1.0.3        \n [70] pkgconfig_2.0.3     systemfonts_1.0.4   evaluate_0.15      \n [73] htmlwidgets_1.5.4   labeling_0.4.2      bit_4.0.4          \n [76] tidyselect_1.1.2    plyr_1.8.7          magrittr_2.0.3     \n [79] R6_2.5.1            generics_0.1.2      multcomp_1.4-19    \n [82] DBI_1.1.3           pillar_1.7.0        haven_2.5.0        \n [85] foreign_0.8-82      withr_2.5.0         datawizard_0.4.1   \n [88] nnet_7.3-17         modelr_0.1.8        crayon_1.5.1       \n [91] utf8_1.2.2          tzdb_0.3.0          rmarkdown_2.14     \n [94] jpeg_0.1-9          grid_4.2.1          readxl_1.4.0       \n [97] data.table_1.14.2   reprex_2.0.1        digest_0.6.29      \n[100] webshot_0.5.3       xtable_1.8-4        munsell_0.5.0      \n[103] viridisLite_0.4.0"
  },
  {
    "objectID": "analysis/SGC4C/1_sgc4C_introduction.html",
    "href": "analysis/SGC4C/1_sgc4C_introduction.html",
    "title": "17  Introduction",
    "section": "",
    "text": "TODO UPDATE\nIn Study 4C we explore the extent to which the orientation of the axes in space influence how a reader interprets its underlying coordinate system."
  },
  {
    "objectID": "analysis/SGC4C/1_sgc4C_introduction.html#methods",
    "href": "analysis/SGC4C/1_sgc4C_introduction.html#methods",
    "title": "17  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 3 levels (Mark: POINT, CROSS, ARROW) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Mark Design: Point, Arrow, Cross )\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 19.1. The list of questions can be found here.\n\n\n\nFigure 17.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\nIn each experimental\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a Triangular Model (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items: The Graph Comprehension Task.\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData were collected by convenience sample of a university subject pool during the winter of 2022. Participants accessed the study via a web browser (asynchronously). The stimulus application required the participant stay in full-screen mode for the entirety of the study."
  },
  {
    "objectID": "analysis/SGC4C/1_sgc4C_introduction.html#analysis",
    "href": "analysis/SGC4C/1_sgc4C_introduction.html#analysis",
    "title": "17  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\n\n\n\n\n\n\n\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#import file\ndf_subjects <- read_rds(\"analysis/SGC4C/data/0-session-level/sgc4c_participants.rds\") #use RDS file as it contains metadata\n\n#NO EXPLANATION COLUMN IN SGC4c DATASET; TRIAL NOT COLLECTED \n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\n# df_q16 <- df_subjects %>% \n#   select(subject, condition, term , mode, explanation) %>% \n#   mutate(\n#     q = 16,\n#     response = explanation\n#   ) %>% select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\n#drop absolute score because we rescore in 2_scoring\ndf_subjects <- df_subjects %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, study, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m,\n                 #exploratory factors\n                 violations, browser, width, height\n                 )\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#set factors\ndf_subjects <- df_subjects %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#read datafiles\ndf_items <- read_rds(\"analysis/SGC4C/data/0-session-level/sgc4c_items.rds\") #use RDS file as it contains metadata\n\n#reduce data collected using new webapp\ndf_items <- df_items %>% \n  select(subject, condition, pretty_condition, study, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  ) %>% \n  mutate(\n    response = str_remove_all(as.character(answer), \",\"),\n    num_o = str_length(response)\n  )%>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4C/data/1-study-level/sgc4c_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4C/data/1-study-level/sgc4c_items.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4C/data/1-study-level/sgc4c_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4C/data/1-study-level/sgc4c_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4C/1_sgc4C_introduction.html#resources",
    "href": "analysis/SGC4C/1_sgc4C_introduction.html#resources",
    "title": "17  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9     \n [5] purrr_0.3.4      readr_2.1.2      tidyr_1.2.0      tibble_3.1.7    \n [9] ggplot2_3.3.6    tidyverse_1.3.1  codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.8.3      svglite_2.1.0     lubridate_1.8.0   assertthat_0.2.1 \n [5] digest_0.6.29     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n [9] backports_1.4.1   reprex_2.0.1      labelled_2.9.1    evaluate_0.15    \n[13] highr_0.9         httr_1.4.3        pillar_1.7.0      rlang_1.0.3      \n[17] curl_4.3.2        readxl_1.4.0      data.table_1.14.2 rstudioapi_0.13  \n[21] rmarkdown_2.14    webshot_0.5.3     foreign_0.8-82    htmlwidgets_1.5.4\n[25] munsell_0.5.0     broom_0.8.0       compiler_4.2.1    modelr_0.1.8     \n[29] xfun_0.31         pkgconfig_2.0.3   systemfonts_1.0.4 htmltools_0.5.2  \n[33] tidyselect_1.1.2  rio_0.5.29        fansi_1.0.3       viridisLite_0.4.0\n[37] crayon_1.5.1      tzdb_0.3.0        dbplyr_2.2.1      withr_2.5.0      \n[41] grid_4.2.1        jsonlite_1.8.0    gtable_0.3.0      lifecycle_1.0.1  \n[45] DBI_1.1.3         magrittr_2.0.3    scales_1.2.0      zip_2.2.0        \n[49] cli_3.3.0         stringi_1.7.6     fs_1.5.2          xml2_1.3.3       \n[53] ellipsis_0.3.2    generics_0.1.2    vctrs_0.4.1       openxlsx_4.2.5   \n[57] tools_4.2.1       glue_1.6.2        hms_1.1.1         fastmap_1.1.0    \n[61] yaml_2.3.5        colorspace_2.0-3  rvest_1.0.2       knitr_1.39       \n[65] haven_2.5.0"
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html",
    "title": "18  Response Scoring",
    "section": "",
    "text": "The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC4C study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#score-sgc-data",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#score-sgc-data",
    "title": "18  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC4C/data/1-study-level/sgc4c_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4C/data/1-study-level/sgc4c_items.rds')\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tri))\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_orth))\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\ndf_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items \ntemp <- derive_interpretation(temp)\ndf_items <- temp \n\n\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#summarize-by-subject",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#summarize-by-subject",
    "title": "18  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC4C/data/1-study-level/sgc4c_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#explore-distributions",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#explore-distributions",
    "title": "18  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  pretty_condition = pretty_condition,\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>%\n  gf_facet_grid(pretty_condition~q) +\n  labs( x = \"Absolute Score\",\n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>%\n  gf_facet_grid(q~pretty_condition) +\n  labs( x = \"Scaled Score\",\n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) +\n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>%\n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\",\n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal()\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>%\n  gf_facet_wrap( ~ pretty_condition) +\n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") +\n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#peeking",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#peeking",
    "title": "18  Response Scoring",
    "section": "PEEKING",
    "text": "PEEKING\n\n\nCODE\nlibrary(performance)\nlibrary(report)\nm1 <- lm(s_SCALED ~ pretty_condition, data = df_subjects)\nsummary(m1)\n\n\n\nCall:\nlm(formula = s_SCALED ~ pretty_condition, data = df_subjects)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.933  -6.700   0.183   7.067  16.800 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(>|t|)  \n(Intercept)                        4.43       2.45    1.81    0.081 .\npretty_conditionORTH-rotate-45    -8.23       3.46   -2.38    0.025 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.48 on 28 degrees of freedom\nMultiple R-squared:  0.168, Adjusted R-squared:  0.138 \nF-statistic: 5.65 on 1 and 28 DF,  p-value: 0.0245\n\n\nCODE\nanova(m1)\n\n\nAnalysis of Variance Table\n\nResponse: s_SCALED\n                 Df Sum Sq Mean Sq F value Pr(>F)  \npretty_condition  1    508     508    5.65  0.025 *\nResiduals        28   2519      90                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCODE\nreport(m1)\n\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\n\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with pretty_condition (formula: s_SCALED ~ pretty_condition). The model explains a statistically significant and moderate proportion of variance (R2 = 0.17, F(1, 28) = 5.65, p = 0.025, adj. R2 = 0.14). The model's intercept, corresponding to pretty_condition = TRI-rotate-45, is at 4.43 (95% CI [-0.58, 9.45], t(28) = 1.81, p = 0.081). Within this model:\n\n  - The effect of pretty condition [ORTH-rotate-45] is statistically significant and negative (beta = -8.23, 95% CI [-15.33, -1.14], t(28) = -2.38, p = 0.025; Std. beta = -0.81, 95% CI [-1.50, -0.11])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation."
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#export",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#export",
    "title": "18  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects), as well as cumulative progress dataframes (df_absolute_progress, df_scaled_progress)\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4C/data/2-scored-data/sgc4c_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4C/data/2-scored-data/sgc4c_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4C/data/2-scored-data/sgc4c_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4C/data/2-scored-data/sgc4c_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4C/data/2-scored-data/sgc4c_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4C/data/2-scored-data/sgc4c_scored_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4C/2_sgc4C_scoring.html#resources",
    "href": "analysis/SGC4C/2_sgc4C_scoring.html#resources",
    "title": "18  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      performance_0.9.1 forcats_0.5.1     stringr_1.4.0    \n [5] dplyr_1.0.9       purrr_0.3.4       readr_2.1.2       tidyr_1.2.0      \n [9] tibble_3.1.7      tidyverse_1.3.1   Hmisc_4.7-0       Formula_1.2-4    \n[13] survival_3.3-1    lattice_0.20-45   pbapply_1.5-0     ggformula_0.10.1 \n[17] ggridges_0.5.3    scales_1.2.0      ggstance_0.3.5    ggplot2_3.3.6    \n[21] kableExtra_1.3.4 \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.1-1       colorspace_2.0-3    rio_0.5.29         \n  [4] ellipsis_0.3.2      estimability_1.4    htmlTable_2.4.0    \n  [7] parameters_0.18.1   base64enc_0.1-3     fs_1.5.2           \n [10] rstudioapi_0.13     farver_2.1.0        bit64_4.0.5        \n [13] fansi_1.0.3         mvtnorm_1.1-3       lubridate_1.8.0    \n [16] xml2_1.3.3          codetools_0.2-18    splines_4.2.1      \n [19] knitr_1.39          polyclip_1.10-0     jsonlite_1.8.0     \n [22] broom_0.8.0         cluster_2.1.3       dbplyr_2.2.1       \n [25] png_0.1-7           effectsize_0.7.0    ggforce_0.3.3      \n [28] compiler_4.2.1      httr_1.4.3          emmeans_1.7.5      \n [31] backports_1.4.1     assertthat_0.2.1    Matrix_1.4-1       \n [34] fastmap_1.1.0       cli_3.3.0           tweenr_1.0.2       \n [37] htmltools_0.5.2     tools_4.2.1         coda_0.19-4        \n [40] gtable_0.3.0        glue_1.6.2          Rcpp_1.0.8.3       \n [43] cellranger_1.1.0    vctrs_0.4.1         svglite_2.1.0      \n [46] insight_0.18.0      xfun_0.31           openxlsx_4.2.5     \n [49] rvest_1.0.2         lifecycle_1.0.1     mosaicCore_0.9.0   \n [52] zoo_1.8-10          MASS_7.3-57         vroom_1.5.7        \n [55] hms_1.1.1           sandwich_3.0-2      parallel_4.2.1     \n [58] RColorBrewer_1.1-3  curl_4.3.2          yaml_2.3.5         \n [61] gridExtra_2.3       labelled_2.9.1      rpart_4.1.16       \n [64] latticeExtra_0.6-29 stringi_1.7.6       bayestestR_0.12.1  \n [67] checkmate_2.1.0     zip_2.2.0           rlang_1.0.3        \n [70] pkgconfig_2.0.3     systemfonts_1.0.4   evaluate_0.15      \n [73] htmlwidgets_1.5.4   labeling_0.4.2      bit_4.0.4          \n [76] tidyselect_1.1.2    plyr_1.8.7          magrittr_2.0.3     \n [79] R6_2.5.1            generics_0.1.2      multcomp_1.4-19    \n [82] DBI_1.1.3           pillar_1.7.0        haven_2.5.0        \n [85] foreign_0.8-82      withr_2.5.0         datawizard_0.4.1   \n [88] nnet_7.3-17         modelr_0.1.8        crayon_1.5.1       \n [91] utf8_1.2.2          tzdb_0.3.0          rmarkdown_2.14     \n [94] jpeg_0.1-9          grid_4.2.1          readxl_1.4.0       \n [97] data.table_1.14.2   reprex_2.0.1        digest_0.6.29      \n[100] webshot_0.5.3       xtable_1.8-4        munsell_0.5.0      \n[103] viridisLite_0.4.0"
  },
  {
    "objectID": "analysis/SGC5A/1_sgc5A_introduction.html",
    "href": "analysis/SGC5A/1_sgc5A_introduction.html",
    "title": "19  Introduction",
    "section": "",
    "text": "In Study 5A we explore the extent to which requiring mouse-cursor interaction with the graph improves interpretation of the underlying coordinate system."
  },
  {
    "objectID": "analysis/SGC5A/1_sgc5A_introduction.html#methods",
    "href": "analysis/SGC5A/1_sgc5A_introduction.html#methods",
    "title": "19  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 19.1. The list of questions can be found here.\n\n\n\nFigure 19.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\nThe green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line. We hypothesize that this presents the reader with an obstacle, at which point they are forced to confront their interpretation of the coordinate system and (ideally) develop a new strategy.\n\n\n\nFigure 19.2: Sample Question (Q=1) graphs for each condition\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items : the Graph Comprehension Task\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData was collected by convenience sample …"
  },
  {
    "objectID": "analysis/SGC5A/1_sgc5A_introduction.html#analysis",
    "href": "analysis/SGC5A/1_sgc5A_introduction.html#analysis",
    "title": "19  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\n\n\n\nPre-Requisite\nFollowed By\n\n\n\n\nwinter2022_clean_sgc5a.Rmd\n2_sgc5_scoring.qmd\n\n\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import file\ndf_subjects <- read_rds(\"analysis/SGC5A/data/0-session-level/sgc5_participants.rds\") #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \n# df_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% select(\n#   subject,condition,term,mode,\n#   gender,age,language, schoolyear, country,\n#   effort,difficulty,confidence,enjoyment,other,\n#   totaltime_m,absolute_score\n# )\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_q16 <- df_subjects %>% \n  dplyr::select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects <- df_subjects %>% \n  # mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 #absolute_score,#drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors\n                 violations, browser, width, height\n                 )\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#set factors\ndf_subjects <- df_subjects %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#read datafiles\ndf_items <- read_rds(\"analysis/SGC5A/data/0-session-level/sgc5_items.rds\") #use RDS file as it contains metadata\n\n#reduce data collected using new webapp\ndf_items <- df_items %>% \n  dplyr::select(subject, condition, pretty_condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  ) %>% \n  mutate(\n    response = str_remove_all(as.character(answer), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC5A/data/1-study-level/sgc5_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC5A/data/1-study-level/sgc5_items.csv\", row.names = FALSE)\nwrite.csv(df_q16,\"analysis/SGC5A/data/1-study-level/sgc5_freeresponse.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC5A/data/1-study-level/sgc5_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC5A/data/1-study-level/sgc5_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC5A/1_sgc5A_introduction.html#resources",
    "href": "analysis/SGC5A/1_sgc5A_introduction.html#resources",
    "title": "19  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] kableExtra_1.3.4 forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9     \n [5] purrr_0.3.4      readr_2.1.2      tidyr_1.2.0      tibble_3.1.7    \n [9] ggplot2_3.3.6    tidyverse_1.3.1  codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.8.3      svglite_2.1.0     lubridate_1.8.0   assertthat_0.2.1 \n [5] digest_0.6.29     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n [9] backports_1.4.1   reprex_2.0.1      labelled_2.9.1    evaluate_0.15    \n[13] highr_0.9         httr_1.4.3        pillar_1.7.0      rlang_1.0.3      \n[17] curl_4.3.2        readxl_1.4.0      data.table_1.14.2 rstudioapi_0.13  \n[21] rmarkdown_2.14    webshot_0.5.3     foreign_0.8-82    htmlwidgets_1.5.4\n[25] munsell_0.5.0     broom_0.8.0       compiler_4.2.1    modelr_0.1.8     \n[29] xfun_0.31         pkgconfig_2.0.3   systemfonts_1.0.4 htmltools_0.5.2  \n[33] tidyselect_1.1.2  rio_0.5.29        fansi_1.0.3       viridisLite_0.4.0\n[37] crayon_1.5.1      tzdb_0.3.0        dbplyr_2.2.1      withr_2.5.0      \n[41] grid_4.2.1        jsonlite_1.8.0    gtable_0.3.0      lifecycle_1.0.1  \n[45] DBI_1.1.3         magrittr_2.0.3    scales_1.2.0      zip_2.2.0        \n[49] cli_3.3.0         stringi_1.7.6     fs_1.5.2          xml2_1.3.3       \n[53] ellipsis_0.3.2    generics_0.1.2    vctrs_0.4.1       openxlsx_4.2.5   \n[57] tools_4.2.1       glue_1.6.2        hms_1.1.1         fastmap_1.1.0    \n[61] yaml_2.3.5        colorspace_2.0-3  rvest_1.0.2       knitr_1.39       \n[65] haven_2.5.0"
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html",
    "title": "20  Response Scoring",
    "section": "",
    "text": "The purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC5 study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.) To review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring."
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#score-sgc-data",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#score-sgc-data",
    "title": "20  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#backup <- read_rds('analysis/SGC5A/data/1-study-level/sgc5_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC5A/data/1-study-level/sgc5_items.rds')\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tri))\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_orth))\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$condition, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\ndf_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n# extra copying for troubleshooting safety\ntemp <- df_items \ntemp <- derive_interpretation(temp)\ndf_items <- temp \n\n\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#summarize-by-subject",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#summarize-by-subject",
    "title": "20  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC5A/data/1-study-level/sgc5_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#explore-distributions",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#explore-distributions",
    "title": "20  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_condition = recode_factor(condition, \"11115\" = \"point-click\"),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, data = df_subjects) %>% \n   gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Total Absolute Score\", \n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01)) + \n geom_line(position=position_jitter(w=0.15, h=0.00), size=0.1) +\n facet_wrap( ~ pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01)) + \n geom_line(position=position_jitter(w=0.15, h=0.00), size=0.1) +\n facet_wrap( ~ pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_histogram(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#peeking",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#peeking",
    "title": "20  Response Scoring",
    "section": "PEEKING",
    "text": "PEEKING\n\n\nCODE\nlibrary(performance)\nlibrary(report)\n\nsgc3a <- read_rds(\"analysis/SGC3A/data/2-scored-data/sgc3a_scored_participants.rds\") %>% filter(condition == \"111\") %>% dplyr::select(-pretty_mode)\n\n\ncomb <- rbind(sgc3a, df_subjects)  \n\ngf_histogram(~s_SCALED, data = comb) %>% \n  gf_facet_wrap(~pretty_condition)\n\n\n\n\n\nCODE\nm1 <- lm(s_SCALED ~ pretty_condition, data = comb)\nsummary(m1)\n\n\n\nCall:\nlm(formula = s_SCALED ~ pretty_condition, data = comb)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.57  -5.49  -3.57   1.51  20.51 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   -6.427      0.647   -9.93   <2e-16 ***\npretty_conditionpoint-click   -1.086      0.997   -1.09     0.28    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.14 on 271 degrees of freedom\nMultiple R-squared:  0.00436,   Adjusted R-squared:  0.000682 \nF-statistic: 1.19 on 1 and 271 DF,  p-value: 0.277\n\n\nCODE\nanova(m1)\n\n\nAnalysis of Variance Table\n\nResponse: s_SCALED\n                  Df Sum Sq Mean Sq F value Pr(>F)\npretty_condition   1     78    78.5    1.19   0.28\nResiduals        271  17935    66.2               \n\n\nCODE\nreport(m1)\n\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\nWarning: 'data_findcols()' is deprecated and will be removed in a future update.\n  Its usage is discouraged. Please use 'data_find()' instead.\n\n\nWe fitted a linear model (estimated using OLS) to predict s_SCALED with pretty_condition (formula: s_SCALED ~ pretty_condition). The model explains a statistically not significant and very weak proportion of variance (R2 = 4.36e-03, F(1, 271) = 1.19, p = 0.277, adj. R2 = 6.82e-04). The model's intercept, corresponding to pretty_condition = control, is at -6.43 (95% CI [-7.70, -5.15], t(271) = -9.93, p < .001). Within this model:\n\n  - The effect of pretty condition [point-click] is statistically non-significant and negative (beta = -1.09, 95% CI [-3.05, 0.88], t(271) = -1.09, p = 0.277; Std. beta = -0.13, 95% CI [-0.37, 0.11])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using the Wald approximation."
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#export",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#export",
    "title": "20  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects), as well as cumulative progress dataframes (df_absolute_progress, df_scaled_progress)\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\nimac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\nsetwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC5A/data/2-scored-data/sgc5a_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC5A/data/2-scored-data/sgc5a_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC5A/data/2-scored-data/sgc5a_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC5A/data/2-scored-data/sgc5a_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC5A/data/2-scored-data/sgc5a_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC5A/data/2-scored-data/sgc5a_scored_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC5A/2_sgc5A_scoring.html#resources",
    "href": "analysis/SGC5A/2_sgc5A_scoring.html#resources",
    "title": "20  Response Scoring",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] report_0.5.1      performance_0.9.1 forcats_0.5.1     stringr_1.4.0    \n [5] dplyr_1.0.9       purrr_0.3.4       readr_2.1.2       tidyr_1.2.0      \n [9] tibble_3.1.7      tidyverse_1.3.1   Hmisc_4.7-0       Formula_1.2-4    \n[13] survival_3.3-1    lattice_0.20-45   pbapply_1.5-0     ggformula_0.10.1 \n[17] ggridges_0.5.3    scales_1.2.0      ggstance_0.3.5    ggplot2_3.3.6    \n[21] kableExtra_1.3.4 \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.1-1       colorspace_2.0-3    rio_0.5.29         \n  [4] ellipsis_0.3.2      estimability_1.4    htmlTable_2.4.0    \n  [7] parameters_0.18.1   base64enc_0.1-3     fs_1.5.2           \n [10] rstudioapi_0.13     farver_2.1.0        bit64_4.0.5        \n [13] fansi_1.0.3         mvtnorm_1.1-3       lubridate_1.8.0    \n [16] xml2_1.3.3          codetools_0.2-18    splines_4.2.1      \n [19] knitr_1.39          polyclip_1.10-0     jsonlite_1.8.0     \n [22] broom_0.8.0         cluster_2.1.3       dbplyr_2.2.1       \n [25] png_0.1-7           effectsize_0.7.0    ggforce_0.3.3      \n [28] compiler_4.2.1      httr_1.4.3          emmeans_1.7.5      \n [31] backports_1.4.1     assertthat_0.2.1    Matrix_1.4-1       \n [34] fastmap_1.1.0       cli_3.3.0           tweenr_1.0.2       \n [37] htmltools_0.5.2     tools_4.2.1         coda_0.19-4        \n [40] gtable_0.3.0        glue_1.6.2          Rcpp_1.0.8.3       \n [43] cellranger_1.1.0    vctrs_0.4.1         svglite_2.1.0      \n [46] insight_0.18.0      xfun_0.31           openxlsx_4.2.5     \n [49] rvest_1.0.2         lifecycle_1.0.1     mosaicCore_0.9.0   \n [52] zoo_1.8-10          MASS_7.3-57         vroom_1.5.7        \n [55] hms_1.1.1           sandwich_3.0-2      parallel_4.2.1     \n [58] RColorBrewer_1.1-3  curl_4.3.2          yaml_2.3.5         \n [61] gridExtra_2.3       labelled_2.9.1      rpart_4.1.16       \n [64] latticeExtra_0.6-29 stringi_1.7.6       bayestestR_0.12.1  \n [67] checkmate_2.1.0     zip_2.2.0           rlang_1.0.3        \n [70] pkgconfig_2.0.3     systemfonts_1.0.4   evaluate_0.15      \n [73] htmlwidgets_1.5.4   labeling_0.4.2      bit_4.0.4          \n [76] tidyselect_1.1.2    plyr_1.8.7          magrittr_2.0.3     \n [79] R6_2.5.1            generics_0.1.2      multcomp_1.4-19    \n [82] DBI_1.1.3           pillar_1.7.0        haven_2.5.0        \n [85] foreign_0.8-82      withr_2.5.0         datawizard_0.4.1   \n [88] nnet_7.3-17         modelr_0.1.8        crayon_1.5.1       \n [91] utf8_1.2.2          tzdb_0.3.0          rmarkdown_2.14     \n [94] jpeg_0.1-9          grid_4.2.1          readxl_1.4.0       \n [97] data.table_1.14.2   reprex_2.0.1        digest_0.6.29      \n[100] webshot_0.5.3       xtable_1.8-4        munsell_0.5.0      \n[103] viridisLite_0.4.0"
  },
  {
    "objectID": "analysis/utils/scoring.html",
    "href": "analysis/utils/scoring.html",
    "title": "Scoring Strategy",
    "section": "",
    "text": "The purpose of this notebook is to describe the strategy for assigning a score ( a measure of accuracy) to response data for the SGC studies. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.)"
  },
  {
    "objectID": "analysis/utils/scoring.html#multiple-response-scoring",
    "href": "analysis/utils/scoring.html#multiple-response-scoring",
    "title": "Scoring Strategy",
    "section": "MULTIPLE RESPONSE SCORING",
    "text": "MULTIPLE RESPONSE SCORING\nThe graph comprehension task of the SGC studies presents readers with a graph, a question, and a series of checkboxes. Participants are instructed to use the graph to answer the question, and respond by selecting all the checkboxes that apply, where each checkbox corresponds to a datapoint in the graph.\n\n\n\nFigure 1. Sample Graph Comprehension (Question # 6)\n\n\nIn the psychology and education literatures on Tests & Measures, the format of this type of question is referred to as Multiple Response (MR), (also: Multiple Choice Multiple Answer (MCMA) and Multiple Answer Multiple Choice (MAMC)). It has a number of properties that make it different from traditional Single Answer Multiple Choice (SAMC) questions, where the respondent marks a single response from a number of options. In particular, there are a number of very different ways that MAMC questions can be scored.\nIn tranditional SAMC format questions, one point is given for selecting the option designated as correct, and zero points given for marking any of the alternative (i.e. distractor) options. Individual response options on MAMC questions, however might be partially correct (\\(i\\)), while responses on other answer options within the same item might be incorrect (\\(n – i\\)). In MR, it is not obvious how to allocate points when the respondent marks a true-correct option (i.e. options that should be selected, denoted \\(p\\)), as well as one or more false-correct options (i.e. options that should not be selected, denoted \\(q\\)). Should partial credit be awarded? If so, are options that respondents false-selected and false-unselected items equally penalized?\nSchmidt et al. (2021) performed a systematic literature review of publications proposing MAMC (or equivalent) scoring schemes, ultimately synthesizing over 80 sources into 27 distinct scoring approaches. Upon reviewing the benefits of trade-offs of each approach, for this study we choose utilize two of the schemes: dichotomous scoring ( Schmidt et al. (2021) scheme #1), and partial scoring \\([-1/q,0, +1/p]\\) ( Schmidt et al. (2021) scheme #26), as well as a scaled discriminant score that leverages partial scoring to discriminate between strategy-specific patterns of response.\n\nResponse Encoding\nFirst, we note that the question type evaluated by Schmidt et al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 3.1: Figure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 3.1), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can also be encoded as [TTFF].\n\n\nScoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\\]\nProperties of the Subject’s Response\n\\[\\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\\]\n\nDichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only correct-select options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\nIn Dichotomous Scoring\n\nscore for the question is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\\] 0 i n\n\n\nCODE\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\nPartial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et al. (2021) identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach ( Schmidt et al. (2021) #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\nSchmidt et al. (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where there are many more response options \\(n\\) than there are options meant to be selected \\(p\\), this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\end{align}\\]\n\n\nCODE\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n\n\n\nPartial Scoring [-1/q, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. “select all correct options”) vs MTF (i.e. “Mark each option as true or false”) questions.\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt et al. (2021) method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts \\(1/(n-p) = 1/q\\) for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\\]\nProperties of Response\n\\[\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\\begin{align}\nf &= (p_s / p) - ({q_s}/{q}) \\\\\n\\end{align}\\]\n\n\nCODE\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  \n  ifelse( (p == 0), return(NA), \"\") #handle empty response set gracefully by returning nothing rather than 0\n  ifelse( (p != 0), return( (t / p) - (f/q)), \"\")\n}\n\n\n\n\n\nComparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    i  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial[-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A____ \n    5 \n    1 \n    1.0 \n    1.00 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB___ \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    A___E \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    AB__E \n    3 \n    0 \n    0.2 \n    0.50 \n  \n  Only Incorrect Selections\n\n    A____ \n    ____E \n    3 \n    0 \n    0.2 \n    -0.25 \n  \n  \n    A____ \n    ___DE \n    2 \n    0 \n    -0.2 \n    -0.50 \n  \n  Completely Inverse Response \n\n    A____ \n    _BCDE \n    0 \n    0 \n    -1.0 \n    -1.00 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABCDE \n    1 \n    0 \n    -0.6 \n    0.00 \n  \n  \n    A____ \n    _____ \n    4 \n    0 \n    0.6 \n    0.00 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt, abs, correct,i,names,partial1,partial2,response,title)\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    $i$  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial [-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A__...__ \n    15 \n    1 \n    1.000 \n    1.000 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB_...__ \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    A__..._O \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    AB_..._O \n    13 \n    0 \n    0.733 \n    0.857 \n  \n  Only Incorrect Selections\n\n    A____ \n    ___..._O \n    13 \n    0 \n    0.733 \n    -0.071 \n  \n  \n    A____ \n    ___...NO \n    12 \n    0 \n    0.600 \n    -0.143 \n  \n  Completely Inverse Response \n\n    A____ \n    _BC...NO \n    0 \n    0 \n    -1.000 \n    -1.000 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABC...NO \n    1 \n    0 \n    -0.867 \n    0.000 \n  \n  \n    A____ \n    ___...__ \n    14 \n    0 \n    0.867 \n    0.000 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt, abs, correct,i,names,partial1,partial2,response,title)\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n\n\n\n\n\nDecision\n\n\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options."
  },
  {
    "objectID": "analysis/utils/scoring.html#sec-scoringOverview",
    "href": "analysis/utils/scoring.html#sec-scoringOverview",
    "title": "Scoring Strategy",
    "section": "SCORING SGC DATA",
    "text": "SCORING SGC DATA\nIn SGC_3A we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key.\n5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\nFor each study in the SGC project, MR data will be scored by following these steps:\n(1) Preparing answer keys: For each dataset+question set combination, an answer key is that defines the ‘correct’ answer set under each interpretation of the graph (i.e. a triangular answer, an orthogonal answer, etc).\n(2) Calculate strategy scores: Using the strategy specific answer keys, an interpretation subscore is calculated for each response for each interpretation.\n(3) Interpretation classification: The interpretation subscores are compared in order to classify each response as a particular interpretation. If no classification can be made, the response is classified as ‘?’.\n(4) Calculate Absolute and Scaled Scores: Two final scores are calculated for each response; an Absolute score that indicates if the response was precisely correct according to the triangular interpretation, and a Scaled score that assigns a numeric value to the interpretation given by the response (ranging from -1 to +1)\n\n1. Prepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#LOAD INDIVIDUAL KEY FILES \nkey_control_raw <- read_csv('analysis/utils/keys/SGCX_scaffold_control_key.csv') %>% mutate(condition = \"DEFAULT\", phase = \"scaffold\")\nkey_impasse_raw <- read_csv('analysis/utils/keys/SGCX_scaffold_impasse_key.csv')%>% mutate(condition = \"impasse\", phase = \"scaffold\")\ncs = rep('c', 23) %>% str_c(collapse=\"\") #create column spec \nkey_test_raw <- read_csv('analysis/utils/keys/SGCX_test_key.csv', col_types = cs)%>% mutate(condition = \"DEFAULT\", phase = \"test\") \n\n#JOIN THEM\nkeys_raw <- rbind(key_control_raw, key_impasse_raw, key_test_raw )\n\n#CLEANUP\nrm(key_control_raw, key_impasse_raw, key_test_raw)\n\n\nIn order to calculate scores using the \\([-1/q, +1/p]\\) algorithm, we need to define the subset of all response options (set N) that should be selected (set P) and should not be selected (set Q). In order to calculate subscores for each graph interpretation (i.e. triangular, orthogonal, tversky) we must define these sets independently for each interpretation. For each question, the keys_raw dataframe gives us set N (all response options), and a set P (options that should be selected) for each interpretation. From these we must derive set Q for each interpretation.\n\nSET \\(N\\), all response options (superset) . This set is the same across all interpretations (a property of the question) and is given in the answer key.\nSET \\(P\\), \\(P \\subset N\\) , the subset of options that should be selected (rewarded as +1/p) . This set differs by interpretation, and is given in the answer key.\nSET \\(A, A \\subset N, A \\sqcup P\\) , the subset of options that should not be selected, but if they are, aren’t penalized (i.e. these options are ignored. Not rewarded, nor penalized). These include any options referenced in the question (i.e. select shifts that start at the same time as X; don’t penalize if they also select ‘X’), as well as options within 0.5hr offset from the data point to accommodate reasonable visual errors. This set differs by interpretation, and is given in the answer key (columns REF_POINT and _also).\nSET \\(Q\\), the subset of options that should not be selected and are penalized (as -1/q). This set differs by interpretation and is not given in the answer key. We can derive set Q for each interpretation by \\(Q = N - (P \\cup A)\\)\n\nThe next step in scoring is preparing interpretation-specific answer keys that specify sets N, P, A and Q for each question.\n\nTriangular Key\nFirst we construct a key set based on the ‘Triangular’ interpretation (i.e. the actually correct answers).\n\n\nCODE\nverify_tri = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TRIANGULAR KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tri <- keys_raw %>% \n  select(Q, condition, OPTIONS, TRIANGULAR, TRI_allow, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    TRI_allow = str_replace_na(TRI_allow,\"\"),\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TRIANGULAR,\n    set_p = str_replace_na(set_p,\"\"),#replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TRI_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"),#replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_tri)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tri[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tri[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tri[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tri[x,'set_q'] = Q\n  keys_tri[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tri[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tri <- keys_tri %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_tri <- keys_tri %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n\n\nThis leaves us a dataframe keys_tri that define the sets of response options consistent with the triangular graph interpretation.\nTo verify we have generated the correct sets, we verify that for each question, each option in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n\nOrthogonal Key\nNext we construct a key set based on the ‘Orthogonal’ interpretation.\n\n\nCODE\nverify_orth = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT ORTHOGONAL KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_orth <- keys_raw %>% \n  select(Q, condition, OPTIONS, ORTHOGONAL, ORTH_allow, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    ORTH_allow = str_replace_na(ORTH_allow,\"\"),\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = ORTHOGONAL,\n    set_p = str_replace_na(set_p,\"\"),#replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(ORTH_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answer options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_orth)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_orth[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_orth[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_orth[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_orth[x,'set_q'] = Q\n  keys_orth[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  # print(tempunion)\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n\n  verify_orth[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_orth <- keys_orth %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_orth <- keys_orth %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x, cs)\n\n\nThis leaves us a dataframe keys_orth that define the sets of response options consistent with the orthogonal graph interpretation.\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n\nTversky Keys\nNext we construct the key set based on a partial-understanding strategy we refer to as ‘Tversky’. We use the label Tversky as shorthand for a partial interpretation of the coordinate system where subjects select a set of responses that lay along a connecting line from the referenced data point or referenced time for that item. The term is named for Barbara Tversky based on her work on graphical primitives (e.g. “lines connect, arrows direct, boxes contain”).\n\n\nCODE\nverify_max = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-MAX\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_max <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_max, TV_max_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_max = str_replace_na(TV_max,\"\"),\n    TV_max_allow = str_replace_na(TV_max_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_max,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_max_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_max)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_max[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_max[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_max[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_max[x,'set_q'] = Q\n  keys_tversky_max[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_max[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_max <- keys_tversky_max %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_tversky_max <- keys_tversky_max %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\nverify_tversky_start = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-START\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_start <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_start, TV_start_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_start = str_replace_na(TV_start,\"\"),\n    TV_start_allow = str_replace_na(TV_start_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_start,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_start_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_start)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_start[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_start[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_start[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_start[x,'set_q'] = Q\n  keys_tversky_start[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_start[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_start <- keys_tversky_start %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_tversky_start <- keys_tversky_start %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\nverify_tversky_end = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-END\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_end <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_end, TV_end_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_end = str_replace_na(TV_end,\"\"),\n    TV_end_allow = str_replace_na(TV_end_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_end,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_end_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_end)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_end[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_end[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_end[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_end[x,'set_q'] = Q\n  keys_tversky_end[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_end[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_end <- keys_tversky_end %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_tversky_end <- keys_tversky_end %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\nverify_tversky_duration = c()\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-DURATION\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_duration <- keys_raw %>% \n  select(Q, condition, OPTIONS, REF_POINT, TV_dur, TV_dur_allow) %>% \n  mutate(\n  \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    TV_dur = str_replace_na(TV_dur,\"\"),\n    TV_dur_allow = str_replace_na(TV_dur_allow,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_dur,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_dur_allow,REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_duration)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_duration[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_duration[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_duration[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_duration[x,'set_q'] = Q\n  keys_tversky_duration[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_duration[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_duration <- keys_tversky_duration %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_tversky_duration <- keys_tversky_duration %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n\n\nThis leaves us four dataframes, each corresponding to a different variant of a ‘lines connecting to reference point’ strategy.\n- keys_tversky_max : the superset of lines connecting options - keys_tversky_start : lines connecting to the rightward diagonal (start time) of the reference point - keys_tversky_end: lines connecting to the leftward diagonal (end time) of the reference point - keys_tversky_duration: lines connecting to the horizontal y-intercept (duration) of the reference point\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n\nBOTH Key\nNext we construct a key set based on the intersection of the ‘TRIANGULAR’ and ‘ORTHOGONAL’ interpretation\n\n\nCODE\nverify_both = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT BOTH KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_both <- keys_raw %>% \n  select(Q, condition, OPTIONS, BOTH) %>% \n  mutate(\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = BOTH,\n    set_p = str_replace_na(set_p,\"\"),#replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = \"\",\n    set_a = \"\",\n    n_a = 0,\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n),\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_both)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_both[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_both[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_both[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_both[x,'set_q'] = Q\n  keys_both[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_both[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_both <- keys_both %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_both <- keys_both %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n\n\nThis leaves us a dataframe keys_both that define the sets of response options consistent with the triangular graph interpretation.\nTo verify we have generated the correct sets, we verify that for each question, each option in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n\nSatisficing Key\nNext we construct two keys based on the ‘Satisficing’ strategy. Satisficing involves selecting any data points within 0.5hr visual offset of the orthogonal interpretation of the graph (because no orthogonal response option is available). One key represents selecting a point slightly to the left of the orthogonal, and the other key represents selecting a point slightly to the right of the orthogonal. The “Satisficing” strategy involves the reader selecting data points nearest to the orthogonal projection from the reference point in the question. We observe this strategy in some readers when there is no orthogonal response available (i.e. in the impasse condition), so they select the points nearest to the projection (i.e. “close enough”).\n\n\nCODE\nverify_satisfice_right = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT SATISFICE RIGHT KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_satisfice_right <- keys_raw %>% \n  select(Q, condition, OPTIONS, SATISFICE_right, REF_POINT) %>% \n  mutate(\n    #replace NAs\n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n\n    #P options that SHOULD be selected (rewarded)\n    set_p = SATISFICE_right,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n\n    #A options that are ignored if selected\n    set_a = str_c(REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n\n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_satisfice_right)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_satisfice_right[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_satisfice_right[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_satisfice_right[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to data frame\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_satisfice_right[x,'set_q'] = Q\n  keys_satisfice_right[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_satisfice_right[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_satisfice_right <- keys_satisfice_right %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q)%>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_satisfice_right <- keys_satisfice_right %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n\n\n\nverify_satisfice_left = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT SATISFICE left KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_satisfice_left <- keys_raw %>% \n  select(Q, condition, OPTIONS, SATISFICE_left, REF_POINT) %>% \n  mutate(\n    \n    #replace NAs \n    REF_POINT = str_replace_na(REF_POINT,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = SATISFICE_left,\n    set_p = str_replace_na(set_p,\"\"), #replace na if empty\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(REF_POINT, sep=\"\"),\n    set_a = str_replace_na(set_a,\"\"), #replace na if empty\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_satisfice_left)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_satisfice_left[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_satisfice_left[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_satisfice_left[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist() \n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  s = str_replace_na(s,\"\")\n  # print(s)\n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  #save set to data frame\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_satisfice_left[x,'set_q'] = Q\n  keys_satisfice_left[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_satisfice_left[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_satisfice_left <- keys_satisfice_left %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q)%>% mutate(verify = n_p + n_a + n_q)\n\n#4. replace condition 111 with \"general\" to accomodate other conditions [only impasse is special]\nkeys_satisfice_left <- keys_satisfice_left %>% mutate(\n  condition = replace(condition, condition != \"impasse\", \"DEFAULT\")\n)\n\n#cleanup\nrm(A, N, n_q, P, Q, s, tempunion, x)\n\n\nThis leaves us a dataframe keys_satisfice that define the sets of response options consistent with the orthogonal graph interpretation.\nTo verify we have generated the correct sets, we verify that for each question, each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE\n\n\nCODE\n#cleanup\nrm(verify_tri, verify_orth, verify_max, verify_tversky_duration, verify_tversky_end, verify_tversky_start, verify_satisfice_right, verify_satisfice_left)\n\n\nFinally, we need to clean up and generalize our answer keys to accommodate the experimental conditions for Study SGC4-SGC5. In both of these studies the answer set (and underlying graphed data set) are identical, the conditions differ only based on the structure of the gridlines or marks used to represent the data, or interactive mode of the answer format.\n\n\nExport Keys\n\n\nCODE\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nwrite.csv(keys_raw,\"analysis/utils/keys/parsed_keys/keys_raw\", row.names = FALSE)\nwrite.csv(keys_orth,\"analysis/utils/keys/parsed_keys/keys_orth\", row.names = FALSE)\nwrite.csv(keys_tri,\"analysis/utils/keys/parsed_keys/keys_tri\", row.names = FALSE)\nwrite.csv(keys_both,\"analysis/utils/keys/parsed_keys/keys_both\", row.names = FALSE)\nwrite.csv(keys_satisfice_left,\"analysis/utils/keys/parsed_keys/keys_satisfice_left\", row.names = FALSE)\nwrite.csv(keys_satisfice_right,\"analysis/utils/keys/parsed_keys/keys_satisfice_right\", row.names = FALSE)\nwrite.csv(keys_tversky_duration,\"analysis/utils/keys/parsed_keys/keys_tversky_duration\", row.names = FALSE)\nwrite.csv(keys_tversky_end,\"analysis/utils/keys/parsed_keys/keys_tversky_end\", row.names = FALSE)\nwrite.csv(keys_tversky_max,\"analysis/utils/keys/parsed_keys/keys_tversky_max\", row.names = FALSE)\nwrite.csv(keys_tversky_start,\"analysis/utils/keys/parsed_keys/keys_tversky_start\", row.names = FALSE)\n\n\n\n\n\n2. Calculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangular interpretation?\nscore_ORTH How consistent is the response with the orthogonal interpretation?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation?\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\nTo facilitate scoring, we import the following helper functions in each scoring script.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\nprint(calc_subscore)\n\n\nfunction (question, cond, response, keyframe) \n{\n    if (cond == \"IMPASSE\" & question < 6) {\n        p = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"impasse\") %>% dplyr::select(set_p) %>% pull(set_p) %>% \n            str_split(\"\") %>% unlist()\n        q = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"impasse\") %>% dplyr::select(set_q) %>% pull(set_q) %>% \n            str_split(\"\") %>% unlist()\n        pn = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"impasse\") %>% dplyr::select(n_p)\n        qn = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"impasse\") %>% dplyr::select(n_q)\n    }\n    else {\n        p = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"DEFAULT\") %>% dplyr::select(set_p) %>% pull(set_p) %>% \n            str_split(\"\") %>% unlist()\n        q = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"DEFAULT\") %>% dplyr::select(set_q) %>% pull(set_q) %>% \n            str_split(\"\") %>% unlist()\n        pn = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"DEFAULT\") %>% dplyr::select(n_p)\n        qn = keyframe %>% filter(Q == question) %>% filter(condition == \n            \"DEFAULT\") %>% dplyr::select(n_q)\n    }\n    if (response != \"\") {\n        response = response %>% str_split(\"\") %>% unlist()\n    }\n    ps = length(intersect(response, p))\n    qs = length(intersect(response, q))\n    x = f_partialP(ps, pn, qs, qn) %>% unlist() %>% as.numeric()\n    rm(p, q, pn, qn, ps, qs)\n    return(x)\n}\n\n\n\n\n3. Derive Interpretation\nNext, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\nprint(derive_interpretation)\n\n\nfunction (df) \n{\n    print(\"DERIVING INTERPRETATION\")\n    threshold_range = 0.5\n    threshold_frenzy = 4\n    for (x in 1:nrow(df)) {\n        t = df[x, ] %>% dplyr::select(score_TV_max, score_TV_start, \n            score_TV_end, score_TV_duration)\n        t.long = gather(t, score, value, 1:4)\n        t.long$value <- t.long$value %>% unlist\n        t.long[t.long == \"\"] = NA\n        if (length(unique(t.long$value)) == 1) {\n            if (is.na(unique(t.long$value))) {\n                df[x, \"score_TVERSKY\"] = NA\n                df[x, \"tv_type\"] = NA\n            }\n        }\n        else {\n            df[x, \"score_TVERSKY\"] = as.numeric(max(t.long$value, \n                na.rm = TRUE))\n            df[x, \"tv_type\"] = t.long[which.max(t.long$value), \n                \"score\"]\n        }\n        t = df[x, ] %>% dplyr::select(score_SAT_left, score_SAT_right)\n        t.long = gather(t, score, value, 1:2)\n        t.long$value <- t.long$value %>% unlist\n        t.long[t.long == \"\"] = NA\n        if (length(unique(t.long$value)) == 1) {\n            if (is.na(unique(t.long$value))) {\n                df[x, \"score_SATISFICE\"] = NA\n                df[x, \"sat_type\"] = NA\n            }\n        }\n        else {\n            df[x, \"score_SATISFICE\"] = as.numeric(max(t.long$value, \n                na.rm = TRUE))\n            df[x, \"sat_type\"] = t.long[which.max(t.long$value), \n                \"score\"]\n        }\n        t = df[x, ] %>% dplyr::select(score_TRI, score_TVERSKY, \n            score_SATISFICE, score_ORTH)\n        t.long = gather(t, score, value, 1:4)\n        t.long$value <- t.long$value %>% unlist\n        t.long[t.long == \"\"] = NA\n        df[x, \"top_score\"] = as.numeric(max(t.long$value, na.rm = TRUE))\n        df[x, \"top_type\"] = t.long[which.max(t.long$value), \"score\"]\n        r = as.numeric(range(t.long$value, na.rm = TRUE))\n        r = diff(r)\n        df[x, \"range\"] = r\n        if (r < threshold_range) {\n            df[x, \"best\"] = \"?\"\n        }\n        else {\n            p = df[x, \"top_type\"]\n            if (p == \"score_TRI\") {\n                df[x, \"best\"] = \"Triangular\"\n            }\n            else if (p == \"score_ORTH\") {\n                df[x, \"best\"] = \"Orthogonal\"\n            }\n            else if (p == \"score_TVERSKY\") {\n                df[x, \"best\"] = \"Tversky\"\n            }\n            else if (p == \"score_SATISFICE\") {\n                df[x, \"best\"] = \"Satisfice\"\n            }\n        }\n        if (!is.na(df[x, \"score_BOTH\"])) {\n            if (df[x, \"score_BOTH\"] == 1) {\n                df[x, \"best\"] = \"both tri + orth\"\n            }\n        }\n        if (df[x, \"num_o\"] == 0) {\n            df[x, \"best\"] = \"blank\"\n        }\n        if (df[x, \"num_o\"] > threshold_frenzy) {\n            df[x, \"best\"] = \"frenzy\"\n        }\n        if (!is.na(df[x, \"score_REF\"])) {\n            if (df[x, \"score_REF\"] == 1) {\n                df[x, \"best\"] = \"reference\"\n            }\n        }\n    }\n    rm(t, t.long, x, r, p)\n    rm(threshold_frenzy, threshold_range)\n    df$int2 <- factor(df$best, levels = c(\"Triangular\", \"Tversky\", \n        \"Satisfice\", \"Orthogonal\", \"reference\", \"both tri + orth\", \n        \"blank\", \"frenzy\", \"?\"))\n    df$interpretation <- factor(df$best, levels = c(\"Orthogonal\", \n        \"Satisfice\", \"frenzy\", \"?\", \"reference\", \"blank\", \"both tri + orth\", \n        \"Tversky\", \"Triangular\"))\n    df$high_interpretation <- fct_collapse(df$interpretation, \n        orthogonal = c(\"Satisfice\", \"Orthogonal\"), neg.trans = c(\"frenzy\", \n            \"?\"), neutral = c(\"reference\", \"blank\"), pos.trans = c(\"Tversky\", \n            \"both tri + orth\"), triangular = \"Triangular\")\n    df$tv_type = as.factor(df$tv_type)\n    df$top_type = as.factor(df$top_type)\n    df$high_interpretation = factor(df$high_interpretation, levels = c(\"orthogonal\", \n        \"neg.trans\", \"neutral\", \"pos.trans\", \"triangular\"))\n    df <- df %>% dplyr::select(-best)\n    return(df)\n}\n\n\n\n\n4. Derive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\nprint(calc_scaled)\n\n\nfunction (v) \n{\n    v <- recode(v, Orthogonal = -1, Satisfice = -1, frenzy = -0.5, \n        `?` = -0.5, reference = 0, blank = 0, `both tri + orth` = 0.5, \n        Tversky = 0.5, Triangular = 1)\n    return(v)\n}\n\n\n\n\n5. Summarize by Subject\nThe final step in the scoring procedure is to summarise the item-level scores by subject, and save certain summaries to the subject-level record. We also construct two long-format dataframes containing cummulative progress scores (the point-in-time [absolute, scaled] scores for each subject on each question).\n\n\nCODE\nprint(summarise_bySubject)\n\n\nfunction (subjects, items) \n{\n    subjects_summary <- items %>% filter(q %nin% c(6, 9)) %>% \n        group_by(subject) %>% dplyr::summarise(subject = as.character(subject), \n        s_TRI = sum(score_TRI, na.rm = TRUE), s_ORTH = sum(score_ORTH, \n            na.rm = TRUE), s_TVERSKY = sum(score_TVERSKY, na.rm = TRUE), \n        s_SATISFICE = sum(score_SATISFICE, na.rm = TRUE), s_REF = sum(score_REF, \n            na.rm = TRUE), s_ABS = sum(score_ABS, na.rm = TRUE), \n        s_NABS = sum(score_niceABS, na.rm = TRUE), s_SCALED = sum(score_SCALED, \n            na.rm = TRUE), DV_percent_NABS = s_NABS/13, rt_m = sum(rt_s)/60, \n        item_avg_rt = mean(rt_s), item_min_rt = min(rt_s), item_max_rt = max(rt_s), \n        item_n_TRI = sum(interpretation == \"Triangular\"), item_n_ORTH = sum(interpretation == \n            \"Orthogonal\"), item_n_TV = sum(interpretation == \n            \"Tversky\"), item_n_SAT = sum(interpretation == \"Satisfice\"), \n        item_n_OTHER = sum(interpretation %nin% c(\"Triangular\", \n            \"Orthogonal\", \"Tversky\", \"Satisfice\")), item_n_POS = sum(high_interpretation == \n            \"pos.trans\"), item_n_NEG = sum(high_interpretation == \n            \"neg.trans\"), item_n_NEUTRAL = sum(high_interpretation == \n            \"neutral\")) %>% arrange(subject) %>% slice(1L)\n    subjects_q1 <- items %>% filter(q == 1) %>% mutate(item_q1_NABS = score_niceABS, \n        item_q1_SCALED = score_SCALED, item_q1_interpretation = interpretation, \n        item_q1_rt = rt_s, ) %>% dplyr::select(subject, item_q1_NABS, \n        item_q1_SCALED, item_q1_interpretation, item_q1_rt) %>% \n        arrange(subject)\n    subjects_q5 <- items %>% filter(q == 5) %>% mutate(item_q5_NABS = score_niceABS, \n        item_q5_SCALED = score_SCALED, item_q5_interpretation = interpretation, \n        item_q5_rt = rt_s, ) %>% dplyr::select(subject, item_q5_NABS, \n        item_q5_SCALED, item_q5_interpretation, item_q5_rt) %>% \n        arrange(subject)\n    subjects_q7 <- items %>% filter(q == 7) %>% mutate(item_q7_NABS = score_niceABS, \n        item_q7_interpretation = interpretation, item_q7_rt = rt_s, \n        ) %>% dplyr::select(subject, item_q7_NABS, item_q7_interpretation, \n        item_q7_rt) %>% arrange(subject)\n    subjects_q15 <- items %>% filter(q == 15) %>% mutate(item_q15_NABS = score_niceABS, \n        item_q15_interpretation = interpretation, item_q15_rt = rt_s, \n        ) %>% dplyr::select(subject, item_q15_NABS, item_q15_interpretation, \n        item_q15_rt) %>% arrange(subject)\n    subjects_scaffold <- items %>% filter(q < 6) %>% group_by(subject) %>% \n        dplyr::summarise(item_scaffold_NABS = sum(score_niceABS), \n            item_scaffold_SCALED = sum(score_SCALED), item_scaffold_rt = sum(rt_s)/60) %>% \n        dplyr::select(subject, item_scaffold_NABS, item_scaffold_SCALED, \n            item_scaffold_rt) %>% arrange(subject)\n    subjects_test <- items %>% filter(q %nin% c(1, 2, 3, 4, 5, \n        6, 9)) %>% group_by(subject) %>% dplyr::summarise(item_test_NABS = sum(score_niceABS), \n        item_test_SCALED = sum(score_SCALED), item_test_rt = sum(rt_s)/60) %>% \n        dplyr::select(subject, item_test_NABS, item_test_SCALED, \n            item_test_rt) %>% arrange(subject)\n    print(unique(subjects_summary$subject == subjects$subject))\n    print(unique(subjects_summary$subject == subjects_q1$subject))\n    print(unique(subjects_summary$subject == subjects_q5$subject))\n    print(unique(subjects_summary$subject == subjects_q7$subject))\n    print(unique(subjects_summary$subject == subjects_q15$subject))\n    print(unique(subjects_summary$subject == subjects_scaffold$subject))\n    print(unique(subjects_summary$subject == subjects_test$subject))\n    x = merge(subjects, subjects_summary, by.x = \"subject\", by.y = \"subject\")\n    x = merge(x, subjects_q1)\n    x = merge(x, subjects_q5)\n    x = merge(x, subjects_q7)\n    x = merge(x, subjects_q15)\n    x = merge(x, subjects_scaffold)\n    x = merge(x, subjects_test)\n    subjects <- x\n    rm(subjects_q1, subjects_q5, subjects_q7, subjects_q15, subjects_scaffold, \n        subjects_test, subjects_summary, x)\n    return(subjects)\n}\n\n\nCODE\nprint(progress_Absolute)\n\n\nfunction (items) \n{\n    x <- items %>% filter(q %nin% c(6, 9)) %>% dplyr::select(subject, \n        mode, pretty_condition, q, score_niceABS)\n    wide <- x %>% pivot_wider(names_from = q, names_glue = \"q_{q}\", \n        values_from = score_niceABS)\n    wide$c1 = wide$q_1\n    wide$c2 = wide$c1 + wide$q_2\n    wide$c3 = wide$c2 + wide$q_3\n    wide$c4 = wide$c3 + wide$q_4\n    wide$c5 = wide$c4 + wide$q_5\n    wide$c6 = wide$c5 + wide$q_7\n    wide$c7 = wide$c6 + wide$q_8\n    wide$c8 = wide$c7 + wide$q_10\n    wide$c9 = wide$c8 + wide$q_11\n    wide$c10 = wide$c9 + wide$q_12\n    wide$c11 = wide$c10 + wide$q_13\n    wide$c12 = wide$c11 + wide$q_14\n    wide$c13 = wide$c12 + wide$q_15\n    wide <- wide %>% dplyr::select(subject, mode, pretty_condition, \n        c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13)\n    df_absolute_progress <- wide %>% pivot_longer(cols = c1:c13, \n        names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\n    df_absolute_progress$question <- as.integer(df_absolute_progress$question)\n    rm(x, wide)\n    return(df_absolute_progress)\n}\n\n\nCODE\nprint(progress_Scaled)\n\n\nfunction (items) \n{\n    x <- items %>% filter(q %nin% c(6, 9)) %>% dplyr::select(subject, \n        mode, pretty_condition, q, score_SCALED)\n    wide <- x %>% pivot_wider(names_from = q, names_glue = \"q_{q}\", \n        values_from = score_SCALED)\n    wide$c1 = wide$q_1\n    wide$c2 = wide$c1 + wide$q_2\n    wide$c3 = wide$c2 + wide$q_3\n    wide$c4 = wide$c3 + wide$q_4\n    wide$c5 = wide$c4 + wide$q_5\n    wide$c6 = wide$c5 + wide$q_7\n    wide$c7 = wide$c6 + wide$q_8\n    wide$c8 = wide$c7 + wide$q_10\n    wide$c9 = wide$c8 + wide$q_11\n    wide$c10 = wide$c9 + wide$q_12\n    wide$c11 = wide$c10 + wide$q_13\n    wide$c12 = wide$c11 + wide$q_14\n    wide$c13 = wide$c12 + wide$q_15\n    wide <- wide %>% dplyr::select(subject, mode, pretty_condition, \n        c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13)\n    df_scaled_progress <- wide %>% pivot_longer(cols = c1:c13, \n        names_to = \"question\", names_pattern = \"c(.*)\", values_to = \"score\")\n    df_scaled_progress$question <- as.integer(df_scaled_progress$question)\n    rm(x, wide)\n    return(df_scaled_progress)\n}\n\n\n\n\n\n\n\n\nSchmidt, Dennis, Tobias Raupach, Annette Wiegand, Manfred Herrmann, and Philipp Kanzow. 2021. “Relation Between Examinees’ True Knowledge and Examination Scores: Systematic Review and Exemplary Calculations on Multiple-True-False Items.” Educational Research Review 34 (November): 100409. https://doi.org/10.1016/j.edurev.2021.100409."
  },
  {
    "objectID": "analysis/SGC4B/2_sgc4B_scoring.html#explore-responses",
    "href": "analysis/SGC4B/2_sgc4B_scoring.html#explore-responses",
    "title": "17  Response Scoring",
    "section": "EXPLORE RESPONSES",
    "text": "EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nScaffold Phase\nThe first five questions constitute the ‘scaffold’ (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\nQuestion #1\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\n\n\n\nFigure 17.1: Question 1 — NonImpasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Control Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    A \n    OI \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    CF \n    Z \n  \n  \n    Tversky [start diagonal] \n    F \n    Z \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nHere we summarize the distinct response options given by participants on this item. Each letter in response indicates a checkbox selected by the participant (See Figure 17.1 ). n indicates the number of participants who gave this response, while interpretation indicates the graph interpretation most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\nNotice that for this Question, the Triangular answer is the same as the Tversky [start diagonal] answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 2) %>% \n  # pack_rows(\"Orthogonal\", 3, 3) %>% \n  # pack_rows(\"Other\", 4, 4)  %>% \n  # pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    29 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    CF \n    3 \n    Tversky \n    0 \n    0.923 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    A \n    236 \n    Orthogonal \n    0 \n    -0.077 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AIO \n    1 \n    Orthogonal \n    0 \n    -0.231 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AF \n    1 \n    both tri + orth \n    0 \n    0.923 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACF \n    1 \n    ? \n    0 \n    0.846 \n    0.917 \n    NA \n    0.833 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #2\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.2: Q2—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==2)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n    E \n    G \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AKJX \n    Z \n  \n  \n    Tversky [start diagonal] \n    AK \n    Z \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 4) %>% \n  # pack_rows(\"Orthogonal\", 5, 7) %>%\n  # pack_rows(\"Other\", 8, 8)  %>% \n  # pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    35 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    DK \n    2 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    KZ \n    1 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.167 \n    1.0 \n  \n  \n    J \n    7 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AK \n    1 \n    Tversky \n    0 \n    0.917 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    X \n    1 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    E \n    215 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DE \n    4 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EG \n    2 \n    Orthogonal \n    0 \n    -0.167 \n    -0.154 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    D \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #3\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.3: Q3—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==3)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Control Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    Z \n    FIO \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AUBFOJ \n     \n  \n  \n    Tversky [start diagonal] \n    OJ \n     \n  \n  \n    Tversky [end diagonal] \n    F \n    Z \n  \n  \n    Tversky [duration line] \n    AUB \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    41 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    0.0 \n    1.0 \n  \n  \n    FG \n    2 \n    Triangular \n    0 \n    0.917 \n    0.917 \n    NA \n    -0.1 \n    1.0 \n  \n  \n    FU \n    1 \n    Triangular \n    0 \n    0.917 \n    0.917 \n    NA \n    -0.1 \n    1.0 \n  \n  \n    O \n    4 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    0.0 \n    0.5 \n  \n  \n    ABU \n    2 \n    Tversky \n    0 \n    -0.250 \n    1.000 \n    NA \n    -0.3 \n    0.5 \n  \n  \n    IO \n    2 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    0.0 \n    0.5 \n  \n  \n    ABCU \n    1 \n    Tversky \n    0 \n    -0.250 \n    1.000 \n    NA \n    -0.3 \n    0.5 \n  \n  \n    JO \n    1 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    Z \n    157 \n    Orthogonal \n    0 \n    0.000 \n    0.000 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    AZ \n    1 \n    Orthogonal \n    0 \n    -0.083 \n    0.242 \n    NA \n    0.9 \n    -1.0 \n  \n  \n    FZ \n    1 \n    both tri + orth \n    1 \n    1.000 \n    1.000 \n    NA \n    1.0 \n    0.5 \n  \n  \n     \n    9 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n    BDEFGKU \n    1 \n    frenzy \n    0 \n    0.500 \n    0.500 \n    NA \n    -0.6 \n    -0.5 \n  \n  \n    A \n    41 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    U \n    3 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    AH \n    2 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    AFZ \n    1 \n    ? \n    0 \n    0.917 \n    0.917 \n    NA \n    0.9 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 17)  \n\n\n\n\nQuestion #4\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.4: Q4—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==4)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n    U \n    OF \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    51 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    B \n    1 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    BH \n    1 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    U \n    130 \n    Orthogonal \n    0 \n    -0.071 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    6 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FOU \n    2 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    OU \n    2 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DEU \n    1 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    0.833 \n    -1.0 \n  \n  \n    EFU \n    1 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    0.917 \n    -1.0 \n  \n  \n    IOU \n    1 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    0.917 \n    -1.0 \n  \n  \n    UX \n    1 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    0.917 \n    -1.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACFHIJKOUZ \n    1 \n    frenzy \n    0 \n    0.357 \n    0.357 \n    NA \n    0.417 \n    -0.5 \n  \n  \n    DE \n    46 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    E \n    5 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    F \n    5 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    G \n    3 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    D \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    HJU \n    1 \n    ? \n    0 \n    0.857 \n    0.857 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 3) %>% \n#   pack_rows(\"Orthogonal\", 4, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 16) \n\n\n\nTBL4 test\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n |\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\nQuestion #5\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.5: Q5—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==5)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    O \n    AZ \n  \n  \n    Orthgonal \n    U \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    UGX \n    AZKD \n  \n  \n    Tversky [start diagonal] \n    X \n     \n  \n  \n    Tversky [end diagonal] \n    UG \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    O \n    101 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    AO \n    2 \n    Triangular \n    1 \n    1.000 \n    -0.143 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    IO \n    2 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    FO \n    1 \n    Triangular \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    HJO \n    1 \n    Triangular \n    0 \n    0.818 \n    -0.231 \n    NA \n    -0.231 \n    1.0 \n  \n  \n    HO \n    1 \n    Triangular \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    FG \n    1 \n    Tversky \n    0 \n    -0.182 \n    0.417 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    U \n    68 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    5 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    HU \n    3 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    IU \n    3 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    CHJU \n    1 \n    Orthogonal \n    0 \n    -0.364 \n    0.250 \n    NA \n    0.769 \n    -1.0 \n  \n  \n    I \n    2 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    OU \n    1 \n    both tri + orth \n    0 \n    0.909 \n    0.417 \n    NA \n    0.923 \n    0.5 \n  \n  \n     \n    15 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    BDEFGHJKOUX \n    1 \n    frenzy \n    0 \n    0.091 \n    0.250 \n    NA \n    0.231 \n    -0.5 \n  \n  \n    DEHJUX \n    1 \n    frenzy \n    0 \n    -0.545 \n    0.615 \n    NA \n    0.615 \n    -0.5 \n  \n  \n    FHIJKOUX \n    1 \n    frenzy \n    0 \n    0.455 \n    0.538 \n    NA \n    0.538 \n    -0.5 \n  \n  \n    FHJKOUZ \n    1 \n    frenzy \n    0 \n    0.545 \n    0.000 \n    NA \n    0.538 \n    -0.5 \n  \n  \n    FHKOXZ \n    1 \n    frenzy \n    0 \n    0.636 \n    0.615 \n    NA \n    -0.462 \n    -0.5 \n  \n  \n    F \n    14 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    H \n    8 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    K \n    8 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    J \n    5 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DJ \n    4 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HJ \n    3 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    Z \n    3 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    C \n    2 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    E \n    2 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    FZ \n    2 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HK \n    2 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    AC \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    AZ \n    1 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    BHK \n    1 \n    ? \n    0 \n    -0.273 \n    -0.231 \n    NA \n    -0.231 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DE \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    EK \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>% \n#   pack_rows(\"Lines-Connect\", 5, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 9) %>% \n#   pack_rows(\"Other\", 10, 11) %>% \n#   pack_rows(\"Unknown\", 12, 22) \n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\n\nTesting Phase\nThe following 10 questions were the same for both conditions.\n\nQuestion #7\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.6: Q7-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    OX \n     \n  \n  \n    Orthgonal \n    BF \n    M \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    IJZNCHOX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n    IJZN \n     \n  \n  \n    Tversky [duration line] \n    CH \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #7\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    OX \n    48 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    IJOX \n    1 \n    Triangular \n    0 \n    0.875 \n    0.875 \n    NA \n    -0.267 \n    1.0 \n  \n  \n    IO \n    1 \n    Triangular \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    MX \n    1 \n    Triangular \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    CH \n    1 \n    Tversky \n    0 \n    -0.125 \n    1.000 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    BF \n    202 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FZ \n    13 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BDFIJMNOX \n    1 \n    frenzy \n    0 \n    0.562 \n    0.562 \n    NA \n    0.600 \n    -0.5 \n  \n  \n    BDFIJMNOXZ \n    1 \n    frenzy \n    0 \n    0.500 \n    0.571 \n    NA \n    0.533 \n    -0.5 \n  \n  \n    LP \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.133 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>%\n#   pack_rows(\"Lines-Connect\", 6, 9) %>%\n#   pack_rows(\"Orthogonal\", 10, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 17)\n\n\n\n\nQuestion #8\n\n\n\nFigure 17.7: Q8-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    E \n    F \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #8\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    40 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    CGM \n    4 \n    Triangular \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    1.0 \n  \n  \n    AG \n    1 \n    Triangular \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    1.0 \n  \n  \n    AGK \n    1 \n    Triangular \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    1.0 \n  \n  \n    CG \n    1 \n    Triangular \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    1.0 \n  \n  \n    FG \n    1 \n    Triangular \n    0 \n    0.933 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    E \n    140 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EI \n    5 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EIJ \n    3 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EF \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EJ \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EG \n    1 \n    both tri + orth \n    0 \n    0.933 \n    NA \n    NA \n    0.929 \n    0.5 \n  \n  \n     \n    7 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJNOZ \n    2 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    CDGHNZ \n    1 \n    frenzy \n    0 \n    0.667 \n    NA \n    NA \n    -0.429 \n    -0.5 \n  \n  \n    CDGLNXZ \n    1 \n    frenzy \n    0 \n    0.667 \n    NA \n    NA \n    -0.429 \n    -0.5 \n  \n  \n    CEGHOZ \n    1 \n    frenzy \n    0 \n    0.667 \n    NA \n    NA \n    0.643 \n    -0.5 \n  \n  \n    DEHIJNZ \n    1 \n    frenzy \n    0 \n    -0.467 \n    NA \n    NA \n    0.571 \n    -0.5 \n  \n  \n    DHNOZ \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    DIJMN \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    DIJNO \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    IJ \n    17 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    F \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    J \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    I \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    M \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    A \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    HOZ \n    2 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    AX \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    DIJN \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DJN \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    DNOZ \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    HL \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    IJM \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    LX \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Orthogonal\", 11, 16) %>%\n#   pack_rows(\"Other\", 17, 21) %>%\n#   pack_rows(\"Unknown\", 22, 45)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #10\n\n\n\nFigure 17.8: Q10-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    E \n     \n  \n  \n    Orthgonal \n    X \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    EGZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n    E \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #10\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    E \n    60 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    BEF \n    1 \n    Triangular \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    1.0 \n  \n  \n    Z \n    20 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    G \n    2 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    GJ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    X \n    126 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FX \n    8 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BX \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.938 \n    -1.0 \n  \n  \n    F \n    4 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    EX \n    4 \n    both tri + orth \n    0 \n    0.938 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    B \n    29 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    7 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    LO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>%\n#   pack_rows(\"Lines-Connect\", 3, 7) %>%\n#   pack_rows(\"Orthogonal\", 8, 11) %>%\n#   pack_rows(\"Other\", 12, 14) %>%\n#   pack_rows(\"Unknown\", 15, 27)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #11\n\n\n\nFigure 17.9: Q11-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at 12pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    ML \n     \n  \n  \n    Orthgonal \n    FB \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #11\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    LM \n    54 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.125 \n    1.0 \n  \n  \n    M \n    3 \n    Triangular \n    0 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    AGM \n    1 \n    Triangular \n    0 \n    0.375 \n    NA \n    NA \n    -0.188 \n    1.0 \n  \n  \n    L \n    1 \n    Triangular \n    0 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    BF \n    206 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    EF \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    0.438 \n    -1.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCEFGIJKP \n    1 \n    frenzy \n    0 \n    -0.625 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    EIJ \n    1 \n    ? \n    0 \n    -0.188 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    IX \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 9) %>%\n#   pack_rows(\"Other\", 10, 12) %>%\n#   pack_rows(\"Unknown\", 13, 17)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #12\n\n\n\nFigure 17.10: Q12-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    GZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #12\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    52 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    FG \n    2 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    GLM \n    1 \n    Triangular \n    0 \n    0.875 \n    0.875 \n    NA \n    -0.188 \n    1.0 \n  \n  \n    GP \n    1 \n    Triangular \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    1.0 \n  \n  \n    Z \n    3 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    KZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    NZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    B \n    196 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    9 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    2 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Lines-Connect\", 4, 6) %>%\n#   pack_rows(\"Orthogonal\", 7, 8) %>%\n#   pack_rows(\"Other\", 9, 10) %>%\n#   pack_rows(\"Unknown\", 11, 14)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #13\n\n\n\nFigure 17.11: Q13-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts end when Z begins?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EF \n     \n  \n  \n    Orthgonal \n    FX \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #13\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EF \n    53 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    0.433 \n    1.0 \n  \n  \n    FX \n    141 \n    Orthogonal \n    0 \n    0.433 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    X \n    9 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    OX \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    KX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    BFX \n    1 \n    Orthogonal \n    0 \n    0.367 \n    NA \n    NA \n    0.933 \n    -1.0 \n  \n  \n    BX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    F \n    9 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    HL \n    7 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BF \n    6 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    CH \n    4 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DN \n    4 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    EX \n    3 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    HLP \n    3 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    HN \n    3 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    GO \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    BIJM \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.267 \n    -0.5 \n  \n  \n    CG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CGO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    CO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HI \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    KZ \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    LP \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Orthogonal\", 4, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 36)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #14\n\n\n\nFigure 17.12: Q14-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at 3pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    X \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XJND \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    JND \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #14\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    X \n    64 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.059 \n    1.0 \n  \n  \n    OX \n    2 \n    Triangular \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    1.0 \n  \n  \n    FX \n    1 \n    Triangular \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    1.0 \n  \n  \n    HX \n    1 \n    Triangular \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    1.0 \n  \n  \n    B \n    147 \n    Orthogonal \n    0 \n    -0.059 \n    -0.059 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    4 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BIO \n    3 \n    Orthogonal \n    0 \n    -0.176 \n    -0.176 \n    NA \n    0.882 \n    -1.0 \n  \n  \n    BO \n    1 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BX \n    3 \n    both tri + orth \n    0 \n    0.941 \n    0.941 \n    NA \n    0.941 \n    0.5 \n  \n  \n     \n    24 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    O \n    8 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    H \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    HLP \n    2 \n    ? \n    0 \n    -0.176 \n    -0.176 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.059 \n    0.333 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    F \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    IJM \n    1 \n    ? \n    0 \n    -0.176 \n    0.200 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.118 \n    0.267 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 7) %>%\n#   pack_rows(\"Other\", 8, 9) %>%\n#   pack_rows(\"Unknown\", 10, 22)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nQuestion #15\n\n\n\nFigure 17.13: Q15-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Coffee breaks happen halfway through a shift. Which shifts share a break at 2pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    XK \n     \n  \n  \n    Orthgonal \n    EF \n    B \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XKZ \n     \n  \n  \n    Tversky [start diagonal] \n    Z \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #15\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    KX \n    68 \n    Triangular \n    1 \n    1.000 \n    0.667 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    X \n    9 \n    Triangular \n    0 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    K \n    5 \n    Triangular \n    0 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    DJNX \n    1 \n    Triangular \n    0 \n    0.312 \n    0.133 \n    NA \n    -0.267 \n    1.0 \n  \n  \n    HK \n    1 \n    Triangular \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    NX \n    1 \n    Triangular \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    OX \n    1 \n    Triangular \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    FZ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    0.433 \n    0.5 \n  \n  \n    GZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    HLZ \n    1 \n    Tversky \n    0 \n    -0.188 \n    0.882 \n    NA \n    -0.200 \n    0.5 \n  \n  \n    NZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    EF \n    111 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    21 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BF \n    8 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BEF \n    4 \n    Orthogonal \n    0 \n    -0.188 \n    -0.176 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    E \n    3 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    CF \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FI \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    AEIM \n    1 \n    Orthogonal \n    0 \n    -0.250 \n    -0.235 \n    NA \n    0.300 \n    -1.0 \n  \n  \n    CE \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EFL \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    -0.176 \n    NA \n    0.933 \n    -1.0 \n  \n  \n    EG \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EI \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EM \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FO \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    L \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AG \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    BG \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FNX \n    1 \n    ? \n    0 \n    0.375 \n    0.200 \n    NA \n    0.367 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HN \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IJM \n    1 \n    ? \n    0 \n    -0.188 \n    -0.176 \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Lines-Connect\", 11, 13) %>%\n#   pack_rows(\"Orthogonal\", 14, 22) %>%\n#   pack_rows(\"Other\", 23, 23) %>%\n#   pack_rows(\"Unknown\", 24, 44)\n\n\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nNON-DISCRIMINANT\n\nQuestion #6 NONDISCRIM\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 17.14: Q6-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) are six hours long?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EG \n     \n  \n  \n    Orthgonal \n    EG \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\nTODO discuss non discriminant\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #6\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EG \n    272 \n    both tri + orth \n    1 \n    1 \n    NA \n    NA \n    1 \n    0.5 \n  \n\n\n\n\n\n\n\nQuestion #9 NONDISCRIM\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) begins before J begins and ends during B?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    I \n     \n  \n  \n    Orthgonal \n    I \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #9\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    I \n    214 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    18 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    E \n    15 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    EI \n    3 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FI \n    3 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    HKM \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    HX \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IMO \n    1 \n    ? \n    0 \n    0.867 \n    NA \n    NA \n    0.867 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Other\", 1, 2) %>%\n#   pack_rows(\"Unknown\", 3, 19)"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#explore-responses",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#explore-responses",
    "title": "14  Response Scoring",
    "section": "EXPLORE RESPONSES",
    "text": "EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nScaffold Phase\nThe first five questions constitute the ‘scaffold’ (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\nQuestion #1\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\n\n\n\nFigure 14.1: Question 1 — NonImpasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Control Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    A \n    OI \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    CF \n    Z \n  \n  \n    Tversky [start diagonal] \n    F \n    Z \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nHere we summarize the distinct response options given by participants on this item. Each letter in response indicates a checkbox selected by the participant (See Figure 17.1 ). n indicates the number of participants who gave this response, while interpretation indicates the graph interpretation most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\nNotice that for this Question, the Triangular answer is the same as the Tversky [start diagonal] answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 2) %>% \n  # pack_rows(\"Orthogonal\", 3, 3) %>% \n  # pack_rows(\"Other\", 4, 4)  %>% \n  # pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    59 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    CF \n    17 \n    Tversky \n    0 \n    0.923 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    C \n    3 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    ABCU \n    1 \n    Tversky \n    0 \n    -0.308 \n    0.786 \n    NA \n    0.750 \n    0.5 \n  \n  \n    AC \n    1 \n    Tversky \n    0 \n    -0.154 \n    0.929 \n    NA \n    0.917 \n    0.5 \n  \n  \n    ACE \n    1 \n    Tversky \n    0 \n    -0.231 \n    0.857 \n    NA \n    0.833 \n    0.5 \n  \n  \n    FK \n    1 \n    Tversky \n    0 \n    0.923 \n    0.923 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    A \n    477 \n    Orthogonal \n    0 \n    -0.077 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AIO \n    3 \n    Orthogonal \n    0 \n    -0.231 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AO \n    1 \n    Orthogonal \n    0 \n    -0.154 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AF \n    2 \n    both tri + orth \n    0 \n    0.923 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCDEHIJKOU \n    1 \n    frenzy \n    0 \n    -0.846 \n    0.286 \n    NA \n    0.333 \n    -0.5 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.077 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    Z \n    2 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    ACF \n    1 \n    ? \n    0 \n    0.846 \n    0.917 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    AFJU \n    1 \n    ? \n    0 \n    0.769 \n    0.769 \n    NA \n    0.750 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.154 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    DX \n    1 \n    ? \n    0 \n    -0.154 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    EH \n    1 \n    ? \n    0 \n    -0.154 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.077 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #2\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.2: Q2—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==2)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n    E \n    G \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AKJX \n    Z \n  \n  \n    Tversky [start diagonal] \n    AK \n    Z \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 4) %>% \n  # pack_rows(\"Orthogonal\", 5, 7) %>%\n  # pack_rows(\"Other\", 8, 8)  %>% \n  # pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    73 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    DK \n    4 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    J \n    17 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AK \n    10 \n    Tversky \n    0 \n    0.917 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    JK \n    2 \n    Tversky \n    0 \n    0.917 \n    0.923 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    X \n    2 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    A \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    EJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n    HJU \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.846 \n    NA \n    -0.250 \n    0.5 \n  \n  \n    IJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.923 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    KX \n    1 \n    Tversky \n    0 \n    0.917 \n    0.923 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    E \n    438 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DE \n    10 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EG \n    1 \n    Orthogonal \n    0 \n    -0.167 \n    -0.154 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    D \n    6 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    4 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJO \n    1 \n    frenzy \n    0 \n    -0.417 \n    0.692 \n    NA \n    0.667 \n    -0.5 \n  \n  \n    B \n    2 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    CD \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    UZ \n    1 \n    ? \n    0 \n    -0.083 \n    -0.091 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #3\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.3: Q3—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==3)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Control Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    Z \n    FIO \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AUBFOJ \n     \n  \n  \n    Tversky [start diagonal] \n    OJ \n     \n  \n  \n    Tversky [end diagonal] \n    F \n    Z \n  \n  \n    Tversky [duration line] \n    AUB \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    68 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    0.0 \n    1.0 \n  \n  \n    A \n    70 \n    Tversky \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    ABU \n    8 \n    Tversky \n    0 \n    -0.250 \n    1.000 \n    NA \n    -0.3 \n    0.5 \n  \n  \n    JO \n    8 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    O \n    5 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    0.0 \n    0.5 \n  \n  \n    FG \n    2 \n    Tversky \n    0 \n    0.917 \n    0.917 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    BOU \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.576 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    DJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    DJO \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.917 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    HJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    IO \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    0.0 \n    0.5 \n  \n  \n    J \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    KO \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    Z \n    353 \n    Orthogonal \n    0 \n    0.000 \n    0.000 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    IOZ \n    2 \n    Orthogonal \n    0 \n    -0.167 \n    0.333 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    DUZ \n    1 \n    Orthogonal \n    0 \n    -0.167 \n    0.152 \n    NA \n    0.8 \n    -1.0 \n  \n  \n    EZ \n    1 \n    Orthogonal \n    0 \n    -0.083 \n    -0.083 \n    NA \n    0.9 \n    -1.0 \n  \n  \n    C \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n    AF \n    1 \n    both tri + orth \n    0 \n    0.917 \n    0.917 \n    NA \n    -0.1 \n    0.5 \n  \n  \n     \n    17 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n    ABDEFGHIJKOUXZ \n    3 \n    frenzy \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    -0.5 \n  \n  \n    ABDEFGKUZ \n    1 \n    frenzy \n    0 \n    0.417 \n    0.455 \n    NA \n    0.3 \n    -0.5 \n  \n  \n    ABJOU \n    1 \n    frenzy \n    0 \n    -0.417 \n    0.833 \n    NA \n    -0.4 \n    -0.5 \n  \n  \n    U \n    9 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    AH \n    5 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    EU \n    4 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    0.0 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    DE \n    1 \n    ? \n    0 \n    -0.167 \n    -0.167 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    DI \n    1 \n    ? \n    0 \n    -0.167 \n    -0.167 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    EFK \n    1 \n    ? \n    0 \n    0.833 \n    0.833 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    HIU \n    1 \n    ? \n    0 \n    -0.250 \n    0.152 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 17)  \n\n\n\n\nQuestion #4\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.4: Q4—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==4)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n    U \n    OF \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    97 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    B \n    15 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AH \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    BDEG \n    1 \n    Tversky \n    0 \n    -0.286 \n    0.786 \n    NA \n    -0.333 \n    0.5 \n  \n  \n    BH \n    1 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    HK \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    U \n    294 \n    Orthogonal \n    0 \n    -0.071 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    17 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    OU \n    4 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    UX \n    4 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    0.917 \n    -1.0 \n  \n  \n    FOU \n    3 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    HU \n    1 \n    both tri + orth \n    0 \n    0.929 \n    0.929 \n    NA \n    0.917 \n    0.5 \n  \n  \n     \n    15 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACDEFHIJKOUXZ \n    1 \n    frenzy \n    0 \n    0.143 \n    0.143 \n    NA \n    0.167 \n    -0.5 \n  \n  \n    DE \n    74 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    E \n    11 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    F \n    8 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    K \n    6 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DEU \n    5 \n    ? \n    0 \n    -0.214 \n    -0.214 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    G \n    5 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    X \n    3 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    Z \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    BHU \n    1 \n    ? \n    0 \n    0.857 \n    0.923 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DEK \n    1 \n    ? \n    0 \n    -0.214 \n    -0.214 \n    NA \n    -0.250 \n    -0.5 \n  \n  \n    DEOU \n    1 \n    ? \n    0 \n    -0.286 \n    -0.286 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    DK \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    HJ \n    1 \n    ? \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    HJU \n    1 \n    ? \n    0 \n    0.857 \n    0.857 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 3) %>% \n#   pack_rows(\"Orthogonal\", 4, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 16) \n\n\n\nTBL4 test\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n |\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\nQuestion #5\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.5: Q5—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==5)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    O \n    AZ \n  \n  \n    Orthgonal \n    U \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    UGX \n    AZKD \n  \n  \n    Tversky [start diagonal] \n    X \n     \n  \n  \n    Tversky [end diagonal] \n    UG \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    O \n    167 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    IO \n    3 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    OZ \n    1 \n    Triangular \n    1 \n    1.000 \n    -0.143 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    X \n    4 \n    Tversky \n    0 \n    -0.091 \n    1.000 \n    NA \n    -0.077 \n    0.5 \n  \n  \n    G \n    3 \n    Tversky \n    0 \n    -0.091 \n    0.500 \n    NA \n    -0.077 \n    0.5 \n  \n  \n    BG \n    2 \n    Tversky \n    0 \n    -0.182 \n    0.417 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    BDFG \n    1 \n    Tversky \n    0 \n    -0.364 \n    0.250 \n    NA \n    -0.308 \n    0.5 \n  \n  \n    DHJX \n    1 \n    Tversky \n    0 \n    -0.364 \n    0.769 \n    NA \n    -0.308 \n    0.5 \n  \n  \n    DJX \n    1 \n    Tversky \n    0 \n    -0.273 \n    0.846 \n    NA \n    -0.231 \n    0.5 \n  \n  \n    FG \n    1 \n    Tversky \n    0 \n    -0.182 \n    0.417 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    HJOX \n    1 \n    Tversky \n    0 \n    0.727 \n    0.769 \n    NA \n    -0.308 \n    0.5 \n  \n  \n    JO \n    1 \n    Tversky \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    UX \n    1 \n    Tversky \n    0 \n    -0.182 \n    0.923 \n    NA \n    0.923 \n    0.5 \n  \n  \n    U \n    192 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    5 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    HU \n    5 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    IU \n    3 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FOU \n    1 \n    Orthogonal \n    0 \n    0.818 \n    0.333 \n    NA \n    0.846 \n    -1.0 \n  \n  \n    I \n    4 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    OU \n    5 \n    both tri + orth \n    0 \n    0.909 \n    0.417 \n    NA \n    0.923 \n    0.5 \n  \n  \n     \n    32 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCDEFGHJKOUXZ \n    1 \n    frenzy \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    DEHIJO \n    1 \n    frenzy \n    0 \n    0.636 \n    -0.385 \n    NA \n    -0.385 \n    -0.5 \n  \n  \n    F \n    34 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    H \n    25 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    K \n    14 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DJ \n    9 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    J \n    9 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    C \n    6 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    E \n    6 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    FO \n    6 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HK \n    6 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    A \n    5 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    Z \n    4 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    HJ \n    3 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    B \n    2 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    EH \n    2 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    AC \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    BEFK \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    DE \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    DEHJ \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    DJO \n    1 \n    ? \n    0 \n    0.818 \n    -0.231 \n    NA \n    -0.231 \n    -0.5 \n  \n  \n    EHJK \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    FZ \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HIJ \n    1 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    JK \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>% \n#   pack_rows(\"Lines-Connect\", 5, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 9) %>% \n#   pack_rows(\"Other\", 10, 11) %>% \n#   pack_rows(\"Unknown\", 12, 22) \n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\n\nTesting Phase\nThe following 10 questions were the same for both conditions.\n\nQuestion #7\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.6: Q7-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    OX \n     \n  \n  \n    Orthgonal \n    BF \n    M \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    IJZNCHOX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n    IJZN \n     \n  \n  \n    Tversky [duration line] \n    CH \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #7\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    OX \n    91 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    IJ \n    5 \n    Tversky \n    0 \n    -0.125 \n    0.500 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    CH \n    3 \n    Tversky \n    0 \n    -0.125 \n    1.000 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    H \n    2 \n    Tversky \n    0 \n    -0.062 \n    0.500 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    O \n    1 \n    Tversky \n    0 \n    0.500 \n    0.500 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    X \n    1 \n    Tversky \n    0 \n    0.500 \n    0.500 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    BF \n    414 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FZ \n    25 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    F \n    6 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BI \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EF \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FJ \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    BDFIJMNOXZ \n    3 \n    frenzy \n    0 \n    0.500 \n    0.571 \n    NA \n    0.533 \n    -0.5 \n  \n  \n    BCDFHIJMNOXZ \n    2 \n    frenzy \n    0 \n    0.375 \n    0.600 \n    NA \n    0.400 \n    -0.5 \n  \n  \n    BDFIJNOXZ \n    2 \n    frenzy \n    0 \n    0.562 \n    0.643 \n    NA \n    0.533 \n    -0.5 \n  \n  \n    BDFIMNOXZ \n    1 \n    frenzy \n    0 \n    0.562 \n    0.562 \n    NA \n    0.600 \n    -0.5 \n  \n  \n    BDFJMNOXZ \n    1 \n    frenzy \n    0 \n    0.562 \n    0.562 \n    NA \n    0.600 \n    -0.5 \n  \n  \n    BDFJNOXZ \n    1 \n    frenzy \n    0 \n    0.625 \n    0.625 \n    NA \n    0.600 \n    -0.5 \n  \n  \n    BFIJOZ \n    1 \n    frenzy \n    0 \n    0.188 \n    0.536 \n    NA \n    0.733 \n    -0.5 \n  \n  \n    BFIOZ \n    1 \n    frenzy \n    0 \n    0.250 \n    0.286 \n    NA \n    0.800 \n    -0.5 \n  \n  \n    IJNOXZ \n    1 \n    frenzy \n    0 \n    0.750 \n    0.857 \n    NA \n    -0.400 \n    -0.5 \n  \n  \n    DN \n    2 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FJOX \n    1 \n    ? \n    0 \n    0.875 \n    0.875 \n    NA \n    0.300 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.062 \n    0.250 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    KL \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    0.250 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>%\n#   pack_rows(\"Lines-Connect\", 6, 9) %>%\n#   pack_rows(\"Orthogonal\", 10, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 17)\n\n\n\n\nQuestion #8\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    E \n    F \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #8\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    81 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    CG \n    4 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    CGM \n    3 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    CFGO \n    2 \n    Tversky \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    AG \n    1 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    AGK \n    1 \n    Tversky \n    0 \n    0.867 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    BFG \n    1 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.071 \n    0.5 \n  \n  \n    E \n    333 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EIJ \n    8 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EI \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EF \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EFIJ \n    2 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    AE \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    CEF \n    1 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EIJM \n    1 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.786 \n    -1.0 \n  \n  \n    EG \n    4 \n    both tri + orth \n    0 \n    0.933 \n    NA \n    NA \n    0.929 \n    0.5 \n  \n  \n     \n    17 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJNOZ \n    4 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    ABFGK \n    1 \n    frenzy \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    CDEGHIJNZ \n    1 \n    frenzy \n    0 \n    0.467 \n    NA \n    NA \n    0.429 \n    -0.5 \n  \n  \n    CDEGHNOZ \n    1 \n    frenzy \n    0 \n    0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    CEFGHZ \n    1 \n    frenzy \n    0 \n    0.667 \n    NA \n    NA \n    0.714 \n    -0.5 \n  \n  \n    CFGHZ \n    1 \n    frenzy \n    0 \n    0.733 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DEIJNZ \n    1 \n    frenzy \n    0 \n    -0.400 \n    NA \n    NA \n    0.643 \n    -0.5 \n  \n  \n    DHIJNOZ \n    1 \n    frenzy \n    0 \n    -0.467 \n    NA \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    DHNOZ \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    DIJNO \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    EFGIJ \n    1 \n    frenzy \n    0 \n    0.733 \n    NA \n    NA \n    0.786 \n    -0.5 \n  \n  \n    EFIJM \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    0.786 \n    -0.5 \n  \n  \n    EGJKMOPZ \n    1 \n    frenzy \n    0 \n    0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    IJ \n    22 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    I \n    15 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    M \n    6 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    O \n    6 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    F \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    J \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AK \n    4 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    IJM \n    4 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    L \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    DJN \n    3 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    BF \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    D \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AKO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    AKP \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    CEG \n    1 \n    ? \n    0 \n    0.867 \n    NA \n    NA \n    0.857 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    CZ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    DHNZ \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DJNX \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    DN \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    DNO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    JK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    KO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    NZ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Orthogonal\", 11, 16) %>%\n#   pack_rows(\"Other\", 17, 21) %>%\n#   pack_rows(\"Unknown\", 22, 45)\n\n\n\n\nQuestion #10\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    E \n     \n  \n  \n    Orthgonal \n    X \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    EGZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n    E \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #10\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    E \n    120 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    EF \n    3 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    34 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    G \n    5 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    XZ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n    CGO \n    1 \n    Tversky \n    0 \n    -0.188 \n    0.875 \n    NA \n    -0.188 \n    0.5 \n  \n  \n    FZ \n    1 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    GK \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    GN \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    X \n    269 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FX \n    13 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BX \n    7 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.938 \n    -1.0 \n  \n  \n    F \n    4 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    EX \n    3 \n    both tri + orth \n    0 \n    0.938 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n     \n    17 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    EFHJLMNO \n    1 \n    frenzy \n    0 \n    0.625 \n    0.625 \n    NA \n    -0.438 \n    -0.5 \n  \n  \n    B \n    55 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    17 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IJ \n    8 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    I \n    4 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    BJ \n    3 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    L \n    3 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    H \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>%\n#   pack_rows(\"Lines-Connect\", 3, 7) %>%\n#   pack_rows(\"Orthogonal\", 8, 11) %>%\n#   pack_rows(\"Other\", 12, 14) %>%\n#   pack_rows(\"Unknown\", 15, 27)\n\n\n\n\nQuestion #11\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at 12pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    ML \n     \n  \n  \n    Orthgonal \n    FB \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #11\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    LM \n    105 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.125 \n    1.0 \n  \n  \n    M \n    15 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    L \n    2 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    KL \n    1 \n    Tversky \n    0 \n    0.438 \n    NA \n    NA \n    -0.125 \n    0.5 \n  \n  \n    MOX \n    1 \n    Tversky \n    0 \n    0.375 \n    NA \n    NA \n    -0.188 \n    0.5 \n  \n  \n    BF \n    423 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    B \n    4 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    F \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    AGM \n    1 \n    Orthogonal \n    0 \n    0.375 \n    NA \n    NA \n    -0.188 \n    -1.0 \n  \n  \n    BE \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    0.438 \n    -1.0 \n  \n  \n    BFXZ \n    1 \n    Orthogonal \n    0 \n    -0.250 \n    NA \n    NA \n    0.875 \n    -1.0 \n  \n  \n    BLM \n    1 \n    both tri + orth \n    0 \n    0.938 \n    NA \n    NA \n    0.375 \n    0.5 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACDGHKLMNOPXZ \n    2 \n    frenzy \n    0 \n    0.312 \n    NA \n    NA \n    -0.812 \n    -0.5 \n  \n  \n    DHLMNOXZ \n    1 \n    frenzy \n    0 \n    0.625 \n    NA \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    FGHIJKLN \n    1 \n    frenzy \n    0 \n    0.062 \n    NA \n    NA \n    0.062 \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    CG \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    EIJ \n    1 \n    ? \n    0 \n    -0.188 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    GK \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    0.438 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 9) %>%\n#   pack_rows(\"Other\", 10, 12) %>%\n#   pack_rows(\"Unknown\", 13, 17)\n\n\n\n\nQuestion #12\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    GZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #12\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    102 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    FG \n    6 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    10 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    BXZ \n    1 \n    Tversky \n    0 \n    -0.188 \n    0.875 \n    NA \n    0.875 \n    0.5 \n  \n  \n    EG \n    1 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    EZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    GP \n    1 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    B \n    426 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    13 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    1 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    EFGHILMOX \n    1 \n    frenzy \n    0 \n    0.562 \n    0.562 \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    E \n    3 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    X \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IK \n    1 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Lines-Connect\", 4, 6) %>%\n#   pack_rows(\"Orthogonal\", 7, 8) %>%\n#   pack_rows(\"Other\", 9, 10) %>%\n#   pack_rows(\"Unknown\", 11, 14)\n\n\n\n\nQuestion #13\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts end when Z begins?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EF \n     \n  \n  \n    Orthgonal \n    FX \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #13\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EF \n    100 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    0.433 \n    1.0 \n  \n  \n    E \n    1 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.067 \n    1.0 \n  \n  \n    FX \n    330 \n    Orthogonal \n    0 \n    0.433 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    X \n    16 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    OX \n    5 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    BX \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    KX \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    JX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    AX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    CX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    MX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    XZ \n    1 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    Z \n    2 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    12 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    AEFIJKLPX \n    1 \n    frenzy \n    0 \n    0.533 \n    NA \n    NA \n    0.533 \n    -0.5 \n  \n  \n    BDIJMNOX \n    1 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.033 \n    -0.5 \n  \n  \n    CEGOX \n    1 \n    frenzy \n    0 \n    0.233 \n    NA \n    NA \n    0.233 \n    -0.5 \n  \n  \n    BF \n    14 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    F \n    14 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    DN \n    11 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HL \n    11 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    EX \n    6 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    HN \n    4 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HK \n    3 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    H \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    HO \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    LP \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    AG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    BFM \n    1 \n    ? \n    0 \n    0.367 \n    NA \n    NA \n    0.367 \n    -0.5 \n  \n  \n    BIJM \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.267 \n    -0.5 \n  \n  \n    BIO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    BM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DL \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DNP \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    EO \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    FNZ \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    GK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HI \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HLP \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    KO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    MN \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Orthogonal\", 4, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 36)\n\n\n\n\nQuestion #14\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at 3pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    X \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XJND \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    JND \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #14\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    X \n    116 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.059 \n    1.0 \n  \n  \n    OX \n    2 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    CX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    EFX \n    1 \n    Tversky \n    0 \n    0.882 \n    0.882 \n    NA \n    -0.176 \n    0.5 \n  \n  \n    FX \n    1 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    JN \n    1 \n    Tversky \n    0 \n    -0.118 \n    0.667 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    B \n    341 \n    Orthogonal \n    0 \n    -0.059 \n    -0.059 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    13 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BIO \n    4 \n    Orthogonal \n    0 \n    -0.176 \n    -0.176 \n    NA \n    0.882 \n    -1.0 \n  \n  \n    BE \n    2 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BIJM \n    1 \n    Orthogonal \n    0 \n    -0.235 \n    0.133 \n    NA \n    0.824 \n    -1.0 \n  \n  \n    BO \n    1 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BX \n    6 \n    both tri + orth \n    0 \n    0.941 \n    0.941 \n    NA \n    0.941 \n    0.5 \n  \n  \n     \n    40 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    DJMNX \n    1 \n    frenzy \n    0 \n    0.765 \n    0.929 \n    NA \n    -0.294 \n    -0.5 \n  \n  \n    O \n    13 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    K \n    5 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    F \n    4 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    HLP \n    4 \n    ? \n    0 \n    -0.176 \n    -0.176 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    Z \n    4 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    E \n    3 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    G \n    3 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    H \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    CM \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    FO \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    HI \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    HP \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    JO \n    1 \n    ? \n    0 \n    -0.118 \n    0.267 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.059 \n    0.333 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.118 \n    0.267 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 7) %>%\n#   pack_rows(\"Other\", 8, 9) %>%\n#   pack_rows(\"Unknown\", 10, 22)\n\n\n\n\nQuestion #15\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Coffee breaks happen halfway through a shift. Which shifts share a break at 2pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    XK \n     \n  \n  \n    Orthgonal \n    EF \n    B \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XKZ \n     \n  \n  \n    Tversky [start diagonal] \n    Z \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #15\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    KX \n    117 \n    Triangular \n    1 \n    1.000 \n    0.667 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    X \n    10 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    K \n    4 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    KO \n    2 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    CX \n    1 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    OX \n    3 \n    Tversky \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    Z \n    3 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    DJNX \n    2 \n    Tversky \n    0 \n    0.312 \n    0.133 \n    NA \n    -0.267 \n    0.5 \n  \n  \n    FZ \n    2 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    0.433 \n    0.5 \n  \n  \n    AK \n    1 \n    Tversky \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    DNX \n    1 \n    Tversky \n    0 \n    0.375 \n    0.200 \n    NA \n    -0.200 \n    0.5 \n  \n  \n    EF \n    251 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    50 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BF \n    36 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    E \n    15 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    10 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BEF \n    3 \n    Orthogonal \n    0 \n    -0.188 \n    -0.176 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EI \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EL \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FJ \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FM \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FN \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    13 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCFG \n    1 \n    frenzy \n    0 \n    -0.312 \n    -0.294 \n    NA \n    0.300 \n    -0.5 \n  \n  \n    FIJKNO \n    1 \n    frenzy \n    0 \n    0.188 \n    0.000 \n    NA \n    0.167 \n    -0.5 \n  \n  \n    H \n    9 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    B \n    6 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    C \n    5 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FX \n    5 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    I \n    3 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HL \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    J \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    BEX \n    1 \n    ? \n    0 \n    0.375 \n    0.200 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    BJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    BK \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    BM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    GK \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HK \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    JX \n    1 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Lines-Connect\", 11, 13) %>%\n#   pack_rows(\"Orthogonal\", 14, 22) %>%\n#   pack_rows(\"Other\", 23, 23) %>%\n#   pack_rows(\"Unknown\", 24, 44)\n\n\n\n\n\nNON-DISCRIMINANT\n\nQuestion #6 NONDISCRIM\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 14.7: Q6-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) are six hours long?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EG \n     \n  \n  \n    Orthgonal \n    EG \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\nTODO discuss non discriminant\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #6\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EG \n    580 \n    both tri + orth \n    1 \n    1 \n    NA \n    NA \n    1 \n    0.5 \n  \n\n\n\n\n\n\n\nQuestion #9 NONDISCRIM\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) begins before J begins and ends during B?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    I \n     \n  \n  \n    Orthgonal \n    I \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #9\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    I \n    459 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    31 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    BEFHIJLMOZ \n    1 \n    frenzy \n    0 \n    0.533 \n    NA \n    NA \n    0.533 \n    -0.5 \n  \n  \n    E \n    39 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    10 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FI \n    5 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    F \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    J \n    4 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    N \n    4 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    EH \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IM \n    2 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    L \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    EI \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    FJ \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FK \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FMZ \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    KL \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    Z \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Other\", 1, 2) %>%\n#   pack_rows(\"Unknown\", 3, 19)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#peek",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#peek",
    "title": "5  Response Scoring",
    "section": "PEEK",
    "text": "PEEK\n\n\nCODE\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_niceABS, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = interpretation, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Interpretation [directional test]\")\n\n\nWarning: Number of labels is greater than default palette color count.Select\nanother color `palette` (and/or `package`).\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_STATE, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"State [directional test]\")"
  },
  {
    "objectID": "analysis/SGC3B/2_sgc3B_scoring.html#peek",
    "href": "analysis/SGC3B/2_sgc3B_scoring.html#peek",
    "title": "11  Response Scoring",
    "section": "PEEK",
    "text": "PEEK\n\n\nCODE\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_niceABS, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = interpretation, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Interpretation [directional test]\")\n\n\nWarning: Number of labels is greater than default palette color count.Select\nanother color `palette` (and/or `package`).\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_STATE, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"State [directional test]\")"
  },
  {
    "objectID": "analysis/SGC4A/2_sgc4A_scoring.html#peek",
    "href": "analysis/SGC4A/2_sgc4A_scoring.html#peek",
    "title": "14  Response Scoring",
    "section": "PEEK",
    "text": "PEEK\n\n\nCODE\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_niceABS, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = interpretation, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Interpretation [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_STATE, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"State [directional test]\")"
  },
  {
    "objectID": "analysis/SGC4D/1_sgc4D_introduction.html",
    "href": "analysis/SGC4D/1_sgc4D_introduction.html",
    "title": "20  Introduction",
    "section": "",
    "text": "In Study 4D we explore the extent to which the Y-XIS and SHAPE of the triangle of the graph influence how a reader interprets its underlying coordinate system.\nExperimental Hypothesis:"
  },
  {
    "objectID": "analysis/SGC4D/1_sgc4D_introduction.html#methods",
    "href": "analysis/SGC4D/1_sgc4D_introduction.html#methods",
    "title": "20  Introduction",
    "section": "METHODS",
    "text": "METHODS\n\nTODO Design\nWe employed a mixed design with 1 between-subjects factor with 4 levels (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Graphical Framework: ORTH-FULL, ORTH-SPARSE, ORTH-GRID, TRI-SPARSE)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Accuracy : Is the response triangular-correct?\nResponse Interpretation : (derived) With which interpretation of the graph is the subject’s response on an individual question consistent?\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 20.1. The list of questions can be found here.\n\n\n\nFigure 20.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser.\n(1) Upon starting, they submitted informed consent, before reading task instructions.\n(2) Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule.\n(3) Then participants completed an experimental block of 15 items : the Graph Comprehension Task\n(4) Following the experimental block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData were collected by convenience sample of a university subject pool during the winter of 2022. Participants accessed the study via a web browser (asynchronously). The stimulus application required the participant stay in full-screen mode for the entirety of the study."
  },
  {
    "objectID": "analysis/SGC4D/1_sgc4D_introduction.html#analysis",
    "href": "analysis/SGC4D/1_sgc4D_introduction.html#analysis",
    "title": "20  Introduction",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nData were collected via a custom web application and stored in a NoSQL database. The following exclusion criteria were applied during data cleaning:\n\ncompletion status : “success” ; subject must have finished all parts of the study, including demographic questionnaire\nsession ID: [in list] ; subject must have been assigned to valid data collection session (discard testing and piloting data)\nbrowser interaction violations < 3; subject must have fewer than 3 violations of non-allowed browser interactions (i.e. resizing window, leaving browser tab or leaving fullscreen mode)\nself-rated effort > 2; subjects who reported, “not trying hard/rushing through questions” or “started out trying hard but giving up at some point” were excluded from analysis.\nattention check ==TRUE ; subjects who failed to answer a mid-study attention check question (Graph Comprehension Task Question #6) are excluded\n\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\nParticipants\nFirst we import participant-level data, selecting only the columns relevant for analysis. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. No raw data (responses and response times) are discarded, only algorithmically-derived scores for the responses.\nNOTE: Data for the isocelese traingular conditions were originally run under the study code SGC4A, under a different naming scheme. \n\n\nCODE\n#IMPORT PARTICIPANT DATA FOR CONDITIONS 111 AND 113 \n\n#set datafiles\nfall17 <- \"analysis/SGC4A/data/0-session-level/fall17_sgc4a_participants.csv\"\nspring18 <- \"analysis/SGC4A/data/0-session-level/spring18_sgc4a_participants.csv\"\nwinter22 <- \"analysis/SGC4A/data/0-session-level/winter22_sgc4a_participants.rds\"\nsummer22 <- \"analysis/SGC4A/data/0-session-level/su22_sgc4a_participants.rds\"\nsummer4d <- \"analysis/SGC4D/data/0-session-level/sgc4d_participants.rds\"\n\n#LOAD DATAFILES\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\") %>% filter(condition %in% c(111,113))\ndf_subjects_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\") %>% filter(condition %in% c(111,113))\ndf_subjects_winter22 <- read_rds(winter22) %>% filter(condition %in% c(111,113))#use RDS file as it contains metadata\ndf_subjects_summer22 <- read_rds(summer22) %>% filter(condition %in% c(111,113))#use RDS file as it contains metadata\ndf_subjects_summer4d <- read_rds(summer4d) \n\n#SAVE METADATA FROM WINTER AS TEMPLATE, but no rows \ndf_subjects <- df_subjects_summer22 %>% filter(condition=='X') %>% \n  dplyr::select(\n  subject,condition,pretty_condition, term,mode,\n  gender,age,language, schoolyear, country, disability,\n  effort, difficulty, confidence, enjoyment,other,\n  totaltime_m, \n  # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n  #exploratory factors\n  violations, browser, width, height\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    condition = as.factor(condition),\n    pretty_condition = \"NULL\",\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\",\n    violations = \"NULL\",\n    browser = \"NULL\",\n    width = \"NULL\",\n    height = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, pretty_condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, \n                # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                #exploratory factors\n                violations, browser, width, height)\n\n\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  dplyr::select(subject, condition, pretty_condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% dplyr::select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_summer22 <- df_subjects_summer22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_summer4d <- df_subjects_summer4d %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, pretty_condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, \n                 # absolute_score, #drop absolute score as this is re-scored [though should be the same]\n                 #exploratory factors \n                 violations, browser, width, height)\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#compare dataframe columns\n# janitor::compare_df_cols(df_subjects, df_subjects_winter22, df_subjects_before)\n\n#combine ADD DATAFRAMES\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_summer22, df_subjects_before, df_subjects_summer4d) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\"),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\",\"summer22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    gender = factor(gender),\n    schoolyear = factor(schoolyear, levels=c(\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Other\"))\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#REFACTOR CONDITIONS\ndf_subjects <- df_subjects %>% mutate(\n     pretty_condition = recode_factor(condition,\n                                   \"111\" = \"Orth-Isosceles\",\n                                   \"113\" = \"Tri-Isosceles\",\n                                   \"11111112\" = \"Orth-Equilateral\",\n                                   \"11311112\" = \"Tri-Equilateral\"\n    ),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_subjects_fall17, df_subjects_spring18, df_subjects_winter22,df_subjects_before, df_subjects_summer22, df_subjects_summer4d)\nrm(fall17,spring18,winter22, summer22, summer4d)\n\n\n\n\nItems\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # #mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#set datafiles\nfall17 <- \"analysis/SGC4D/data/0-session-level/fall17_sgc4a_blocks.csv\"\nspring18 <- \"analysis/SGC4D/data/0-session-level/spring18_sgc4a_blocks.csv\"\nwinter22 <- \"analysis/SGC4D/data/0-session-level/winter22_sgc4a_items.rds\"\nsummer22 <- \"analysis/SGC4D/data/0-session-level/su22_sgc4a_items.rds\"\nsummer4d <- \"analysis/SGC4D/data/0-session-level/sgc4d_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read_csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\") %>% filter(condition %in% c(111,113))\ndf_items_spring18 <- read_csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")%>% filter(condition %in% c(111,113))\ndf_items_winter22 <- read_rds(winter22) %>% filter(condition %in% c(111,113))#use RDS file as it contains metadata\ndf_items_summer22 <- read_rds(summer22)%>% filter(condition %in% c(111,113)) #use RDS file as it contains metadata\ndf_items_summer4d <- read_rds(summer4d) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% dplyr::select(q,relation) %>% unique()\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% dplyr::select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n\n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\ndf_items_summer22 <- df_items_summer22 %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\ndf_items_summer4d <- df_items_summer4d %>% \n  dplyr::select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22, df_items_summer22, df_items_before, df_items_summer4d) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term, levels= c(\"fall17\",\"spring18\",\"fall21\",\"winter22\",\"summer22\")),\n    mode = factor(mode, levels=c(\"lab-synch\",\"asynch\")),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  ) %>% \n  # handle NA values (why are some empty responses blank and others NA?) \n  mutate(\n    response = replace_na(response, \"\"),\n    num_o = replace_na(num_o, 0)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% dplyr::select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_winter22_q16 <- df_winter22_q16 %>% dplyr::select(-pretty_condition)\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#REFACTOR CONDITIONS\ndf_items <- df_items %>% mutate(\n  pretty_condition = recode_factor(condition,\n                                   \"111\" = \"Orth-Isosceles\",\n                                   \"113\" = \"Tri-Isosceles\",\n                                   \"11111112\" = \"Orth-Equilateral\",\n                                   \"11311112\" = \"Tri-Equilateral\"\n    ),\n    pretty_mode = recode_factor(mode, \"lab-synch\" = \"laboratory\", \"asynch\" =  \"online-replication\")\n) \n\n#CLEANUP\nrm(df_items_fall17, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16, df_items_summer22, df_items_summer4d)\nrm(fall17,spring18,winter22, map_relations, summer22, summer4d)\n\n\n\n\nValidation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE\n\n\n\n\nExport\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n# HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# # mbp = \"/Users/amyfox/Sites/RESEARCH/SGC—Scaffolding Graph Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4D/data/1-study-level/sgc4d_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4D/data/1-study-level/sgc4d_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"analysis/SGC4D/data/1-study-level/sgc4d_freeresponse.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4D/data/1-study-level/sgc4d_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4D/data/1-study-level/sgc4d_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC4D/1_sgc4D_introduction.html#resources",
    "href": "analysis/SGC4D/1_sgc4D_introduction.html#resources",
    "title": "20  Introduction",
    "section": "RESOURCES",
    "text": "RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1    stringr_1.4.0    dplyr_1.0.9      purrr_0.3.4     \n [5] readr_2.1.2      tidyr_1.2.0      tibble_3.1.7     ggplot2_3.3.6   \n [9] tidyverse_1.3.1  kableExtra_1.3.4 codebook_0.9.2  \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.8.3      svglite_2.1.0     lubridate_1.8.0   assertthat_0.2.1 \n [5] digest_0.6.29     utf8_1.2.2        R6_2.5.1          cellranger_1.1.0 \n [9] backports_1.4.1   reprex_2.0.1      labelled_2.9.1    evaluate_0.15    \n[13] httr_1.4.3        highr_0.9         pillar_1.7.0      rlang_1.0.3      \n[17] curl_4.3.2        readxl_1.4.0      data.table_1.14.2 rstudioapi_0.13  \n[21] rmarkdown_2.14    webshot_0.5.3     foreign_0.8-82    htmlwidgets_1.5.4\n[25] bit_4.0.4         munsell_0.5.0     broom_0.8.0       compiler_4.2.1   \n[29] modelr_0.1.8      xfun_0.31         pkgconfig_2.0.3   systemfonts_1.0.4\n[33] htmltools_0.5.2   tidyselect_1.1.2  rio_0.5.29        fansi_1.0.3      \n[37] viridisLite_0.4.0 crayon_1.5.1      tzdb_0.3.0        dbplyr_2.2.1     \n[41] withr_2.5.0       grid_4.2.1        jsonlite_1.8.0    gtable_0.3.0     \n[45] lifecycle_1.0.1   DBI_1.1.3         magrittr_2.0.3    scales_1.2.0     \n[49] zip_2.2.0         cli_3.3.0         stringi_1.7.6     vroom_1.5.7      \n[53] fs_1.5.2          xml2_1.3.3        ellipsis_0.3.2    generics_0.1.2   \n[57] vctrs_0.4.1       openxlsx_4.2.5    tools_4.2.1       bit64_4.0.5      \n[61] glue_1.6.2        hms_1.1.1         parallel_4.2.1    fastmap_1.1.0    \n[65] yaml_2.3.5        colorspace_2.0-3  rvest_1.0.2       knitr_1.39       \n[69] haven_2.5.0"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#score-sgc-data",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#score-sgc-data",
    "title": "21  Response Scoring",
    "section": "SCORE SGC DATA",
    "text": "SCORE SGC DATA\nTo review the strategy behind Multiple Response scoring for the SGC project, refer to section ?sec-scoring.\nIn SGC we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehension task asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\nBased on prior observational studies where we observed emergence of other alternative interpretations (i.e. transitional interpretations) we also calculate subscores for these alternatives.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key. 5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing strategy) answer key.\n\nPrepare Answer Keys\nWe start by importing three answer keys: (1) Q1 - Q5 [control condition], (2) Q1-Q5 [impasse condition], (3) Q6-15. Separate answer keys by condition are required for Q1-Q5 because the stimuli for each condition visualize a different underlying dataset (i.e. the graphs show datapoints in different positions). Q6-Q15 are identical across conditions. Each answer key includes a row for each question, and a column defining the subset of response options that correspond to different graph interpretations.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n#imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n#setwd(imac)\n\n#SAVE KEYS FOR FUTURE USE\nkeys_raw <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_raw\")\nkeys_orth <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_orth\")\nkeys_tri <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tri\")\nkeys_both <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_both\")\nkeys_satisfice_left <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_left\")\nkeys_satisfice_right <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_satisfice_right\")\nkeys_tversky_duration <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_duration\")\nkeys_tversky_end <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_end\")\nkeys_tversky_max <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_max\")\nkeys_tversky_start <-  read_csv(\"analysis/utils/keys/parsed_keys/keys_tversky_start\")\n\n\n\n\nCalculate Subscores\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (e.g. keys_orth, keys_tri, etc…), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item in df_items, and can be used to determine which graph interpretation the subject held.\nSpecifically, the following scores are calculated for each item:\nInterpretation Subscores\n\nscore_TRI How consistent is the response with the triangularinterpretation?\nscore_ORTH How consistent is the response with the orthogonalinterpretation?\nscore_BOTH How consistent is the response with both the orthogonal and triangular interpretations?\nscore_SATISFICE is calculated by taking the maximum value of :\n\nscore_SAT_left How consistent is the response with the (left side) Satisficing interpretation?\nscore_SAT_right How consistent is the response with the (right side) Satisficing interpretation\n\nscore_TVERSKY is calculated by taking the maximum value of:\n\nscore_TV_max How consistent is the response with the (maximal) Tversky interpretation?\nscore_TV_start How consistent is the response with the (start-time) Tversky interpretation?\nscore_TV_end How consistent is the response with the (end-time) Tversky interpretation?\nscore_TV_duration How consistent is the response with the (duration) Tversky interpretation?\n\nscore_REF Did the response select only the reference point?\n\nAbsolute Scores\n\nscore_ABS Is the response strictly correct? (triangular interpretation)\nscore_niceABS Is the response strictly correct? (triangular interpretation, not penalizing ref points). This is a more generous version of the Absolute score that does not penalize the participant if in addition to the correct answer in addition to they also select the data point referenced in the question.\n\n\n\nCODE\n#HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#backup <- read_rds('analysis/SGC4D/data/1-study-level/sgc4d_items.rds') #for troubleshooting only\ndf_items <- read_rds('analysis/SGC4D/data/1-study-level/sgc4d_items.rds')\n\n#ADD TEMP IMPASSE COLUMN\ndf_items <- df_items %>% mutate(\n  IMPASSE = substr(condition,2,2),\n  IMPASSE = recode_factor(IMPASSE, \"1\"=\"none\", \"2\"=\"IMPASSE\")\n)\n\n\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\nsource(\"analysis/utils/scoring.R\")\n\n\nnote: this cell takes approximately 30 minutes to run on the full df_items dataframe with 4950 records\n\n\nCODE\n#RUN THIS <OR> THE CALCULATE-SCORES-FORLOOP [not both]\n# backup <- df_items\n# df_items <- backup %>%  sample_n(200)\n\n#ALPHEBETIZE RESPONSE\ndf_items$response = pbmapply(reorder_inplace, df_items$response)\n\n#STRATEGY PARTIAL-SUBSCORES\ndf_items$score_TRI = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tri))\n\ndf_items$score_ORTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response,  MoreArgs = list(keyframe = keys_orth))\n\ndf_items$score_BOTH = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_both))\n\ndf_items$score_SAT_left = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_left))\ndf_items$score_SAT_right = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_satisfice_right))\n\ndf_items$score_TV_max = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_max))\ndf_items$score_TV_start = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_start))\ndf_items$score_TV_end = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_end))\ndf_items$score_TV_duration = pbmapply(calc_subscore, df_items$q, df_items$IMPASSE, df_items$response, MoreArgs = list(keyframe = keys_tversky_duration))\n\n#SPECIAL ABSOLUTE SUBSCORES\ndf_items$score_REF = pbmapply(calc_refscore, df_items$q, df_items$response)\n\n#OLD score_BOTH... new one is above (explicitly in key)\n# df_items$score_BOTH = as.integer((df_items$score_TRI == 1) & (df_items$score_ORTH ==1))\n\n#ABSOLUTE SCORES\ndf_items$score_ABS = as.integer(df_items$correct) \ndf_items$score_niceABS  <- as.integer((df_items$score_TRI == 1)) #tri doesn't penalize ref or ve-area\n\n\n\n\nDerive Interpretation\nFinally, we use the interpretation subscores to classify the response as a particular interpretation. This classification algorithm : (1) First decides if the response matches one or more ‘special’ situations (blank response, reference point response, both ORTH and TRI) (2) If response doesn’t match a special situation, it compares the individual subscores, and subscores and decides if they are discriminant (i.e. are the scores different enough to make a prediction). A discriminant threshold of 0.5pts (on a scale from -1 to +1 is used) (2) If the variance in subscores surpasses the threshold, the interpretation is classified based on the highest subscore (TRIANGULAR, ORTHOGONAL, TVERSKY, SATISFICE) (3) If the variance does not surpass the threshold, the interpretation is labelled as “?”, indicating it cannot be classified, and is of an unknown interpretation.\nThe final output is called interpretation.\n\n\nCODE\n#stoopid extra copying for troubleshooting safety\ntemp <- df_items #%>% head(16) %>% tail(1)\ntemp <- derive_interpretation(temp)\n\n\n[1] \"DERIVING INTERPRETATION\"\n\n\nCODE\ndf_items <- temp\n\n\n\n\n? SPECIAL EXCEPTIONS\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nLook for special exceptions (essentially pass through cases) that are missed by the threshold partial p calculations, but fit particular interpretations. (ie. a clearly tversky interpretation that only includes 1 or 2 of the 3 possible options)\nALSO reconciles issues when interpetation == triangular but scoreniceabs = 0 ::: {.cell}\n\nCODE\n# #temp setup for protection\n# backup <- df_items\ntemp <- df_items %>% mutate(\n  override = \"\"\n)\n\n## CONTROL. Q==1. \"FK\" derives as 'TRI', should be tversky start\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==1) & (IMPASSE ==\"none\") & (response == \"FK\"),\n  tv_type = \"score_TV_start\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"TRI\"\n)\n\n## IMPASS Q==2. \"EK\" derives as 'TRI', should be tversky MAX\ntemp <- temp %>% mutate_when(\n  (q==2) & (IMPASSE ==\"IMPASSE\") & (response == \"EK\"),\n  tv_type = \"score_TV_max\",\n  int2 = \"Tversky\", #override from TRI\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n## CONTROL. Q==3. \"A\" derives as 'unknown', should be tversky duration\n#codes as unknown bc there are 2 other along that line, but A is the closest (shortcut)\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"A\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from ?\n  interpretation = \"Tversky\", #override from ?\n  high_interpretation = \"pos.trans\",\n  override = \"?\"\n)\n\n\n## CONTROL  Q==3 \"AF\" derives as TRI. hardcode as \"both\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"AF\"),\n  int2 = \"both tri + orth\", #override from TRI\n  interpretation = \"both tri + orth\", #override from TRI\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## CONTROL  Q==3 \"EFK\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"EFK\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL  Q==3 \"FG\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"none\") & (response == \"FG\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASS  Q==3 \"AF\" derives as TRI. hardcode as \"TVERSKY-DURATION\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE  Q==3 \"AFG\" derives as TRI. hardcode as \"unknown\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from TRI\n  interpretation = \"?\", #override from TRI\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE  Q==3 \"AH\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AH\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n## IMPASSE  Q==3 \"AO\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE  Q==3 \"AOU\" derives as SATISFICE hardcode as \"angular\"\ntemp <- temp %>% mutate_when(\n  (q==3) & (IMPASSE ==\"IMPASSE\") & (response == \"AOU\"),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## CONTROL Q==4 AH Derives as TRI RECODE as TVERSKY\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response %in% c(\"AH\",\"HK\")),\n  int2 = \"Tversky\", #override from Satisfice\n  interpretation = \"Tversky\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 HJ DERIVES as TRI Recode as ?\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"HJ\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n## CONTROL Q==4 DEU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 DEOU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"DEOU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## CONTROL Q==4 KU DERIVES as ORTH Recode as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"none\") & (response == \"KU\"),\n  int2 = \"?\", #override from Orthogonal\n  interpretation = \"?\", #override from Orthogonal\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Orthogonal\"\n)\n\n## IMPASSE Q==4 BD Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BD\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 BDEG Derives as TVERSKY RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"BDEG\"),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n## IMPASSE Q==4 AFG Derives as SATISFICE RECODE as OTHER\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"?\", #override from Satisfice\n  interpretation = \"?\", #override from Satisfice\n  high_interpretation = \"neg.trans\", #override from orthogonal\n  override = \"Satisfice\"\n)\n\n\n## IMPASSE Q==4 DH Derives as TRI RECODE as BOTH\ntemp <- temp %>% mutate_when(\n  (q==4) & (IMPASSE ==\"IMPASSE\") & (response == \"DH\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AU Derives as TRI RECODE as satisfice\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AU\"),\n  int2 = \"Satisfice\", #override from Triangular\n  interpretation = \"Satisfice\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AZ Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AZ\"),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n## IMPASSE Q==5 AFG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AFG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n\n## IMPASSE Q==5 AF Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AF\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## IMPASSE Q==5 AO Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"IMPASSE\") & (response == \"AO\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5  Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"FO\",\"JO\") ),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 FO, HO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response %in% c(\"HO\",\"FO\",\"DJO\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n## CONTROL Q==5 KO Derives as TRI RECODE as tversky_duration\ntemp <- temp %>% mutate_when(\n  (q==5) & (IMPASSE ==\"none\") & (response == \"KO\"),\n  tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n\n##  Q==7 HOX, OX Derives as TRI but incorrect\n#includes H which is at rather than under 5 hours.\n#give credit \ntemp <- temp %>% mutate_when(\n  (q==7)  & (response %in% c(\"HOX\", \"OX\")),\n  score_niceABS = 1\n)\n\n##  Q==7 AX, MO Derives as TRI RECODE as other\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MO\",\"AX\",\"FJOX\", \"IO\")) ,\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==7 MOX, MX  Derives as TRI RECODE as tversky\ntemp <- temp %>% mutate_when(\n  (q==7 & response %in% c(\"MOX\", \"MX\", \"DX\",\"O\",\"X\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8) & (response %in% c(\"CFGO\",\"BFG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AG\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 AGK Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response == \"AGK\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==8 FG Derives as TRI RECODE as angular\ntemp <- temp %>% mutate_when(\n  (q==8)  & (response %in% c(\"FG\",\"CG\",\"CFG\",\"CGM\",\"CM\",\"ACGP\",\"GM\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==11 M Derives as TRI MISSING RESPONSE\n##LEAVE AS TRI + OVERRIDE SCORENABS\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"M\",\"L\") ),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==11 BLM Derives as TRI set at both\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response == \"BLM\"),\n  int2 = \"both tri + orth\", #override from Satisfice\n  interpretation = \"both tri + orth\", #override from Satisfice\n  high_interpretation = \"pos.trans\", #override from orthogonal\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at ORTH\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"AGM\")),\n  int2 = \"Orthogonal\",\n  interpretation = \"Orthogonal\", \n  high_interpretation = \"orthogonal\", \n  override = \"Triangular\"\n)\n##  Q==11 EKM Derives as TRI set at other\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"EKM\",\"JM\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Triangular\"\n)\n\n##  Q==11 Derives as TRI set at Angular\ntemp <- temp %>% mutate_when(\n  (q==11)  & (response %in% c(\"KL\",\"MOX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==12 Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==12)  & (response %in% c(\"GP\", \"EG\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 E Derives as TRI but incorrect\n##LEAVE AS TRI + OVERRIDE SCORENABS\n##one of two correct answers\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response == \"E\"),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==13 CE Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"CE\",\"EH\")),\n  int2 = \"?\", #override from Triangular\n  interpretation = \"?\", #override from Triangular\n  high_interpretation = \"neg.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==13 EO Derives as TRI set at ?\ntemp <- temp %>% mutate_when(\n  (q==13)  & (response %in% c(\"EO\")),\n  int2 = \"?\", \n  interpretation = \"?\", \n  high_interpretation = \"neg.trans\", \n  override = \"Triangular\"\n)\n\n##  Q==14  Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response %in% c(\"FX\",\"CX\",\"EFX\")),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 OX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"OX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==14 EX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==14)  & (response == \"EX\"),\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 CX Derives as TRI but incorrect \n#within visual margin... give credit\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"CX\",\"KO\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n#  Q==15  Derives as TRI but incorrect \n#missing 1 right answer or within 0.5hr visual error \ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"X\",\"CK\",\"K\",\"GKX\")),\n  score_niceABS = 1\n  # int2 = \"Tversky\", #override from Triangular\n  # interpretation = \"Tversky\", #override from Triangular\n  # high_interpretation = \"pos.trans\", #override from triangular\n  # override = \"Triangular\"\n)\n\n##  Q==15 DJNX Derives as TRI set at Tversky\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"DJNX\", \"OX\", \"AK\",\"DNX\")),\n  # tv_type = \"score_TV_duration\",\n  int2 = \"Tversky\", #override from Triangular\n  interpretation = \"Tversky\", #override from Triangular\n  high_interpretation = \"pos.trans\", #override from triangular\n  override = \"Triangular\"\n)\n\n##  Q==15 AKPX Derives as TRI set at OTHER\ntemp <- temp %>% mutate_when(\n  (q==15)  & (response %in% c(\"AKPX\",\"GK\",\"JX\",\"LX\",\"BK\",\"HK\")),\n  int2 = \"?\", #override from Tversky\n  interpretation = \"?\", #override from Tversky\n  high_interpretation = \"neg.trans\", #override from pos.trans\n  override = \"Tversky\"\n)\n\n#SET BACK\ndf_items <- temp\n\n:::\n\n\nDerive Scaled Score\nThe interpretation response variable gives us the finest grain indication of the reader’s understanding of the graph for a particular question. However, it is a categorical variable, which poses a challenge for analyzing cumulative performance at the subject level. To address this challenge, we derive a scaled_score that converts each possible interpretation to a numeric value on a scale from -1 to +1. This scaling takes advantage of the observation that each interpretation can be positioned along a spectrum of understanding from completely incorrect (orthogonal) to completely correct (triangular). Alternative interpretations lay somewhere between.\nSpecifically, we assign the following values to each interpretation:\n\n(-1) : ORTHOGONAL, SATISFICE (satisfice represents an attempt at an orthogonal answer when none is available)\n(-0.5): ? (some alternative that cannot be identified; but meaningful that it is not orthogonal)\n(0): REFERENCE POINT, BLANK (indicates the individual thinks there is no answer, recognizes that ORTHOGONAL cannot be correct, but does not conceive of triangular)\n(+0.5) TVERSKY, BOTH TRI + ORTH (indicates that they “see” a triangular response, but lack certainty and also select the ORTHOGONAL response)\n(+1) TRIANGULAR +1\n\n\n\nCODE\ndf_items$score_SCALED <- calc_scaled(df_items$interpretation)\n\n\n\n\nDerive State Score\nThe scaled score represents a 5-category ordering of understanding. We also derive a 3-category ordering that gives higher grained access to “orthogonal-like” vs “uncertain” vs “triangle-like” responses.\nSpecifically, we assign the following values to each interpretation:\n\n(orth-like) : orthogonal, satisfice\n(unknown) : unidentified alternatives, blank, both tri&orth, and reference point responses\n(tri-like) : Tverskian and triangular responses\n\n\n\nCODE\ndf_items <- df_items %>% mutate (\n  score_STATE = recode_factor(df_items$score_SCALED,\n                         \"-1\" = \"orth-like\",\n                         \"-0.5\" = \"unknown\",\n                         \"0\" = \"unknown\",\n                         \"0.5\" = \"tri-like\",\n                         \"1\" = \"tri-like\"),\n  score_STATE = as.ordered(score_STATE))"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#summarize-by-subject",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#summarize-by-subject",
    "title": "21  Response Scoring",
    "section": "SUMMARIZE BY SUBJECT",
    "text": "SUMMARIZE BY SUBJECT\nNext, we summarize the item level scores by subject in order to calculate cummulative subscores to be stored on the subject record.\n\n\nCODE\n# #HACK WD FOR LOCAL RUNNING?\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#import subjects\ndf_subjects <- read_rds('analysis/SGC4D/data/1-study-level/sgc4d_participants.rds') %>% mutate(subject = as.character(subject)) %>% arrange(subject)\n\n#make temporary copies for testing safety\ns = df_subjects\ni = df_items \n\n#summarize\ntest_subs <- summarise_bySubject(s,i)\n\n\n`summarise()` has grouped output by 'subject'. You can override using the\n`.groups` argument.\n\n\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nCODE\ndf_subjects <- test_subs\n\n\nWe also summarize absolute and scaled score progress at each question in the task, to explore cumulative performance over the task.\n\n\nCODE\n#GET ABSOLUTE PROGRESS \ndf_absolute_progress <- progress_Absolute(df_items)\n\n#GET SCALED PROGRESS\ndf_scaled_progress <- progress_Scaled(df_items)"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#explore-distributions",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#explore-distributions",
    "title": "21  Response Scoring",
    "section": "EXPLORE DISTRIBUTIONS",
    "text": "EXPLORE DISTRIBUTIONS\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#create temp data frame for visualizations\ndf = df_items %>% filter (q %nin% c(6,9)) %>% mutate(\n  score_niceABS = as.factor(score_niceABS),\n  pretty_interpretation = factor(interpretation,\n    levels = c(\"Orthogonal\", \"Satisfice\", \n               \"frenzy\",\"?\",\n                \"reference\",\"blank\",\n                \"Tversky\", \"both tri + orth\",\n               \"Triangular\" ))\n  )\n\n\n\nAbsolute Score\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE FULL TASK\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (all Items)\",\n        subtitle = paste(\"Impasse Condition (blue) yields more correct responses across the entire task\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY ITEM\ngf_props(~score_niceABS, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(pretty_condition~q) + \n  labs( x = \"Absolute Score\", \n        title = \"Distribution of Absolute Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields more correct responses on each item\",\n        y = \"Proprition of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE BY SUBJECT\ngf_props(~s_NABS, fill = ~pretty_condition, position = position_dodge(), data = df_subjects) %>%\ngf_facet_wrap(~pretty_condition)+\n  labs( x = \"Total Absolute Score\",\n        title = \"Distribution of Total Absolute Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher total absolute scores\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +\n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION ABSOLUTE SCORE TEST PHASE\ngf_props(~item_test_NABS, fill = ~pretty_condition, \n             data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Absolute Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Absolute Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\n\n\nScaled Score\n\n\nCODE\noptions(repr.plot.width =9, repr.plot.height =12)\n\n#DISTRIBUTION SCALED SCORE FULL TASK\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df) +\n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (all Items)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores across the entire task\",\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY ITEM\ngf_props(~score_SCALED, fill = ~pretty_condition, position = position_dodge(), data = df)  %>% \n  gf_facet_grid(q~pretty_condition) + \n  labs( x = \"Scaled Score\", \n        title = \"Distribution of Scaled Score (by Item)\",\n        subtitle = \"Impasse Condition (blue) yields higher scaled scores on each item\",\n        y = \"Proportion of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  scale_y_continuous(breaks=c(0,0.5)) + \n  theme_minimal() + theme(legend.position=\"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE BY SUBJECT\ngf_props(~s_SCALED, fill = ~pretty_condition, data = df_subjects)  %>% \n  gf_facet_grid(pretty_condition ~. )+\n  labs( x = \"Total Scaled Score\", \n        title = \"Distribution of Total Scaled Score (by Subject)\",\n        subtitle = \"Impasse Condition (blue) yields higher cumulative scaled scores\",\n        y = \"Number of Subjects\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#DISTRIBUTION SCALED SCORE TEST PHASE\ngf_histogram(~item_test_SCALED, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap(~pretty_condition) + \n  labs( x = \"Scaled Score in TEST Phase\", \n        title = \"Distribution of TEST PHASE Scaled Score (all Items)\",\n        subtitle = paste(\"\"),\n        y = \"Proportion of Items\") +\n  scale_fill_discrete(name = \"Condition\") +  \n  theme_minimal()\n\n\n\n\n\nCODE\n#QUICK PEEK\n\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_SCALED,\n                type = \"non-parametric\",\n                title = \"Total Scaled Score [directional test]\")\n\n\n\n\n\n\n\nInterpretations\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION\ngf_props(~pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition ~ ., labeller = label_both) + \n  labs( title = \"Distribution of Interpretations (across Task)\",\n        x = \"Graph Interpretation\",\n        y = \"Proportion of Responses\",\n        subtitle = \"Impasse condition (blue) yields fewer Orthogonal and more Triangular responses\") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION ACROSS ITEMS\ngf_propsh(~ pretty_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more Triangular responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#DISTRIBUTION OF INTERPRETATION TYPE ACROSS ITEMS\ngf_propsh(~ high_interpretation, fill = ~pretty_condition, data = df) %>% \n  gf_facet_grid( pretty_condition~q) + \n  labs( title = \"Distribution of Interpretations (by Item)\",\n        subtitle = \"Impasse condition (blue) yields more positive trending responses on each question\",\n        y = \"Interpretation\", x = \"Proportion of Subjects\") + theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\nggbarstats( data = df, x = score_STATE, y = pretty_condition)\n\n\n\n\n\nCODE\nggbarstats( data = df, x = high_interpretation, y = pretty_condition)\n\n\n\n\n\n\n\nProgress over Task\n\n\nCODE\n#VISUALIZE progress over time ABSOLUTE score \nggplot(data = df_absolute_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Absolute Score over sequence of task\", x = \"Question\" , y = \"Cumulative Absolute Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\n#VISUALIZE progress over time SCALED score \nggplot(data = df_scaled_progress, aes(x = question, y = score, group = subject, alpha = 0.01, color = pretty_condition)) + \n geom_line(position=position_jitter(w=0.15, h=0.15), size=0.1) +\n facet_wrap(~pretty_condition) + \n labs (title = \"Cumulative Scaled Score over sequence of task\", x = \"Question\" , y = \"Cumulative Scaled Score\") + \n scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13)) +\n theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\nInterpretation Subscores\n\n\nCODE\ngf_density(~ s_TRI, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Triangular Score\",\n        subtitle = \"Impasse shifts density toward higher Triagular scores\",\n        x = \"Item Triangular Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_ORTH, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Orthogonal Score\",\n        subtitle = \"Impasse shifts density toward lower Orthogonal scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_density(~ s_TVERSKY, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Tversky Score\",\n        subtitle = \"Impasse shifts density toward higher Tversky scores\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_histogram(~ s_SATISFICE, fill = ~pretty_condition, data = df_subjects) %>% \n  gf_facet_wrap( ~ pretty_condition) + \n  labs( title = \"Distribution of Total Satisfice Score\",\n        subtitle = \"Satisficing only occurs in impasse, when no orthogonal response is available\",\n        x = \"Item Orthogonal Score\", y = \"Proportion of Subjects\") + \n        theme_minimal() + theme(legend.position = \"blank\")"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#peek",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#peek",
    "title": "21  Response Scoring",
    "section": "PEEK",
    "text": "PEEK\n\n\nCODE\nggbetweenstats( data = df_subjects,\n                x = pretty_condition, y = s_NABS,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_niceABS, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Total Absolute Score [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = interpretation, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"Interpretation [directional test]\")\n\n\n\n\n\nCODE\nggbarstats( data = df_items,\n                x = score_STATE, y = pretty_condition,\n                type = \"non-parametric\",\n                title = \"State [directional test]\")"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#explore-responses",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#explore-responses",
    "title": "21  Response Scoring",
    "section": "EXPLORE RESPONSES",
    "text": "EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, indicate how each response was scored, and what interpretation of the graph is indicated by different responses.\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items ) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\nScaffold Phase\nThe first five questions constitute the ‘scaffold’ (or learning) phase, where participants see a different version of the stimulus (specifically a different dataset is visualized) invoking a different experimental condition.\n\nQuestion #1\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==1)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q1 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\n\n\n\nFigure 21.1: Question 1 — NonImpasse Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==1)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q1 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q1 Control Condition :  Which shift(s) start at 11 am?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    A \n    OI \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    CF \n    Z \n  \n  \n    Tversky [start diagonal] \n    F \n    Z \n  \n  \n    Tversky [end diagonal] \n    C \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\nHere we summarize the distinct response options given by participants on this item. Each letter in response indicates a checkbox selected by the participant (See Figure 21.1 ). n indicates the number of participants who gave this response, while interpretation indicates the graph interpretation most consistent with that response. At the right of this table are the Absolute, followed by Partial Credit subscores for each response. NA indicates that there is no score calculated (occurs when there is no subset of response options that accord with that interpretation for this question).\nNotice that for this Question, the Triangular answer is the same as the Tversky [start diagonal] answer. In fact, for most questions, one of the Tversky sub-types will match the correct response.\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 1 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 1) %>% \n  # pack_rows(\"Lines-Connect\", 2, 2) %>% \n  # pack_rows(\"Orthogonal\", 3, 3) %>% \n  # pack_rows(\"Other\", 4, 4)  %>% \n  # pack_rows(\"Unknown\", 5, 7)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    46 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    CF \n    12 \n    Tversky \n    0 \n    0.923 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    C \n    3 \n    Tversky \n    0 \n    -0.077 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    ABCU \n    1 \n    Tversky \n    0 \n    -0.308 \n    0.786 \n    NA \n    0.750 \n    0.5 \n  \n  \n    ACE \n    1 \n    Tversky \n    0 \n    -0.231 \n    0.857 \n    NA \n    0.833 \n    0.5 \n  \n  \n    A \n    257 \n    Orthogonal \n    0 \n    -0.077 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AIO \n    3 \n    Orthogonal \n    0 \n    -0.231 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AF \n    1 \n    both tri + orth \n    0 \n    0.923 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCDEHIJKOU \n    1 \n    frenzy \n    0 \n    -0.846 \n    0.286 \n    NA \n    0.333 \n    -0.5 \n  \n  \n    ACF \n    1 \n    ? \n    0 \n    0.846 \n    0.917 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    DX \n    1 \n    ? \n    0 \n    -0.154 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    EH \n    1 \n    ? \n    0 \n    -0.154 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.077 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.077 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #2\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==2)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q2 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.2: Q2—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==2)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q2 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q2 Control Condition :  Which shift(s) start at the same time as D?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    K \n    Z \n  \n  \n    Orthgonal \n    E \n    G \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AKJX \n    Z \n  \n  \n    Tversky [start diagonal] \n    AK \n    Z \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    J \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 2 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) %>%\n  # pack_rows(\"Triangular\", 1, 2) %>%\n  # pack_rows(\"Lines-Connect\", 3, 4) %>% \n  # pack_rows(\"Orthogonal\", 5, 7) %>%\n  # pack_rows(\"Other\", 8, 8)  %>% \n  # pack_rows(\"Unknown\", 9, 10)  %>% \n  footnote(general = \"n = number of responses in sample\", \n           general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    K \n    54 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    DK \n    2 \n    Triangular \n    1 \n    1.000 \n    0.500 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    J \n    15 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AK \n    6 \n    Tversky \n    0 \n    0.917 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    X \n    3 \n    Tversky \n    0 \n    -0.083 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    JK \n    2 \n    Tversky \n    0 \n    0.917 \n    0.923 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    A \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    EJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.923 \n    NA \n    0.917 \n    0.5 \n  \n  \n    E \n    225 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    DE \n    7 \n    Orthogonal \n    0 \n    -0.083 \n    -0.077 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EG \n    2 \n    Orthogonal \n    0 \n    -0.167 \n    -0.154 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    D \n    5 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DEHIJO \n    1 \n    frenzy \n    0 \n    -0.417 \n    0.692 \n    NA \n    0.667 \n    -0.5 \n  \n  \n    Z \n    3 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    B \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    CD \n    1 \n    ? \n    0 \n    -0.083 \n    -0.077 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    UZ \n    1 \n    ? \n    0 \n    -0.083 \n    -0.091 \n    NA \n    -0.167 \n    -0.5 \n  \n\n\nNote:   n = number of responses in sample\n\n\n\n\n\n\nQuestion #3\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==3)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q3 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.3: Q3—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==3)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q3 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q3 Control Condition :  Which shift(s) begin when C ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    F \n    Z \n  \n  \n    Orthgonal \n    Z \n    FIO \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    AUBFOJ \n     \n  \n  \n    Tversky [start diagonal] \n    OJ \n     \n  \n  \n    Tversky [end diagonal] \n    F \n    Z \n  \n  \n    Tversky [duration line] \n    AUB \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 3 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    F \n    50 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    0.0 \n    1.0 \n  \n  \n    A \n    50 \n    Tversky \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    JO \n    7 \n    Tversky \n    0 \n    -0.167 \n    1.000 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    ABU \n    5 \n    Tversky \n    0 \n    -0.250 \n    1.000 \n    NA \n    -0.3 \n    0.5 \n  \n  \n    FG \n    2 \n    Tversky \n    0 \n    0.917 \n    0.917 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    O \n    2 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    0.0 \n    0.5 \n  \n  \n    DJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    DJO \n    1 \n    Tversky \n    0 \n    -0.250 \n    0.917 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    HJ \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.2 \n    0.5 \n  \n  \n    IO \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    0.0 \n    0.5 \n  \n  \n    J \n    1 \n    Tversky \n    0 \n    -0.083 \n    0.500 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    KO \n    1 \n    Tversky \n    0 \n    -0.167 \n    0.417 \n    NA \n    -0.1 \n    0.5 \n  \n  \n    Z \n    176 \n    Orthogonal \n    0 \n    0.000 \n    0.000 \n    NA \n    1.0 \n    -1.0 \n  \n  \n    DUZ \n    1 \n    Orthogonal \n    0 \n    -0.167 \n    0.152 \n    NA \n    0.8 \n    -1.0 \n  \n  \n    EZ \n    1 \n    Orthogonal \n    0 \n    -0.083 \n    -0.083 \n    NA \n    0.9 \n    -1.0 \n  \n  \n    C \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.0 \n    0.0 \n  \n  \n    ABJOU \n    1 \n    frenzy \n    0 \n    -0.417 \n    0.833 \n    NA \n    -0.4 \n    -0.5 \n  \n  \n    U \n    9 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    AH \n    4 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    B \n    4 \n    ? \n    0 \n    -0.083 \n    0.333 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    K \n    4 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n  \n    EU \n    3 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    EFK \n    1 \n    ? \n    0 \n    0.833 \n    0.833 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    UX \n    1 \n    ? \n    0 \n    -0.167 \n    0.242 \n    NA \n    -0.2 \n    -0.5 \n  \n  \n    X \n    1 \n    ? \n    0 \n    -0.083 \n    -0.083 \n    NA \n    -0.1 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 17)  \n\n\n\n\nQuestion #4\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==4)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q4 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.4: Q4—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==4)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q4 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q4 Control Condition :  Which shift(s) end at 4 pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    H \n     \n  \n  \n    Orthgonal \n    U \n    OF \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    BH \n     \n  \n  \n    Tversky [start diagonal] \n    B \n     \n  \n  \n    Tversky [end diagonal] \n    H \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 4 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    H \n    71 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.083 \n    1.0 \n  \n  \n    B \n    14 \n    Tversky \n    0 \n    -0.071 \n    1.000 \n    NA \n    -0.083 \n    0.5 \n  \n  \n    AH \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    BDEG \n    1 \n    Tversky \n    0 \n    -0.286 \n    0.786 \n    NA \n    -0.333 \n    0.5 \n  \n  \n    BH \n    1 \n    Tversky \n    0 \n    0.929 \n    1.000 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    HK \n    1 \n    Tversky \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    0.5 \n  \n  \n    U \n    153 \n    Orthogonal \n    0 \n    -0.071 \n    -0.071 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    8 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    OU \n    4 \n    Orthogonal \n    0 \n    -0.143 \n    -0.143 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FOU \n    2 \n    Orthogonal \n    0 \n    -0.214 \n    -0.214 \n    NA \n    1.000 \n    -1.0 \n  \n  \n     \n    8 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    DE \n    41 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    E \n    7 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    K \n    4 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    HJ \n    3 \n    ? \n    0 \n    0.929 \n    0.929 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    D \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    X \n    2 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    DEOU \n    1 \n    ? \n    0 \n    -0.286 \n    -0.286 \n    NA \n    0.833 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    EK \n    1 \n    ? \n    0 \n    -0.143 \n    -0.143 \n    NA \n    -0.167 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    -0.083 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.071 \n    -0.071 \n    NA \n    0.000 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>% \n#   pack_rows(\"Lines-Connect\", 3, 3) %>% \n#   pack_rows(\"Orthogonal\", 4, 8) %>% \n#   pack_rows(\"Other\", 9, 10) %>% \n#   pack_rows(\"Unknown\", 11, 16) \n\n\n\nTBL4 test\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n |\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\nQuestion #5\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==5)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q5 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.5: Q5—Control Condition\n\n\n\n\nCODE\nq <- keys_raw %>% filter(condition == \"DEFAULT\") %>% filter(Q==5)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist() \noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\", \n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q5 Control Condition : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>% \n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T) \n\n\n\nAnswer Key | Q5 Control Condition :  Coffee breaks happen halfway through a shift. Which shift(s) share a break with I?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    O \n    AZ \n  \n  \n    Orthgonal \n    U \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    UGX \n    AZKD \n  \n  \n    Tversky [start diagonal] \n    X \n     \n  \n  \n    Tversky [end diagonal] \n    UG \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  AIKGXJDBCHUZOFE\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #5 (Control Condition)\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 5 & IMPASSE == \"none\") %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>% \n  arrange(interpretation, desc(count)) %>% \n  dplyr::select(response, count, interpretation, nice, \n         triangular, tversky, satisficing, orthogonal, scaled) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #5 (Control Condition)\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    O \n    97 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    AO \n    1 \n    Triangular \n    1 \n    1.000 \n    -0.143 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    IO \n    1 \n    Triangular \n    1 \n    1.000 \n    -0.077 \n    NA \n    -0.077 \n    1.0 \n  \n  \n    OZ \n    1 \n    Triangular \n    1 \n    1.000 \n    -0.143 \n    NA \n    -0.154 \n    1.0 \n  \n  \n    X \n    5 \n    Tversky \n    0 \n    -0.091 \n    1.000 \n    NA \n    -0.077 \n    0.5 \n  \n  \n    UX \n    2 \n    Tversky \n    0 \n    -0.182 \n    0.923 \n    NA \n    0.923 \n    0.5 \n  \n  \n    BDFG \n    1 \n    Tversky \n    0 \n    -0.364 \n    0.250 \n    NA \n    -0.308 \n    0.5 \n  \n  \n    BG \n    1 \n    Tversky \n    0 \n    -0.182 \n    0.417 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    DJX \n    1 \n    Tversky \n    0 \n    -0.273 \n    0.846 \n    NA \n    -0.231 \n    0.5 \n  \n  \n    HJOX \n    1 \n    Tversky \n    0 \n    0.727 \n    0.769 \n    NA \n    -0.308 \n    0.5 \n  \n  \n    JO \n    1 \n    Tversky \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    KO \n    1 \n    Tversky \n    0 \n    0.909 \n    -0.143 \n    NA \n    -0.154 \n    0.5 \n  \n  \n    U \n    115 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    HU \n    2 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    IU \n    2 \n    Orthogonal \n    0 \n    -0.091 \n    0.500 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FU \n    1 \n    Orthogonal \n    0 \n    -0.182 \n    0.417 \n    NA \n    0.923 \n    -1.0 \n  \n  \n    I \n    2 \n    reference \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    OU \n    1 \n    both tri + orth \n    0 \n    0.909 \n    0.417 \n    NA \n    0.923 \n    0.5 \n  \n  \n     \n    15 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCDEFGHJKOUXZ \n    1 \n    frenzy \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    F \n    27 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    H \n    8 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    K \n    8 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    J \n    6 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    FO \n    4 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    Z \n    4 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    A \n    3 \n    ? \n    0 \n    0.000 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    B \n    3 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    D \n    2 \n    ? \n    0 \n    -0.091 \n    0.000 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    EH \n    2 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HJ \n    2 \n    ? \n    0 \n    -0.182 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HK \n    2 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    DEHJ \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.182 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    DJO \n    1 \n    ? \n    0 \n    0.818 \n    -0.231 \n    NA \n    -0.231 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.091 \n    -0.077 \n    NA \n    -0.077 \n    -0.5 \n  \n  \n    EHJK \n    1 \n    ? \n    0 \n    -0.364 \n    -0.308 \n    NA \n    -0.308 \n    -0.5 \n  \n  \n    FZ \n    1 \n    ? \n    0 \n    -0.091 \n    -0.143 \n    NA \n    -0.154 \n    -0.5 \n  \n  \n    HO \n    1 \n    ? \n    0 \n    0.909 \n    -0.154 \n    NA \n    -0.154 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>% \n#   pack_rows(\"Lines-Connect\", 5, 7) %>% \n#   pack_rows(\"Orthogonal\", 8, 9) %>% \n#   pack_rows(\"Other\", 10, 11) %>% \n#   pack_rows(\"Unknown\", 12, 22) \n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\n\nTesting Phase\nThe following 10 questions were the same for both conditions.\n\nQuestion #7\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 7)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q7 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.6: Q7-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==7)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts less than 5 hours long start at the same time?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    OX \n     \n  \n  \n    Orthgonal \n    BF \n    M \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    IJZNCHOX \n     \n  \n  \n    Tversky [start diagonal] \n    OX \n     \n  \n  \n    Tversky [end diagonal] \n    IJZN \n     \n  \n  \n    Tversky [duration line] \n    CH \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #7\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 7) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #7\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    OX \n    62 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    IJ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.500 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    CH \n    2 \n    Tversky \n    0 \n    -0.125 \n    1.000 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    O \n    2 \n    Tversky \n    0 \n    0.500 \n    0.500 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    DNZ \n    1 \n    Tversky \n    0 \n    -0.188 \n    0.429 \n    NA \n    -0.200 \n    0.5 \n  \n  \n    HL \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.438 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    X \n    1 \n    Tversky \n    0 \n    0.500 \n    0.500 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    BF \n    230 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FZ \n    10 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    B \n    2 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BI \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    BJ \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    0.179 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    EF \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    1 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    BDFIJMNOXZ \n    2 \n    frenzy \n    0 \n    0.500 \n    0.571 \n    NA \n    0.533 \n    -0.5 \n  \n  \n    BDFJMNOXZ \n    1 \n    frenzy \n    0 \n    0.562 \n    0.562 \n    NA \n    0.600 \n    -0.5 \n  \n  \n    IJNOXZ \n    1 \n    frenzy \n    0 \n    0.750 \n    0.857 \n    NA \n    -0.400 \n    -0.5 \n  \n  \n    AG \n    2 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DN \n    2 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BO \n    1 \n    ? \n    0 \n    0.438 \n    0.438 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    EI \n    1 \n    ? \n    0 \n    -0.125 \n    0.179 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.438 \n    0.438 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    0.250 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 5) %>%\n#   pack_rows(\"Lines-Connect\", 6, 9) %>%\n#   pack_rows(\"Orthogonal\", 10, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 17)\n\n\n\n\nQuestion #8\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 8)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q8 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==8)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q: \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q:  Which shift(s) under 7 hours long starts before B starts, and ends after X ends?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    E \n    F \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #8\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 8) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1))\n\n\n\nFrequency of Selected Response Options for Question #8\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    53 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.071 \n    1.0 \n  \n  \n    CG \n    3 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    CFGO \n    2 \n    Tversky \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    0.5 \n  \n  \n    AG \n    1 \n    Tversky \n    0 \n    0.933 \n    NA \n    NA \n    -0.143 \n    0.5 \n  \n  \n    E \n    179 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    EIJ \n    7 \n    Orthogonal \n    0 \n    -0.200 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EI \n    4 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EF \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    AE \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.929 \n    -1.0 \n  \n  \n    EFIJ \n    1 \n    Orthogonal \n    0 \n    -0.267 \n    NA \n    NA \n    0.857 \n    -1.0 \n  \n  \n    EG \n    3 \n    both tri + orth \n    0 \n    0.933 \n    NA \n    NA \n    0.929 \n    0.5 \n  \n  \n     \n    11 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABFGK \n    1 \n    frenzy \n    0 \n    0.800 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    CDEGHIJNZ \n    1 \n    frenzy \n    0 \n    0.467 \n    NA \n    NA \n    0.429 \n    -0.5 \n  \n  \n    DEHIJNOZ \n    1 \n    frenzy \n    0 \n    -0.533 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    DHNOZ \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    -0.357 \n    -0.5 \n  \n  \n    EFIJM \n    1 \n    frenzy \n    0 \n    -0.333 \n    NA \n    NA \n    0.786 \n    -0.5 \n  \n  \n    IJ \n    9 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    I \n    8 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    M \n    7 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    O \n    5 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AK \n    3 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    DN \n    3 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    F \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    IJM \n    3 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    L \n    3 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    CEG \n    2 \n    ? \n    0 \n    0.867 \n    NA \n    NA \n    0.857 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    AKO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    D \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.071 \n    -0.5 \n  \n  \n    DJMN \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.286 \n    -0.5 \n  \n  \n    DJN \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.214 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n  \n    NZ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.143 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Orthogonal\", 11, 16) %>%\n#   pack_rows(\"Other\", 17, 21) %>%\n#   pack_rows(\"Unknown\", 22, 45)\n\n\n\n\nQuestion #10\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 10)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q10 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==10)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    E \n     \n  \n  \n    Orthgonal \n    X \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    EGZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n    E \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #10\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 10) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #10\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    E \n    80 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    EF \n    1 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    21 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    G \n    5 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    XZ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    0.938 \n    0.5 \n  \n  \n    PZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    X \n    139 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FX \n    14 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BX \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.125 \n    NA \n    0.938 \n    -1.0 \n  \n  \n    F \n    3 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    B \n    35 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    IJ \n    5 \n    ? \n    0 \n    -0.125 \n    -0.125 \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    J \n    4 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    A \n    3 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    I \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    K \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    P \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 2) %>%\n#   pack_rows(\"Lines-Connect\", 3, 7) %>%\n#   pack_rows(\"Orthogonal\", 8, 11) %>%\n#   pack_rows(\"Other\", 12, 14) %>%\n#   pack_rows(\"Unknown\", 15, 27)\n\n\n\n\nQuestion #11\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 11)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 11)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q11 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==11)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at 12pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    ML \n     \n  \n  \n    Orthgonal \n    FB \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #11\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 11) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #11\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    LM \n    71 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    -0.125 \n    1.0 \n  \n  \n    M \n    9 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    L \n    2 \n    Triangular \n    1 \n    0.500 \n    NA \n    NA \n    -0.062 \n    1.0 \n  \n  \n    KL \n    1 \n    Tversky \n    0 \n    0.438 \n    NA \n    NA \n    -0.125 \n    0.5 \n  \n  \n    BF \n    233 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    B \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    DF \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    NA \n    NA \n    0.438 \n    -1.0 \n  \n  \n    F \n    1 \n    Orthogonal \n    0 \n    -0.062 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BLM \n    1 \n    both tri + orth \n    0 \n    0.938 \n    NA \n    NA \n    0.375 \n    0.5 \n  \n  \n     \n    3 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    ACDGHKLMNOPXZ \n    2 \n    frenzy \n    0 \n    0.312 \n    NA \n    NA \n    -0.812 \n    -0.5 \n  \n  \n    DHLMNOXZ \n    1 \n    frenzy \n    0 \n    0.625 \n    NA \n    NA \n    -0.500 \n    -0.5 \n  \n  \n    K \n    3 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    EIJ \n    1 \n    ? \n    0 \n    -0.188 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    KX \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 9) %>%\n#   pack_rows(\"Other\", 10, 12) %>%\n#   pack_rows(\"Unknown\", 13, 17)\n\n\n\n\nQuestion #12\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 12)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q12 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==12)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) start at the same time as F?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    G \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    GZ \n     \n  \n  \n    Tversky [start diagonal] \n    G \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n    Z \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #12\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 12) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #12\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    G \n    70 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    FG \n    4 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.062 \n    1.0 \n  \n  \n    Z \n    3 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.062 \n    0.5 \n  \n  \n    BJZ \n    1 \n    Tversky \n    0 \n    -0.188 \n    0.875 \n    NA \n    0.875 \n    0.5 \n  \n  \n    EG \n    1 \n    Tversky \n    0 \n    0.938 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    EZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.938 \n    NA \n    -0.125 \n    0.5 \n  \n  \n    B \n    236 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    7 \n    Orthogonal \n    0 \n    -0.062 \n    -0.062 \n    NA \n    1.000 \n    -1.0 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    CEGIO \n    1 \n    frenzy \n    0 \n    0.750 \n    0.750 \n    NA \n    -0.312 \n    -0.5 \n  \n  \n    X \n    3 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.062 \n    -0.062 \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Lines-Connect\", 4, 6) %>%\n#   pack_rows(\"Orthogonal\", 7, 8) %>%\n#   pack_rows(\"Other\", 9, 10) %>%\n#   pack_rows(\"Unknown\", 11, 14)\n\n\n\n\nQuestion #13\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 13)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 13)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q13 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==13)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which 2 shifts end when Z begins?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EF \n     \n  \n  \n    Orthgonal \n    FX \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #13\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 13) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #13\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EF \n    67 \n    Triangular \n    1 \n    1.000 \n    NA \n    NA \n    0.433 \n    1.0 \n  \n  \n    FX \n    170 \n    Orthogonal \n    0 \n    0.433 \n    NA \n    NA \n    1.000 \n    -1.0 \n  \n  \n    X \n    9 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BX \n    3 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    OX \n    2 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    JX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    MX \n    1 \n    Orthogonal \n    0 \n    -0.133 \n    NA \n    NA \n    0.433 \n    -1.0 \n  \n  \n    XZ \n    1 \n    Orthogonal \n    0 \n    -0.067 \n    NA \n    NA \n    0.500 \n    -1.0 \n  \n  \n    Z \n    1 \n    reference \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n     \n    5 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    F \n    14 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    BF \n    7 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    HL \n    7 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    DN \n    6 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HN \n    6 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    LP \n    6 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CO \n    2 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    EX \n    2 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    HLP \n    2 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    N \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    AG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BFM \n    1 \n    ? \n    0 \n    0.367 \n    NA \n    NA \n    0.367 \n    -0.5 \n  \n  \n    BIJM \n    1 \n    ? \n    0 \n    -0.267 \n    NA \n    NA \n    -0.267 \n    -0.5 \n  \n  \n    BM \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    C \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CG \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    CGO \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    DJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    FH \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    FNZ \n    1 \n    ? \n    0 \n    0.433 \n    NA \n    NA \n    0.433 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 3) %>%\n#   pack_rows(\"Orthogonal\", 4, 13) %>%\n#   pack_rows(\"Other\", 14, 14) %>%\n#   pack_rows(\"Unknown\", 15, 36)\n\n\n\n\nQuestion #14\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 14)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 14)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q14 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==14)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) end at 3pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    X \n     \n  \n  \n    Orthgonal \n    B \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XJND \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n    X \n     \n  \n  \n    Tversky [duration line] \n    JND \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #14\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 14) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #14\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    X \n    80 \n    Triangular \n    1 \n    1.000 \n    1.000 \n    NA \n    -0.059 \n    1.0 \n  \n  \n    FX \n    2 \n    Tversky \n    0 \n    0.941 \n    0.941 \n    NA \n    -0.118 \n    0.5 \n  \n  \n    B \n    179 \n    Orthogonal \n    0 \n    -0.059 \n    -0.059 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    BF \n    7 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BI \n    1 \n    Orthogonal \n    0 \n    -0.118 \n    -0.118 \n    NA \n    0.941 \n    -1.0 \n  \n  \n    BIO \n    1 \n    Orthogonal \n    0 \n    -0.176 \n    -0.176 \n    NA \n    0.882 \n    -1.0 \n  \n  \n    BX \n    1 \n    both tri + orth \n    0 \n    0.941 \n    0.941 \n    NA \n    0.941 \n    0.5 \n  \n  \n     \n    24 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    DHLNPZ \n    1 \n    frenzy \n    0 \n    -0.353 \n    0.400 \n    NA \n    -0.353 \n    -0.5 \n  \n  \n    O \n    8 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    K \n    5 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    KO \n    3 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    G \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    HLP \n    2 \n    ? \n    0 \n    -0.176 \n    -0.176 \n    NA \n    -0.176 \n    -0.5 \n  \n  \n    I \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    M \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    Z \n    2 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    AF \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    E \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    FG \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    HI \n    1 \n    ? \n    0 \n    -0.118 \n    -0.118 \n    NA \n    -0.118 \n    -0.5 \n  \n  \n    L \n    1 \n    ? \n    0 \n    -0.059 \n    -0.059 \n    NA \n    -0.059 \n    -0.5 \n  \n  \n    NO \n    1 \n    ? \n    0 \n    -0.118 \n    0.267 \n    NA \n    -0.118 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 4) %>%\n#   pack_rows(\"Orthogonal\", 5, 7) %>%\n#   pack_rows(\"Other\", 8, 9) %>%\n#   pack_rows(\"Unknown\", 10, 22)\n\n\n\n\nQuestion #15\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 15)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 15)) %>%\n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q15 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==15)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Coffee breaks happen halfway through a shift. Which shifts share a break at 2pm?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    XK \n     \n  \n  \n    Orthgonal \n    EF \n    B \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n    XKZ \n     \n  \n  \n    Tversky [start diagonal] \n    Z \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #15\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 15) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #15\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    KX \n    79 \n    Triangular \n    1 \n    1.000 \n    0.667 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    X \n    4 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    CX \n    2 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    KO \n    2 \n    Triangular \n    1 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    1.0 \n  \n  \n    K \n    1 \n    Triangular \n    1 \n    0.500 \n    0.333 \n    NA \n    -0.067 \n    1.0 \n  \n  \n    FZ \n    3 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    0.433 \n    0.5 \n  \n  \n    AK \n    2 \n    Tversky \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    OX \n    2 \n    Tversky \n    0 \n    0.438 \n    0.267 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    HZ \n    1 \n    Tversky \n    0 \n    -0.125 \n    0.941 \n    NA \n    -0.133 \n    0.5 \n  \n  \n    Z \n    1 \n    Tversky \n    0 \n    -0.062 \n    1.000 \n    NA \n    -0.067 \n    0.5 \n  \n  \n    EF \n    127 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    F \n    30 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BF \n    24 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    E \n    9 \n    Orthogonal \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    BE \n    5 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.500 \n    -1.0 \n  \n  \n    CF \n    2 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    BEF \n    1 \n    Orthogonal \n    0 \n    -0.188 \n    -0.176 \n    NA \n    1.000 \n    -1.0 \n  \n  \n    FG \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FJ \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n    FN \n    1 \n    Orthogonal \n    0 \n    -0.125 \n    -0.118 \n    NA \n    0.433 \n    -1.0 \n  \n  \n     \n    9 \n    blank \n    0 \n    0.000 \n    0.000 \n    NA \n    0.000 \n    0.0 \n  \n  \n    ABCFG \n    1 \n    frenzy \n    0 \n    -0.312 \n    -0.294 \n    NA \n    0.300 \n    -0.5 \n  \n  \n    B \n    5 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    0.000 \n    -0.5 \n  \n  \n    BM \n    2 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    C \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    FX \n    2 \n    ? \n    0 \n    0.438 \n    0.267 \n    NA \n    0.433 \n    -0.5 \n  \n  \n    H \n    2 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    A \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AG \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    BC \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    CO \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    GM \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    HL \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    0 \n    -0.125 \n    -0.118 \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    O \n    1 \n    ? \n    0 \n    -0.062 \n    -0.059 \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Triangular\", 1, 10) %>%\n#   pack_rows(\"Lines-Connect\", 11, 13) %>%\n#   pack_rows(\"Orthogonal\", 14, 22) %>%\n#   pack_rows(\"Other\", 23, 23) %>%\n#   pack_rows(\"Unknown\", 24, 44)\n\n\n\n\n\nNON-DISCRIMINANT\n\nQuestion #6 NONDISCRIM\n\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q ==6)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q6 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nFigure 21.7: Q6-Question\n\n\n\n\nCODE\nq <- keys_raw %>% filter(Q==6)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) are six hours long?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    EG \n     \n  \n  \n    Orthgonal \n    EG \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\nTODO discuss non discriminant\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #6\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q == 6) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #6\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    EG \n    313 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    2 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    DHKLNOPXZ \n    1 \n    frenzy \n    0 \n    -0.562 \n    NA \n    NA \n    -0.562 \n    -0.5 \n  \n  \n    DHLNPZ \n    1 \n    frenzy \n    0 \n    -0.375 \n    NA \n    NA \n    -0.375 \n    -0.5 \n  \n  \n    E \n    3 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    O \n    2 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    CFI \n    1 \n    ? \n    0 \n    -0.188 \n    NA \n    NA \n    -0.188 \n    -0.5 \n  \n  \n    CH \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    EF \n    1 \n    ? \n    0 \n    0.438 \n    NA \n    NA \n    0.438 \n    -0.5 \n  \n  \n    EGH \n    1 \n    ? \n    0 \n    0.938 \n    NA \n    NA \n    0.938 \n    -0.5 \n  \n  \n    G \n    1 \n    ? \n    0 \n    0.500 \n    NA \n    NA \n    0.500 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    J \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n  \n    JM \n    1 \n    ? \n    0 \n    -0.125 \n    NA \n    NA \n    -0.125 \n    -0.5 \n  \n  \n    M \n    1 \n    ? \n    0 \n    -0.062 \n    NA \n    NA \n    -0.062 \n    -0.5 \n  \n\n\n\n\n\n\n\nQuestion #9 NONDISCRIM\n ::: {.cell}\n\nCODE\ngf_dhistogram(~ score_niceABS, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Scaled Item Score\", title = \"Distribution of Scaled Scores | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n\nCODE\ngf_props(~interpretation, fill = ~condition, data = df_items %>% filter(q == 9)) %>% \n  gf_facet_grid( condition ~ ., labeller = label_both) + \n  labs( x = \"Interpretation\", title = \"Distribution of Interpretations | Q9 \") + \n  theme_minimal() + theme(legend.position = \"blank\")\n\n\n\n\n:::\n\n\nCODE\nq <- keys_raw %>% filter(Q==9)\nignore <- q %>% dplyr::select(\"REF_POINT\")\nanswers <- q %>% dplyr::select(\"TRIANGULAR\", \"ORTHOGONAL\", \"SATISFICE_left\", \"SATISFICE_right\",\"TV_max\",\"TV_start\", \"TV_end\", \"TV_dur\") %>% unlist()\nves <- q %>% mutate(\n  SATISFICE_left_allow = \"\",\n  SATISFICE_right_allow = \"\"\n) %>% dplyr::select(\"TRI_allow\", \"ORTH_allow\", \"SATISFICE_left_allow\",\"SATISFICE_right_allow\", \"TV_max_allow\",\"TV_start_allow\",\"TV_end_allow\", \"TV_dur_allow\")%>% unlist()\noptions <- q %>% dplyr::select(\"OPTIONS\")\nquestion = q %>%  dplyr::select(\"TEXT\")\nscores <- c(\"Triangular\", \"Orthgonal\", \"Satisficing [left]\", \"Satisficing [right]\", \"Tversky [maximal]\", \"Tversky [start diagonal]\",\n            \"Tversky [end diagonal]\", \"Tversky [duration line]\")\nd = tibble(interpretation = scores, answer = answers, allowed=ves)\nd$answer <- replace_na(d$answer, \"\")\nd$allowed <- replace_na(d$allowed, \"\")\n\ntitle = paste(\"Answer Key | Q : \", question)\ncols = c(\"interpretation\", \"answer\",\"not penalized\")\n\nd %>% kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n  footnote(general = paste(\"15 response options: \", options), general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nAnswer Key | Q :  Which shift(s) begins before J begins and ends during B?\n \n  \n    interpretation \n    answer \n    not penalized \n  \n \n\n  \n    Triangular \n    I \n     \n  \n  \n    Orthgonal \n    I \n     \n  \n  \n    Satisficing [left] \n     \n     \n  \n  \n    Satisficing [right] \n     \n     \n  \n  \n    Tversky [maximal] \n     \n     \n  \n  \n    Tversky [start diagonal] \n     \n     \n  \n  \n    Tversky [end diagonal] \n     \n     \n  \n  \n    Tversky [duration line] \n     \n     \n  \n\n\nNote:   15 response options:  ABCDEFGHIJKLMNOPZX\n\n\n\n\n\n\nCODE\ntitle <- \"Frequency of Selected Response Options for Question #9\"\nnames = c(\"response\",\"n\",\"interpretation\",\"absolute\",\"tri\",\"tversky\",\"satisfice\",\"orthogonal\", \"scaled score\")\n\ndf_items %>% filter(q ==9) %>% group_by(response) %>%\n  dplyr::summarise( count = n(),\n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI),\n                    orthogonal =  unique(score_ORTH),\n                    satisficing =  unique(score_SATISFICE),\n                    tversky = unique(score_TVERSKY),\n                    interpretation = unique(int2),\n                    scaled = unique(score_SCALED)) %>%\n  arrange(interpretation, desc(count)) %>%\n  dplyr::select(response, count, interpretation, nice,\n         triangular, tversky, satisficing, orthogonal, scaled) %>%\n  kbl(caption = title, col.names = names) %>%  kable_classic() %>%\n  add_header_above(c(\" \" = 3, \"Strict Score\" = 1, \"Interpretation Scores\"=4, \"Discriminant\"=1)) \n\n\n\nFrequency of Selected Response Options for Question #9\n \n\n\nStrict Score\nInterpretation Scores\nDiscriminant\n\n  \n    response \n    n \n    interpretation \n    absolute \n    tri \n    tversky \n    satisfice \n    orthogonal \n    scaled score \n  \n \n\n  \n    I \n    258 \n    both tri + orth \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    0.5 \n  \n  \n     \n    17 \n    blank \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    0.0 \n  \n  \n    E \n    29 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    M \n    6 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IM \n    3 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    J \n    3 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    B \n    2 \n    ? \n    0 \n    0.000 \n    NA \n    NA \n    0.000 \n    -0.5 \n  \n  \n    EI \n    2 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    F \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    K \n    2 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    AKP \n    1 \n    ? \n    0 \n    -0.200 \n    NA \n    NA \n    -0.200 \n    -0.5 \n  \n  \n    EH \n    1 \n    ? \n    0 \n    -0.133 \n    NA \n    NA \n    -0.133 \n    -0.5 \n  \n  \n    FI \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    H \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n  \n    IJ \n    1 \n    ? \n    1 \n    1.000 \n    NA \n    NA \n    1.000 \n    -0.5 \n  \n  \n    IO \n    1 \n    ? \n    0 \n    0.933 \n    NA \n    NA \n    0.933 \n    -0.5 \n  \n  \n    N \n    1 \n    ? \n    0 \n    -0.067 \n    NA \n    NA \n    -0.067 \n    -0.5 \n  \n\n\n\n\n\nCODE\n# %>%\n#   pack_rows(\"Other\", 1, 2) %>%\n#   pack_rows(\"Unknown\", 3, 19)"
  },
  {
    "objectID": "analysis/SGC4D/2_sgc4D_scoring.html#export",
    "href": "analysis/SGC4D/2_sgc4D_scoring.html#export",
    "title": "21  Response Scoring",
    "section": "EXPORT",
    "text": "EXPORT\nFinally, we export the scores for each item (df_items) and summarized over subjects (df_subjects), as well as cumulative progress dataframes (df_absolute_progress, df_scaled_progress)\n\n\nCODE\n# imac = \"/Users/amyraefox/Code/SGC-Scaffolding_Graph_Comprehension/SGC-X/ANALYSIS/MAIN\"\n# setwd(imac)\n\n#SAVE FILES\nwrite.csv(df_subjects,\"analysis/SGC4D/data/2-scored-data/sgc4d_scored_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"analysis/SGC4D/data/2-scored-data/sgc4d_scored_items.csv\", row.names = FALSE)\nwrite.csv(df_absolute_progress,\"analysis/SGC4D/data/2-scored-data/sgc4d_absolute_progress.csv\", row.names = FALSE)\nwrite.csv(df_scaled_progress,\"analysis/SGC4D/data/2-scored-data/sgc4d_scaled_progress.csv\", row.names = FALSE)\n\n#SAVE R Data Structures\n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"analysis/SGC4D/data/2-scored-data/sgc4d_scored_participants.rds\") # to R data structure file\nrio::export(df_items, \"analysis/SGC4D/data/2-scored-data/sgc4d_scored_items.rds\") # to R data structure file"
  }
]