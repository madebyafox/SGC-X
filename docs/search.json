[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAIN",
    "section": "",
    "text": "4/29/22 | ported existing .Rmd analysis files to Quarto (.qmd) for sharing status w/ JMH CMW via web"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html",
    "title": "1  Harmonization",
    "section": "",
    "text": "The purpose of this notebook is to harmonize data files for study SGC_3A."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#participants",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#participants",
    "title": "1  Harmonization",
    "section": "3.1 Participants",
    "text": "3.1 Participants\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook.\n\n\nShow the code\n#IMPORT PARTICIPANT DATA\n\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_participants.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_participants.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_participants.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read.csv(fall21) %>% mutate(mode = \"online-asynch\", term = \"fall21\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m,absolute_score\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, absolute_score)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, absolute_score)\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = as.factor(schoolyear)\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,fall21,spring18,winter22)"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#items",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#items",
    "title": "1  Harmonization",
    "section": "3.2 Items",
    "text": "3.2 Items\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nShow the code\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_blocks.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_blocks.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_blocks.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read.csv(fall21) %>% mutate(mode = \"online-asynch\", term = \"fall21\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% select(q,relation) %>% unique()\n\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,fall21,spring18,winter22, map_relations)\n\n\n\n3.2.1 Validation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nShow the code\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nShow the code\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html",
    "title": "2  Response Rescoring",
    "section": "",
    "text": "The purpose of this notebook is to re-score the response accuracy data for the SGC_3A study. This is required because the question type on the graph comprehension task used a ‘Multiple Answer Multiple Choice’ design (MCMA). Warning: this notebook takes several minutes to execute."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#response-encoding",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#response-encoding",
    "title": "2  Response Rescoring",
    "section": "3.1 Response Encoding",
    "text": "3.1 Response Encoding\nFirst, we acknowledge that the question type evaluated by Schmidt et. al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 2), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) (\\(po_{responses} = n\\)). With only four options, we cannot entirely discriminate between all of the response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a far greater range of responses (\\(po_{responses} = 2^{n}\\)). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can be encoded as [TTFF].\n\n\n\n\n\n\nDecision\n\n\n\nIn our analysis, we will transform the MAMC response string recorded for the participant (given in column response), to an MTF encoding."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#scoring-schemes",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#scoring-schemes",
    "title": "2  Response Rescoring",
    "section": "3.2 Scoring Schemes",
    "text": "3.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\n\\(f =\\) resulting score\n\\(n =\\) number of response options\n\\(i =\\) number of correct responses by respondent \\((0 ≤ i ≤ n)\\)\n(correct-selected & correct-unselected)\n\\(p\\) = number of true options (i.e. number of options that should be selected)\n\\(q\\) = number of false options (i.e. number of options that should not be selected) , where (\\(n = p+q\\))\n\n3.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only true-correct options, and does select any additional (i.e. true_incorrect) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the true-correct options, and one or more but not all of the false-correct items, but receive the same score as a respondent selects none of the true-correct options, or all of the false-correct options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating.\nIn Dichotomous Scoring\n\nquestion score is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nShow the code\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n3.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et. al. identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach (Schmidt. et. al 2021 #17). This approach is particularly appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select; and (2) weights an unsure/blank/non-response as superior to an incorrect response.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\n\nSchmidt. et. al (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where n is much greater than p (there are many more answer options than there are options meant to be selected), the previous partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of incorrect options.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n\\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n\n\nShow the code\nf_partialN <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n))\n  \n  #if(n==0) return error\n  ifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n \n  #if(i >n ) return error\n  ifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n  \n  return ((2*i - n) / n) \n}\n\n\n\n\n3.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats all answer options (n) as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly selecting a different item. This is not the case, however, in our study, where the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Whereas failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt. et. al. method #26. Also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nIn Partial Scoring \\([-1/q, +1/p]\\):\n\n\\(p\\) = number of true options (i.e. number of options that should be selected)\n\\(q\\) = number of false options (i.e. number of options that should not be selected)\n\\(p_m\\) = true options selected (i.e. number of options that should be selected that were selected)\n\\(q_m\\) = true false options selected (i.e. number of options that should not be selected that were selected\n\\(n\\) = total number of options, such that \\(n = p + q\\)\n\n\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts 1/(n-p) = 1/q for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nShow the code\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of true-selected options\n  #p = number of true options\n  #f = number of false-selected options\n  #q = number of false options\n  # n = number of options + p + q\n  return( (t / p) - (f/q))\n}\n\n\n\n\n3.2.4 Discriminant Scoring\noption that is consistent with the incorrect-orthogonal interpretation in fact indicates less understanding than incorrectly selecting a nearby but not orthgonally consistent option.\nTODO: correct this section, the actual discriminant score algorithm does not rely on partial scoring [1/n] Although partial scoring gives us an indication of how close the respondent is to approximating the complete pattern of ‘correct’ responses, including partial knowledge, when the partial score is calculated with respect to a singular ‘correct’ set of answer options, it does does not distinguish between different types of partial knowledge. Subjects are rewarded (or penalized) by the same amount regardless of which the false-selections or true-non selections they make.\nIn the case of SGC_3A, however, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus.\nSpecifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations.\nTo capture this important source of variation, we can apply the idea behind the partial scoring strategy in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n\\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t\\) = number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r\\) = number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nShow the code\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}\n\n\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nShow the code\ntitle <- \"Comparison of Scoring Schemes for Simple Scenario\"\noptions <- \"A B C D\"\ncorrect <- \"A X X X\"\nresponse <- \"A X X X\"\n\n\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"ABC__\",        \n              \"_BCDE\",      \n              \"___DE\",\n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               3,               \n               0,          \n               2,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         f_dichom(0,5),\n         f_dichom(2,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              f_partialN(0,5),\n              f_partialN(2,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              f_partialP(0,1,4,4),\n              f_partialP(0,1,2,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial$_{-1/n, +1/n}$\",\n              \"Partial$_{-1/q, +1/p}$\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    footnote(general = paste(\"$i$ = number of options in correct state; _ indicates not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n#cleanup\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response yields a score other than zero; the score does now allow us to differentiate between different response patters.\nAlternatively the Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nIn the Partial \\([-1/q, +1/p]\\) scheme we also find a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options; both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider a question from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nShow the code\ntitle <- \"Comparison of Scoring Schemes for n = 15 options and p = 1 correct option\"\noptions <- \"A B C D\"\ncorrect <- \"A X X X\"\nresponse <- \"A X X X\"\n\n\n\ncorrect <- c( \"A__...__\", \n              \"A__...__\", \n              \"A__...__\", \n              \"A__...__\", \n              \"A__...__\", \n              \"A__...__\")\n\nresponse <- c(\"A__...__\", \n              \"A__..._O\", \n              \"A__...NO\", \n              \"ABC...MNO\",      \n              \"_BC...MNO\",      \n              \"___...__\" )\n\ni <- c(        5,        \n               4,              \n               3,               \n               1,          \n               0,             \n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         f_dichom(1,5),\n         f_dichom(0,5),\n         f_dichom(4,5))\n\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              f_partialN(1,5),\n              f_partialN(0,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              f_partialP(1,1,4,4),\n              f_partialP(0,1,4,4), \n              f_partialP(0,1,0,4))\n\n#TODO DISCRIMINANT\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial$_{-1/n, +1/n}$\",\n              \"Partial$_{-1/q, +1/p}$\",\n              \"Discriminant\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2 , discrim)\n\nkbl(dt, col.names = names, caption = title, digits=4) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 4)) %>% \n    footnote(general = paste(\"$i$ = number of options in correct state; _ indicates not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n#cleanup\n\n\none in Score a blank response (the bottom row) receives the same"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#comparison",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#comparison",
    "title": "2  Response Rescoring",
    "section": "3.3 Comparison",
    "text": "3.3 Comparison\n\n3.3.1 Scoring Algorithms and Properties\nWe can examine each scoring scheme with respect to certain statistical properties.\nThe Expected Chance Score of Multiple True-False (MTF) questions is calculated by the sum of the product of the binomial (\\(p = 0.5\\)) probabilities of each statement marked correctly with the corresponding score for that number of correctly marked statements. ( Schmidt et. al. 2021, Albanese & Sabers (1988)). Importantly, \\(i\\) is not the number of selected options, but rather the number of correctly indicated items, where [T = correctly selected || correctly not selected] and [F = incorrectly selected || incorrectly not selected]_. The \\(f_i\\) refers to the\n\\[\n\\begin{align}\nf_{chance} &= \\sum_{i = 0}^{n} \\binom{n}{i} * (0.5)^i * (1-0.5)^{n-i} * f_i \\\\  \n&= \\sum_{i = 0}^{n} \\binom{n}{i} * (0.5)^n * f_i \\\\\n\\tag{5}\n\\end{align}\n\\]\nwhere\n\n\\(n =\\) number of options in MTF question (data points that can be selected)\n\\(i =\\) number of options marked correctly\n\\(f_i =\\) score for \\(i\\) options marked correctly\n\nNote that we cannot calculate the the expected chance score for Partial Scoring \\([-1/q, +1/p]\\) because the score awarded to a question depends not only on the number of options marked correctly, but also the way in which they are marked (selected vs. unselected)\n\n\nShow the code\nf_chance <- function(n, scheme) {\n \n  if (n < 0) {\"ERROR: n must be greater than 0\"} \n  if (!scheme %in% c(\"d\",\"p\")) {\"ERROR: unknown scoring scheme\"}\n  else {\n    #sum from i=0 to i=n\n    s = 0; #starting value\n    for (x in 0:n) {\n      \n      #binomial coefficient n choose x\n      binom = choose(n,x)\n      \n      #binomial probability of n statements marked correctly\n      bprob = 0.5^n\n\n      #score for x correctly marked items\n      if (scheme == \"d\"){\n        f = f_dichom(x,n)\n      } else if (scheme == \"p\") {\n        f = f_partialN(x,n)\n      }\n      \n      chance_at_x = (binom * bprob*f)\n      s = s + chance_at_x\n    }\n  }\n  s\n}\n\n\n\n\n3.3.2 Comparison of Scoring Schemes\n\n\nShow the code\ntitle <- \"Properties of each scoring scheme for question with $n=4$ response options\"\nschemes <- c(\"Dichotomous\", \" Partial$_{[-1/n, +1/n]}$\")\nf_0 <- c(f_dichom(0,4), f_partialN(0,4))\nf_1 <- c(f_dichom(1,4), f_partialN(1,4))\nf_2 <- c(f_dichom(2,4), f_partialN(2,4))\nf_3 <- c(f_dichom(3,4), f_partialN(3,4))\nf_4 <- c(f_dichom(4,4), f_partialN(4,4))\necs <- c(f_chance(4,\"d\"),f_chance(4,\"p\"))\n\nnames = c(\"Scoring Scheme\",\n              \"$f_0$\",\n              \"$f_1$\",\n              \"$f_2$\",\n              \"$f_3$\",\n              \"$f_4$\",\n              \"Expected Score at Chance\")\n\ndt <- cbind(schemes,f_0,f_1,f_2,f_3,f_4,ecs)\n\nkbl(dt, col.names = names, caption = title)%>%\n  kable_classic() %>%\n  add_header_above(c(\" \" = 1, \"score for $i$ of 4 correctly marked options\" = 5, \" \"=1)) %>% \n  footnote(general = paste(\"$n=4$ response options yields $2^n = 2^4 =$\",2^4,\"possible responses\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n#cleanup\nrm(f_0, f_1, f_2, f_3, f_4, f_e, f_15, ecs, dt, names, schemes, title)           \n\n\n\n\nShow the code\ntitle <- \"Properties of each scoring scheme for question with $n=15$ response options (SGC3A Q1 - Q5)\"\nschemes <- c(\"Dichotomous\", \" Partial$_{[-1/n, +1/n]}$\")\nf_0 <- c(f_dichom(0,15), round(f_partialN(0,15),2))\nf_1 <- c(f_dichom(1,15), round(f_partialN(1,15),2))\nf_2 <- c(f_dichom(2,15), round(f_partialN(2,15),2))\nf_3 <- c(f_dichom(3,15), round(f_partialN(3,15),2))\nf_4 <- c(f_dichom(4,15), round(f_partialN(4,15),2))\nf_e <- c(\"...\",\"...\")\nf_15 <- c(f_dichom(15,15), round(f_partialN(15,15),2))\necs <- c(f_chance(15,\"d\"),f_chance(15,\"p\"))\n\nnames = c(\"Scoring Scheme\",\n              \"$f_0$\",\n              \"$f_1$\",\n              \"$f_2$\",\n              \"$f_3$\",\n              \"$f_4$\",\n              \"$...$\",\n              \"$f_{15}$\",\n              \"Expected Score at Chance\")\n\ndt <- cbind(schemes,f_0,f_1,f_2,f_3,f_4,f_e,f_15,ecs)\n\nkbl(dt, col.names = names, caption = title)%>%\n  kable_classic() %>%\n  add_header_above(c(\" \" = 1, \"score for $i$ of 15 correctly marked options\" = 7, \" \"=1)) %>% \n  footnote(general = paste(\"$n=15$ response options yields $2^n = 2^{15} =$\",2^(15),\"possible responses\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n#cleanup\nrm(f_0, f_1, f_2, f_3, f_4, f_e, f_15, ecs, names, schemes, title)           \n\n\n\n\nShow the code\ntitle <- \"Properties of each scoring scheme for question with $n=18$ response options (SGC3A Q6 - Q15)\"\nschemes <- c(\"Dichotomous\", \" Partial$_{[-1/n, +1/n]}$\")\nf_0 <- c(f_dichom(0,18), round(f_partialN(0,18),2))\nf_1 <- c(f_dichom(1,18), round(f_partialN(1,18),2))\nf_2 <- c(f_dichom(2,18), round(f_partialN(2,18),2))\nf_3 <- c(f_dichom(3,18), round(f_partialN(3,18),2))\nf_4 <- c(f_dichom(4,18), round(f_partialN(4,18),2))\nf_e <- c(\"...\",\"...\")\nf_18 <- c(f_dichom(18,18), round(f_partialN(18,18),2))\necs <- c(f_chance(18,\"d\"),f_chance(18,\"p\"))\n\nnames = c(\"Scoring Scheme\",\n              \"$f_0$\",\n              \"$f_1$\",\n              \"$f_2$\",\n              \"$f_3$\",\n              \"$f_4$\",\n              \"$...$\",\n              \"$f_{18}$\",\n              \"Expected Score at Chance\")\n\ndt <- cbind(schemes,f_0,f_1,f_2,f_3,f_4,f_e,f_18,ecs)\n\nkbl(dt, col.names = names, caption = title)%>%\n  kable_classic() %>%\n  add_header_above(c(\" \" = 1, \"score for $i$ of 18 correctly marked options\" = 7, \" \"=1)) %>% \n  footnote(general = paste(\"$n=18$ response options yields $2^n = 2^{18} =$\",2^(18),\"possible responses\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n#cleanup\nrm(f_0, f_1, f_2, f_3, f_4, f_e, f_18, ecs, names, schemes, title)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-responses-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-responses-as-mtf",
    "title": "2  Response Rescoring",
    "section": "4.1 Encode MAMC Responses as MTF",
    "text": "4.1 Encode MAMC Responses as MTF\nTo calculate partial scores, first we need re-encode participant responses which are currently captured in the answer column of the df_items dataframe. In the present encoding, the letter corresponding to each response item (corresponding to a data point in the stimulus graph) the subject selected on the task interface, is concatenated and stored in answer.\nFor example, if the respondent selected data points A and B, answer = AB. We need to transform this into a single column for each possible response option, encoding whether or not the option was selected A = 1, B = 1, C = 0 ...\n\n\nShow the code\n#SPLIT DF_ITEMS \n#into sub dfs to allow a 1-1 mapping with appropriate answer key\n\n#scaffold phase control condition\nitem_responses_scaffold_111 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"111\")\n\n#scaffold phase impasse condition\nitem_responses_scaffold_121 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"121\")\n\n#test phase descriminant\nitem_responses_test <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q > 5 ) \n  #note we don't need to filter condition bc qs and data are same across conditions\n\n#SPREAD MCMA RESPONSE TO MTF COLUMNS\n#encode the response column [response] as a series of T/F statements per data point\n\n#scaffold phase CONTROL condition\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n) \n\n#scaffold phase IMPASSE condition\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n) \n\n#test phase \nitem_responses_test <- item_responses_test %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_L = as.integer(str_detect(response,\"L\")), #is there a L?\n    r_M = as.integer(str_detect(response,\"M\")), #is there a M?\n    r_N = as.integer(str_detect(response,\"N\")), #is there a N?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_P = as.integer(str_detect(response,\"P\")), #is there a P?\n    r_Z = as.integer(str_detect(response,\"Z\")), #is there a Z?\n    r_X = as.integer(str_detect(response,\"X\"))  #is there a X?\n) \n\n\n#VALIDATE SPLIT\n#n rows in df_items should match sum of nrows in the sub dfs \nnrow(df_items) == sum(nrow(item_responses_scaffold_111), nrow(item_responses_scaffold_121),\n                  nrow(item_responses_test))\n\n\nNow we have three dataframes (one for each group of questions: scaffold phase, test phase, nondiscriminant) with subjects’ response encoded as a series of T/F [1,0] states across all response options (represented as colums prefaced with r_)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-answer-keys-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-answer-keys-as-mtf",
    "title": "2  Response Rescoring",
    "section": "4.2 Encode MAMC Answer Keys as MTF",
    "text": "4.2 Encode MAMC Answer Keys as MTF\nNext, we read the answer keys for the question sets. Note that there is an answer key unique to each experimental condition, because the experimental manipulation (impasse vs. control) is established by changing the pattern of the underlying dataset, which in turn yields different ‘correct’ answers. The divergence in answers across conditions only holds for the first five questions (the scaffold manipulation), while the following 10 questions are displayed with the same dataset (and thus have the same answers, regardless of condition).\n\n\nShow the code\nkey_111 <- read_csv('static/keys/SGC3A_111_key.csv')\nkey_121 <- read_csv('static/keys/SGC3A_121_key.csv')\n\n\nNext, we split the answer key encoding into MTF encoding, just as we did for the response data. Each column indicates whether that response option should be selected in order to count as a correct response. Columns prefixed with tri_ represent triangularly-correct response key, and those prefixed with orth_ represent orthongally-correct response key.\n\n\nShow the code\n#SCAFFOLD KEY CONDITION 111\nkey_scaffolded_c111 <- key_111 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q<6) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR,\"A\")), #is there a A in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR,\"X\")), #is there a X in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR,\"C\")), #is there a C in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR,\"O\")), #is there a O in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR,\"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR,\"J\")), #is there a J in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR,\"H\")), #is there a H in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR,\"F\")), #is there a F in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR,\"K\")), #is there a K in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR,\"D\")), #is there a D in TRIANGULAR?\n    tri_U = as.integer(str_detect(TRIANGULAR,\"U\")), #is there a U in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR,\"E\")), #is there a E in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR,\"G\")), #is there a G in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR,\"B\")), #is there a B in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR,\"Z\"))  #is there a Z in TRIANGULAR?\n   ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL,\"A\")), #is there a A in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL,\"X\")), #is there a X in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL,\"C\")), #is there a C in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL,\"O\")), #is there a O in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL,\"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL,\"J\")), #is there a J in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL,\"H\")), #is there a H in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL,\"F\")), #is there a F in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL,\"K\")), #is there a K in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL,\"D\")), #is there a D in ORTHOGONAL?\n    orth_U = as.integer(str_detect(ORTHOGONAL,\"U\")), #is there a U in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL,\"E\")), #is there a E in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL,\"G\")), #is there a G in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL,\"B\")), #is there a B in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL,\"Z\"))  #is there a Z in ORTHOGONAL?\n   ) \n\n#SCAFFOLD KEY CONDITION 121\nkey_scaffolded_c121 <- key_121 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q<6) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR,\"A\")), #is there a A in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR,\"X\")), #is there a X in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR,\"C\")), #is there a C in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR,\"O\")), #is there a O in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR,\"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR,\"J\")), #is there a J in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR,\"H\")), #is there a H in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR,\"F\")), #is there a F in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR,\"K\")), #is there a K in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR,\"D\")), #is there a D in TRIANGULAR?\n    tri_U = as.integer(str_detect(TRIANGULAR,\"U\")), #is there a U in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR,\"E\")), #is there a E in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR,\"G\")), #is there a G in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR,\"B\")), #is there a B in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR,\"Z\"))  #is there a Z in TRIANGULAR?\n   ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL,\"A\")), #is there a A in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL,\"X\")), #is there a X in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL,\"C\")), #is there a C in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL,\"O\")), #is there a O in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL,\"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL,\"J\")), #is there a J in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL,\"H\")), #is there a H in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL,\"F\")), #is there a F in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL,\"K\")), #is there a K in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL,\"D\")), #is there a D in ORTHOGONAL?\n    orth_U = as.integer(str_detect(ORTHOGONAL,\"U\")), #is there a U in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL,\"E\")), #is there a E in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL,\"G\")), #is there a G in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL,\"B\")), #is there a B in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL,\"Z\"))  #is there a Z in ORTHOGONAL?\n   ) \n\n#TEST KEY\n#key_111 == key_121 across both conditions for q>5\nkey_test <- key_111 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q>5) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR, \"A\")), #is there a A in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR, \"B\")), #is there a B in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR, \"C\")), #is there a C in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR, \"D\")), #is there a D in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR, \"E\")), #is there a E in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR, \"F\")), #is there a F in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR, \"G\")), #is there a G in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR, \"H\")), #is there a H in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR, \"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR, \"J\")), #is there a J in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR, \"K\")), #is there a K in TRIANGULAR?\n    tri_L = as.integer(str_detect(TRIANGULAR, \"L\")), #is there a L in TRIANGULAR?\n    tri_M = as.integer(str_detect(TRIANGULAR, \"M\")), #is there a M in TRIANGULAR?\n    tri_N = as.integer(str_detect(TRIANGULAR, \"N\")), #is there a N in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR, \"O\")), #is there a O in TRIANGULAR?\n    tri_P = as.integer(str_detect(TRIANGULAR, \"P\")), #is there a P in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR, \"Z\")), #is there a Z in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR, \"X\"))  #is there a X in TRIANGULAR?\n  ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL, \"A\")), #is there a A in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL, \"B\")), #is there a B in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL, \"C\")), #is there a C in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL, \"D\")), #is there a D in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL, \"E\")), #is there a E in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL, \"F\")), #is there a F in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL, \"G\")), #is there a G in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL, \"H\")), #is there a H in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL, \"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL, \"J\")), #is there a J in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL, \"K\")), #is there a K in ORTHOGONAL?\n    orth_L = as.integer(str_detect(ORTHOGONAL, \"L\")), #is there a L in ORTHOGONAL?\n    orth_M = as.integer(str_detect(ORTHOGONAL, \"M\")), #is there a M in ORTHOGONAL?\n    orth_N = as.integer(str_detect(ORTHOGONAL, \"N\")), #is there a N in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL, \"O\")), #is there a O in ORTHOGONAL?\n    orth_P = as.integer(str_detect(ORTHOGONAL, \"P\")), #is there a P in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL, \"Z\")), #is there a Z in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL, \"X\"))  #is there a X in ORTHOGONAL?\n  )\n\n\nFor sanity check, we veryify that the answer key for test phase questions (q > 5) is the same across the two condition specific answer keys. As long as this is TRUE, its OK to use key_111.\n\n\nShow the code\n#verify that key_111 == key 121 for q>5\nkey_111 %>% filter(Q >5) %>% select(TRIANGULAR, ORTHOGONAL)== key_121 %>% filter(Q >5)%>% select(TRIANGULAR, ORTHOGONAL)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-i-number-correctly-selected-options",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-i-number-correctly-selected-options",
    "title": "2  Response Rescoring",
    "section": "4.3 Calculate i number correctly selected options",
    "text": "4.3 Calculate i number correctly selected options\nNext, we calculate the \\(i\\), number of correctly indicated options, based on the answer key for each question.\n\n\nShow the code\n#------------------------------------------------------------------\n#calculate i: number of correctly indicated options\n#responses <- vector of T/F responses\n#key <- vector of T/F answers\n#RETURNS SUM correctly indicated items\n#NOTE: THIS IS SUPER BRITTLE \n#relies on fact that columns were ordered the same across the dataframes!\n#should refactor in less imperative mode (more R like!)\n#------------------------------------------------------------------\ncalc_i <- function(responses,key){\n  # print(responses)\n  # print(key)\n  assessment <- responses == key\n  return(sum(assessment))\n}\n\n#------------------------------------------------------------------\n#write_i: write i to response dataframe\n#items <- dataframe of items \n#key <- MTF answerkey for this dataframe\n#RETURNS MUTATING items dataframe\n#------------------------------------------------------------------\nwrite_i <- function(items,keys){\n  #for each row(item) in the items input dataframe\n  for (x in 1:nrow(items)) {\n    #get the question number\n    q = items[x,\"q\"]\n    #get the subjects response vector\n    responses <- as_tibble(items[x,] %>% select(starts_with(\"r_\")))\n    #get key vectors for this question\n    tri_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"tri_\")))\n    orth_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"orth_\")))\n    #write TRI and ORTH response keys to row \n    items[x,\"TRI\"] <- keys %>% filter(Q==q) %>% select(TRIANGULAR)\n    items[x,\"ORTH\"] <- keys %>% filter(Q==q) %>% select(ORTHOGONAL)\n    #calculate number of triangular-correct-options\n    items[x,\"tri_i\"] <- calc_i(responses,tri_key)\n    #calculate number of orthogonal-correct-options\n    items[x,\"orth_i\"] <- calc_i(responses,orth_key)\n  }  \n  return(items) #return mutated items dataframe\n}\n\n#------------------------------------------------------------------\n#count_match: count the number of matching characters in the two strings\n#response <- response string\n#key <- key string\n#returns count of matches\n#------------------------------------------------------------------\ncount_match <- function(response, key){\n  count = 0\n  response = unlist(str_split(response,\"\"))\n  key = unlist(str_split(key,\"\"))\n  count = sum(table(response[response %in% key]))\n  return(count)\n}\n\n\n\n\nShow the code\n#WARNING :: TAKES SEVERAL MINUTES TO RUN\n\n#WRITE I_s\n#~5 mins on MBP\n#~30 seconds on IMAC\nitem_responses_scaffold_111 <- write_i(item_responses_scaffold_111,key_scaffolded_c111)\nitem_responses_scaffold_121 <- write_i(item_responses_scaffold_121,key_scaffolded_c121)\nitem_responses_test <- write_i(item_responses_test,key_test)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-scores",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-scores",
    "title": "2  Response Rescoring",
    "section": "4.4 Calculate Scores",
    "text": "4.4 Calculate Scores\nFinally, we calculate the interpretation scores, absolute score, and discriminant score.\n\n\nShow the code\n#set n = number of answer options\nn_scaffold <- 15\nn_test <- 18\n\n#calculate scores for scaffold phase CONTROL condition \nitem_responses_scaffold_111 <- item_responses_scaffold_111  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i,n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for scaffold phase IMPASSE condition \nitem_responses_scaffold_121 <- item_responses_scaffold_121  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i, n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for TEST phase (Q6 -> Q15)\nitem_responses_test <- item_responses_test  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_test),\n  s_TRI = f_partialN(tri_i, n_test),\n  s_ORTH = f_partialN(orth_i, n_test),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n\nAs a sanity check, we validate the equivalence of the scores\n\n\nShow the code\n#validate that ABS score is always  == f_dichom(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ABS == f_dichom(item_responses_scaffold_111$tri_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_ABS == f_dichom(item_responses_scaffold_121$tri_i,n_scaffold))\nunique(validate <- item_responses_test$s_ABS == f_dichom(item_responses_test$tri_i,n_test))\n\n#validate that ABS score is == 'correct' (calculated in stimulus)\nunique(validate <- as.logical(item_responses_scaffold_111$s_ABS) == (item_responses_scaffold_111$correct))\nunique(validate <- as.logical(item_responses_scaffold_121$s_ABS) == (item_responses_scaffold_121$correct))\nunique(validate <- as.logical(item_responses_test$s_ABS) == (item_responses_test$correct))\n\n\n#validate that TRI score is always  == f_partialN(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_TRI == f_partialN(item_responses_scaffold_111$tri_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_TRI == f_partialN(item_responses_scaffold_121$tri_i,n_scaffold))\nunique(validate <- item_responses_test$s_TRI == f_partialN(item_responses_test$tri_i,n_test))\n\n#validate that ORTH score is always  == f_partialN(orth_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ORTH == f_partialN(item_responses_scaffold_111$orth_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_ORTH == f_partialN(item_responses_scaffold_121$orth_i,n_scaffold))\nunique(validate <- item_responses_test$s_ORTH == f_partialN(item_responses_test$orth_i,n_test))"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#reintegrate-item-dataframe",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#reintegrate-item-dataframe",
    "title": "2  Response Rescoring",
    "section": "4.5 Reintegrate item dataframe",
    "text": "4.5 Reintegrate item dataframe\nThe final step in the process is to re_combine_ the item dataframes.\n\n\nShow the code\n#reduce dataframes before combination\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH, s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_test <- item_responses_test %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"TEST\")\n\n#combine data frames\ntemp <- rbind(item_responses_scaffold_111,item_responses_scaffold_121,item_responses_test)\n\n#dblck all items are accounted for \nif ( nrow(df_items)==nrow(temp) ) {\n  df_items <- temp \n} else {\n    print(\"ERROR! sub dfs don't contain all the df_items\")\n  }\n\n\n#CLEANUP MTF ENCODED ITEMS\nrm(item_responses_scaffold_111, item_responses_scaffold_121, item_responses_test)\nrm(key_111, key_121, key_scaffolded_c111, key_scaffolded_c121, key_test)\nrm(temp)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#references",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#references",
    "title": "2  Response Rescoring",
    "section": "9.1 References",
    "text": "9.1 References\nSchmidt, D., Raupach, T., Wiegand, A., Herrmann, M., & Kanzow, P. (2021). Relation between examinees’ true knowledge and examination scores: Systematic review and exemplary calculations on Multiple-True-False items. Educational Research Review, 34, 100409. https://doi.org/10.1016/j.edurev.2021.100409\nAlbanese, M. A., & Sabers, D. L. (1988). Multiple True-False Items: A Study of Inter-item Correlations, Scoring Alternatives, and Reliability Estimation. Journal of Educational Measurement, 25(2), 111–123. https://doi.org/10.1111/j.1745-3984.1988.tb00296.x"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#resources-1",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#resources-1",
    "title": "2  Response Rescoring",
    "section": "9.2 Resources",
    "text": "9.2 Resources\non kable tables\nhttps://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#session",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#session",
    "title": "2  Response Rescoring",
    "section": "9.3 Session",
    "text": "9.3 Session\n\n\nShow the code\nsessionInfo()"
  }
]