[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAIN",
    "section": "",
    "text": "5/4/22 | replaced scoring strategy partial[-1/n, +1/n] to partial [-1/q, + 1/p]\n4/29/22 | ported existing .Rmd analysis files to Quarto (.qmd) for sharing status w/ JMH CMW via web"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html",
    "title": "1  Harmonization",
    "section": "",
    "text": "The purpose of this notebook is to harmonize data files for study SGC_3A."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#participants",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#participants",
    "title": "1  Harmonization",
    "section": "3.1 Participants",
    "text": "3.1 Participants\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_participants.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_participants.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_participants.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read.csv(fall21) %>% mutate(mode = \"online-asynch\", term = \"fall21\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m,absolute_score\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, absolute_score)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, absolute_score)\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = as.factor(schoolyear)\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,fall21,spring18,winter22)"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#items",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#items",
    "title": "1  Harmonization",
    "section": "3.2 Items",
    "text": "3.2 Items\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_blocks.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_blocks.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_blocks.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read.csv(fall21) %>% mutate(mode = \"online-asynch\", term = \"fall21\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% select(q,relation) %>% unique()\n\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,fall21,spring18,winter22, map_relations)\n\n\n\n3.2.1 Validation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html",
    "title": "2  Response Rescoring",
    "section": "",
    "text": "The purpose of this notebook is to re-score the response accuracy data for the SGC_3A study. This is required because the question type on the graph comprehension task used a ‘Multiple Answer Multiple Choice’ design (MCMA). Warning: this notebook takes several minutes to execute."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#response-encoding",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#response-encoding",
    "title": "2  Response Rescoring",
    "section": "3.1 Response Encoding",
    "text": "3.1 Response Encoding\nFirst, we note that the question type evaluated by Schmidt et. al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 2), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can be encoded as [TTFF].\n\n\n\n\n\n\nDecision\n\n\n\nIn our analysis, we will transform the MAMC response string recorded for the participant (given in column response), to an MTF encoding."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#scoring-schemes",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#scoring-schemes",
    "title": "2  Response Rescoring",
    "section": "3.2 Scoring Schemes",
    "text": "3.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\n\\]\nProperties of the Subject’s Response\n\\[\n  \\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\n\\]\n\n3.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only true-correct options, and does select any additional (i.e. true_incorrect) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the true-correct options, and one or more but not all of the false-correct items, but receive the same score as a respondent selects none of the true-correct options, or all of the false-correct options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating.\nIn Dichotomous Scoring\n\nquestion score is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nShow the code\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n3.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et. al. identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach (Schmidt. et. al 2021 #17). This approach is particularly appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select; and (2) weights an unsure/blank/non-response as superior to an incorrect response.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\n\nSchmidt. et. al (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where n is much greater than p (there are many more answer options than there are options meant to be selected), the previous partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of incorrect options.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n  \\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n::: {.cell}\n\nShow the code\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n:::\n\n\n3.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats all answer options (n) as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly selecting a different item. This is not the case, however, in our study, where the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Whereas failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt. et. al. method #26. Also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts 1/(n-p) = 1/q for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n\\]\nProperties of Response\n\\[\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nShow the code\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  return( (t / p) - (f/q))\n}\n\n\n\n\n3.2.4 Comparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nShow the code\ntitle <- \"Comparison of Scoring Schemes for $n = 5$ options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial$_{-1/n, +1/n}$\",\n              \"Partial$_{-1/q, +1/p}$\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"$i$ = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nShow the code\ntitle <- \"Comparison of Scoring Schemes for SGC3 with $n=15$ and $p=1$ options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial$_{-1/n, +1/n}$\",\n              \"Partial$_{-1/q, +1/p}$\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"$i$ = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#comparison",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#comparison",
    "title": "2  Response Rescoring",
    "section": "3.4 Comparison",
    "text": "3.4 Comparison"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-responses-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-responses-as-mtf",
    "title": "2  Response Rescoring",
    "section": "4.1 Encode MAMC Responses as MTF",
    "text": "4.1 Encode MAMC Responses as MTF\nTo calculate partial scores, first we need re-encode participant responses which are currently captured in the answer column of the df_items dataframe. In the present encoding, the letter corresponding to each response item (corresponding to a data point in the stimulus graph) the subject selected on the task interface, is concatenated and stored in answer.\nFor example, if the respondent selected data points A and B, answer = AB. We need to transform this into a single column for each possible response option, encoding whether or not the option was selected A = 1, B = 1, C = 0 ...\n\n\nShow the code\n#SPLIT DF_ITEMS \n#into sub dfs to allow a 1-1 mapping with appropriate answer key\n\n#scaffold phase control condition\nitem_responses_scaffold_111 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"111\")\n\n#scaffold phase impasse condition\nitem_responses_scaffold_121 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"121\")\n\n#test phase descriminant\nitem_responses_test <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q > 5 ) \n  #note we don't need to filter condition bc qs and data are same across conditions\n\n#SPREAD MCMA RESPONSE TO MTF COLUMNS\n#encode the response column [response] as a series of T/F statements per data point\n\n#scaffold phase CONTROL condition\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n  ) \n\n#scaffold phase IMPASSE condition\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n  ) \n\n#test phase \nitem_responses_test <- item_responses_test %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_L = as.integer(str_detect(response,\"L\")), #is there a L?\n    r_M = as.integer(str_detect(response,\"M\")), #is there a M?\n    r_N = as.integer(str_detect(response,\"N\")), #is there a N?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_P = as.integer(str_detect(response,\"P\")), #is there a P?\n    r_Z = as.integer(str_detect(response,\"Z\")), #is there a Z?\n    r_X = as.integer(str_detect(response,\"X\"))  #is there a X?\n  ) \n\n\n#VALIDATE SPLIT\n#n rows in df_items should match sum of nrows in the sub dfs \nnrow(df_items) == sum(nrow(item_responses_scaffold_111), nrow(item_responses_scaffold_121),\n                      nrow(item_responses_test))\n\n\nNow we have three dataframes (one for each group of questions: scaffold phase, test phase, nondiscriminant) with subjects’ response encoded as a series of T/F [1,0] states across all response options (represented as colums prefaced with r_)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-answer-keys-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#encode-mamc-answer-keys-as-mtf",
    "title": "2  Response Rescoring",
    "section": "4.2 Encode MAMC Answer Keys as MTF",
    "text": "4.2 Encode MAMC Answer Keys as MTF\nNext, we read the answer keys for the question sets. Note that there is an answer key unique to each experimental condition, because the experimental manipulation (impasse vs. control) is established by changing the pattern of the underlying dataset, which in turn yields different ‘correct’ answers. The divergence in answers across conditions only holds for the first five questions (the scaffold manipulation), while the following 10 questions are displayed with the same dataset (and thus have the same answers, regardless of condition).\n\n\nShow the code\nkey_111 <- read_csv('static/keys/SGC3A_111_key.csv')\nkey_121 <- read_csv('static/keys/SGC3A_121_key.csv')\n\n\nNext, we split the answer key encoding into MTF encoding, just as we did for the response data. Each column indicates whether that response option should be selected in order to count as a correct response. Columns prefixed with tri_ represent triangularly-correct response key, and those prefixed with orth_ represent orthongally-correct response key.\n\n\nShow the code\n#SCAFFOLD KEY CONDITION 111\nkey_scaffolded_c111 <- key_111 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q<6) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR,\"A\")), #is there a A in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR,\"X\")), #is there a X in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR,\"C\")), #is there a C in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR,\"O\")), #is there a O in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR,\"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR,\"J\")), #is there a J in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR,\"H\")), #is there a H in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR,\"F\")), #is there a F in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR,\"K\")), #is there a K in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR,\"D\")), #is there a D in TRIANGULAR?\n    tri_U = as.integer(str_detect(TRIANGULAR,\"U\")), #is there a U in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR,\"E\")), #is there a E in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR,\"G\")), #is there a G in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR,\"B\")), #is there a B in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR,\"Z\"))  #is there a Z in TRIANGULAR?\n   ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL,\"A\")), #is there a A in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL,\"X\")), #is there a X in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL,\"C\")), #is there a C in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL,\"O\")), #is there a O in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL,\"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL,\"J\")), #is there a J in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL,\"H\")), #is there a H in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL,\"F\")), #is there a F in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL,\"K\")), #is there a K in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL,\"D\")), #is there a D in ORTHOGONAL?\n    orth_U = as.integer(str_detect(ORTHOGONAL,\"U\")), #is there a U in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL,\"E\")), #is there a E in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL,\"G\")), #is there a G in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL,\"B\")), #is there a B in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL,\"Z\"))  #is there a Z in ORTHOGONAL?\n   ) \n\n#SCAFFOLD KEY CONDITION 121\nkey_scaffolded_c121 <- key_121 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q<6) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR,\"A\")), #is there a A in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR,\"X\")), #is there a X in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR,\"C\")), #is there a C in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR,\"O\")), #is there a O in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR,\"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR,\"J\")), #is there a J in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR,\"H\")), #is there a H in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR,\"F\")), #is there a F in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR,\"K\")), #is there a K in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR,\"D\")), #is there a D in TRIANGULAR?\n    tri_U = as.integer(str_detect(TRIANGULAR,\"U\")), #is there a U in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR,\"E\")), #is there a E in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR,\"G\")), #is there a G in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR,\"B\")), #is there a B in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR,\"Z\"))  #is there a Z in TRIANGULAR?\n   ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL,\"A\")), #is there a A in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL,\"X\")), #is there a X in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL,\"C\")), #is there a C in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL,\"O\")), #is there a O in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL,\"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL,\"J\")), #is there a J in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL,\"H\")), #is there a H in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL,\"F\")), #is there a F in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL,\"K\")), #is there a K in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL,\"D\")), #is there a D in ORTHOGONAL?\n    orth_U = as.integer(str_detect(ORTHOGONAL,\"U\")), #is there a U in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL,\"E\")), #is there a E in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL,\"G\")), #is there a G in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL,\"B\")), #is there a B in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL,\"Z\"))  #is there a Z in ORTHOGONAL?\n   ) \n\n#TEST KEY\n#key_111 == key_121 across both conditions for q>5\nkey_test <- key_111 %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(Q>5) %>% \n  #create \"triangle correct\" columns\n  mutate(\n    tri_A = as.integer(str_detect(TRIANGULAR, \"A\")), #is there a A in TRIANGULAR?\n    tri_B = as.integer(str_detect(TRIANGULAR, \"B\")), #is there a B in TRIANGULAR?\n    tri_C = as.integer(str_detect(TRIANGULAR, \"C\")), #is there a C in TRIANGULAR?\n    tri_D = as.integer(str_detect(TRIANGULAR, \"D\")), #is there a D in TRIANGULAR?\n    tri_E = as.integer(str_detect(TRIANGULAR, \"E\")), #is there a E in TRIANGULAR?\n    tri_F = as.integer(str_detect(TRIANGULAR, \"F\")), #is there a F in TRIANGULAR?\n    tri_G = as.integer(str_detect(TRIANGULAR, \"G\")), #is there a G in TRIANGULAR?\n    tri_H = as.integer(str_detect(TRIANGULAR, \"H\")), #is there a H in TRIANGULAR?\n    tri_I = as.integer(str_detect(TRIANGULAR, \"I\")), #is there a I in TRIANGULAR?\n    tri_J = as.integer(str_detect(TRIANGULAR, \"J\")), #is there a J in TRIANGULAR?\n    tri_K = as.integer(str_detect(TRIANGULAR, \"K\")), #is there a K in TRIANGULAR?\n    tri_L = as.integer(str_detect(TRIANGULAR, \"L\")), #is there a L in TRIANGULAR?\n    tri_M = as.integer(str_detect(TRIANGULAR, \"M\")), #is there a M in TRIANGULAR?\n    tri_N = as.integer(str_detect(TRIANGULAR, \"N\")), #is there a N in TRIANGULAR?\n    tri_O = as.integer(str_detect(TRIANGULAR, \"O\")), #is there a O in TRIANGULAR?\n    tri_P = as.integer(str_detect(TRIANGULAR, \"P\")), #is there a P in TRIANGULAR?\n    tri_Z = as.integer(str_detect(TRIANGULAR, \"Z\")), #is there a Z in TRIANGULAR?\n    tri_X = as.integer(str_detect(TRIANGULAR, \"X\"))  #is there a X in TRIANGULAR?\n  ) %>% \n  #create \"orthogonal correct\" columns\n  mutate(\n    orth_A = as.integer(str_detect(ORTHOGONAL, \"A\")), #is there a A in ORTHOGONAL?\n    orth_B = as.integer(str_detect(ORTHOGONAL, \"B\")), #is there a B in ORTHOGONAL?\n    orth_C = as.integer(str_detect(ORTHOGONAL, \"C\")), #is there a C in ORTHOGONAL?\n    orth_D = as.integer(str_detect(ORTHOGONAL, \"D\")), #is there a D in ORTHOGONAL?\n    orth_E = as.integer(str_detect(ORTHOGONAL, \"E\")), #is there a E in ORTHOGONAL?\n    orth_F = as.integer(str_detect(ORTHOGONAL, \"F\")), #is there a F in ORTHOGONAL?\n    orth_G = as.integer(str_detect(ORTHOGONAL, \"G\")), #is there a G in ORTHOGONAL?\n    orth_H = as.integer(str_detect(ORTHOGONAL, \"H\")), #is there a H in ORTHOGONAL?\n    orth_I = as.integer(str_detect(ORTHOGONAL, \"I\")), #is there a I in ORTHOGONAL?\n    orth_J = as.integer(str_detect(ORTHOGONAL, \"J\")), #is there a J in ORTHOGONAL?\n    orth_K = as.integer(str_detect(ORTHOGONAL, \"K\")), #is there a K in ORTHOGONAL?\n    orth_L = as.integer(str_detect(ORTHOGONAL, \"L\")), #is there a L in ORTHOGONAL?\n    orth_M = as.integer(str_detect(ORTHOGONAL, \"M\")), #is there a M in ORTHOGONAL?\n    orth_N = as.integer(str_detect(ORTHOGONAL, \"N\")), #is there a N in ORTHOGONAL?\n    orth_O = as.integer(str_detect(ORTHOGONAL, \"O\")), #is there a O in ORTHOGONAL?\n    orth_P = as.integer(str_detect(ORTHOGONAL, \"P\")), #is there a P in ORTHOGONAL?\n    orth_Z = as.integer(str_detect(ORTHOGONAL, \"Z\")), #is there a Z in ORTHOGONAL?\n    orth_X = as.integer(str_detect(ORTHOGONAL, \"X\"))  #is there a X in ORTHOGONAL?\n  )\n\n\nFor sanity check, we veryify that the answer key for test phase questions (q > 5) is the same across the two condition specific answer keys. As long as this is TRUE, its OK to use key_111.\n\n\nShow the code\n#verify that key_111 == key 121 for q>5\nkey_111 %>% filter(Q >5) %>% select(TRIANGULAR, ORTHOGONAL)== key_121 %>% filter(Q >5)%>% select(TRIANGULAR, ORTHOGONAL)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-i-number-correctly-selected-options",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-i-number-correctly-selected-options",
    "title": "2  Response Rescoring",
    "section": "4.3 Calculate i number correctly selected options",
    "text": "4.3 Calculate i number correctly selected options\nNext, we calculate the \\(i\\), number of correctly indicated options, based on the answer key for each question.\n\n\nShow the code\n#------------------------------------------------------------------\n#calculate i: number of correctly indicated options\n#responses <- vector of T/F responses\n#key <- vector of T/F answers\n#RETURNS SUM correctly indicated items\n#NOTE: THIS IS SUPER BRITTLE \n#relies on fact that columns were ordered the same across the dataframes!\n#should refactor in less imperative mode (more R like!)\n#------------------------------------------------------------------\ncalc_i <- function(responses,key){\n  # print(responses)\n  # print(key)\n  assessment <- responses == key\n  return(sum(assessment))\n}\n\n#------------------------------------------------------------------\n#write_i: write i to response dataframe\n#items <- dataframe of items \n#key <- MTF answerkey for this dataframe\n#RETURNS MUTATING items dataframe\n#------------------------------------------------------------------\nwrite_i <- function(items,keys){\n  #for each row(item) in the items input dataframe\n  for (x in 1:nrow(items)) {\n    #get the question number\n    q = items[x,\"q\"]\n    #get the subjects response vector\n    responses <- as_tibble(items[x,] %>% select(starts_with(\"r_\")))\n    #get key vectors for this question\n    tri_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"tri_\")))\n    orth_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"orth_\")))\n    #write TRI and ORTH response keys to row \n    items[x,\"TRI\"] <- keys %>% filter(Q==q) %>% select(TRIANGULAR)\n    items[x,\"ORTH\"] <- keys %>% filter(Q==q) %>% select(ORTHOGONAL)\n    #calculate number of triangular-correct-options\n    items[x,\"tri_i\"] <- calc_i(responses,tri_key)\n    #calculate number of orthogonal-correct-options\n    items[x,\"orth_i\"] <- calc_i(responses,orth_key)\n  }  \n  return(items) #return mutated items dataframe\n}\n\n#------------------------------------------------------------------\n#count_match: count the number of matching characters in the two strings\n#response <- response string\n#key <- key string\n#returns count of matches\n#------------------------------------------------------------------\ncount_match <- function(response, key){\n  count = 0\n  response = unlist(str_split(response,\"\"))\n  key = unlist(str_split(key,\"\"))\n  count = sum(table(response[response %in% key]))\n  return(count)\n}\n\n\n\n\nShow the code\n#WARNING :: TAKES SEVERAL MINUTES TO RUN\n\n#WRITE I_s\n#~5 mins on MBP\n#~30 seconds on IMAC\nitem_responses_scaffold_111 <- write_i(item_responses_scaffold_111,key_scaffolded_c111)\nitem_responses_scaffold_121 <- write_i(item_responses_scaffold_121,key_scaffolded_c121)\nitem_responses_test <- write_i(item_responses_test,key_test)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-scores",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#calculate-scores",
    "title": "2  Response Rescoring",
    "section": "4.4 Calculate Scores",
    "text": "4.4 Calculate Scores\nFinally, we calculate the interpretation scores, absolute score, and discriminant score.\n\n\nShow the code\n#set n = number of answer options\nn_scaffold <- 15\nn_test <- 18\n\n#calculate scores for scaffold phase CONTROL condition \nitem_responses_scaffold_111 <- item_responses_scaffold_111  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i,n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for scaffold phase IMPASSE condition \nitem_responses_scaffold_121 <- item_responses_scaffold_121  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i, n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for TEST phase (Q6 -> Q15)\nitem_responses_test <- item_responses_test  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_test),\n  s_TRI = f_partialN(tri_i, n_test),\n  s_ORTH = f_partialN(orth_i, n_test),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n\nAs a sanity check, we validate the equivalence of the scores\n\n\nShow the code\n#validate that ABS score is always  == f_dichom(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ABS == f_dichom(item_responses_scaffold_111$tri_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_ABS == f_dichom(item_responses_scaffold_121$tri_i,n_scaffold))\nunique(validate <- item_responses_test$s_ABS == f_dichom(item_responses_test$tri_i,n_test))\n\n#validate that ABS score is == 'correct' (calculated in stimulus)\nunique(validate <- as.logical(item_responses_scaffold_111$s_ABS) == (item_responses_scaffold_111$correct))\nunique(validate <- as.logical(item_responses_scaffold_121$s_ABS) == (item_responses_scaffold_121$correct))\nunique(validate <- as.logical(item_responses_test$s_ABS) == (item_responses_test$correct))\n\n\n#validate that TRI score is always  == f_partialN(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_TRI == f_partialN(item_responses_scaffold_111$tri_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_TRI == f_partialN(item_responses_scaffold_121$tri_i,n_scaffold))\nunique(validate <- item_responses_test$s_TRI == f_partialN(item_responses_test$tri_i,n_test))\n\n#validate that ORTH score is always  == f_partialN(orth_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ORTH == f_partialN(item_responses_scaffold_111$orth_i,n_scaffold))\nunique(validate <- item_responses_scaffold_121$s_ORTH == f_partialN(item_responses_scaffold_121$orth_i,n_scaffold))\nunique(validate <- item_responses_test$s_ORTH == f_partialN(item_responses_test$orth_i,n_test))"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#reintegrate-item-dataframe",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#reintegrate-item-dataframe",
    "title": "2  Response Rescoring",
    "section": "4.5 Reintegrate item dataframe",
    "text": "4.5 Reintegrate item dataframe\nThe final step in the process is to re_combine_ the item dataframes.\n\n\nShow the code\n#reduce dataframes before combination\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH, s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_test <- item_responses_test %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"TEST\")\n\n#combine data frames\ntemp <- rbind(item_responses_scaffold_111,item_responses_scaffold_121,item_responses_test)\n\n#dblck all items are accounted for \nif ( nrow(df_items)==nrow(temp) ) {\n  df_items <- temp \n} else {\n    print(\"ERROR! sub dfs don't contain all the df_items\")\n  }\n\n\n#CLEANUP MTF ENCODED ITEMS\nrm(item_responses_scaffold_111, item_responses_scaffold_121, item_responses_test)\nrm(key_111, key_121, key_scaffolded_c111, key_scaffolded_c121, key_test)\nrm(temp)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#references",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#references",
    "title": "2  Response Rescoring",
    "section": "9.1 References",
    "text": "9.1 References\nSchmidt, D., Raupach, T., Wiegand, A., Herrmann, M., & Kanzow, P. (2021). Relation between examinees’ true knowledge and examination scores: Systematic review and exemplary calculations on Multiple-True-False items. Educational Research Review, 34, 100409. https://doi.org/10.1016/j.edurev.2021.100409\nAlbanese, M. A., & Sabers, D. L. (1988). Multiple True-False Items: A Study of Inter-item Correlations, Scoring Alternatives, and Reliability Estimation. Journal of Educational Measurement, 25(2), 111–123. https://doi.org/10.1111/j.1745-3984.1988.tb00296.x"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#resources-1",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#resources-1",
    "title": "2  Response Rescoring",
    "section": "9.2 Resources",
    "text": "9.2 Resources\n\non kable tables\nhttps://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\non Rmd math symbols\nhttps://rpruim.github.io/s341/S19/from-class/MathinRmd.html\non installing missing TEX packages\nhttps://bookdown.org/yihui/rmarkdown-cookbook/install-latex-pkgs.html"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#session",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#session",
    "title": "2  Response Rescoring",
    "section": "9.3 Session",
    "text": "9.3 Session\n\n\nShow the code\nsessionInfo()"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#a-discriminant-score",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#a-discriminant-score",
    "title": "2  Response Rescoring",
    "section": "3.3 A Discriminant Score",
    "text": "3.3 A Discriminant Score\nThough it appears the Partial \\([-1/q, +1/p]\\) scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options the same. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under \\([-1/q, +1/q]\\). These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are more incorrect than others. We want to be able to differentiate between these responses.\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define four interpretations for which to define options.\n\nTriangular : the (true, correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\nOrthogonal: the (incorrect) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\nLines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the correct projection).\nSatisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nThus for each item, in the graph_comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\\[\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n\\]\nFor example, for the following sample stimuli, TODO IMAGE\n\\[\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n\\]\noption that is consistent with the incorrect-orthogonal interpretation in fact indicates less understanding than incorrectly selecting a nearby but not orthgonally consistent option.\nTODO: correct this section, the actual discriminant score algorithm does not rely on partial scoring [1/n] Although partial scoring gives us an indication of how close the respondent is to approximating the complete pattern of ‘correct’ responses, including partial knowledge, when the partial score is calculated with respect to a singular ‘correct’ set of answer options, it does does not distinguish between different types of partial knowledge. Subjects are rewarded (or penalized) by the same amount regardless of which the false-selections or true-non selections they make.\nIn the case of SGC_3A, however, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus.\nSpecifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations.\nTo capture this important source of variation, we can apply the idea behind the partial scoring strategy in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n  \\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t = |T| =\\) number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r = |R| =\\) number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nShow the code\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_rescoring.html#section",
    "href": "analysis/SGC3A/2_sgc3A_rescoring.html#section",
    "title": "2  Response Rescoring",
    "section": "3.4 ",
    "text": "3.4"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html",
    "title": "2  Response Scoring",
    "section": "",
    "text": "THIS NOTEBOOK IS INCOMPLETE\nThe purpose of this notebook is to score (assign a measure of accuracy) to response data for the SGC_3A study. This is required because the question type on the graph comprehension task used a ‘Multiple Response’ (MR) question design. Here, we evaluate different approaches to scoring multiple response questions, and transform raw item responses (e.g. boxes ABC are checked) to a measure of response accuracy. (Warning: this notebook takes several minutes to execute.)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#response-encoding",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#response-encoding",
    "title": "2  Response Scoring",
    "section": "3.1 Response Encoding",
    "text": "3.1 Response Encoding\nFirst, we note that the question type evaluated by Schmidt et al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 3.1: Figure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 3.1), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can be encoded as [TTFF].\n\n\n\n\n\n\nDecision\n\n\n\nIn our analysis, we will transform the MAMC response string recorded for the participant (given in column response), to an MTF encoding."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#scoring-schemes",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#scoring-schemes",
    "title": "2  Response Scoring",
    "section": "3.2 Scoring Schemes",
    "text": "3.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\n\\]\nProperties of the Subject’s Response\n\\[\n  \\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\n\\]\n\n3.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only correct-select options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\nIn Dichotomous Scoring\n\nscore for the question is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nCODE\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n3.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et al. (2021) identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach ( Schmidt et al. (2021) #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\nSchmidt et al. (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where there are many more response options \\(n\\) than there are options meant to be selected \\(p\\), this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n  \\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n\n\nCODE\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n\n\n\n3.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. “select all correct options”) vs MTF (i.e. “Mark each option as true or false”) questions.\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt et al. (2021) method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts \\(1/(n-p) = 1/q\\) for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n\\]\nProperties of Response\n\\[\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nCODE\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  return( (t / p) - (f/q))\n}\n\n\n\n\n3.2.4 Comparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    i  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial[-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A____ \n    5 \n    1 \n    1.0 \n    1.00 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB___ \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    A___E \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    AB__E \n    3 \n    0 \n    0.2 \n    0.50 \n  \n  Only Incorrect Selections\n\n    A____ \n    ____E \n    3 \n    0 \n    0.2 \n    -0.25 \n  \n  \n    A____ \n    ___DE \n    2 \n    0 \n    -0.2 \n    -0.50 \n  \n  Completely Inverse Response \n\n    A____ \n    _BCDE \n    0 \n    0 \n    -1.0 \n    -1.00 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABCDE \n    1 \n    0 \n    -0.6 \n    0.00 \n  \n  \n    A____ \n    _____ \n    4 \n    0 \n    0.6 \n    0.00 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    $i$  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial [-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A__...__ \n    15 \n    1 \n    1.000 \n    1.000 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB_...__ \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    A__..._O \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    AB_..._O \n    13 \n    0 \n    0.733 \n    0.857 \n  \n  Only Incorrect Selections\n\n    A____ \n    ___..._O \n    13 \n    0 \n    0.733 \n    -0.071 \n  \n  \n    A____ \n    ___...NO \n    12 \n    0 \n    0.600 \n    -0.143 \n  \n  Completely Inverse Response \n\n    A____ \n    _BC...NO \n    0 \n    0 \n    -1.000 \n    -1.000 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABC...NO \n    1 \n    0 \n    -0.867 \n    0.000 \n  \n  \n    A____ \n    ___...__ \n    14 \n    0 \n    0.867 \n    0.000 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n\n\n\n\n\nDecision\n\n\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#a-discriminant-score",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#a-discriminant-score",
    "title": "2  Response Scoring",
    "section": "3.3 A Discriminant Score",
    "text": "3.3 A Discriminant Score\nThough it appears the Partial \\([-1/q, +1/p]\\) scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options in the same way.\nIn the case of the SGC study paradigm, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus. Specifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under \\([-1/q, +1/q]\\). These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are more incorrect than others. We want to be able to differentiate between these responses.\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define four interpretations for which to define options. We can think of these as four different answer keys, each defining the set of ‘correct’ options (those that should be selected) under each interpretation of the graph.\n\nTriangular : the (true, actually correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\nOrthogonal: the (incorrect but most common) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\nLines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the correct projection).\nSatisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nTODO FIX THIS SECTION ONWARDS … RESPONSE SETS NEED NOT BE MUTUTALLY EXCLUSIVE\nThus for each item, in the graph comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\\[\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n\\]\nFor example, for the following sample stimuli, TODO IMAGE\n\\[\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n\\]\nTo capture this important source of variation, we can apply the idea behind the partial scoring \\([-1/q, +1/p]\\) scheme in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n  \\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t = |T| =\\) number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r = |R| =\\) number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nShow the code\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#section",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#section",
    "title": "2  Response Scoring",
    "section": "2.2 ",
    "text": "2.2"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#encode-mamc-responses-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#encode-mamc-responses-as-mtf",
    "title": "2  Response Scoring",
    "section": "4.4 Encode MAMC Responses as MTF",
    "text": "4.4 Encode MAMC Responses as MTF\nTo calculate partial scores, first we need re-encode participant responses which are currently captured in the answer column of the df_items dataframe. In the present encoding, the letter corresponding to each response item (corresponding to a data point in the stimulus graph) the subject selected on the task interface, is concatenated and stored in answer.\nFor example, if the respondent selected data points A and B, answer = AB. We need to transform this into a single column for each possible response option, encoding whether or not the option was selected A = 1, B = 1, C = 0 ...\n\n\nCODE\n#read datafiles, set mode and term\ndf_items <- read_rds('data/sgc3a_items.rds')\n\n#SPLIT DF_ITEMS \n#into sub dfs to allow a 1-1 mapping with appropriate answer key\n\n#scaffold phase control condition\nitem_responses_scaffold_111 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"111\")\n\n#scaffold phase impasse condition\nitem_responses_scaffold_121 <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q < 6) %>% \n  #filter only the control condition \n  filter(condition == \"121\")\n\n#test phase descriminant\nitem_responses_test <- df_items %>% \n  #filter only q < 6, the 'scaffold' items\n  filter(q > 5 ) \n  #note we don't need to filter condition bc qs and data are same across conditions\n\n#SPREAD MCMA RESPONSE TO MTF COLUMNS\n#encode the response column [response] as a series of T/F statements per data point\n\n#scaffold phase CONTROL condition\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n  ) \n\n#scaffold phase IMPASSE condition\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_X = as.integer(str_detect(response,\"X\")), #is there a X?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_U = as.integer(str_detect(response,\"U\")), #is there a U?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_Z = as.integer(str_detect(response,\"Z\"))  #is there a Z?\n  ) \n\n#test phase \nitem_responses_test <- item_responses_test %>% \n  #split response to TF columns\n  mutate(\n    r_A = as.integer(str_detect(response,\"A\")), #is there a A?\n    r_B = as.integer(str_detect(response,\"B\")), #is there a B?\n    r_C = as.integer(str_detect(response,\"C\")), #is there a C?\n    r_D = as.integer(str_detect(response,\"D\")), #is there a D?\n    r_E = as.integer(str_detect(response,\"E\")), #is there a E?\n    r_F = as.integer(str_detect(response,\"F\")), #is there a F?\n    r_G = as.integer(str_detect(response,\"G\")), #is there a G?\n    r_H = as.integer(str_detect(response,\"H\")), #is there a H?\n    r_I = as.integer(str_detect(response,\"I\")), #is there a I?\n    r_J = as.integer(str_detect(response,\"J\")), #is there a J?\n    r_K = as.integer(str_detect(response,\"K\")), #is there a K?\n    r_L = as.integer(str_detect(response,\"L\")), #is there a L?\n    r_M = as.integer(str_detect(response,\"M\")), #is there a M?\n    r_N = as.integer(str_detect(response,\"N\")), #is there a N?\n    r_O = as.integer(str_detect(response,\"O\")), #is there a O?\n    r_P = as.integer(str_detect(response,\"P\")), #is there a P?\n    r_Z = as.integer(str_detect(response,\"Z\")), #is there a Z?\n    r_X = as.integer(str_detect(response,\"X\"))  #is there a X?\n  ) \n\n#VALIDATE SPLIT\n\n#n rows in df_items should match sum of nrows in the sub dfs \n\nnrow(df_items) == sum(nrow(item_responses_scaffold_111), nrow(item_responses_scaffold_121),\n\n                      nrow(item_responses_test))\n\n\n[1] TRUE\n\n\nNow we have three data frames (one for each group of questions: scaffold phase control condition, scaffold phase experimental condition, and test phase) with subjects’ response encoded as a series of T/F [1,0] states across all response options (represented as columns prefaced with r_)\n\n\nCODE\nhead(item_responses_scaffold_111)\n\n\n  subject condition     term   mode\n1   JCKEW       111 winter22 asynch\n2   JCKEW       111 winter22 asynch\n3   JCKEW       111 winter22 asynch\n4   JCKEW       111 winter22 asynch\n5   JCKEW       111 winter22 asynch\n6   86P6B       111 winter22 asynch\n                                                                                 question\n1                                                          Which shift(s) start at 11 am?\n2                                             Which shift(s) start at the same time as D?\n3                                                       Which shift(s) begin when C ends?\n4                                                             Which shift(s) end at 4 pm?\n5 Coffee breaks happen halfway through a shift.</br> Which shift(s) share a break with I?\n6                                                          Which shift(s) start at 11 am?\n  q response correct   rt_s num_o r_A r_X r_C r_O r_I r_J r_H r_F r_K r_D r_U\n1 1        A   FALSE  18.71     1   1   0   0   0   0   0   0   0   0   0   0\n2 2        E   FALSE   8.92     1   0   0   0   0   0   0   0   0   0   0   0\n3 3        Z   FALSE  26.06     1   0   0   0   0   0   0   0   0   0   0   0\n4 4        U   FALSE  27.08     1   0   0   0   0   0   0   0   0   0   0   1\n5 5        U   FALSE  52.12     1   0   0   0   0   0   0   0   0   0   0   1\n6 1        F    TRUE 105.08     1   0   0   0   0   0   0   0   1   0   0   0\n  r_E r_G r_B r_Z\n1   0   0   0   0\n2   1   0   0   0\n3   0   0   0   1\n4   0   0   0   0\n5   0   0   0   0\n6   0   0   0   0"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#encode-mamc-answer-keys-as-mtf",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#encode-mamc-answer-keys-as-mtf",
    "title": "2  Response Scoring",
    "section": "4.5 Encode MAMC Answer Keys as MTF",
    "text": "4.5 Encode MAMC Answer Keys as MTF\nNext, we read the answer keys for the question sets. Note that there is an answer key unique to each experimental condition, because the experimental manipulation (impasse vs. control) is established by changing the pattern of the underlying dataset, which in turn yields different ‘correct’ answers. The divergence in answers across conditions only holds for the first five questions (the scaffold manipulation), while the following 10 questions are displayed with the same dataset (and thus have the same answers, regardless of condition).\nTODO UPDATE THIS Next, we split the answer key encoding into MTF encoding, just as we did for the response data. Each column indicates whether that response option should be selected in order to count as a correct response. Columns prefixed with tri_ represent triangularly-correct response key, and those prefixed with orth_ represent orthogonally-correct response key.\n\n\n\n\n\n\nSchmidt, Dennis, Tobias Raupach, Annette Wiegand, Manfred Herrmann, and Philipp Kanzow. 2021. “Relation Between Examinees’ True Knowledge and Examination Scores: Systematic Review and Exemplary Calculations on Multiple-True-False Items.” Educational Research Review 34 (November): 100409. https://doi.org/10.1016/j.edurev.2021.100409."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#calculate-i-number-correctly-selected-options",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#calculate-i-number-correctly-selected-options",
    "title": "2  Response Scoring",
    "section": "4.3 Calculate i number correctly selected options",
    "text": "4.3 Calculate i number correctly selected options\nNext, we calculate the \\(i\\), number of correctly indicated options, based on the answer key for each question.\n\n\nShow the code\n#------------------------------------------------------------------\n#calculate i: number of correctly indicated options\n#responses <- vector of T/F responses\n#key <- vector of T/F answers\n#RETURNS SUM correctly indicated items\n#NOTE: THIS IS SUPER BRITTLE \n#relies on fact that columns were ordered the same across the dataframes!\n#should refactor in less imperative mode (more R like!)\n#------------------------------------------------------------------\ncalc_i <- function(responses,key){\n  # print(responses)\n  # print(key)\n  assessment <- responses == key\n  return(sum(assessment))\n}\n\n#------------------------------------------------------------------\n#write_i: write i to response dataframe\n#items <- dataframe of items \n#key <- MTF answerkey for this dataframe\n#RETURNS MUTATING items dataframe\n#------------------------------------------------------------------\nwrite_i <- function(items,keys){\n  #for each row(item) in the items input dataframe\n  for (x in 1:nrow(items)) {\n    #get the question number\n    q = items[x,\"q\"]\n    #get the subjects response vector\n    responses <- as_tibble(items[x,] %>% select(starts_with(\"r_\")))\n    #get key vectors for this question\n    tri_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"tri_\")))\n    orth_key = as_tibble(keys %>% filter(Q==q) %>% select(starts_with(\"orth_\")))\n    #write TRI and ORTH response keys to row \n    items[x,\"TRI\"] <- keys %>% filter(Q==q) %>% select(TRIANGULAR)\n    items[x,\"ORTH\"] <- keys %>% filter(Q==q) %>% select(ORTHOGONAL)\n    #calculate number of triangular-correct-options\n    items[x,\"tri_i\"] <- calc_i(responses,tri_key)\n    #calculate number of orthogonal-correct-options\n    items[x,\"orth_i\"] <- calc_i(responses,orth_key)\n  }  \n  return(items) #return mutated items dataframe\n}\n\n#------------------------------------------------------------------\n#count_match: count the number of matching characters in the two strings\n#response <- response string\n#key <- key string\n#returns count of matches\n#------------------------------------------------------------------\ncount_match <- function(response, key){\n  count = 0\n  response = unlist(str_split(response,\"\"))\n  key = unlist(str_split(key,\"\"))\n  count = sum(table(response[response %in% key]))\n  return(count)\n}\n\n\n\n\nShow the code\n#WARNING :: TAKES SEVERAL MINUTES TO RUN\n\n#WRITE I_s\n#~5 mins on MBP\n#~30 seconds on IMAC\nitem_responses_scaffold_111 <- write_i(item_responses_scaffold_111,key_scaffolded_c111)\nitem_responses_scaffold_121 <- write_i(item_responses_scaffold_121,key_scaffolded_c121)\nitem_responses_test <- write_i(item_responses_test,key_test)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#calculate-scores",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#calculate-scores",
    "title": "2  Response Scoring",
    "section": "4.4 Calculate Scores",
    "text": "4.4 Calculate Scores\nFinally, we calculate the interpretation scores, absolute score, and discriminant score.\n\n\nShow the code\n#set n = number of answer options\nn_scaffold <- 15\nn_test <- 18\n\n#calculate scores for scaffold phase CONTROL condition \nitem_responses_scaffold_111 <- item_responses_scaffold_111  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i,n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for scaffold phase IMPASSE condition \nitem_responses_scaffold_121 <- item_responses_scaffold_121  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_scaffold),\n  s_TRI = f_partialN(tri_i, n_scaffold),\n  s_ORTH = f_partialN(orth_i, n_scaffold),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n#calculate scores for TEST phase (Q6 -> Q15)\nitem_responses_test <- item_responses_test  %>% mutate(\n  s_ABS = f_dichom(tri_i, n_test),\n  s_TRI = f_partialN(tri_i, n_test),\n  s_ORTH = f_partialN(orth_i, n_test),\n   #number of options in key\n  t = str_length(TRI),\n  r = str_length(ORTH),\n  d = n_scaffold - (t+r),\n  #number of selected options matching key\n  t_s = Vectorize(count_match)(response,TRI),\n  r_s = Vectorize(count_match)(response,ORTH),\n  # d_s = , #todo add selections for other strategies\n  # s = t_s + r_s + d_s \n  s_DISC = Vectorize(f_discrim)(t_s,t,r_s,r)\n)\n\n\nAs a sanity check, we validate the equivalence of the scores\n\n\nShow the code\n#validate that ABS score is always  == f_dichom(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ABS == f_dichom(item_responses_scaffold_111$tri_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_scaffold_121$s_ABS == f_dichom(item_responses_scaffold_121$tri_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_test$s_ABS == f_dichom(item_responses_test$tri_i,n_test))\n\n\n[1] TRUE\n\n\nShow the code\n#validate that ABS score is == 'correct' (calculated in stimulus)\nunique(validate <- as.logical(item_responses_scaffold_111$s_ABS) == (item_responses_scaffold_111$correct))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- as.logical(item_responses_scaffold_121$s_ABS) == (item_responses_scaffold_121$correct))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- as.logical(item_responses_test$s_ABS) == (item_responses_test$correct))\n\n\n[1] TRUE\n\n\nShow the code\n#validate that TRI score is always  == f_partialN(tri_i, 15)\nunique(validate <- item_responses_scaffold_111$s_TRI == f_partialN(item_responses_scaffold_111$tri_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_scaffold_121$s_TRI == f_partialN(item_responses_scaffold_121$tri_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_test$s_TRI == f_partialN(item_responses_test$tri_i,n_test))\n\n\n[1] TRUE\n\n\nShow the code\n#validate that ORTH score is always  == f_partialN(orth_i, 15)\nunique(validate <- item_responses_scaffold_111$s_ORTH == f_partialN(item_responses_scaffold_111$orth_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_scaffold_121$s_ORTH == f_partialN(item_responses_scaffold_121$orth_i,n_scaffold))\n\n\n[1] TRUE\n\n\nShow the code\nunique(validate <- item_responses_test$s_ORTH == f_partialN(item_responses_test$orth_i,n_test))\n\n\n[1] TRUE"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#reintegrate-item-dataframe",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#reintegrate-item-dataframe",
    "title": "2  Response Scoring",
    "section": "4.5 Reintegrate item dataframe",
    "text": "4.5 Reintegrate item dataframe\nThe final step in the process is to re_combine_ the item dataframes.\n\n\nShow the code\n#reduce dataframes before combination\nitem_responses_scaffold_111 <- item_responses_scaffold_111 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH, s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_scaffold_121 <- item_responses_scaffold_121 %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"LEARN\")\n\nitem_responses_test <- item_responses_test %>% \n  select(subject, condition, term, mode, question, rt_s,\n         q, correct, response, TRI, ORTH, \n         num_o, tri_i, orth_i, \n         s_ABS, s_TRI, s_ORTH,s_DISC) %>% \n  mutate(phase = \"TEST\")\n\n#combine data frames\ntemp <- rbind(item_responses_scaffold_111,item_responses_scaffold_121,item_responses_test)\n\n#dblck all items are accounted for \nif ( nrow(df_items)==nrow(temp) ) {\n  df_items <- temp \n} else {\n    print(\"ERROR! sub dfs don't contain all the df_items\")\n  }\n\n\n#CLEANUP MTF ENCODED ITEMS\nrm(item_responses_scaffold_111, item_responses_scaffold_121, item_responses_test)\nrm(key_111, key_121, key_scaffolded_c111, key_scaffolded_c121, key_test)\nrm(temp)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#references",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#references",
    "title": "2  Response Scoring",
    "section": "9.1 References",
    "text": "9.1 References\nSchmidt, D., Raupach, T., Wiegand, A., Herrmann, M., & Kanzow, P. (2021). Relation between examinees’ true knowledge and examination scores: Systematic review and exemplary calculations on Multiple-True-False items. Educational Research Review, 34, 100409. https://doi.org/10.1016/j.edurev.2021.100409\nAlbanese, M. A., & Sabers, D. L. (1988). Multiple True-False Items: A Study of Inter-item Correlations, Scoring Alternatives, and Reliability Estimation. Journal of Educational Measurement, 25(2), 111–123. https://doi.org/10.1111/j.1745-3984.1988.tb00296.x"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#resources-1",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#resources-1",
    "title": "2  Response Scoring",
    "section": "9.2 Resources",
    "text": "9.2 Resources\n\non kable tables\nhttps://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\non Rmd math symbols\nhttps://rpruim.github.io/s341/S19/from-class/MathinRmd.html\non installing missing TEX packages\nhttps://bookdown.org/yihui/rmarkdown-cookbook/install-latex-pkgs.html"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#session",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#session",
    "title": "2  Response Scoring",
    "section": "9.3 Session",
    "text": "9.3 Session\n\n\nShow the code\nsessionInfo()\n\n\nR version 4.0.2 (2020-06-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS  10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggformula_0.10.1 ggridges_0.5.3   scales_1.1.1     ggstance_0.3.5  \n [5] kableExtra_1.3.1 forcats_0.5.0    stringr_1.4.0    dplyr_1.0.2     \n [9] purrr_0.3.4      readr_1.4.0      tidyr_1.1.2      tibble_3.1.2    \n[13] ggplot2_3.3.5    tidyverse_1.3.0 \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5        lubridate_1.7.9   assertthat_0.2.1  digest_0.6.27    \n [5] utf8_1.2.1        ggforce_0.3.3     R6_2.5.0          cellranger_1.1.0 \n [9] plyr_1.8.6        backports_1.2.1   labelled_2.8.0    reprex_0.3.0     \n[13] evaluate_0.14     httr_1.4.2        highr_0.8         pillar_1.6.1     \n[17] rlang_0.4.11      readxl_1.3.1      rstudioapi_0.13   blob_1.2.1       \n[21] rmarkdown_2.11    labeling_0.4.2    webshot_0.5.2     htmlwidgets_1.5.2\n[25] polyclip_1.10-0   munsell_0.5.0     broom_0.7.12      compiler_4.0.2   \n[29] modelr_0.1.8      xfun_0.29         pkgconfig_2.0.3   htmltools_0.5.2  \n[33] tidyselect_1.1.0  mosaicCore_0.9.0  fansi_0.5.0       viridisLite_0.4.0\n[37] crayon_1.4.1      dbplyr_1.4.4      withr_2.4.2       MASS_7.3-51.6    \n[41] grid_4.0.2        jsonlite_1.7.1    gtable_0.3.0      lifecycle_1.0.0  \n[45] DBI_1.1.0         magrittr_2.0.1    cli_3.3.0         stringi_1.7.3    \n[49] farver_2.1.0      fs_1.5.0          xml2_1.3.2        ellipsis_0.3.2   \n[53] generics_0.0.2    vctrs_0.3.8       tools_4.0.2       glue_1.6.2       \n[57] tweenr_1.0.2      hms_0.5.3         fastmap_1.1.0     yaml_2.2.1       \n[61] colorspace_2.0-2  rvest_0.3.6       knitr_1.37        haven_2.3.1"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Schmidt, Dennis, Tobias Raupach, Annette Wiegand, Manfred Herrmann, and\nPhilipp Kanzow. 2021. “Relation Between Examinees’ True Knowledge\nand Examination Scores: Systematic Review and Exemplary Calculations on\nMultiple-True-False\nItems.” Educational Research Review 34 (November):\n100409. https://doi.org/10.1016/j.edurev.2021.100409."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_exploreResponse.html",
    "href": "analysis/SGC3A/2_sgc3A_exploreResponse.html",
    "title": "3  Response Exploration",
    "section": "",
    "text": "The purpose of this notebook is to explore item-level response data collected for study SGC-3: The Insight Hypothesis\nFirst we import item-level data from the cleaned and wrangled R data structure file.\n\n\nCODE\ndf_items <- read_rds('data/sgc3a_items.rds')\n\n\n\n\n\n\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\nIn the ‘interpretation’ column we indicate which interpretation of the graph stimulus is indicated by each combination of response options. Note that ALL CAPS indicates the precise interpretation, while lowercase indicates a partially-consistent selection of options.\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"lines-connect\",\"(both ortho & tri)\",\"?\",\"?\",\"triangular\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthongal\", 3, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 4) %>% \n  pack_rows(\"other\", 5, 7) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    22 \n    TRIANGULAR \n  \n  \n    Z \n    1 \n    triangular \n  \n  Orthongal\n\n    A \n    129 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    CF \n    3 \n    lines-connect \n  \n  other\n\n    AF \n    1 \n    (both ortho & tri) \n  \n  \n    IJD \n    1 \n    ? \n  \n  \n    X \n    1 \n    ? \n  \n\n\n\n\n\nNearly all of the subjects selected a response consistent with one of the identified interpretations.\nNote that options highlighted in light grey are considered within the range of ‘visual error’.\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nindicates the correct interpretation of the coordinate system\na triangular-like interpretation, where the respondent selects any datapoints intersecting the lines that connect to the reference time\nindicates the incorrect, Cartesian interpretation of the coordinate system\n\n\n\n\n\n\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\n                     \"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\"ortho + satisfice\",\"TRIANGULAR\")\n\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthogonal\", 3, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 7) %>% \n  pack_rows(\"other\", 8, 10) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    K \n    24 \n    TRIANGULAR \n  \n  \n    KD \n    1 \n    TRIANGULAR \n  \n  Orthogonal\n\n    DE \n    3 \n    ORTHONGAL \n  \n  \n    E \n    121 \n    ORTHOGONAL \n  \n  \n    EG \n    1 \n    ortho + satisfice \n  \n  Lines-Connect\n\n    J \n    4 \n    LINES-CONNECT \n  \n  \n    AK \n    1 \n    LINES-CONNECT \n  \n  other\n\n    D \n    1 \n    (reference point) \n  \n  \n    B \n    1 \n     \n  \n  \n    C \n    1 \n     \n  \n\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\"LINES-CONNECT\",\n                     \"lines-connect\",\"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\n                     \"\",\"\",\"\",\"\",\"\",\"\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 7) %>% \n  pack_rows(\"other\", 8, 17) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    24 \n    TRIANGULAR \n  \n  Orthogonal\n\n    AUB \n    4 \n    ORTHONGAL \n  \n  \n    Z \n    94 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    A \n    18 \n    LINES-CONNECT \n  \n  \n    K \n    3 \n    LINES-CONNECT \n  \n  \n    OJ \n    2 \n    LINES-CONNECT \n  \n  \n    O \n    3 \n    lines-connect \n  \n  other\n\n    C \n    1 \n    (reference point) \n  \n  \n    AH \n    1 \n     \n  \n  \n    AIOZFHJXKUDEGB \n    1 \n     \n  \n  \n    DE \n    1 \n     \n  \n  \n    E \n    1 \n     \n  \n  \n    FKE \n    1 \n     \n  \n  \n    OJD \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    U \n    1 \n     \n  \n  \n    UE \n    1 \n     \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-lines connect\",\"BLANK\",\"orth-lines connect\",\n                     \"lines-connect\",\"orthogonal\",\"\",\"\",\"\",\n                     \"\",\"\",\"\",\"\",\"\",\"\" )\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 6) %>% \n  pack_rows(\"other\", 7, 16) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    H \n    29 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    87 \n    ORTHOGONAL \n  \n  \n    FU \n    2 \n    orthogonal \n  \n  \n    DE \n    14 \n    orth-lines connect \n  \n  \n    E \n    6 \n    orth-lines connect \n  \n  Lines-Connect\n\n    B \n    3 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    K \n    2 \n     \n  \n  \n    O \n    2 \n     \n  \n  \n    AH \n    1 \n     \n  \n  \n    CAIOZFHJXKU \n    1 \n     \n  \n  \n    D \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    KU \n    1 \n     \n  \n  \n    OUDE \n    1 \n     \n  \n  \n    UDE \n    1 \n     \n  \n\n\n\n\n\nIn Question 4 we see more than one variant of an orthogonal interpretation emerge.\n\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\n\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-satistice\",\"BLANK\",\"orth-satisfice\",\n                     \"orth-satistice\",\"\",\"\",\"\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\n                     \"(reference point)\",\"\",\"\",\"\",\"lines-connect\")\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 9) %>% \n  pack_rows(\"Lines Connect\", 10, 10) %>% \n  pack_rows(\"other\", 11, 22) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    O \n    50 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    64 \n    ORTHOGONAL \n  \n  \n    F \n    10 \n    orth-satistice \n  \n  \n    J \n    3 \n    orth-satistice \n  \n  \n    H \n    3 \n    orth-satisfice \n  \n  \n    K \n    2 \n    orth-satisfice \n  \n  \n    FK \n    1 \n    orth-satisfice \n  \n  \n    HJ \n    1 \n    orth-satisfice \n  \n  \n    HU \n    1 \n    orth-satisfice \n  \n  Lines Connect\n\n    Z \n    1 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    I \n    1 \n    (reference point) \n  \n  \n    OF \n    3 \n     \n  \n  \n    B \n    2 \n     \n  \n  \n    FG \n    2 \n     \n  \n  \n    JD \n    2 \n     \n  \n  \n    C \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    HJDE \n    1 \n     \n  \n  \n    OH \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    X \n    1 \n     \n  \n\n\n\n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\n\n\nWe can compare these responses to those produced by participants in the experimental impasse condition (condition = 121).\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\ninterpretation = c(\"BLANK\",\"TRIANGULAR\",\"partial-satisfice\",\"LINES-CONNECT\",\n                   \"partial-satisfice\",\"partial-satisfice\",\"partial-lines-connect\",\n                   \"\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  kbl(caption = title) %>%  kable_classic() \n\n\n`summarise()` ungrouping output (override with `.groups` argument)\n\n\n\nFrequency of Selected Response Options for Question #1 (Impasse Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  \n     \n    57 \n    BLANK \n  \n  \n    F \n    49 \n    TRIANGULAR \n  \n  \n    O \n    28 \n    partial-satisfice \n  \n  \n    CF \n    14 \n    LINES-CONNECT \n  \n  \n    AI \n    9 \n    partial-satisfice \n  \n  \n    A \n    4 \n    partial-satisfice \n  \n  \n    C \n    3 \n    partial-lines-connect \n  \n  \n    E \n    2 \n     \n  \n  \n    I \n    2 \n    partial-satisfice \n  \n  \n    AO \n    1 \n    partial-satisfice \n  \n  \n    CO \n    1 \n    partial-satisfice \n  \n  \n    OA \n    1 \n    partial-satisfice \n  \n  \n    X \n    1"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_exploreResponse.html#control-condition",
    "href": "analysis/SGC3A/2_sgc3A_exploreResponse.html#control-condition",
    "title": "3  Response Exploration",
    "section": "3.1 Control Condition",
    "text": "3.1 Control Condition\n\n3.1.1 Question #1\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\nIn the ‘interpretation’ column we indicate which interpretation of the graph stimulus is indicated by each combination of response options. Note that ALL CAPS indicates the precise interpretation, while lowercase indicates a partially-consistent selection of options.\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"lines-connect\",\"(both ortho & tri)\",\"?\",\"?\",\"triangular\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthongal\", 3, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 4) %>% \n  pack_rows(\"other\", 5, 7) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    22 \n    TRIANGULAR \n  \n  \n    Z \n    1 \n    triangular \n  \n  Orthongal\n\n    A \n    129 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    CF \n    3 \n    lines-connect \n  \n  other\n\n    AF \n    1 \n    (both ortho & tri) \n  \n  \n    IJD \n    1 \n    ? \n  \n  \n    X \n    1 \n    ? \n  \n\n\n\n\n\nNearly all of the subjects selected a response consistent with one of the identified interpretations.\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nindicates the correct interpretation of the coordinate system\na triangular-like interpretation, where the respondent selects any datapoints intersecting the lines that connect to the reference time\nindicates the incorrect, Cartesian interpretation of the coordinate system\n\n\n\nThough three respondents clicked answer options that don’t accord with any particular interpretation.\n\n\n\n3.1.2 Question #2\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\n                     \"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\"ortho + satisfice\",\"TRIANGULAR\")\n\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthogonal\", 3, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 7) %>% \n  pack_rows(\"other\", 8, 10) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    K \n    24 \n    TRIANGULAR \n  \n  \n    KD \n    1 \n    TRIANGULAR \n  \n  Orthogonal\n\n    DE \n    3 \n    ORTHONGAL \n  \n  \n    E \n    121 \n    ORTHOGONAL \n  \n  \n    EG \n    1 \n    ortho + satisfice \n  \n  Lines-Connect\n\n    J \n    4 \n    LINES-CONNECT \n  \n  \n    AK \n    1 \n    LINES-CONNECT \n  \n  other\n\n    D \n    1 \n    (reference point) \n  \n  \n    B \n    1 \n     \n  \n  \n    C \n    1 \n     \n  \n\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n3.1.3 Question #3\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\"LINES-CONNECT\",\n                     \"lines-connect\",\"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\n                     \"\",\"\",\"\",\"\",\"\",\"\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 7) %>% \n  pack_rows(\"other\", 8, 17) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    24 \n    TRIANGULAR \n  \n  Orthogonal\n\n    AUB \n    4 \n    ORTHONGAL \n  \n  \n    Z \n    94 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    A \n    18 \n    LINES-CONNECT \n  \n  \n    K \n    3 \n    LINES-CONNECT \n  \n  \n    OJ \n    2 \n    LINES-CONNECT \n  \n  \n    O \n    3 \n    lines-connect \n  \n  other\n\n    C \n    1 \n    (reference point) \n  \n  \n    AH \n    1 \n     \n  \n  \n    AIOZFHJXKUDEGB \n    1 \n     \n  \n  \n    DE \n    1 \n     \n  \n  \n    E \n    1 \n     \n  \n  \n    FKE \n    1 \n     \n  \n  \n    OJD \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    U \n    1 \n     \n  \n  \n    UE \n    1 \n     \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n3.1.4 Question #4\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-lines connect\",\"BLANK\",\"orth-lines connect\",\n                     \"lines-connect\",\"orthogonal\",\"\",\"\",\"\",\n                     \"\",\"\",\"\",\"\",\"\",\"\" )\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 6) %>% \n  pack_rows(\"other\", 7, 16) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    H \n    29 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    87 \n    ORTHOGONAL \n  \n  \n    FU \n    2 \n    orthogonal \n  \n  \n    DE \n    14 \n    orth-lines connect \n  \n  \n    E \n    6 \n    orth-lines connect \n  \n  Lines-Connect\n\n    B \n    3 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    K \n    2 \n     \n  \n  \n    O \n    2 \n     \n  \n  \n    AH \n    1 \n     \n  \n  \n    CAIOZFHJXKU \n    1 \n     \n  \n  \n    D \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    KU \n    1 \n     \n  \n  \n    OUDE \n    1 \n     \n  \n  \n    UDE \n    1 \n     \n  \n\n\n\n\n\nIn Question 4 we see more than one variant of an orthogonal interpretation emerge.\n\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\n3.1.5 Question #5\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-satistice\",\"BLANK\",\"orth-satisfice\",\n                     \"orth-satistice\",\"\",\"\",\"\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\n                     \"(reference point)\",\"\",\"\",\"\",\"lines-connect\")\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 9) %>% \n  pack_rows(\"Lines Connect\", 10, 10) %>% \n  pack_rows(\"other\", 11, 22) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    O \n    50 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    64 \n    ORTHOGONAL \n  \n  \n    F \n    10 \n    orth-satistice \n  \n  \n    J \n    3 \n    orth-satistice \n  \n  \n    H \n    3 \n    orth-satisfice \n  \n  \n    K \n    2 \n    orth-satisfice \n  \n  \n    FK \n    1 \n    orth-satisfice \n  \n  \n    HJ \n    1 \n    orth-satisfice \n  \n  \n    HU \n    1 \n    orth-satisfice \n  \n  Lines Connect\n\n    Z \n    1 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    I \n    1 \n    (reference point) \n  \n  \n    OF \n    3 \n     \n  \n  \n    B \n    2 \n     \n  \n  \n    FG \n    2 \n     \n  \n  \n    JD \n    2 \n     \n  \n  \n    C \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    HJDE \n    1 \n     \n  \n  \n    OH \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    X \n    1 \n     \n  \n\n\n\n\n\nTODO note the compelling cases of internal inconsistency (HJDE)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_exploreResponse.html#impasse-condition",
    "href": "analysis/SGC3A/2_sgc3A_exploreResponse.html#impasse-condition",
    "title": "3  Response Exploration",
    "section": "3.2 Impasse Condition",
    "text": "3.2 Impasse Condition\nWe can compare these responses to those produced by participants in the experimental impasse condition (condition = 121).\n\n\nShow the code\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\ninterpretation = c(\"BLANK\",\"TRIANGULAR\",\"partial-satisfice\",\"LINES-CONNECT\",\n                   \"partial-satisfice\",\"partial-satisfice\",\"partial-lines-connect\",\n                   \"\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  kbl(caption = title) %>%  kable_classic() \n\n\n`summarise()` ungrouping output (override with `.groups` argument)\n\n\n\nFrequency of Selected Response Options for Question #1 (Impasse Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  \n     \n    57 \n    BLANK \n  \n  \n    F \n    49 \n    TRIANGULAR \n  \n  \n    O \n    28 \n    partial-satisfice \n  \n  \n    CF \n    14 \n    LINES-CONNECT \n  \n  \n    AI \n    9 \n    partial-satisfice \n  \n  \n    A \n    4 \n    partial-satisfice \n  \n  \n    C \n    3 \n    partial-lines-connect \n  \n  \n    E \n    2 \n     \n  \n  \n    I \n    2 \n    partial-satisfice \n  \n  \n    AO \n    1 \n    partial-satisfice \n  \n  \n    CO \n    1 \n    partial-satisfice \n  \n  \n    OA \n    1 \n    partial-satisfice \n  \n  \n    X \n    1"
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html",
    "href": "analysis/SGC3A/SGC3A.html",
    "title": "SGC3A",
    "section": "",
    "text": "In Study 3A we explore a hypothesis that emerged from analysis of Study 2, namely that presenting a learning with a situation that induces a state of impasse will increase the probability that learners experience a moment of insight, and in turn restructure their interpretation of the coordinate system.\nIn the context of Study 2, an impasse state was (unintentionally) induced when the combination of question + data set yielded no available answer in the incorrect (cartesian) interpretation of the graph. In Study 3A, we test this hypothesis by comparing performance between a (treatment) group receiving impasse-inducing questions followed by normal questions, and a non-impasse control.\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\nFigure 1: Posing a mental impasse\n\n\nTo try the study yourself:\n\ncontrol condition\nimpasse condition\n\n\n\nH1. Learners posed with impasse-inducing questions will be more likely to correct interpret the graph.\n\nH0. Learners posed with impasse-inducing questions will be no more likely to correctly interpret the graph."
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#hypotheses",
    "href": "analysis/SGC3A/SGC3A.html#hypotheses",
    "title": "SGC3A",
    "section": "Hypotheses",
    "text": "Hypotheses\nH1. Learners posed with impasse-inducing questions will be more likely to correct interpret the graph.\n\nH0. Learners posed with impasse-inducing questions will be no more likely to correctly interpret the graph."
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#design",
    "href": "analysis/SGC3A/SGC3A.html#design",
    "title": "SGC3A",
    "section": "Design",
    "text": "Design\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Scaffold: control,impasse)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\nResponse Accuracy : Is the response triangular-correct?\n(derived) Interpretation : With which interpretation of the graph is the subject’s response on an individual question consistent?\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 1.1. The list of questions can be found here.\n\n\n\nFigure 1.1: Sample Question (Q=1) for Graph Comprehension Task\n\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\nThe green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line.\n\n\n\nFigure 1.2: Sample Question (Q=1) graphs for each condition\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser. Upon starting, they submitted informed consent, before reading task instructions. Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule. Then participants completed a test block of 15 items. In the IMPASSE condition, the first five questions included an IMPASSE problem state. For participants in the CONTROL condition, the dataset was structure such that there was always an available ‘orthogonal answer’ for the first 5 questions. In both conditions, the remaining 10 questions were not structured as impasse. Following the test block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData was collected by convenience sample of a university subject pool. Initial data (Fall 2017, Spring 2018) were collected in-person, with large groups of students simultaneously completing the study (independently) in a computer lab. In Fall 2021 and Winter 2022 we collected additional data to replicate results in a remote format (students completing the study asynchronously on their own computers)."
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#response-scoring",
    "href": "analysis/SGC3A/SGC3A.html#response-scoring",
    "title": "SGC3A",
    "section": "Response Scoring",
    "text": "Response Scoring\nBecause the graph comprehension task utilizes a Multiple-Response (MR) format (rather than simple multiple choice), the raw response data (the combination of answer options selected) for each question first need to be assigned a score. Approaches to scoring MR data and score transformations are derived in section 3. after harmonizing section 2"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#todo-a-discriminant-score",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#todo-a-discriminant-score",
    "title": "2  Response Scoring",
    "section": "2.2 TODO A Discriminant Score",
    "text": "2.2 TODO A Discriminant Score\nThough it appears the Partial \\([-1/q, +1/p]\\) scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options in the same way.\nIn the case of the SGC study paradigm, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus. Specifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under \\([-1/q, +1/q]\\). These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are more incorrect than others. We want to be able to differentiate between these responses.\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define four interpretations for which to define options. We can think of these as four different answer keys, each defining the set of ‘correct’ options (those that should be selected) under each interpretation of the graph.\n\nTriangular : the (true, actually correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\nOrthogonal: the (incorrect but most common) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\nLines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the correct projection).\nSatisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nTODO FIX THIS SECTION ONWARDS … RESPONSE SETS NEED NOT BE MUTUTALLY EXCLUSIVE\nThus for each item, in the graph comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\\[\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n\\]\nFor example, for the following sample stimuli, TODO IMAGE\n\\[\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n\\]\nTo capture this important source of variation, we can apply the idea behind the partial scoring \\([-1/q, +1/p]\\) scheme in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n  \\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t = |T| =\\) number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r = |R| =\\) number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nCODE\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#prepare-answer-keys",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#prepare-answer-keys",
    "title": "2  Response Scoring",
    "section": "4.1 Prepare Answer Keys",
    "text": "4.1 Prepare Answer Keys\nWe start by preparing the answer keys for each stimulus set and stimulus interpretation. For each stimulus set (experimental condition, which defines the underlying dataset visualized in the stimulus) there is an answer key.\nTODO ADD DATA DICTIONARY.\n\n\nCODE\nkey_111_raw <- read_csv('keys/SGC3A_scaffold_111_key.csv') %>% mutate(condition = 111, phase = \"scaffold\")\nkey_121_raw <- read_csv('keys/SGC3A_scaffold_121_key.csv')%>% mutate(condition = 121, phase = \"scaffold\")\nkey_test_raw <- read_csv('keys/SGC3A_test_key.csv')%>% mutate(condition = \"\", phase = \"test\")\n\nkeys_raw <- rbind(key_111_raw, key_121_raw, key_test_raw)\nrm(key_111_raw, key_121_raw, key_test_raw)\n\n\nIn order to calculate scores using the \\([-1/q, +1/p]\\) algorithm, we need to define the subset of all response options (set N) that should be selected (set P) and should not be selected (set Q). In order to calculate subscores for each graph interpretation (triangular, orthogonal) we must define these sets independently for each interpretation. The answer key files the ‘correct’ answer (i.e. set P) for each interpretation, for each question. We must derive the contents of set Q based on set\n\nSET N = all response options (superset) \\(N\\)\nSET P = all options that should be selected (rewarded as +1/p) \\(P \\subset N\\)\nSET A = items that should not be selected, but if they are, don’t penalize (ignored) \\(A \\subset N\\)\nSET Q = all options that should NOT be selected (penalized as -1/q) \\(Q = N - (P \\cup A)\\)\n\n\n\nCODE\nverify = c() #sanity check\n\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT ORTHOGONAL KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_orth <- keys_raw %>% \n  select(Q, condition, OPTIONS, ORTHOGONAL, ORTHve, ALSO, TRIANGULAR) %>% \n  mutate(\n    \n    #replace NAs \n    ORTHve = str_replace_na(ORTHve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = ORTHOGONAL,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(ORTHve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_orth)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_orth[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_orth[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_orth[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_orth[x,'set_q'] = Q\n  keys_orth[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder for ease of use\nkeys_orth <- keys_orth %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TRIANGULAR KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tri <- keys_raw %>% \n  select(Q, condition, OPTIONS, TRIANGULAR, TRIve, ALSO, ORTHOGONAL) %>% \n  mutate(\n    \n    #replace NAs \n    TRIve = str_replace_na(TRIve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TRIANGULAR,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TRIve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_tri)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tri[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tri[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tri[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tri[x,'set_q'] = Q\n  keys_tri[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder for ease of use\nkeys_tri <- keys_tri %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n\n\nTo verify we have generated the correct sets, we verify that for each row (question), each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#prepare-response-data",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#prepare-response-data",
    "title": "2  Response Scoring",
    "section": "4.2 Prepare Response Data",
    "text": "4.2 Prepare Response Data\n\n\nCODE\ndf_items <- read_rds('data/sgc3a_items.rds')\ndf_items <- df_items %>% filter( condition == 111) %>% filter(q<6) \n\n\n\n\nCODE\n##———————————————————————————————————————————————————————————————\n##CALCULATE P AND Q for ORTH AND TRI\n##———————————————————————————————————————————————————————————————\n#for each response (row), calculate p_s and q_s for that question\nfor (x in 1:nrow(df_items)) {\n\n  #get properties of the RESPONSE ITEM\n  qu = df_items[x,'q']\n  cond = df_items[x,'condition']\n  r = df_items[x,'response'] %>% str_split(\"\") %>% unlist()\n  \n  #get KEYS for this question for this condition\n  if (qu < 6) { \n    \n    #get triangular keys\n    tri_p = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    tri_q = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    tri_pn = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_p)\n    tri_qn = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_q)\n    \n    #get orthogonal keys\n     orth_p = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_q = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n     orth_pn = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_p)\n     orth_qn = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_q)\n    \n  } else {\n    \n      #get triangular keys\n    tri_p = keys_tri %>% filter(Q == qu) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    tri_q = keys_tri %>% filter(Q == qu) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    tri_pn = keys_tri %>% filter(Q == qu)  %>% select(n_p)\n    tri_qn = keys_tri %>% filter(Q == qu)  %>% select(n_q)\n    \n    #get orthogonal keys\n    orth_p = keys_orth %>% filter(Q == qu) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    orth_q = keys_orth %>% filter(Q == qu) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    orth_pn = keys_orth %>% filter(Q == qu) %>% select(n_p)\n    orth_qn = keys_orth %>% filter(Q == qu) %>% select(n_q)\n  }\n  \n  #calculate and save qs and ps\n  tri_ps = length(intersect(r,tri_p))\n  tri_qs = length(intersect(r,tri_q))\n  orth_ps = length(intersect(r,orth_p))\n  orth_qs = length(intersect(r,orth_q))\n  \n  df_items[x,'tri_ps'] = tri_ps\n  df_items[x,'tri_qs'] = tri_qs\n  df_items[x,'orth_ps'] = orth_ps\n  df_items[x,'orth_qs'] = orth_qs\n \n  #calculate subscores\n  # f_partialP <- function(t,p,f,q) \n  df_items[x,'score_TRI'] = f_partialP(tri_ps,tri_pn,tri_qs,tri_qn)\n  df_items[x,'score_ORTH'] = f_partialP(orth_ps,orth_pn,orth_qs,orth_qn)\n}\n\n#cleanup\nrm(orth_pn, orth_p, orth_qn, orth_q, orth_ps, orth_qs,  tri_pn, tri_p, tri_qn, tri_q, tri_ps, tri_qs, qu, cond, r,x)\n\n\n\n\nCODE\ndf_items$DISC <- df_items$score_TRI - df_items$score_ORTH\ngf_jitter(score_TRI ~ score_ORTH, data = df_items, alpha = 0.2)\n\n\n\n\n\nCODE\ngf_jitter(score_TRI ~ DISC, data = df_items , alpha=0.2,  color = ~q)\n\n\n\n\n\nCODE\ngf_dhistogram(~df_items$DISC, data = df_items)\n\n\nWarning: Use of `df_items$DISC` is discouraged. Use `DISC` instead."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#summarize-by-subject",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#summarize-by-subject",
    "title": "2  Response Scoring",
    "section": "4.3 Summarize By subject",
    "text": "4.3 Summarize By subject\n\n\nCODE\nsubjects <- df_items %>% group_by(subject) %>% summarize(\n  TRI = sum(score_TRI),\n  ORTH = sum(score_ORTH),\n  DISCRIM = sum(score_TRI + score_ORTH),\n  ABSOLUTE = sum(correct),\n  condition = unique(condition)\n)\n\n\n`summarise()` ungrouping output (override with `.groups` argument)\n\n\n\n\nCODE\ngf_dhistogram(~DISCRIM, data = subjects)  %>%  gf_facet_grid(~condition)\n\n\n\n\n\nCODE\ngf_dhistogram(~ABSOLUTE, data = subjects)\n\n\n\n\n\nCODE\ngf_jitter(ABSOLUTE ~ DISCRIM, data = subjects, alpha = 0.2)\n\n\n\n\n\nTODO TRAPDOOR?\nSET T = options that result in -1 score (trapdoor)\nTODO: TEST first with NO trapdoor, and see what the scores yield, then if the responses can be scaled based on comparing subscores\nf_partialP <- function(t,p,f,q) {\nt = number of correct-selected options p = number of true options f = number of incorrect-selected options q = number of false options n = number of options + p + q return( (t / p) - (f/q)) }\nTo prepare for partial scoring [-1/q, + 1/p], we first need to define the parameters t, p , f, q\nOur approach to calculating an ORTHOGONAL PARTIAL score is as follows:\n\n1/p for each correct-selected\n-1/q for each incorrect-selected (except ‘allowed’ based on reference point and visual error)\ntrapdoor : default to -1 if select triangular\n\n\n\nCODE\ntest <- data.frame(\n  response = c(\"A\",\"ABC\")\n)"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#sec-SGC3A-harmonize",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#sec-SGC3A-harmonize",
    "title": "1  Harmonization",
    "section": "1.1 INTRODUCTION",
    "text": "1.1 INTRODUCTION\nData for study SGC_3A were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n\n\nPeriod\nModality\n\n\n\n\nFall 2017\nin person, SONA groups in computer lab\n\n\nSpring 2018\nin person, SONA groups in computer lab\n\n\nFall 2021\nasynchronous, online, SONA\n\n\nWinter 2022\nasynchronous, online, SONA\n\n\n\nData collected in Fall 2017, Spring 2018 constitute the original SGC_3A study, conducted in person. Data collected in Fall 2021, Winter 2022 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#harmonization",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#harmonization",
    "title": "1  Harmonization",
    "section": "1.1 HARMONIZATION",
    "text": "1.1 HARMONIZATION\nData for study SGC_3A were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n\n\nPeriod\nModality\n\n\n\n\nFall 2017\nin person, SONA groups in computer lab\n\n\nSpring 2018\nin person, SONA groups in computer lab\n\n\nFall 2021\nasynchronous, online, SONA\n\n\nWinter 2022\nasynchronous, online, SONA\n\n\n\nData collected in Fall 2017, Spring 2018 constitute the original SGC_3A study, conducted in person. Data collected in Fall 2021, Winter 2022 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application.\nThe underlying data structure of the stimulus web application changed across the data collection period, resulting in slightly different data files (i.e. columns are not named consistently). In this section, we combine the files from each data collection period into a single harmonized data file for analysis (one for participants, one for items).\n\n1.1.1 Participants\nFirst we import participant-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_subjects containing one row for each subject (across all periods). Note that we are not discarding any response data. Rather, we discard columns that are automatically recorded by the stimulus web application and help the application run.\nNote that we discard some columns representing scores calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook.\n\n\nCODE\n#IMPORT PARTICIPANT DATA\n\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_participants.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_participants.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_participants.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_participants.rds\"\n\n#read datafiles, set mode and term\ndf_subjects_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_subjects_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_subjects_fall21 <- read.csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_subjects_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_subjects <- df_subjects_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  gender,age,language, schoolyear, country,\n  effort,difficulty,confidence,enjoyment,other,\n  totaltime_m,absolute_score\n)\n\n#reduce data collected using OLD webapp to useful columns\ndf_subjects_before <- rbind(df_subjects_fall17, df_subjects_spring18, df_subjects_fall21) %>% \n  #rename and summarize some columns\n  mutate(\n    totaltime_m = totalTime / 1000 / 60,  \n    absolute_score = triangular_score,\n    language = native_language,\n    gender = sex,\n    schoolyear = year) %>% \n  #create placeholders for cols not collected until NEW webapp [for later rbind]\n  mutate(\n    effort = \"NULL\",\n    difficulty = \"NULL\",\n    confidence = \"NULL\",\n    enjoyment = \"NULL\",\n    other = \"NULL\",\n    disability = \"NULL\"\n  ) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select(subject, condition, term, mode, \n                #demographics\n                gender, age, language, schoolyear, country,\n                #placeholder effort survey\n                effort, difficulty, confidence, enjoyment, \n                #placeholder misc \n                other, disability,\n                #response characteristics\n                totaltime_m, absolute_score)\n\n#save 'explanation' columns from winter22, which is actually a response to a free response item (Q16); was recorded with item_level data in old webapp\ndf_winter22_q16 <- df_subjects_winter22 %>% \n  select(subject, condition, term , mode, explanation) %>% \n  mutate(\n    q = 16,\n    response = explanation\n  ) %>% select(-explanation)\n\n#reduce data collected using NEW webapp to useful columns\ndf_subjects_winter22 <- df_subjects_winter22 %>% \n  mutate(score = absolute_score) %>% \n  #select only columns we'll be analyzing, discard others\n  dplyr::select( subject, condition, term, mode, \n                 #demographics\n                 gender, age, language, schoolyear, country,\n                 #effort survey\n                 effort, difficulty, confidence, enjoyment, \n                 #explanations\n                 other,disability,\n                 #response characteristics\n                 totaltime_m, absolute_score)\n\n\neffort_labels <- c(\"I tried my best on each question\", \"I tried my best on most questions\")\n\n#combine dataframes from old and new webapps\ndf_subjects <- rbind(df_subjects, df_subjects_winter22, df_subjects_before) %>% \n  #refactor factors\n  mutate (\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    gender = factor(gender),\n    schoolyear = as.factor(schoolyear)\n  )\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_subjects$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_subjects$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_subjects$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_subjects$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_subjects$gender) <- \"What is your gender identity?\"\nvar_label(df_subjects$schoolyear) <- \"What is your year in school?\"\n\n#CLEANUP\nrm(df_subjects_fall17,df_subjects_fall21, df_subjects_spring18, df_subjects_winter22,df_subjects_before)\nrm(fall17,fall21,spring18,winter22)\n\n\n\n\n1.1.2 Items\nNext we import item-level data from each data collection period, selecting only the columns relevant for analysis, and renaming columns to be consistent across each file. The result is a single data frame df_items containing one row for each graph comprehension task question (qs=15) (across all periods). A second data frame df_freeresponse contains one row for each free response strategy question (last question posed to participants in Winter2022) Note that we do not discard any response data. Rather, we do discard several columns representing accuracy scores for responses that were calculated in the stimulus engine. These scores were calculated differently across collection periods, and so we discard them and recalculate scores in the next analysis notebook. Original response data are always preserved.\n\n\nCODE\n#set datafiles\nfall17 <- \"data/session-level/fall17_sgc3a_blocks.csv\"\nspring18 <- \"data/session-level/spring18_sgc3a_blocks.csv\"\nfall21 <- \"data/session-level/fall21_sgc3a_blocks.csv\"\nwinter22 <- \"data/session-level/winter22_sgc3a_items.rds\"\n\n#read datafiles, set mode and term\ndf_items_fall17 <- read.csv(fall17) %>% mutate(mode = \"lab-synch\", term = \"fall17\")\ndf_items_spring18 <- read.csv(spring18) %>% mutate(mode = \"lab-synch\", term = \"spring18\")\ndf_items_fall21 <- read.csv(fall21) %>% mutate(mode = \"asynch\", term = \"fall21\")\ndf_items_winter22 <- read_rds(winter22) #use RDS file as it contains metadata\n\n#get mapping being question # and interval relation the question tests, that is encoded only in the winter22 data files\nmap_relations <- df_items_winter22 %>% group_by(q) %>% select(q,relation) %>% unique()\n\n\n#SAVE METADATA FROM WINTER, but no rows \ndf_items <- df_items_winter22 %>% filter(condition=='X') %>% select(\n  subject,condition,term,mode,\n  question, q, answer, correct, rt_s\n) \n  \n#reduce data collected using old webapp\ndf_items_before <- rbind(df_items_fall17, df_items_spring18, df_items_fall21) %>% \n  mutate(rt_s = rt / 1000, correct = as.logical(correct)) %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) \n  \n#reduce data collected using new webapp\ndf_items_winter22 <- df_items_winter22 %>% \n  select(subject, condition, term, mode, question, q, answer, correct, rt_s) %>% #unfactor before combine\n  mutate(\n    subject = as.character(subject),\n    condition = as.character(condition),\n    term = as.character(term),\n    mode = as.character(mode),\n    q = as.integer(q),\n    correct = as.logical(correct)\n  )\n\n#combine dataframes from old and new webapps\ndf_items <- rbind(df_items, df_items_winter22,df_items_before) %>% \n  #refactorize columns\n  mutate(\n    subject = factor(subject),\n    condition = factor(condition),\n    term = factor(term),\n    mode = factor(mode),\n    q = as.integer(q)) %>% \n  #rename answer column to RESPONSE \n  rename(response = answer) %>% \n  #remove all commas and make as character string\n  mutate(\n    response = str_remove_all(as.character(response), \",\"),\n    num_o = str_length(response)\n  )\n\n\n#FIX METADATA\n#Add metadata for columns that lost it [factors, for some reason!]\nvar_label(df_items$subject) <- \"ID of subject (randomly assigned in stimulus app).\"\nvar_label(df_items$condition) <- \"ID indicates randomly assigned condition (111 -> control, 121 -> impasse).\"\nvar_label(df_items$term) <- \"indicates if session was run with experimenter present or asynchronously\"\nvar_label(df_items$mode) <- \"indicates mode in which the participant completed the study\"\nvar_label(df_items$q) <- \"Question Number (in order)\"\nvar_label(df_items$correct) <- \"Is the response (strictly) correct? [dichotomous scoring]\"\nvar_label(df_items$response) <- \"options (datapoints) selected by the subject\"\nvar_label(df_items$num_o) <- \"number of options selected by the subject\"\n\n#HANDLE FREE RESPONSE QUESTION #16 \n#save `free response` Q#16 in its own dataframe\ndf_freeresponse <- df_items %>% filter(q == 16) %>% select(-question,-correct,-rt_s,-num_o)\n#add data from wi22 [stored on subject data]\ndf_freeresponse <- rbind(df_freeresponse, df_winter22_q16)\n#add question description\ndf_freeresponse <- df_freeresponse %>% mutate(\n    question = \"Please describe how to determine what event(s) start at 12pm?\",\n    response = as.character(response) #doesn't need to be factor\n  ) \n#remove 'free response' Q#16 from df_items\ndf_items <- df_items %>% filter (q != 16)\n\n#CLEANUP\nrm(df_items_fall17,df_items_fall21, df_items_spring18, df_items_winter22, df_items_before, df_winter22_q16)\nrm(fall17,fall21,spring18,winter22, map_relations)\n\n\n\n1.1.2.1 Validation\nNext, we validate that we have the complete number of item-level records based on the number of subject-level records\n\n\nCODE\n#the number of items should be equal to 15 x the number of subjects\nnrow(df_items) == 15* nrow(df_subjects) #TRUE\n\n\n[1] TRUE\n\n\nCODE\n#each subject should have 15 items\ndf_items %>% group_by(subject) %>% summarise(n = n()) %>% filter(n != 15) %>% nrow() == 0\n\n\n[1] TRUE"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#export",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#export",
    "title": "1  Harmonization",
    "section": "1.2 EXPORT",
    "text": "1.2 EXPORT\nFinally, we export the (session-harmonized) data for analysis, as CSVs, and .RDS (includes metadata)\n\n\nCODE\n#SAVE FILES\nwrite.csv(df_subjects,\"data/sgc3a_participants.csv\", row.names = FALSE)\nwrite.csv(df_items,\"data/sgc3a_items.csv\", row.names = FALSE)\nwrite.csv(df_freeresponse,\"data/sgc3a_items.csv\", row.names = FALSE)\n\n#SAVE R Data Structures \n#export R DATA STRUCTURES (include codebook metadata)\nrio::export(df_subjects, \"data/sgc3a_participants.rds\") # to R data structure file\nrio::export(df_items, \"data/sgc3a_items.rds\") # to R data structure file"
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#resources",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#resources",
    "title": "1  Harmonization",
    "section": "1.3 RESOURCES",
    "text": "1.3 RESOURCES\n\n\nCODE\nsessionInfo()\n\n\nR version 4.0.2 (2020-06-22)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS  10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] codebook_0.9.2  forcats_0.5.0   stringr_1.4.0   dplyr_1.0.2    \n [5] purrr_0.3.4     readr_1.4.0     tidyr_1.1.2     tibble_3.1.2   \n [9] ggplot2_3.3.5   tidyverse_1.3.0\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5        lubridate_1.7.9   assertthat_0.2.1  digest_0.6.27    \n [5] utf8_1.2.1        R6_2.5.0          cellranger_1.1.0  backports_1.2.1  \n [9] reprex_0.3.0      labelled_2.8.0    evaluate_0.14     httr_1.4.2       \n[13] pillar_1.6.1      rlang_0.4.11      curl_4.3          readxl_1.3.1     \n[17] rstudioapi_0.13   data.table_1.13.2 blob_1.2.1        rmarkdown_2.11   \n[21] foreign_0.8-80    htmlwidgets_1.5.2 munsell_0.5.0     broom_0.7.12     \n[25] compiler_4.0.2    modelr_0.1.8      xfun_0.29         pkgconfig_2.0.3  \n[29] htmltools_0.5.2   tidyselect_1.1.0  rio_0.5.16        fansi_0.5.0      \n[33] crayon_1.4.1      dbplyr_1.4.4      withr_2.4.2       grid_4.0.2       \n[37] jsonlite_1.7.1    gtable_0.3.0      lifecycle_1.0.0   DBI_1.1.0        \n[41] magrittr_2.0.1    scales_1.1.1      zip_2.1.1         cli_3.3.0        \n[45] stringi_1.7.3     fs_1.5.0          xml2_1.3.2        ellipsis_0.3.2   \n[49] generics_0.0.2    vctrs_0.3.8       openxlsx_4.2.3    tools_4.0.2      \n[53] glue_1.6.2        hms_0.5.3         fastmap_1.1.0     yaml_2.2.1       \n[57] colorspace_2.0-2  rvest_0.3.6       knitr_1.37        haven_2.3.1"
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#introduction",
    "href": "analysis/SGC3A/SGC3A.html#introduction",
    "title": "SGC3A",
    "section": "INTRODUCTION",
    "text": "INTRODUCTION\nIn Study 3A we explore a hypothesis that emerged from analysis of Study 2, namely that presenting a learning with a situation that induces a state of impasse will increase the probability that learners experience a moment of insight, and in turn restructure their interpretation of the coordinate system.\nIn the context of Study 2, an impasse state was (unintentionally) induced when the combination of question + data set yielded no available answer in the incorrect (cartesian) interpretation of the graph. In Study 3A, we test this hypothesis by comparing performance between a (treatment) group receiving impasse-inducing questions followed by normal questions, and a non-impasse control.\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\nFigure 1: Posing a mental impasse\n\n\nTo try the study yourself:\n\ncontrol condition\nimpasse condition\n\n\nHypotheses\nH1. Learners posed with impasse-inducing questions will be more likely to correct interpret the graph.\n\nH0. Learners posed with impasse-inducing questions will be no more likely to correctly interpret the graph."
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#methods",
    "href": "analysis/SGC3A/SGC3A.html#methods",
    "title": "SGC3A",
    "section": "METHODS",
    "text": "METHODS\n\nDesign\nWe employed a mixed design with 1 between-subjects factor with 2 levels (Scaffold: control, impasse) and 15 items (within-subjects factor).\nIndependent Variables:\n\nB-S (Scaffold: control,impasse)\nW-S (Item x 15)\n\nDependent Variables:\n\nResponse Latency : Time from stimulus onset to clicking ‘Submit’ button: time in (s)\nResponse Accuracy : Is the response triangular-correct?\n(derived) Interpretation : With which interpretation of the graph is the subject’s response on an individual question consistent?\n\n\n\nMaterials\nStimuli consisted of a series of 15 graph comprehension questions, each testing a different combination of time interval relations, to be read from a Triangular-Model graph. Figure 2. The list of questions can be found here.\n\n\n\nFigure 2: Sample Question (Q=1) for Graph Comprehension Task\n\n\nNote that across both control and impasse conditions, both the question, response options and graph structure were identical. The experimental manipulation (posing a mental impasse) was accomplished by changing the position of datapoints in the impasse-condition graph, such that for any given question, there was no available response option if the reader were to interpret the graph as cartesian (making an orthogonal rather than diagonal projection from the x-axis.)\nThe green line indicates the ideal-scanpath to the correct (triangular) answer to the first question, and the red line indicates the (incorrect) orthogonal interpretation. In the IMPASSE figure (at right), there are no data points that intersect the red line.\n\n\n\nFigure 3: Sample Question (Q=1) graphs for each condition\n\n\n\n\nProcedure\nParticipants completed the study via a web-browser. Upon starting, they submitted informed consent, before reading task instructions. Participants were introduced to a scenario in which they were to play the role of a project manager, scheduling shifts for a group of employees. The schedule of the employees was presented in a TriangularModel (TM) graph, and they would be answering question about the schedule. Then participants completed a test block of 15 items. In the IMPASSE condition, the first five questions included an IMPASSE problem state. For participants in the CONTROL condition, the dataset was structure such that there was always an available ‘orthogonal answer’ for the first 5 questions. In both conditions, the remaining 10 questions were not structured as impasse. Following the test block, participants answered a free-response question about their strategy for reading the graph, followed by a demographic questionnaire and debrief.\n\n\nSample\nData was collected by convenience sample of a university subject pool. Initial data (Fall 2017, Spring 2018) were collected in-person, with large groups of students simultaneously completing the study (independently) in a computer lab. In Fall 2021 and Winter 2022 we collected additional data to replicate results in a remote format (students completing the study asynchronously on their own computers)."
  },
  {
    "objectID": "analysis/SGC3A/SGC3A.html#analysis",
    "href": "analysis/SGC3A/SGC3A.html#analysis",
    "title": "SGC3A",
    "section": "ANALYSIS",
    "text": "ANALYSIS\n\nData Preparation\nBefore our data can be analyzed, data files from individual data collection periods must be harmonized into a common data format (Section 1).\n\n\nResponse Scoring\nBecause the graph comprehension task utilizes a Multiple-Response (MR) format (rather than simple multiple choice), the raw response data (the combination of answer options selected) for each question first need to be assigned a score. Approaches to scoring MR data and score transformations are derived in Section 2."
  },
  {
    "objectID": "analysis/SGC3A/1_sgc3A_harmonize.html#introduction",
    "href": "analysis/SGC3A/1_sgc3A_harmonize.html#introduction",
    "title": "1  Harmonization",
    "section": "1.1 INTRODUCTION",
    "text": "1.1 INTRODUCTION\nData for study SGC_3A were collected across four time periods, interrupted by the Covid-19 pandemic.\n\n\n\nPeriod\nModality\n\n\n\n\nFall 2017\nin person, SONA groups in computer lab\n\n\nSpring 2018\nin person, SONA groups in computer lab\n\n\nFall 2021\nasynchronous, online, SONA\n\n\nWinter 2022\nasynchronous, online, SONA\n\n\n\nData collected in Fall 2017, Spring 2018 constitute the original SGC_3A study, conducted in person. Data collected in Fall 2021, Winter 2022 constitute the web-based replication, conducted online (asynchronously). In all cases, the experiment was administered via a web application."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html",
    "title": "3  Exploration",
    "section": "",
    "text": "THIS NOTEBOOK IS INCOMPLETE\nTODO\nThe purpose of this notebook is explore the distribution of dependent variables for Study SGC3A."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#data-structure",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#data-structure",
    "title": "3  Exploration",
    "section": "3.1 Data Structure",
    "text": "3.1 Data Structure\nData was initially collected (in person, SONA groups in computer lab) in Fall 2017. In Spring 2018, additional data were collected after small modifications were made to the experimental platform to increase the size of multiple-choice input buttons, and to add an additional free-response question following the main task block. In Fall 2021, the study was replicated using asynchronous, online SONA pool.\n\n\nCODE\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl() %>%  kable_classic()\n\n\n\n \n  \n      \n    111 \n    121 \n    Sum \n  \n \n\n  \n    winter22 \n    28 \n    37 \n    65 \n  \n  \n    fall17 \n    27 \n    27 \n    54 \n  \n  \n    spring18 \n    35 \n    37 \n    72 \n  \n  \n    fall21 \n    68 \n    71 \n    139 \n  \n  \n    Sum \n    158 \n    172 \n    330"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#participants",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#participants",
    "title": "3  Exploration",
    "section": "3.2 Participants",
    "text": "3.2 Participants\n\n\nCODE\n#Describe participants\nsubject.stats <- rbind(\n  \"lab\"= df_subjects %>% filter(mode == 'lab-synch') %>% select(age) %>% unlist() %>% favstats(),\n  \"online\" = df_subjects %>% filter(mode == \"asynch\") %>% select(age) %>% unlist() %>% favstats()\n) \nsubject.stats$female <- c(\n  (df_subjects %>% filter(mode == 'lab-synch') %>%  filter(gender==\"Female\") %>% count())$n,\n  (df_subjects %>% filter(mode == \"asynch\") %>% filter(gender==\"Female\") %>% count())$n\n)\n\n\nFor in-person collection, 126 participants (60 % female ) undergraduate STEM majors at a public American University participated in person in exchange for course credit (age: 18 - 33 years). Participants were randomly assigned to one of two experimental groups.\nFor online replication 204 participants (70 % female ) undergraduate STEM majors at a public American University participated online, asynchronously in exchange for course credit (age: 18 - 31 years). Participants were randomly assigned to one of two experimental groups."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#sample",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#sample",
    "title": "3  Exploration",
    "section": "3.1 Sample",
    "text": "3.1 Sample\n\n3.1.1 Data Collection\nData was initially collected (in person, SONA groups in computer lab) in Fall 2017. In Spring 2018, additional data were collected after small modifications were made to the experimental platform to increase the size of multiple-choice input buttons, and to add an additional free-response question following the main task block. In Fall 2021, the study was replicated using asynchronous, online SONA pool, with additional participants collected in Winter 2022.\n\n\nCODE\ntitle = \"Participants by Condition and Data Collection Period\"\ncols = c(\"Control Condition\",\"Impasse Condition\",\"Total for Period\")\ncont <- table(df_subjects$term, df_subjects$condition)\ncont %>% addmargins() %>% kbl(caption = title, col.names = cols) %>%  kable_classic()\n\n\n\nParticipants by Condition and Data Collection Period\n \n  \n      \n    Control Condition \n    Impasse Condition \n    Total for Period \n  \n \n\n  \n    winter22 \n    28 \n    37 \n    65 \n  \n  \n    fall17 \n    27 \n    27 \n    54 \n  \n  \n    spring18 \n    35 \n    37 \n    72 \n  \n  \n    fall21 \n    68 \n    71 \n    139 \n  \n  \n    Sum \n    158 \n    172 \n    330 \n  \n\n\n\n\n\n\n\n3.1.2 Participants\n\n\nCODE\n#Describe participants\nsubject.stats <- rbind(\n  \"lab\"= df_subjects %>% filter(mode == 'lab-synch') %>% select(age) %>% unlist() %>% favstats(),\n  \"online\" = df_subjects %>% filter(mode == \"asynch\") %>% select(age) %>% unlist() %>% favstats()\n) \nsubject.stats$female <- c(\n  (df_subjects %>% filter(mode == 'lab-synch') %>%  filter(gender==\"Female\") %>% count())$n,\n  (df_subjects %>% filter(mode == \"asynch\") %>% filter(gender==\"Female\") %>% count())$n\n)\n\ntitle = \"Descriptive Statistics of Participant Age and Gender\"\nsubject.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Participant Age and Gender\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n    female \n  \n \n\n  \n    lab \n    18 \n    19 \n    20 \n    21 \n    33 \n    20.4 \n    2.12 \n    126 \n    0 \n    78 \n  \n  \n    online \n    18 \n    20 \n    20 \n    21 \n    31 \n    20.6 \n    2.00 \n    204 \n    0 \n    137 \n  \n\n\n\n\n\nFor in-person collection, 126 participants (60 % female ) undergraduate STEM majors at a public American University participated in person in exchange for course credit (age: 18 - 33 years). Participants were randomly assigned to one of two experimental groups.\nFor online replication 204 participants (70 % female ) undergraduate STEM majors at a public American University participated online, asynchronously in exchange for course credit (age: 18 - 31 years). Participants were randomly assigned to one of two experimental groups."
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#response-accuracy",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#response-accuracy",
    "title": "3  Exploration",
    "section": "3.2 Response Accuracy",
    "text": "3.2 Response Accuracy\n\n3.2.1 Cumulative Scores\nCumulative scores indicate the response accuracy by participant across all items in the graph comprehension task.\n\n3.2.1.1 Cumulative Absolute Score\nRecall from Section 2.1.2.1 that the absolute score (following the dichotomous scoring approach) indicates if the subject’s response for a particular item was perfectly correct: whether they selected all correct answer options and no others. The absolute score for an individual item is either 0 or 1. When cumulated across the entire set of items, the cumulative absolute score for an individual subject ranges from [0,15].\n\n\nCODE\ntitle = \"Descriptive Statistics of Response Accuracy (Absolute Score)\"\nabs.stats <- rbind(\n  \"lab\"= df_subjects %>% filter(mode == 'lab-synch') %>% select(absolute_score) %>% unlist() %>% favstats(),\n  \"online\" = df_subjects %>% filter(mode == \"asynch\") %>% select(absolute_score) %>% unlist() %>% favstats()\n) \nabs.stats %>% kbl (caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Accuracy (Absolute Score)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    1 \n    2 \n    3 \n    11 \n    15 \n    5.81 \n    4.89 \n    126 \n    0 \n  \n  \n    online \n    0 \n    2 \n    2 \n    8 \n    15 \n    4.64 \n    4.73 \n    204 \n    0 \n  \n\n\n\n\n\nFor in person collection, cumulative absolute scores (n = 126) range from 1 to 15 with a mean score of (M = 5.81, SD = 4.89).\nFor online replication, (online) cumulative accuracy scores (n = 204) range from 0 to 15 with a mean score of (M = 4.64, SD = 4.73).\n\n\nCODE\n#VISUALIZE distribution of response accuracy\nplab <- gf_dhistogram(~absolute_score, data = df_subjects) %>%\n  gf_vline(xintercept = ~abs.stats[\"lab\",]$mean, color = \"blue\") +\n  labs(title=\"Lab\", x = \"Cumulative Absolute Score\", y=\"% of subjects\") + theme_minimal()\n\nponline <- gf_dhistogram(~absolute_score, data = df_subjects) %>%\n  gf_vline(xintercept = ~abs.stats[\"online\",]$mean, color = \"blue\") +\n  labs(title=\"Online\", x = \"Cumulative Absolute Score\", y=\"% of subjects\") + theme_minimal()\n\nplot <-ggarrange(plab, ponline, common.legend = TRUE, nrow = 1, ncol =2)\nannotate_figure(plot, top = text_grob(\"Cumulative Absolute Accuracy Score by Study\",\n   color = \"black\", face = \"bold\", size = 14))\n\n\n\n\n\nTODO double check that the subject-totals match the sum of the item level totals\n\n\n3.2.1.2 Cumulative Interpretation Scores\n\n\n\n3.2.2 Item Score\nItem scores indicate the response accuracy by a participant on each individual question in the graph comprehension task.\n\n3.2.2.1 Item Absolute Score\n\n\n3.2.2.2 Item Interpretation Scores"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#response-latency",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#response-latency",
    "title": "3  Exploration",
    "section": "3.3 Response Latency",
    "text": "3.3 Response Latency\n\nTODO: Investigate super high and super low response times..\nTODO: Investigate appropriate models for response time data. (see: https://lindeloev.github.io/shiny-rt/).\nEspecially see https://lindeloev.github.io/shiny-rt/ for ideas on modelling reaction time data\n\n\n3.3.1 Time on Study\n\n\nCODE\n#DESCRIBE distribution of response time\ntime.stats <- rbind(\n  \"lab\"= df_subjects %>% filter(mode == 'lab-synch') %>% select(totaltime_m) %>% unlist() %>% favstats(),\n  \"online\"= df_subjects %>% filter(mode == 'asynch') %>% select(totaltime_m) %>% unlist() %>% favstats()\n)\n\ntitle = \"Descriptive Statistics of Response Latency (Time on Study)\"\ntime.stats %>% kbl(caption = title) %>% kable_classic()\n\n\n\nDescriptive Statistics of Response Latency (Time on Study)\n \n  \n      \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    lab \n    6.01 \n    10.50 \n    12.2 \n    14.4 \n    23.9 \n    12.8 \n    3.37 \n    126 \n    0 \n  \n  \n    online \n    2.91 \n    9.18 \n    11.5 \n    15.0 \n    111.0 \n    13.4 \n    9.21 \n    204 \n    0 \n  \n\n\n\n\n\nTotal time on study for in person subjects (n = 126) ranged from 6.01 to 23.86 minutes with a mean duration of (M = 12.8, SD = 3.37).\nTotal time on study for online replication subjects (n = 204) ranged from 2.91 to 111.02 minutes with a mean duration of (M = 13.37, SD = 9.21).\n\n\nCODE\n#VISUALIZE distribution of response time\nplab <- gf_dhistogram(~totaltime_m, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"lab\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist=\"gamma\", color=\"red\")+\n  labs(title=\"Lab\", x = \"Total Time (mins)\", y = \"% subjects\") +  theme_minimal()\n\nponline <- gf_dhistogram(~totaltime_m, data = df_subjects) %>%\n  gf_vline(xintercept = ~time.stats[\"online\",]$mean, color = \"black\") %>% \n  gf_fitdistr(dist = \"gamma\", color=\"red\")+\n  labs(title=\"Online\", x = \"Total Time (mins)\", y = \"% subjects\") +  theme_minimal()\n\nplot <-ggarrange(plab, ponline, common.legend = TRUE, nrow = 1, ncol =2)\n\nannotate_figure(plot, \n                top = text_grob(\"Total Time by Study Mode\",color = \"black\", face = \"bold\", size = 14),\n                bottom = text_grob(\"fit by Gamma distribution\", face = \"italic\", size = 10))\n\n\n\n\n\nTODO consider log transform of response latency data see archive sgc3A_participants.Rmd\n\n\n3.3.2 Time on Question\nTODO time on question"
  },
  {
    "objectID": "analysis/SGC3A/3_sgc3A_exploration.html#resources",
    "href": "analysis/SGC3A/3_sgc3A_exploration.html#resources",
    "title": "3  Exploration",
    "section": "3.4 Resources",
    "text": "3.4 Resources\n\nhttps://rpkgs.datanovia.com/ggpubr/reference/index.html"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#introduction",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#introduction",
    "title": "2  Response Scoring",
    "section": "2.1 INTRODUCTION",
    "text": "2.1 INTRODUCTION\nThe graph comprehension task of study SGC 3A presents readers with a graph, a question, and a series of checkboxes. Participants are instructed to use the graph to answer the question, and respond by selecting all the checkboxes that apply, where each checkbox corresponds to a datapoint in the graph.\n\n\n\nFigure 1. Sample Graph Comprehension (Question # 6)\n\n\nIn the psychological and education literatures on Tests & Measures, the format of this type of question is referred to as Multiple Response (MR), (also: Multiple Choice Multiple Answer (MCMA) and Multiple Answer Multiple Choice (MAMC)). It has a number of properties that make it different from traditional Single Answer Multiple Choice (SAMC) questions, where the respondent marks a single response from a number of options. In particular, there are a number of very different ways that MAMC questions can be scored.\nIn tranditional SAMC format questions, one point is given for selecting the option designated as correct, and zero points given for marking any of the alternative (i.e. distractor) options. Individual response options on MAMC questions, however might be partially correct (\\(i\\)), while responses on other answer options within the same item might be incorrect (\\(n – i\\)). In MAMC, it is not obvious how to allocate points when the respondent marks a true-correct option (i.e. options that should be selected), as well as one or more false-correct options (i.e. options that should not be selected). Should partial credit be awarded? If so, are options that respondents false-selected and false-unselected items equally penalized?\nSchmidt et al. (2021) performed a systematic literature review of publications proposing MAMC (or equivalent) scoring schemes, ultimately synthesizing over 80 sources into 27 distinct scoring approaches. Upon reviewing the benefits of trade-offs of each approach, for this study we choose utilize two of the schemes: dichotomous scoring ( Schmidt et al. (2021) scheme #1), and partial scoring \\([-1/q,0, +1/p]\\) ( Schmidt et al. (2021) scheme #26), as well as a scaled discriminant score that leverages partial scoring to discriminate between strategy-specific patterns of response.\n\n2.1.1 Response Encoding\nFirst, we note that the question type evaluated by Schmidt et al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 2.1: Figure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 2.1), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can be encoded as [TTFF].\n\n\n\n\n\n\nDecision\n\n\n\nIn our analysis, we will transform the MAMC response string recorded for the participant (given in column response), to an MTF encoding.\n\n\n\n\n2.1.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\n\\]\nProperties of the Subject’s Response\n\\[\n  \\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\n\\]\n\n2.1.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only correct-select options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\nIn Dichotomous Scoring\n\nscore for the question is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nCODE\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n2.1.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et al. (2021) identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach ( Schmidt et al. (2021) #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\nSchmidt et al. (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where there are many more response options \\(n\\) than there are options meant to be selected \\(p\\), this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n  \\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n\n\nCODE\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n\n\n\n2.1.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. “select all correct options”) vs MTF (i.e. “Mark each option as true or false”) questions.\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt et al. (2021) method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts \\(1/(n-p) = 1/q\\) for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n\\]\nProperties of Response\n\\[\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nCODE\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  return( (t / p) - (f/q))\n}\n\n\n\n\n2.1.2.4 Comparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    i  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial[-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A____ \n    5 \n    1 \n    1.0 \n    1.00 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB___ \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    A___E \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    AB__E \n    3 \n    0 \n    0.2 \n    0.50 \n  \n  Only Incorrect Selections\n\n    A____ \n    ____E \n    3 \n    0 \n    0.2 \n    -0.25 \n  \n  \n    A____ \n    ___DE \n    2 \n    0 \n    -0.2 \n    -0.50 \n  \n  Completely Inverse Response \n\n    A____ \n    _BCDE \n    0 \n    0 \n    -1.0 \n    -1.00 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABCDE \n    1 \n    0 \n    -0.6 \n    0.00 \n  \n  \n    A____ \n    _____ \n    4 \n    0 \n    0.6 \n    0.00 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt)\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    $i$  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial [-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A__...__ \n    15 \n    1 \n    1.000 \n    1.000 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB_...__ \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    A__..._O \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    AB_..._O \n    13 \n    0 \n    0.733 \n    0.857 \n  \n  Only Incorrect Selections\n\n    A____ \n    ___..._O \n    13 \n    0 \n    0.733 \n    -0.071 \n  \n  \n    A____ \n    ___...NO \n    12 \n    0 \n    0.600 \n    -0.143 \n  \n  Completely Inverse Response \n\n    A____ \n    _BC...NO \n    0 \n    0 \n    -1.000 \n    -1.000 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABC...NO \n    1 \n    0 \n    -0.867 \n    0.000 \n  \n  \n    A____ \n    ___...__ \n    14 \n    0 \n    0.867 \n    0.000 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt, abs,correct,i,names,partial1,partial2,response,title)\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n\n\n\n\n\nDecision\n\n\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options."
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#score-the-data",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#score-the-data",
    "title": "2  Response Scoring",
    "section": "2.3 SCORE THE DATA",
    "text": "2.3 SCORE THE DATA\nIn SGC_3A we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehensiontask asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key.\n5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing stategy) answer key.\n\n2.3.1 Prepare Answer Keys\nWe start by importing the answer keys for each stimulus set. For each stimulus set (defined by condition+task phase) an answer key file exist that defines the set of response options that indicate each graph interpretation.\n\n\nCODE\nkey_111_raw <- read_csv('keys/SGC3A_scaffold_111_key.csv') %>% mutate(condition = 111, phase = \"scaffold\")\nkey_121_raw <- read_csv('keys/SGC3A_scaffold_121_key.csv')%>% mutate(condition = 121, phase = \"scaffold\")\nkey_test_raw <- read_csv('keys/SGC3A_test_key.csv')%>% mutate(condition = \"\", phase = \"test\")\n\nkeys_raw <- rbind(key_111_raw, key_121_raw, key_test_raw)\nrm(key_111_raw, key_121_raw, key_test_raw)\n\n\nIn order to calculate scores using the \\([-1/q, +1/p]\\) algorithm, we need to define the subset of all response options (set N) that should be selected (set P) and should not be selected (set Q). In order to calculate subscores for each graph interpretation (triangular, orthogonal) we must define these sets independently for each interpretation. The answer key files the ‘correct’ answer (i.e. set P) for each interpretation, for each question. We must derive the contents of set Q based on set\n\nSET N = all response options (superset) \\(N\\)\nSET P = all options that should be selected (rewarded as +1/p) \\(P \\subset N\\)\nSET A = items that should not be selected, but if they are, don’t penalize (ignored) \\(A \\subset N\\)\nSET Q = all options that should NOT be selected (penalized as -1/q) \\(Q = N - (P \\cup A)\\)\n\n\n\nCODE\nverify = c() #sanity check\n\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT ORTHOGONAL KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_orth <- keys_raw %>% \n  select(Q, condition, OPTIONS, ORTHOGONAL, ORTHve, ALSO, TRIANGULAR) %>% \n  mutate(\n    \n    #replace NAs \n    ORTHve = str_replace_na(ORTHve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = ORTHOGONAL,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(ORTHve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_orth)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_orth[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_orth[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_orth[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_orth[x,'set_q'] = Q\n  keys_orth[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_orth <- keys_orth %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TRIANGULAR KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tri <- keys_raw %>% \n  select(Q, condition, OPTIONS, TRIANGULAR, TRIve, ALSO, ORTHOGONAL) %>% \n  mutate(\n    \n    #replace NAs \n    TRIve = str_replace_na(TRIve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TRIANGULAR,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TRIve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_tri)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tri[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tri[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tri[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tri[x,'set_q'] = Q\n  keys_tri[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tri <- keys_tri %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n\n\nThis leaves us with two dataframes keys_orth and keys_tri that define the sets of response options consistent with each graph interpretation\nTo verify we have generated the correct sets, we verify that for each row (question), each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE **TODO TROUBLESHOOT FALSE; THINK THIS IS BECAUSE KEY FILE IS INCOMPLETE FOR ALL BUT RAW 111\n\n\n2.3.2 Score Items\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (keys_orth, keys_tri), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item, and can be used to determine which graph interpretation the subject held.\nscore_TRI (how triangular was the subject’s response?) score_ORTH(how orthogonal was the subject’s response)\n\n\nCODE\ndf_items <- read_rds('data/sgc3a_items.rds')\ndf_items <- df_items %>% filter(q < 6) %>% filter(condition == 111)\n\n\nnote: this cell takes approximately 3 minutes to run\n\n\nCODE\n##———————————————————————————————————————————————————————————————\n##CALCULATE P AND Q for ORTH AND TRI\n##———————————————————————————————————————————————————————————————\n#for each response (row), calculate p_s and q_s for that question\nfor (x in 1:nrow(df_items)) {\n\n  #get properties of the RESPONSE ITEM\n  qu = df_items[x,'q']\n  cond = df_items[x,'condition']\n  r = df_items[x,'response'] %>% str_split(\"\") %>% unlist()\n  \n  #get KEYS for this question for this condition\n  if (qu < 6) { \n    \n    #get triangular keys\n    tri_p = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    tri_q = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    tri_pn = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_p)\n    tri_qn = keys_tri %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_q)\n    \n    #get orthogonal keys\n     orth_p = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_q = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n     orth_pn = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_p)\n     orth_qn = keys_orth %>% filter(Q == qu) %>% filter(condition == cond) %>% select(n_q)\n    \n  } else {\n    \n    #get triangular keys\n    tri_p = keys_tri %>% filter(Q == qu) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    tri_q = keys_tri %>% filter(Q == qu) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    tri_pn = keys_tri %>% filter(Q == qu)  %>% select(n_p)\n    tri_qn = keys_tri %>% filter(Q == qu)  %>% select(n_q)\n    \n    #get orthogonal keys\n    orth_p = keys_orth %>% filter(Q == qu) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    orth_q = keys_orth %>% filter(Q == qu) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    orth_pn = keys_orth %>% filter(Q == qu) %>% select(n_p)\n    orth_qn = keys_orth %>% filter(Q == qu) %>% select(n_q)\n  }\n  \n  #calculate and save qs and ps\n  tri_ps = length(intersect(r,tri_p))\n  tri_qs = length(intersect(r,tri_q))\n  orth_ps = length(intersect(r,orth_p))\n  orth_qs = length(intersect(r,orth_q))\n  \n  df_items[x,'tri_ps'] = tri_ps\n  df_items[x,'tri_qs'] = tri_qs\n  df_items[x,'orth_ps'] = orth_ps\n  df_items[x,'orth_qs'] = orth_qs\n \n  #calculate subscores\n  # f_partialP <- function(t,p,f,q) \n  df_items[x,'score_TRI'] = f_partialP(tri_ps,tri_pn,tri_qs,tri_qn)\n  df_items[x,'score_ORTH'] = f_partialP(orth_ps,orth_pn,orth_qs,orth_qn)\n}\n\n#ALSO recast absolute score as integer based on boolean 'correct\ndf_items$score_ABS <- as.integer(df_items$correct)\n\n#cleanup\nrm(orth_pn, orth_p, orth_qn, orth_q, orth_ps, orth_qs,  tri_pn, tri_p, tri_qn, tri_q, tri_ps, tri_qs, qu, cond, r,x)\n\n\n\n\nCODE\ntest <- df_items %>% filter(q<6) %>% filter(condition == 111)\n\ngf_histogram(~score_TRI, data = test)\n\n\n\n\n\nCODE\ngf_histogram(~score_ORTH, data = test)\n\n\n\n\n\nCODE\ngf_histogram(~score_ABS, data = test)"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#explore-responses",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#explore-responses",
    "title": "2  Response Scoring",
    "section": "2.4 EXPLORE RESPONSES",
    "text": "2.4 EXPLORE RESPONSES\nIn this section we explore responses given by participants to each particular item in the graph comprehension task, and indicate how each response was scored, and what interpretation of the graph is indicated.\n\n2.4.1 Control Condition\n\n\nCODE\n# title = \"Answer Key for Control Condition Scaffold Phase (Q1 - Q5)\"\n# cols = c(\"Q\",\"Relation\",\"selected\",\"allow\",\"selected\",\"allow\",\"tversky\",\"satisfice\",\"IGNORE\")\n# keys_raw %>% filter(condition == 111) %>% mutate(\n#   IGNORE = replace_na(ALSO, \"\"),\n#   t_ignore = replace_na(TRIve, \"\"),\n#   o_ignore = replace_na(ORTHve, \"\")\n#   ) %>% select(Q, RELATION,TRIANGULAR, t_ignore, ORTHOGONAL, o_ignore, TVERSKY, SATISFICE, IGNORE) %>% \n#   kbl(caption = title, col.names = cols) %>% kable_classic() %>%\n#   add_header_above(c(\" \" = 2, \"Triangular\" = 2, \"Orthogonal\" = 2, \" \"=3))\n\n\n\n\nCODE\nf_partialC <- function(ps,p,qs,q) {\n                       # gs,g) {\n\n  #penalty_q = penalty for selecting an incorrect option\n  #penalty_g = penalty for selecting an irrelevant option\n  \n  #ps = number of correct-selected options\n  #p = number of true options\n  \n  #qs = number of incorrect-selected options\n  #q = number of false options\n  \n  \n  #gs = number of irrelevantly selected options\n  #g = number of irrelevant options\n  \n  \n  #n = number of options + p + q\n  # return( (ps/p) - (qs/q) )\n}\n\n\n\n2.4.1.1 Question #1\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\nIn the ‘interpretation’ column we indicate which interpretation of the graph stimulus is indicated by each combination of response options. Note that ALL CAPS indicates the precise interpretation, while lowercase indicates a partially-consistent selection of options.\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\ninterpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"lines-connect\",\"(both ortho & tri)\",\"?\",\"?\",\"?\")\nnames = c(\"response\",\"n\",\"interpretation\",\"best guess\",\"strict\",\"nice\",\"tri\",\"orth\",\"tv_max\",\"tv_start\",\"tv_end\",\"tv_dur\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    strict = unique(score_ABS), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    tversky_max = unique(score_TV_max),\n                    tversky_start = unique(score_TV_start),\n                    tversky_end = unique(score_TV_end),\n                    tversky_duration = unique(score_TV_duration),\n                    best = unique(best)\n                    # DISC =  triangular - orthogonal\n                    # DISC = (score_TRI - score_ORTH) \n                    ) %>% arrange(-count) %>% \n    cbind(interpretation) %>% arrange(desc(interpretation)) %>%\n  select(response, count, interpretation, best, strict, nice, triangular, orthogonal, \n         tversky_max, tversky_start, tversky_end, tversky_duration) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 4, \"Strict Scores\" = 2, \"Interpretation Scores\"=6)) %>%\n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthongal\", 2, 2) %>% \n  pack_rows(\"Lines-Connect\", 3, 3) %>% \n  pack_rows(\"other\", 4, 7) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n\n\nStrict Scores\nInterpretation Scores\n\n  \n    response \n    n \n    interpretation \n    best guess \n    strict \n    nice \n    tri \n    orth \n    tv_max \n    tv_start \n    tv_end \n    tv_dur \n  \n \n\n  Triangular\n\n    F \n    22 \n    TRIANGULAR \n    score_TRI \n    1 \n    1 \n    1.000 \n    -0.083 \n    0.500 \n    1.000 \n    -0.071 \n     \n  \n  Orthongal\n\n    A \n    129 \n    ORTHOGONAL \n    score_ORTH \n    0 \n    0 \n    -0.077 \n    1.000 \n    -0.083 \n    -0.077 \n    -0.071 \n     \n  \n  Lines-Connect\n\n    CF \n    3 \n    lines-connect \n    score_TVERSKY \n    0 \n    0 \n    0.923 \n    -0.167 \n    1.000 \n    0.923 \n    0.929 \n     \n  \n  other\n\n    AF \n    1 \n    (both ortho & tri) \n    TRI + ORTH \n    0 \n    0 \n    0.923 \n    0.917 \n    0.417 \n    0.923 \n    -0.143 \n     \n  \n  \n    IJD \n    1 \n    ? \n    ? \n    0 \n    0 \n    -0.231 \n    -0.167 \n    -0.250 \n    -0.231 \n    -0.214 \n     \n  \n  \n    X \n    1 \n    ? \n    ? \n    0 \n    0 \n    -0.077 \n    -0.083 \n    -0.083 \n    -0.077 \n    -0.071 \n     \n  \n  \n    Z \n    1 \n    ? \n    ? \n    0 \n    0 \n    0.000 \n    -0.083 \n    0.000 \n    0.000 \n    -0.071 \n     \n  \n\n\n\n\n\nNearly all of the subjects selected a response consistent with one of the identified interpretations (indicated in all caps).\nNote that options highlighted in light grey are considered within the range of ‘visual error’.\n\n\n\n\n\n\n\nWhich shifts start at 11am?\n\n\n\n\n\n\nResponse: F\n\nTRI_score = 1\nORTH_score = -0.083\nindicates the triangular (correct) interpretation of the coordinate system\n\n\n\n\nResponse: A\n\nindicates an orthogonal (incorrect) interpretation of the coordinate system\n\n\n\n\nA number of alternative responses were given:\n\n\n\n\n\n\n\n\n\nAlternate Responses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.1.2 Question #2\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\n                     \"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\"ortho + satisfice\",\"TRIANGULAR\")\n\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n dplyr::summarise( count = n(), \n                    strict = unique(score_ABS), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    tversky_max = unique(score_TV_max),\n                    tversky_start = unique(score_TV_start),\n                    tversky_end = unique(score_TV_end),\n                    tversky_duration = unique(score_TV_duration),\n                    best = unique(best)\n                    # DISC =  triangular - orthogonal\n                    # DISC = (score_TRI - score_ORTH) \n                    ) %>% arrange(-count) %>% \n    cbind(interpretation) %>% arrange(desc(interpretation)) %>%\n  select(response, count, interpretation, best, strict, nice, triangular, orthogonal, \n         tversky_max, tversky_start, tversky_end, tversky_duration) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 4, \"Strict Scores\" = 2, \"Interpretation Scores\"=6)) %>%\n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthogonal\", 3, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 7) %>% \n  pack_rows(\"other\", 8, 10) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n\n\nStrict Scores\nInterpretation Scores\n\n  \n    response \n    n \n    interpretation \n    best guess \n    strict \n    nice \n    tri \n    orth \n    tv_max \n    tv_start \n    tv_end \n    tv_dur \n  \n \n\n  Triangular\n\n    K \n    24 \n    TRIANGULAR \n    score_TRI \n    1 \n    1 \n    1.000 \n    -0.083 \n    0.250 \n    0.500 \n    -0.077 \n    -0.0769230769230769 \n  \n  \n    KD \n    1 \n    TRIANGULAR \n    score_TRI \n    0 \n    1 \n    1.000 \n    -0.083 \n    0.250 \n    0.500 \n    -0.077 \n    -0.0769230769230769 \n  \n  Orthogonal\n\n    DE \n    3 \n    ORTHONGAL \n    score_ORTH \n    0 \n    0 \n    -0.083 \n    1.000 \n    -0.111 \n    -0.091 \n    -0.077 \n    -0.0769230769230769 \n  \n  \n    E \n    121 \n    ORTHOGONAL \n    score_ORTH \n    0 \n    0 \n    -0.083 \n    1.000 \n    -0.111 \n    -0.091 \n    -0.077 \n    -0.0769230769230769 \n  \n  \n    EG \n    1 \n    ortho + satisfice \n    score_ORTH \n    0 \n    0 \n    -0.167 \n    1.000 \n    -0.222 \n    -0.182 \n    -0.154 \n    -0.153846153846154 \n  \n  Lines-Connect\n\n    J \n    4 \n    LINES-CONNECT \n    score_TVERSKY \n    0 \n    0 \n    -0.083 \n    -0.083 \n    0.250 \n    -0.091 \n    -0.077 \n    1 \n  \n  \n    AK \n    1 \n    LINES-CONNECT \n    score_TVERSKY \n    0 \n    0 \n    0.917 \n    -0.167 \n    0.500 \n    1.000 \n    -0.154 \n    -0.153846153846154 \n  \n  other\n\n    D \n    1 \n    (reference point) \n    reference \n    0 \n    0 \n    0.000 \n    0.000 \n    0.000 \n    0.000 \n    0.000 \n    0 \n  \n  \n    B \n    1 \n     \n    ? \n    0 \n    0 \n    -0.083 \n    -0.083 \n    -0.111 \n    -0.091 \n    -0.077 \n    -0.0769230769230769 \n  \n  \n    C \n    1 \n     \n    ? \n    0 \n    0 \n    -0.083 \n    -0.083 \n    -0.111 \n    -0.091 \n    -0.077 \n    -0.0769230769230769 \n  \n\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\nWhich shift(s) start at the same time as D?\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\n\n\n\nAn incorrect orthogonal interpretation yields point K\n\n\n\n\n\n\n\n\n\n\n\n\nAlternative Responses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.1.3 Question #3\nPICK UP TROUBLESHOOTING INTERPRETATION ALGORITHM ABOVE, BASED ON MATCHES TO THESE SCORES HERE ::: {.cell}\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\"LINES-CONNECT\",\n                     \"lines-connect\",\"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\n                     \"\",\"\",\"\",\"\",\"\",\"\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n   dplyr::summarise( count = n(), \n                    strict = unique(score_ABS), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    tversky_max = unique(score_TV_max),\n                    tversky_start = unique(score_TV_start),\n                    tversky_end = unique(score_TV_end),\n                    tversky_duration = unique(score_TV_duration),\n                    best = unique(best)\n                    # DISC =  triangular - orthogonal\n                    # DISC = (score_TRI - score_ORTH) \n                    ) %>% arrange(-count) %>% \n    cbind(interpretation) %>% arrange(desc(interpretation)) %>%\n  select(response, count, interpretation, best, strict, nice, triangular, orthogonal, \n         tversky_max, tversky_start, tversky_end, tversky_duration) %>% \n  kbl(caption = title, col.names = names) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 4, \"Strict Scores\" = 2, \"Interpretation Scores\"=6)) %>%\n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 7) %>% \n  pack_rows(\"other\", 8, 17) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n\n\nStrict Scores\nInterpretation Scores\n\n  \n    response \n    n \n    interpretation \n    best guess \n    strict \n    nice \n    tri \n    orth \n    tv_max \n    tv_start \n    tv_end \n    tv_dur \n  \n \n\n  Triangular\n\n    F \n    24 \n    TRIANGULAR \n    score_TRI \n    1 \n    1 \n    1.000 \n    0.0 \n    0.167 \n    -0.083 \n    1.000 \n    -0.0909090909090909 \n  \n  Orthogonal\n\n    AUB \n    4 \n    ORTHONGAL \n    score_TVERSKY \n    0 \n    0 \n    -0.250 \n    -0.3 \n    0.500 \n    -0.250 \n    -0.250 \n    1 \n  \n  \n    Z \n    94 \n    ORTHOGONAL \n    score_ORTH \n    0 \n    0 \n    0.000 \n    1.0 \n    -0.125 \n    -0.083 \n    0.000 \n    -0.0909090909090909 \n  \n  Lines-Connect\n\n    A \n    18 \n    LINES-CONNECT \n    ? \n    0 \n    0 \n    -0.083 \n    -0.1 \n    0.167 \n    -0.083 \n    -0.083 \n    0.333333333333333 \n  \n  \n    K \n    3 \n    LINES-CONNECT \n    ? \n    0 \n    0 \n    -0.083 \n    -0.1 \n    -0.125 \n    -0.083 \n    -0.083 \n    -0.0909090909090909 \n  \n  \n    OJ \n    2 \n    LINES-CONNECT \n    score_TVERSKY \n    0 \n    0 \n    -0.167 \n    -0.1 \n    0.333 \n    1.000 \n    -0.167 \n    -0.181818181818182 \n  \n  \n    O \n    3 \n    lines-connect \n    score_TVERSKY \n    0 \n    0 \n    -0.083 \n    0.0 \n    0.167 \n    0.500 \n    -0.083 \n    -0.0909090909090909 \n  \n  other\n\n    C \n    1 \n    (reference point) \n    reference \n    0 \n    0 \n    0.000 \n    0.0 \n    0.000 \n    0.000 \n    0.000 \n    0 \n  \n  \n    AH \n    1 \n     \n    ? \n    0 \n    0 \n    -0.167 \n    -0.2 \n    0.042 \n    -0.167 \n    -0.167 \n    0.242424242424242 \n  \n  \n    AIOZFHJXKUDEGB \n    1 \n     \n    frenzy \n    0 \n    0 \n    0.000 \n    0.0 \n    0.000 \n    0.000 \n    0.000 \n    0 \n  \n  \n    DE \n    1 \n     \n    ? \n    0 \n    0 \n    -0.167 \n    -0.2 \n    -0.250 \n    -0.167 \n    -0.167 \n    -0.181818181818182 \n  \n  \n    E \n    1 \n     \n    ? \n    0 \n    0 \n    -0.083 \n    -0.1 \n    -0.125 \n    -0.083 \n    -0.083 \n    -0.0909090909090909 \n  \n  \n    FKE \n    1 \n     \n    score_TRI \n    0 \n    0 \n    0.833 \n    -0.2 \n    -0.083 \n    -0.250 \n    0.833 \n    -0.272727272727273 \n  \n  \n    OJD \n    1 \n     \n    score_TVERSKY \n    0 \n    0 \n    -0.250 \n    -0.2 \n    0.208 \n    0.917 \n    -0.250 \n    -0.272727272727273 \n  \n  \n    OK \n    1 \n     \n    score_TVERSKY \n    0 \n    0 \n    -0.167 \n    -0.1 \n    0.042 \n    0.417 \n    -0.167 \n    -0.181818181818182 \n  \n  \n    U \n    1 \n     \n    ? \n    0 \n    0 \n    -0.083 \n    -0.1 \n    0.167 \n    -0.083 \n    -0.083 \n    0.333333333333333 \n  \n  \n    UE \n    1 \n     \n    ? \n    0 \n    0 \n    -0.167 \n    -0.2 \n    0.042 \n    -0.167 \n    -0.167 \n    0.242424242424242 \n  \n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n2.4.1.4 Question #4\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-lines connect\",\"BLANK\",\"orth-lines connect\",\n                     \"lines-connect\",\"orthogonal\",\"\",\"\",\"\",\n                     \"\",\"\",\"\",\"\",\"\",\"\" )\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>%  dplyr::summarise( count = n(), \n                    strict = unique(score_ABS), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    DISC =  triangular - orthogonal\n                    # DISC = (score_TRI - score_ORTH) \n                    ) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  select(response, count, interpretation, strict, nice, triangular, orthogonal, DISC) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Scores\" = 2, \"Interpretation Scores\"=2, \" \"=1)) %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 6) %>% \n  pack_rows(\"other\", 7, 16) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Scores\nInterpretation Scores\n\n\n  \n    response \n    count \n    interpretation \n    strict \n    nice \n    triangular \n    orthogonal \n    DISC \n  \n \n\n  Triangular\n\n    H \n    29 \n    TRIANGULAR \n    1 \n    1 \n    1.000 \n    -0.071 \n    1.07 \n  \n  Orthogonal\n\n    U \n    87 \n    ORTHOGONAL \n    0 \n    0 \n    -0.071 \n    1.000 \n    -1.07 \n  \n  \n    FU \n    2 \n    orthogonal \n    0 \n    0 \n    -0.143 \n    0.929 \n    -1.07 \n  \n  \n    DE \n    14 \n    orth-lines connect \n    0 \n    0 \n    -0.143 \n    -0.143 \n    0.00 \n  \n  \n    E \n    6 \n    orth-lines connect \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  Lines-Connect\n\n    B \n    3 \n    lines-connect \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  other\n\n     \n    6 \n    BLANK \n    0 \n    0 \n    0.000 \n    0.000 \n    0.00 \n  \n  \n    K \n    2 \n     \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  \n    O \n    2 \n     \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  \n    AH \n    1 \n     \n    0 \n    0 \n    0.929 \n    -0.143 \n    1.07 \n  \n  \n    CAIOZFHJXKU \n    1 \n     \n    0 \n    0 \n    0.286 \n    0.286 \n    0.00 \n  \n  \n    D \n    1 \n     \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  \n    G \n    1 \n     \n    0 \n    0 \n    -0.071 \n    -0.071 \n    0.00 \n  \n  \n    KU \n    1 \n     \n    0 \n    0 \n    -0.143 \n    0.929 \n    -1.07 \n  \n  \n    OUDE \n    1 \n     \n    0 \n    0 \n    -0.286 \n    0.786 \n    -1.07 \n  \n  \n    UDE \n    1 \n     \n    0 \n    0 \n    -0.214 \n    0.857 \n    -1.07 \n  \n\n\n\n\n\nIn Question 4 we see more than one variant of an orthogonal interpretation emerge.\n\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\n2.4.1.5 Question #5\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-satistice\",\"BLANK\",\"orth-satisfice\",\n                     \"orth-satistice\",\"\",\"\",\"\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\n                     \"(reference point)\",\"\",\"\",\"\",\"lines-connect\")\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  dplyr::summarise( count = n(), \n                    strict = unique(score_ABS), \n                    nice = unique(score_niceABS),\n                    triangular = unique(score_TRI), \n                    orthogonal =  unique(score_ORTH),\n                    DISC =  triangular - orthogonal\n                    # DISC = (score_TRI - score_ORTH) \n                    ) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  select(response, count, interpretation, strict, nice, triangular, orthogonal, DISC) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  add_header_above(c(\" \" = 3, \"Strict Scores\" = 2, \"Interpretation Scores\"=2, \" \"=1)) %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 9) %>% \n  pack_rows(\"Lines Connect\", 10, 10) %>% \n  pack_rows(\"other\", 11, 22) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n\n\nStrict Scores\nInterpretation Scores\n\n\n  \n    response \n    count \n    interpretation \n    strict \n    nice \n    triangular \n    orthogonal \n    DISC \n  \n \n\n  Triangular\n\n    O \n    50 \n    TRIANGULAR \n    1 \n    1 \n    1.000 \n    -0.077 \n    1.077 \n  \n  Orthogonal\n\n    U \n    64 \n    ORTHOGONAL \n    0 \n    0 \n    -0.091 \n    1.000 \n    -1.091 \n  \n  \n    F \n    10 \n    orth-satistice \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    J \n    3 \n    orth-satistice \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    H \n    3 \n    orth-satisfice \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    K \n    2 \n    orth-satisfice \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    FK \n    1 \n    orth-satisfice \n    0 \n    0 \n    -0.182 \n    -0.154 \n    -0.028 \n  \n  \n    HJ \n    1 \n    orth-satisfice \n    0 \n    0 \n    -0.182 \n    -0.154 \n    -0.028 \n  \n  \n    HU \n    1 \n    orth-satisfice \n    0 \n    0 \n    -0.182 \n    0.923 \n    -1.105 \n  \n  Lines Connect\n\n    Z \n    1 \n    lines-connect \n    0 \n    0 \n    0.000 \n    -0.077 \n    0.077 \n  \n  other\n\n     \n    6 \n    BLANK \n    0 \n    0 \n    0.000 \n    0.000 \n    0.000 \n  \n  \n    I \n    1 \n    (reference point) \n    0 \n    0 \n    0.000 \n    0.000 \n    0.000 \n  \n  \n    OF \n    3 \n     \n    0 \n    0 \n    0.909 \n    -0.154 \n    1.063 \n  \n  \n    B \n    2 \n     \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    FG \n    2 \n     \n    0 \n    0 \n    -0.182 \n    -0.154 \n    -0.028 \n  \n  \n    JD \n    2 \n     \n    0 \n    0 \n    -0.182 \n    -0.154 \n    -0.028 \n  \n  \n    C \n    1 \n     \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    G \n    1 \n     \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n  \n    HJDE \n    1 \n     \n    0 \n    0 \n    -0.364 \n    -0.308 \n    -0.056 \n  \n  \n    OH \n    1 \n     \n    0 \n    0 \n    0.909 \n    -0.154 \n    1.063 \n  \n  \n    OK \n    1 \n     \n    0 \n    0 \n    0.909 \n    -0.154 \n    1.063 \n  \n  \n    X \n    1 \n     \n    0 \n    0 \n    -0.091 \n    -0.077 \n    -0.014 \n  \n\n\n\n\n\nTODO note the compelling cases of internal inconsistency (HJDE)\n\n\n\n2.4.2 Impasse Condition\nWe can compare these responses to those produced by participants in the experimental impasse condition (condition = 121).\n\n\nCODE\n# \n# #define interpretation for each response\n# #NOTE: this is manually defined, based on inspecting answer options\n# interpretation = c(\"BLANK\",\"TRIANGULAR\",\"partial-satisfice\",\"LINES-CONNECT\",\n#                    \"partial-satisfice\",\"partial-satisfice\",\"partial-lines-connect\",\n#                    \"\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"\")\n# \n# title <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\n# df_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n#    dplyr::summarise( count = n(), \n#                     strict = unique(score_ABS), \n#                     nice = unique(score_niceABS),\n#                     triangular = unique(score_TRI), \n#                     orthogonal =  unique(score_ORTH),\n#                     DISC =  triangular - orthogonal\n#                     # DISC = (score_TRI - score_ORTH) \n#                     ) %>% arrange(-count) %>% cbind(interpretation) %>% \n#   arrange(desc(interpretation)) %>% \n#   select(response, count, interpretation, strict, nice, triangular, orthogonal, DISC) %>% \n#   kbl(caption = title) %>%  kable_classic() %>% \n#   add_header_above(c(\" \" = 3, \"Strict Scores\" = 2, \"Interpretation Scores\"=2, \" \"=1)) \n\n\n\n\n2.4.3 Summarize By subject\n\n\nCODE\ndf_items$DISC <- df_items$score_TRI - df_items$score_ORTH\ngf_jitter(score_TRI ~ score_ORTH, data = df_items, alpha = 0.2)\n\n\n\n\n\nCODE\ngf_jitter(score_TRI ~ DISC, data = df_items , alpha=0.2,  color = ~q)\n\n\n\n\n\nCODE\ngf_dhistogram(~df_items$DISC, data = df_items)\n\n\nWarning: Use of `df_items$DISC` is discouraged. Use `DISC` instead.\n\n\n\n\n\nCODE\ngf_bar(~best, data = df_items) %>% gf_facet_grid(q~condition)\n\n\n\n\n\n\n\nCODE\nsubject_scores <- df_items %>% group_by(subject) %>% dplyr::summarize(\n  TRI = sum(score_TRI),\n  ORTH = sum(score_ORTH),\n  DISCRIM = sum(score_TRI + score_ORTH),\n  ABSOLUTE = sum(correct),\n  condition = unique(condition)\n)\n\n\n`summarise()` ungrouping output (override with `.groups` argument)\n\n\nCODE\nhead(subject_scores)\n\n\n# A tibble: 6 x 6\n  subject    TRI  ORTH DISCRIM ABSOLUTE condition\n  <fct>    <dbl> <dbl>   <dbl>    <int> <fct>    \n1 04YXZ    0.356 1.40     1.76        0 111      \n2 0F1A8   -0.323 3.92     3.60        0 111      \n3 194UU   -0.573 3.7      3.13        0 111      \n4 19SNU   -0.323 5        4.68        0 111      \n5 1ZY3L    4.92  0.685    5.61        4 111      \n6 2BBZ9   -0.323 5        4.68        0 111      \n\n\n\n\nCODE\n# gf_dhistogram(~DISCRIM, data = subject_scores)  %>%  gf_facet_grid(~condition)\n# \n# gf_dhistogram(~ABSOLUTE, data = subject_scores)\n# \n# gf_jitter(ABSOLUTE ~ DISCRIM, data = subject_scores, alpha = 0.2)\n\n\nTODO TRAPDOOR?\nSET T = options that result in -1 score (trapdoor)\nTODO: TEST first with NO trapdoor, and see what the scores yield, then if the responses can be scaled based on comparing subscores\nf_partialP <- function(t,p,f,q) {\nt = number of correct-selected options p = number of true options f = number of incorrect-selected options q = number of false options n = number of options + p + q return( (t / p) - (f/q)) }\nTo prepare for partial scoring [-1/q, + 1/p], we first need to define the parameters t, p , f, q\nOur approach to calculating an ORTHOGONAL PARTIAL score is as follows:\n\n1/p for each correct-selected\n-1/q for each incorrect-selected (except ‘allowed’ based on reference point and visual error)\ntrapdoor : default to -1 if select triangular"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#section-1",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#section-1",
    "title": "2  Response Scoring",
    "section": "2.5 ",
    "text": "2.5 \n\n\n\n\n\n\nSchmidt, Dennis, Tobias Raupach, Annette Wiegand, Manfred Herrmann, and Philipp Kanzow. 2021. “Relation Between Examinees’ True Knowledge and Examination Scores: Systematic Review and Exemplary Calculations on Multiple-True-False Items.” Educational Research Review 34 (November): 100409. https://doi.org/10.1016/j.edurev.2021.100409."
  },
  {
    "objectID": "analysis/SGC3A/x_sgc3A_exploreResponse.html",
    "href": "analysis/SGC3A/x_sgc3A_exploreResponse.html",
    "title": "4  Response Exploration",
    "section": "",
    "text": "The purpose of this notebook is to explore item-level response data collected for study SGC-3: The Insight Hypothesis\nFirst we import item-level data from the cleaned and wrangled R data structure file."
  },
  {
    "objectID": "analysis/SGC3A/x_sgc3A_exploreResponse.html#control-condition",
    "href": "analysis/SGC3A/x_sgc3A_exploreResponse.html#control-condition",
    "title": "4  Response Exploration",
    "section": "4.1 Control Condition",
    "text": "4.1 Control Condition\n\n4.1.1 Question #1\nWe start by exploring the range of response options checked by participants on Question 1, for those assigned to the control (non-impasse) condition (condition = 111).\nIn the ‘interpretation’ column we indicate which interpretation of the graph stimulus is indicated by each combination of response options. Note that ALL CAPS indicates the precise interpretation, while lowercase indicates a partially-consistent selection of options.\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"lines-connect\",\"(both ortho & tri)\",\"?\",\"?\",\"triangular\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Control Condition)\"\ndf_items %>% filter(q == 1 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthongal\", 3, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 4) %>% \n  pack_rows(\"other\", 5, 7) \n\n\n\nFrequency of Selected Response Options for Question #1 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    22 \n    TRIANGULAR \n  \n  \n    Z \n    1 \n    triangular \n  \n  Orthongal\n\n    A \n    129 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    CF \n    3 \n    lines-connect \n  \n  other\n\n    AF \n    1 \n    (both ortho & tri) \n  \n  \n    IJD \n    1 \n    ? \n  \n  \n    X \n    1 \n    ? \n  \n\n\n\n\n\nNearly all of the subjects selected a response consistent with one of the identified interpretations.\nNote that options highlighted in light grey are considered within the range of ‘visual error’.\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nindicates the correct interpretation of the coordinate system\na triangular-like interpretation, where the respondent selects any datapoints intersecting the lines that connect to the reference time\nindicates the incorrect, Cartesian interpretation of the coordinate system\n\n\n\n\n\n4.1.2 Question #2\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\n                     \"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\"ortho + satisfice\",\"TRIANGULAR\")\n\ntitle <- \"Frequency of Selected Response Options for Question #2 (Control Condition)\"\ndf_items %>% filter(q == 2 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 2) %>% \n  pack_rows(\"Orthogonal\", 3, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 7) %>% \n  pack_rows(\"other\", 8, 10) \n\n\n\nFrequency of Selected Response Options for Question #2 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    K \n    24 \n    TRIANGULAR \n  \n  \n    KD \n    1 \n    TRIANGULAR \n  \n  Orthogonal\n\n    DE \n    3 \n    ORTHONGAL \n  \n  \n    E \n    121 \n    ORTHOGONAL \n  \n  \n    EG \n    1 \n    ortho + satisfice \n  \n  Lines-Connect\n\n    J \n    4 \n    LINES-CONNECT \n  \n  \n    AK \n    1 \n    LINES-CONNECT \n  \n  other\n\n    D \n    1 \n    (reference point) \n  \n  \n    B \n    1 \n     \n  \n  \n    C \n    1 \n     \n  \n\n\n\n\n\nAgain, we see that most subjects selected a response consistent with one of the identified interpretations. (note, when the question stem includes a data point rather than time as reference, we do not penalize respondents for selecting the reference data point in addition to an interpretation consistent response. For example, in this question, we do not penalize respondents for selecting option D, the reference point in the question. )\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n4.1.3 Question #3\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"LINES-CONNECT\",\"ORTHONGAL\",\"LINES-CONNECT\",\n                     \"lines-connect\",\"LINES-CONNECT\",\"\",\"\",\"(reference point)\",\n                     \"\",\"\",\"\",\"\",\"\",\"\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #3 (Control Condition)\"\ndf_items %>% filter(q == 3 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 3) %>% \n  pack_rows(\"Lines-Connect\", 4, 7) %>% \n  pack_rows(\"other\", 8, 17) \n\n\n\nFrequency of Selected Response Options for Question #3 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    F \n    24 \n    TRIANGULAR \n  \n  Orthogonal\n\n    AUB \n    4 \n    ORTHONGAL \n  \n  \n    Z \n    94 \n    ORTHOGONAL \n  \n  Lines-Connect\n\n    A \n    18 \n    LINES-CONNECT \n  \n  \n    K \n    3 \n    LINES-CONNECT \n  \n  \n    OJ \n    2 \n    LINES-CONNECT \n  \n  \n    O \n    3 \n    lines-connect \n  \n  other\n\n    C \n    1 \n    (reference point) \n  \n  \n    AH \n    1 \n     \n  \n  \n    AIOZFHJXKUDEGB \n    1 \n     \n  \n  \n    DE \n    1 \n     \n  \n  \n    E \n    1 \n     \n  \n  \n    FKE \n    1 \n     \n  \n  \n    OJD \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    U \n    1 \n     \n  \n  \n    UE \n    1 \n     \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrect — Triangular\nIncorrect — Lines Connect\nIncorrect — Orthogonal\n\n\n\n\n\n\n\n\n\nA correct (triangular) interpretation of the coordinate system yields data point K.\nAn incorrect interpretation that is not orthogonal yields selection of datapoints that are connected by a line to data point D, such as K and A, or alternatively, J.\nAn incorrect orthogonal interpretation involves selecting data point E, the orthogonal projection from the reference point D to the x-axis.\n\n\n\n\n\n4.1.4 Question #4\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-lines connect\",\"BLANK\",\"orth-lines connect\",\n                     \"lines-connect\",\"orthogonal\",\"\",\"\",\"\",\n                     \"\",\"\",\"\",\"\",\"\",\"\" )\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 4 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 5) %>% \n  pack_rows(\"Lines-Connect\", 6, 6) %>% \n  pack_rows(\"other\", 7, 16) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    H \n    29 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    87 \n    ORTHOGONAL \n  \n  \n    FU \n    2 \n    orthogonal \n  \n  \n    DE \n    14 \n    orth-lines connect \n  \n  \n    E \n    6 \n    orth-lines connect \n  \n  Lines-Connect\n\n    B \n    3 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    K \n    2 \n     \n  \n  \n    O \n    2 \n     \n  \n  \n    AH \n    1 \n     \n  \n  \n    CAIOZFHJXKU \n    1 \n     \n  \n  \n    D \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    KU \n    1 \n     \n  \n  \n    OUDE \n    1 \n     \n  \n  \n    UDE \n    1 \n     \n  \n\n\n\n\n\nIn Question 4 we see more than one variant of an orthogonal interpretation emerge.\n\n\n\n\n\n\n\nOrthogonal\nOrthogonal-LinesConnecting\n\n\n\n\n\n\n\n\nIf the subject calculates end time for each data point (using duration on the y axis), they find that an (incorrect) projection of point U ‘end time’ intersects with the (incorrect) orthogonal projection of 4:00PM.\nAlternatively, some subjects selected points E and D which intersect with an orthogonal projection from 4:00pm. We call this an ’orthogonal-lines connect” strategy, because it (incorrectly) adapts the orthogonal procedure for finding events that start at 4:00pm in order to find those that end at 4:00pm, thus selecting any data point with an orthogonal intersection with 4:00pm.\n\n\n\n\n\n4.1.5 Question #5\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\n  interpretation = c(\"ORTHOGONAL\",\"TRIANGULAR\",\"orth-satistice\",\"BLANK\",\"orth-satisfice\",\n                     \"orth-satistice\",\"\",\"\",\"\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\"\",\"orth-satisfice\",\n                     \"(reference point)\",\"\",\"\",\"\",\"lines-connect\")\n\ntitle <- \"Frequency of Selected Response Options for Question #4 (Control Condition)\"\ndf_items %>% filter(q == 5 & condition == 111) %>% group_by(response) %>% \n  summarise( count = n())  %>% arrange(-count) %>% cbind(interpretation) %>% \n  arrange(desc(interpretation)) %>% \n  kbl(caption = title) %>%  kable_classic() %>% \n  pack_rows(\"Triangular\", 1, 1) %>% \n  pack_rows(\"Orthogonal\", 2, 9) %>% \n  pack_rows(\"Lines Connect\", 10, 10) %>% \n  pack_rows(\"other\", 11, 22) \n\n\n\nFrequency of Selected Response Options for Question #4 (Control Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  Triangular\n\n    O \n    50 \n    TRIANGULAR \n  \n  Orthogonal\n\n    U \n    64 \n    ORTHOGONAL \n  \n  \n    F \n    10 \n    orth-satistice \n  \n  \n    J \n    3 \n    orth-satistice \n  \n  \n    H \n    3 \n    orth-satisfice \n  \n  \n    K \n    2 \n    orth-satisfice \n  \n  \n    FK \n    1 \n    orth-satisfice \n  \n  \n    HJ \n    1 \n    orth-satisfice \n  \n  \n    HU \n    1 \n    orth-satisfice \n  \n  Lines Connect\n\n    Z \n    1 \n    lines-connect \n  \n  other\n\n     \n    6 \n    BLANK \n  \n  \n    I \n    1 \n    (reference point) \n  \n  \n    OF \n    3 \n     \n  \n  \n    B \n    2 \n     \n  \n  \n    FG \n    2 \n     \n  \n  \n    JD \n    2 \n     \n  \n  \n    C \n    1 \n     \n  \n  \n    G \n    1 \n     \n  \n  \n    HJDE \n    1 \n     \n  \n  \n    OH \n    1 \n     \n  \n  \n    OK \n    1 \n     \n  \n  \n    X \n    1 \n     \n  \n\n\n\n\n\nTODO note the compelling cases of internal inconsistency (HJDE)"
  },
  {
    "objectID": "analysis/SGC3A/x_sgc3A_exploreResponse.html#impasse-condition",
    "href": "analysis/SGC3A/x_sgc3A_exploreResponse.html#impasse-condition",
    "title": "4  Response Exploration",
    "section": "4.1 Impasse Condition",
    "text": "4.1 Impasse Condition\nWe can compare these responses to those produced by participants in the experimental impasse condition (condition = 121).\n\n\nCODE\n#define interpretation for each response\n#NOTE: this is manually defined, based on inspecting answer options\ninterpretation = c(\"BLANK\",\"TRIANGULAR\",\"partial-satisfice\",\"LINES-CONNECT\",\n                   \"partial-satisfice\",\"partial-satisfice\",\"partial-lines-connect\",\n                   \"\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"partial-satisfice\",\"\")\n\ntitle <- \"Frequency of Selected Response Options for Question #1 (Impasse Condition)\"\ndf_items %>% filter(q == 1 & condition == 121) %>% group_by(response) %>% \n  summarise( count = n()) %>% arrange(-count)  %>% cbind(interpretation) %>% \n  kbl(caption = title) %>%  kable_classic() \n\n\n`summarise()` ungrouping output (override with `.groups` argument)\n\n\n\nFrequency of Selected Response Options for Question #1 (Impasse Condition)\n \n  \n    response \n    count \n    interpretation \n  \n \n\n  \n     \n    57 \n    BLANK \n  \n  \n    F \n    49 \n    TRIANGULAR \n  \n  \n    O \n    28 \n    partial-satisfice \n  \n  \n    CF \n    14 \n    LINES-CONNECT \n  \n  \n    AI \n    9 \n    partial-satisfice \n  \n  \n    A \n    4 \n    partial-satisfice \n  \n  \n    C \n    3 \n    partial-lines-connect \n  \n  \n    E \n    2 \n     \n  \n  \n    I \n    2 \n    partial-satisfice \n  \n  \n    AO \n    1 \n    partial-satisfice \n  \n  \n    CO \n    1 \n    partial-satisfice \n  \n  \n    OA \n    1 \n    partial-satisfice \n  \n  \n    X \n    1"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#scoring-multiple-response-questions",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#scoring-multiple-response-questions",
    "title": "2  Response Scoring",
    "section": "2.1 Scoring Multiple Response Questions",
    "text": "2.1 Scoring Multiple Response Questions\nThe graph comprehension task of study SGC 3A presents readers with a graph, a question, and a series of checkboxes. Participants are instructed to use the graph to answer the question, and respond by selecting all the checkboxes that apply, where each checkbox corresponds to a datapoint in the graph.\n\n\n\nFigure 1. Sample Graph Comprehension (Question # 6)\n\n\nIn the psychology and education literatures on Tests & Measures, the format of this type of question is referred to as Multiple Response (MR), (also: Multiple Choice Multiple Answer (MCMA) and Multiple Answer Multiple Choice (MAMC)). It has a number of properties that make it different from traditional Single Answer Multiple Choice (SAMC) questions, where the respondent marks a single response from a number of options. In particular, there are a number of very different ways that MAMC questions can be scored.\nIn tranditional SAMC format questions, one point is given for selecting the option designated as correct, and zero points given for marking any of the alternative (i.e. distractor) options. Individual response options on MAMC questions, however might be partially correct (\\(i\\)), while responses on other answer options within the same item might be incorrect (\\(n – i\\)). In MAMC, it is not obvious how to allocate points when the respondent marks a true-correct option (i.e. options that should be selected), as well as one or more false-correct options (i.e. options that should not be selected). Should partial credit be awarded? If so, are options that respondents false-selected and false-unselected items equally penalized?\nSchmidt et al. (2021) performed a systematic literature review of publications proposing MAMC (or equivalent) scoring schemes, ultimately synthesizing over 80 sources into 27 distinct scoring approaches. Upon reviewing the benefits of trade-offs of each approach, for this study we choose utilize two of the schemes: dichotomous scoring ( Schmidt et al. (2021) scheme #1), and partial scoring \\([-1/q,0, +1/p]\\) ( Schmidt et al. (2021) scheme #26), as well as a scaled discriminant score that leverages partial scoring to discriminate between strategy-specific patterns of response.\n\n2.1.1 Response Encoding\nFirst, we note that the question type evaluated by Schmidt et al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 2.1: Figure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 2.1), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can be encoded as [TTFF].\n\n\n\n\n\n\nDecision\n\n\n\nIn our analysis, we will transform the MAMC response string recorded for the participant (given in column response), to an MTF encoding.\n\n\n\n\n2.1.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\n\\]\nProperties of the Subject’s Response\n\\[\n  \\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\n\\]\n\n2.1.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only correct-select options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\nIn Dichotomous Scoring\n\nscore for the question is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nCODE\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n2.1.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et al. (2021) identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach ( Schmidt et al. (2021) #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\nSchmidt et al. (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where there are many more response options \\(n\\) than there are options meant to be selected \\(p\\), this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n  \\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n\n\nCODE\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n\n\n\n2.1.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. “select all correct options”) vs MTF (i.e. “Mark each option as true or false”) questions.\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt et al. (2021) method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts \\(1/(n-p) = 1/q\\) for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n\\]\nProperties of Response\n\\[\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nCODE\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  return( (t / p) - (f/q))\n}\n\n\n\n\n2.1.2.4 Comparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    i  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial[-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A____ \n    5 \n    1 \n    1.0 \n    1.00 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB___ \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    A___E \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    AB__E \n    3 \n    0 \n    0.2 \n    0.50 \n  \n  Only Incorrect Selections\n\n    A____ \n    ____E \n    3 \n    0 \n    0.2 \n    -0.25 \n  \n  \n    A____ \n    ___DE \n    2 \n    0 \n    -0.2 \n    -0.50 \n  \n  Completely Inverse Response \n\n    A____ \n    _BCDE \n    0 \n    0 \n    -1.0 \n    -1.00 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABCDE \n    1 \n    0 \n    -0.6 \n    0.00 \n  \n  \n    A____ \n    _____ \n    4 \n    0 \n    0.6 \n    0.00 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt)\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    $i$  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial [-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A__...__ \n    15 \n    1 \n    1.000 \n    1.000 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB_...__ \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    A__..._O \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    AB_..._O \n    13 \n    0 \n    0.733 \n    0.857 \n  \n  Only Incorrect Selections\n\n    A____ \n    ___..._O \n    13 \n    0 \n    0.733 \n    -0.071 \n  \n  \n    A____ \n    ___...NO \n    12 \n    0 \n    0.600 \n    -0.143 \n  \n  Completely Inverse Response \n\n    A____ \n    _BC...NO \n    0 \n    0 \n    -1.000 \n    -1.000 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABC...NO \n    1 \n    0 \n    -0.867 \n    0.000 \n  \n  \n    A____ \n    ___...__ \n    14 \n    0 \n    0.867 \n    0.000 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt, abs,correct,i,names,partial1,partial2,response,title)\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n\n\n\n\n\nDecision\n\n\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options.\n\n\n\n\n\n2.1.3 TODO A Discriminant Score\nThough it appears the Partial \\([-1/q, +1/p]\\) scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options in the same way.\nIn the case of the SGC study paradigm, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus. Specifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under \\([-1/q, +1/q]\\). These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are more incorrect than others. We want to be able to differentiate between these responses.\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define four interpretations for which to define options. We can think of these as four different answer keys, each defining the set of ‘correct’ options (those that should be selected) under each interpretation of the graph.\n\nTriangular : the (true, actually correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\nOrthogonal: the (incorrect but most common) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\nLines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the correct projection).\nSatisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nTODO FIX THIS SECTION ONWARDS … RESPONSE SETS NEED NOT BE MUTUTALLY EXCLUSIVE\nThus for each item, in the graph comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\\[\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n\\]\nFor example, for the following sample stimuli, TODO IMAGE\n\\[\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n\\]\nTo capture this important source of variation, we can apply the idea behind the partial scoring \\([-1/q, +1/p]\\) scheme in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n  \\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t = |T| =\\) number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r = |R| =\\) number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nCODE\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#multiple-response-scoring",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#multiple-response-scoring",
    "title": "2  Response Scoring",
    "section": "2.1 MULTIPLE RESPONSE SCORING",
    "text": "2.1 MULTIPLE RESPONSE SCORING\nThe graph comprehension task of study SGC 3A presents readers with a graph, a question, and a series of checkboxes. Participants are instructed to use the graph to answer the question, and respond by selecting all the checkboxes that apply, where each checkbox corresponds to a datapoint in the graph.\n\n\n\nFigure 1. Sample Graph Comprehension (Question # 6)\n\n\nIn the psychology and education literatures on Tests & Measures, the format of this type of question is referred to as Multiple Response (MR), (also: Multiple Choice Multiple Answer (MCMA) and Multiple Answer Multiple Choice (MAMC)). It has a number of properties that make it different from traditional Single Answer Multiple Choice (SAMC) questions, where the respondent marks a single response from a number of options. In particular, there are a number of very different ways that MAMC questions can be scored.\nIn tranditional SAMC format questions, one point is given for selecting the option designated as correct, and zero points given for marking any of the alternative (i.e. distractor) options. Individual response options on MAMC questions, however might be partially correct (\\(i\\)), while responses on other answer options within the same item might be incorrect (\\(n – i\\)). In MR, it is not obvious how to allocate points when the respondent marks a true-correct option (i.e. options that should be selected, denoted \\(p\\)), as well as one or more false-correct options (i.e. options that should not be selected, denoted \\(q\\)). Should partial credit be awarded? If so, are options that respondents false-selected and false-unselected items equally penalized?\nSchmidt et al. (2021) performed a systematic literature review of publications proposing MAMC (or equivalent) scoring schemes, ultimately synthesizing over 80 sources into 27 distinct scoring approaches. Upon reviewing the benefits of trade-offs of each approach, for this study we choose utilize two of the schemes: dichotomous scoring ( Schmidt et al. (2021) scheme #1), and partial scoring \\([-1/q,0, +1/p]\\) ( Schmidt et al. (2021) scheme #26), as well as a scaled discriminant score that leverages partial scoring to discriminate between strategy-specific patterns of response.\n\n2.1.1 Response Encoding\nFirst, we note that the question type evaluated by Schmidt et al. (2021) is referred to as Multiple True-False (MTF), a variant of MAMC where respondents are presented with a question (stem) and series of response options with True/False (e.g. radio buttons) for each. Depending on the implementation of the underlying instrument, it may or may not be possible for respondents to not respond to a particular option (i.e. leave the item ‘blank’). Although MTF questions have a different underlying implementation (and potentially different psychometric properties) they are identical in their mathematical properties; that is, responses to a MAMC question of ‘select all that apply’ can be coded as a series of T/F responses to each response option\n\n\n\nFigure 2.1: Figure 2. SAMC (vs) MAMC (vs) MTF\n\n\nIn this example (Figure 2.1), we see an example of a question with four response options (\\(n=4\\)) in each question type. In the SAMC approach (at left), there are four possible responses, given explicitly by the response options (respondent can select only one) \\((\\text{number of possible responses} = n)\\). With only four possible responses, we cannot entirely discriminate between all combinations of the underlying response variants we might be interested in, and must always choose an ‘ideal subset’ of possible distractors to present as response options. In the MAMC (middle) and MTF (at right), the same number of response options (\\(n=4\\)) yield a much greater number \\((\\text{number of possible responses} = 2^{n})\\). We can also see the equivalence between a MAMC and MTF format questions with the same response options. Options the respondent selects in MAMC are can be coded as T, and options they leave unselected can be coded as F. Thus, for response options (ABCD), a response of [AB] can also be encoded as [TTFF].\n\n\n2.1.2 Scoring Schemes\nIn the sections that follow, we use the terminology:\nProperties of the Stimulus-Question\n\\[\n\\begin{align}\nn &= \\text{number of response options} \\\\  \n  &= p + q \\\\\n  p &= \\text{number of true-select options (i.e. should be selected)} \\\\\n  q &= \\text{number of true-unselect options (i.e. should not be selected)}\n\\end{align}\n\\]\nProperties of the Subject’s Response\n\\[\n  \\begin{align}\ni &= \\text{number of options in correct state}, (0 ≤ i ≤ n) \\\\\nf &= \\text{resulting score}\n\\end{align}\n\\]\n\n2.1.2.1 Dichotomous Scoring\nDichotomous Scoring is the strictest scoring scheme, where a response only receives points if it is exactly correct, meaning the respondent includes only correct-select options, and does select any additional (i.e. incorrect-select) options that should not be selected. This is also known as all or nothing scoring, and importantly, it ignores any partial knowledge that a participant may be expressing through their choice of options. They may select some but not all of the correct-select options, and one or more but not all of the correct-unselect items, but receive the same score as a respondent selects none of the correct-select options, or all of the correct-unselect options. In this sense, dichotomous scoring tells us only about perfect knowledge, and ignores any indication of partial knowledge the respondent may be indicating through their selection of response options.\nIn Dichotomous Scoring\n\nscore for the question is either 0 or 1\nfull credit is only given if all responses are correct; otherwise no credit\ndoes not account for partial knowledge. - with increasing number of response options, scoring becomes stricter as each statement must be marked correctly.\n\nThe algorithm for dichotomous scoring is given by:\n\\[\n\\begin{gather*}\nf =\n\\begin{cases}\n  1, \\text{if } i = n \\\\    \n  0, \\text{otherwise}    \n\\end{cases}\n\\end{gather*}\n\\tag{1}\n\\text{where } 0 \\le i \\le n\n\\]\n\n\nCODE\nf_dichom <- function(i, n) {\n \n  # print(paste(\"i is :\",i,\" n is:\",n)) \n  \n  #if (n == 0 ) return error \n  ifelse( (n == 0), print(\"ERROR n can't be 0\"), \"\")\n  \n  #if (i > n ) return error \n  ifelse( (i > n), print(\"i n can't > n\"), \"\")\n  \n  #if (i==n) return 1, else 0\n  return (ifelse( (i==n), 1 , 0))\n \n}\n\n\n\n\n2.1.2.2 Partial Scoring [-1/n, +1/n]\nPartial Scoring refers to a class or scoring schemes that award the respondent partial credit depending on pattern of options they select. Schmidt et al. (2021) identify twenty-six different partial credit scoring schemes in the literature, varying in the range of possible scores, and the relative weighting of incorrectly selected (vs) incorrectly unselected options.\nA particularly elegant approach to partial scoring is referred to as the \\([-1/n, +1/n]\\) approach ( Schmidt et al. (2021) #17). This approach is appealing in the context of SGC3A, because it: (1) takes into account all information provided by the respondent: the pattern of what the select, and choose not to select.\nIn Partial Scoring \\([-1/n, +1/n]\\):\n\nScores range from [-1, +1]\nOne point is awarded if all options are correct\nOne point point is subtracted if all options are incorrect.\nIntermediate results are credited as fractions accordingly (\\(+1/n\\) for each correct, \\(-1/n\\) for each incorrect)\nThis results in at chance performance (i.e. half of the given options marked correctly), being awarded 0 points are awarded\n\nThis scoring is more consistent with the motivating theory that Triangular Graph readers start out with an incorrect (i.e. orthogonal, cartesian) interpretation of the coordinate system, and transition to a correct (i.e. triangular) interpretation. But the first step in making this transition is realizing the cartesian interpretation is incorrect, which may yield blank responses where the respondent is essentially saying, ‘there is no correct answer to this question’.\nSchmidt et al. (2021) describe the Partial \\({[-1/n, +1/n]}\\) scoring scheme as the only scoring method (of the 27 described) where respondents’ scoring results can be interpreted as a percentage of their true knowledge. One important drawback of this method is that a respondent may receive credit (a great deal of credit, depending on the number of answer options n) even if she did not select any options. In the case (such as ours) where there are many more response options \\(n\\) than there are options meant to be selected \\(p\\), this partial scoring algorithm poses a challenge because the respondent can achieve an almost completely perfect score by selecting a small number of options that should not be selected.\nThe algorithm for partial scoring\\([-1/n, +1/n]\\) is given by:\n\\[\n  \\begin{align}\nf &= (1/n * i) - (1/n * (n-i)) \\\\\n&= (2i - n)/{n}\n\\tag{2}\n\\end{align}\n\\]\n\n\nCODE\nf_partialN <- function(i, n) {\n\n# print(paste(\"i is :\",i,\" n is:\",n))\n\n#if(n==0) return error\nifelse((n==0),print(\"ERROR: n should not be 0\"),\"\")\n\n#if(i >n ) return error\nifelse((i > n),print(\"ERROR: i CANNOT BE GREATER THAN n\"),\"\")\n\nreturn ((2*i - n) / n) \n}\n\n\n\n\n2.1.2.3 Partial Scoring [-1/p, +1/p]\nOne drawback of the Partial Scoring \\([-1/n, +1/n]\\) approach is that treats the choice to select, and choice to not select options as equally indicative of the respondent’s understanding. That is to say, incorrectly selecting one particular option is no more or less informative than incorrectly not-selecting a different item. This represents an important difference between MAMC (i.e. “select all correct options”) vs MTF (i.e. “Mark each option as true or false”) questions.\nIn our study, the selection of any particular option (remember options represent data points on the stimulus graph) is indicative of a particular interpretation of the stimulus. Incorrectly selecting an option indicates an interpretation of the graph with respect to that particular option. Alternatively, failing to select a correct option might mean the individual has a different interpretation, or that they failed to find all the data points consistent with the interpretation.\nFor this reason, we consider another alternative Partial Scoring scheme that takes into consideration only the selected statements, without penalizing statements incorrectly not selected. (See Schmidt et al. (2021) method #26; also referred to as the Morgan-Method) This partial scoring scheme takes into consideration that the most effort-free (or ‘default’) response for any given item is the null, or blank response. Blank responses indicate no understanding, perhaps confusion, or refusal to answer. These lack of responses are awarded zero credit. Whereas taking the action to select an incorrect option is effortful, and is indicative of incorrect understanding.\nPartial Scoring \\([-1/q, +1/p]\\):\n\nawards +1/p for each correctly selected option (\\(p_s\\)), and subtracts \\(1/(n-p) = 1/q\\) for each incorrectly selected option (\\(q_s\\))\nonly considers selected options; does not penalize nor reward unselected options\n\nProperties of Item\n\\[\n\\begin{align}\np &= \\text{number of true-select options (i.e. should be selected)} \\\\\nq &= \\text{number of true-unselect options (i.e. should not be selected)} \\\\\nn &= \\text{number of options} \\: ( n = p + q)\n\\end{align}\n\\]\nProperties of Response\n\\[\n\\begin{align}\np_s &= \\text{number of true-select options selected (i.e. number of correctly checked options)}\\\\\nq_s &= \\text{number of true-unselect options selected (i.e. number of incorrectly checked options }\n\\end{align}\n\\]\nThe algorithm for partial scoring \\([-1/q, +1/p]\\) is given by:\n\\[\n\\begin{align}\nf &= (p_m / p) - ({q_m}/{q}) \\\\\n\\tag{3}\n\\end{align}\n\\]\n\n\nCODE\nf_partialP <- function(t,p,f,q) {\n\n  #t = number of correct-selected options\n  #p = number of true options\n  #f = number of incorrect-selected options\n  #q = number of false options\n  #n = number of options + p + q\n  ifelse( (p == 0), return(\"\"), \"\") #handle empty response set gracefully by returning nothing\n  ifelse( (p != 0), return( (t / p) - (f/q)), \"\")\n  \n  # return( (t / p) - (f/q))\n}\n\n\n\n\n\n2.1.3 Comparison of Schemes\nWhich scoring scheme is most appropriate for the goals of the graph comprehension task?\nConsider the following example:\nFor a question with \\(n = 5\\) response options (data points A, B, C, D and E) with a correct response of A, the schemes under consideration yield the following scores:\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",        \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A____\",  \n              \"AB___\",      \n              \"A___E\",      \n              \"AB__E\",        \n              \"____E\",\n              \"___DE\",\n              \"_BCDE\",      \n              \"ABCDE\",      \n              \"_____\" )\n\ni <- c(        5,       \n               4,              \n               4,              \n               3,               \n               \n               3,\n               2,\n               0,\n               1,\n               4)\n\nabs <- c(f_dichom(5,5), \n         f_dichom(4,5), \n         f_dichom(4,5), \n         f_dichom(3,5), \n         \n         f_dichom(3,5), \n         f_dichom(2,5),\n         f_dichom(0,5),\n         f_dichom(1,5),\n         f_dichom(4,5))\n\npartial1 <- c(f_partialN(5,5), \n              f_partialN(4,5), \n              f_partialN(4,5), \n              f_partialN(3,5), \n              \n              f_partialN(3,5), \n              f_partialN(2,5),\n              f_partialN(0,5),\n              f_partialN(1,5),\n              f_partialN(4,5))\n\npartial2 <- c(f_partialP(1,1,0,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,1,4), \n              f_partialP(1,1,2,4), \n              \n              f_partialP(0,1,1,4),\n              f_partialP(0,1,2,4),\n              f_partialP(0,1,4,4),\n              f_partialP(1,1,4,4), \n              f_partialP(0,1,0,4))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"i \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial[-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for n = 5 options [ A,B,C,D,E ]\n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    i  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial[-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A____ \n    5 \n    1 \n    1.0 \n    1.00 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB___ \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    A___E \n    4 \n    0 \n    0.6 \n    0.75 \n  \n  \n    A____ \n    AB__E \n    3 \n    0 \n    0.2 \n    0.50 \n  \n  Only Incorrect Selections\n\n    A____ \n    ____E \n    3 \n    0 \n    0.2 \n    -0.25 \n  \n  \n    A____ \n    ___DE \n    2 \n    0 \n    -0.2 \n    -0.50 \n  \n  Completely Inverse Response \n\n    A____ \n    _BCDE \n    0 \n    0 \n    -1.0 \n    -1.00 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABCDE \n    1 \n    0 \n    -0.6 \n    0.00 \n  \n  \n    A____ \n    _____ \n    4 \n    0 \n    0.6 \n    0.00 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt)\n\n\n\nWe see that in the Dichotomous scheme, only the precisely correct response (row 1) yields a score other than zero. This scheme does now allow us to differentiate between different response patters.\nThe Partial \\([-1/n, +1/n]\\) scheme yields a range from \\([-1,1]\\), differentiating between responses. However, a blank response (bottom row) receives the same score (0.6) as the selection of the correct option + 1 incorrect option (row 2), which is problematic with for the goals of this study, where we need to differentiate between states of confusion or uncertainty yielding blank responses and the intentional selection of incorrect items.\nThe Partial \\([-1/q, +1/p]\\) scheme also yields a range of scores from \\([-1,1]\\). A blank response (bottom row) yields the same score (\\(0\\)) as the selection of all answer options (row 7); both are patterns of behavior we would expect to see if a respondent is confused or uncertain that there is a correct answer to the question.\n\nNext we consider an example from our study, with \\(n = 15\\) options and \\(p = 1\\) correct option to be selected.\n\n\nCODE\ntitle <- \"Comparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \"\n\ncorrect <- c( \"A____\",  \n              \"A____\",      \n              \"A____\",      \n              \"A____\",        \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\",      \n              \"A____\" ) \n\nresponse <- c(\"A__...__\",  \n              \"AB_...__\",      \n              \"A__..._O\",      \n              \"AB_..._O\",        \n              \"___..._O\",      \n              \"___...NO\",      \n              \"_BC...NO\",\n              \"ABC...NO\",      \n              \"___...__\" )\n\ni <- c(        15,       \n               14,              \n               14,              \n               13,\n               13,               \n               12,          \n               0,\n               1,\n               14)\n\nabs <- c(f_dichom(15,15), \n         f_dichom(14,15), \n         f_dichom(14,15), \n         f_dichom(13,15), \n         f_dichom(13,15),\n         f_dichom(12,15),\n         f_dichom(0,15),\n         f_dichom(1,15),\n         f_dichom(14,15))\n\npartial1 <- c(f_partialN(15,15), \n              f_partialN(14,15), \n              f_partialN(14,15), \n              f_partialN(13,15), \n              f_partialN(13,15),\n              f_partialN(12,15),\n              f_partialN(0,15),\n              f_partialN(1,15),\n              f_partialN(14,15))\n\npartial2 <- c(f_partialP(1,1,0,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,1,14), \n              f_partialP(1,1,2,14), \n              f_partialP(0,1,1,14),\n              f_partialP(0,1,2,14),\n              f_partialP(0,1,14,14),\n              f_partialP(1,1,14,14), \n              f_partialP(0,1,0,14))\n\nnames = c(    \"Correct Answer\",\n              \"Response\",\n              \"$i$ \",\n              \"Dichotomous\",\n              \"Partial [-1/n, +1/n]\",\n              \"Partial [-1/q, +1/p]\")\n\ndt <- data.frame(correct, response, i, abs, partial1 , partial2)\n\nkbl(dt, col.names = names, caption = title, digits=3) %>%\n  kable_classic() %>%\n    add_header_above(c(\"Response Scenario \" = 3, \"Scores\" = 3)) %>% \n    pack_rows(\"Perfect Response\", 1, 1) %>%\n    pack_rows(\"Correct + Extra Incorrect Selections\", 2, 4) %>%\n    pack_rows(\"Only Incorrect Selections\", 5, 6) %>%\n    pack_rows(\"Completely Inverse Response \", 7, 7) %>%\n    pack_rows(\"Selected ALL or NONE\", 8, 9) %>%\n    footnote(general = paste(\"i = number of options in correct state; _ indicates option not selected\"),\n           general_title = \"Note: \",footnote_as_chunk = T)\n\n\n\nComparison of Scoring Schemes for SGC3 with n=15 and p=1 options [A,B...N,O]  \n \n\nResponse Scenario \nScores\n\n  \n    Correct Answer \n    Response \n    $i$  \n    Dichotomous \n    Partial [-1/n, +1/n] \n    Partial [-1/q, +1/p] \n  \n \n\n  Perfect Response\n\n    A____ \n    A__...__ \n    15 \n    1 \n    1.000 \n    1.000 \n  \n  Correct + Extra Incorrect Selections\n\n    A____ \n    AB_...__ \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    A__..._O \n    14 \n    0 \n    0.867 \n    0.929 \n  \n  \n    A____ \n    AB_..._O \n    13 \n    0 \n    0.733 \n    0.857 \n  \n  Only Incorrect Selections\n\n    A____ \n    ___..._O \n    13 \n    0 \n    0.733 \n    -0.071 \n  \n  \n    A____ \n    ___...NO \n    12 \n    0 \n    0.600 \n    -0.143 \n  \n  Completely Inverse Response \n\n    A____ \n    _BC...NO \n    0 \n    0 \n    -1.000 \n    -1.000 \n  \n  Selected ALL or NONE\n\n    A____ \n    ABC...NO \n    1 \n    0 \n    -0.867 \n    0.000 \n  \n  \n    A____ \n    ___...__ \n    14 \n    0 \n    0.867 \n    0.000 \n  \n\n\nNote:   i = number of options in correct state; _ indicates option not selected\n\n\n\n\nCODE\n#cleanup\nrm(dt, abs,correct,i,names,partial1,partial2,response,title)\n\n\nHere again we see that the Partial \\([-1/q, +1/p]\\) scheme allows us differentiate between patterns of responses, in a way that is more sensible for the goals of the SGC3 graph comprehension task.\n\n\n\n\n\n\nDecision\n\n\n\nThe Partial \\([-1/q, +1/p]\\) scheme is more appropriate for scoring the graph comprehension task than the Partial \\([-1/n, +1/n]\\) scheme because it allows us to differentially penalize incorrectly selected and incorrectly not selected answer options.\n\n\n\n\n2.1.4 TODO A Discriminant Score\nThough it appears the Partial \\([-1/q, +1/p]\\) scheme is a more appropriate scoring method for differentiating between meaningful patterns of responses, it does have one significant limitation: it treats all incorrectly selected answer options in the same way.\nIn the case of the SGC study paradigm, the choice of which options the subject selects reveals important information about their understanding of the graph stimulus. Specifically, there are certain patterns of options that correspond to a triangular versus orthogonal interpretations. In the previous example, rows 2 and 3 both indicate a subject has selected the correct option (A) plus one additional option (B or O). Both responses receive the same score under \\([-1/q, +1/q]\\). These two responses may be very meaningfully different, however if one of the alternate options chosen indicates a different interpretation of the stimulus. The inclusion of data-point B might be reasonable under some degree of visual tracing error, while the inclusion of data-point O might indicate a cartesian misinterpretation of the coordinate system. Essentially, some answer options are more incorrect than others. We want to be able to differentiate between these responses.\nTo accomplish this task, we need to sets of interpretation-consistent options for each item. Based on our prior work, we define four interpretations for which to define options. We can think of these as four different answer keys, each defining the set of ‘correct’ options (those that should be selected) under each interpretation of the graph.\n\nTriangular : the (true, actually correct) triangular interpretation of the coordinate system; indicated by data points intersecting the appropriate diagonal projection from the x-axis.\nOrthogonal: the (incorrect but most common) cartesian interpretation of the coordinate system; indicated by data points intersecting an (invisible) orthogonal projection from the x-axis.\nLines-Connect: an (incorrect) interpretation that is partially-triangular, insofar as it is indicated by data points intersecting any diagonal projection from the x-axis (not necessarily the correct projection).\nSatisficing: an (incorrect) interpretation that indicated by selecting the data points nearest to the (invisible) orthogonal projection from the x-axis; indicates an orthogonal interpretation in absence of an available orthogonal intersect.\n\nTODO FIX THIS SECTION ONWARDS … RESPONSE SETS NEED NOT BE MUTUTALLY EXCLUSIVE\nThus for each item, in the graph comprehension task, we will define five sets, whose members constitute a partition of the set of answer options.\n\\[\n\\begin{align}\nQ &= \\text{the (universal) set of all answer options } \\\\\n\\\\\nT &=  \\{o:o \\:is\\:triangular  \\}, |T| \\ne 0  \\\\\nR &=  \\{o:o \\:is\\:orthogonal \\} \\\\\nL &=  \\{o:o \\:is\\:line-connecting \\} \\\\\nS &=  \\{o:o \\:is\\:satisficing \\} \\\\\n\\\\\n\\emptyset &= T \\cap R \\cap L \\cap S  \\: \\text{(the interpretation sets are disjoint)}\\\\\nD &= Q - \\{T \\cup R \\cup L \\cup S \\} , \\text{(distractors; the remaining options not consistent with any interpretation})\n\\\\\n\\end{align}\n\\]\nFor example, for the following sample stimuli, TODO IMAGE\n\\[\n\\begin{align}\nQ &= \\{a, b, c, d, e, f, g \\} \\\\\n  &= \\{ \\{a \\}\\}, \\{b\\}, \\{c,d\\}, \\{e\\},  \\{f,g\\}\\} \\\\\n\\\\\nT &= \\{ a \\} \\\\\nR &= \\{ b \\} \\\\\nL &= \\{ c,d \\} \\\\\nS &= \\{ e \\} \\\\\nD &= \\{ f, g\\} \\\\\n\\end{align}\n\\]\nTo capture this important source of variation, we can apply the idea behind the partial scoring \\([-1/q, +1/p]\\) scheme in combination with the response option subgroups given by the graph interpretations to produce a single score (scaled from \\(-1\\) to \\(+1\\)) that captures the nature of the respondent’s partial knowledge.\nA Discriminant Score will offer:\n\n+1 for a complete triangular response\n-1 for a complete orthogonal response\n+/- fraction of complete triangular or orthogonal response\n0 for non-strategy responses\n0 for blank (empty) responses\n\n\\[\n  \\begin{align}\n\\text{Score}_{discriminant} &= 0 + 1*(t_s / t) - 1 * (r_s / r) + 0*(d_s / d) \\\\\n&= (t_s / t) - (r_s / r)\n\\tag{4}\n\\end{align}\n\\]\nWhere:\n\n\\(t = |T| =\\) number of triangular-correct options (consistent with triangular interpretation), \\(t \\gt 0\\)\n\\(r = |R| =\\) number of orthogonal-correct options (consistent with orthogonal interpretation), \\(t \\gt 0\\)\n\\(d\\) = number of non-strategy options (not consistent with either interpretation), \\(t \\gt 0\\)\n\\(n\\) = total number of response options (equals the number of checkboxes in the question; equals the number of data points in the stimulus graph)\n\\(n = t + r + d\\) (15 for scaffold phase, 18 for test phase)\n\\(t_s\\) = number of triangular-correct options selected, \\(t_s \\ge 0\\)\n\\(r_s\\) = number of orthogonal-correct options selected, \\(r_s \\ge 0\\)\n\\(d_s\\) = number of non-strategy options options selected, \\(d_s \\ge 0\\)\n\\(s\\) = number of options selected, \\(s \\ge 0\\)\n\\(s = t_s + r_s + d_s\\)\n\nTODO:: add 0.5(tversky) - 0.5(satisficing)\n\n\nCODE\nf_discrim <- function(t_s,t,r_s,r){\n  return((t_s / t) - (r_s / r))\n}"
  },
  {
    "objectID": "analysis/SGC3A/2_sgc3A_scoring.html#score-sgc-data",
    "href": "analysis/SGC3A/2_sgc3A_scoring.html#score-sgc-data",
    "title": "2  Response Scoring",
    "section": "2.3 SCORE SGC DATA",
    "text": "2.3 SCORE SGC DATA\nIn SGC_3A we are fundamentally interested in understanding how a participant interprets the presented graph (stimulus). The graph comprehensiontask asks them to select the data points in the graph that meet the criteria posed in the question. To assess a participant’s performance, for each question (q=15) we will calculate the following scores:\nAn overall, strict score:\n1. Absolute Score : using dichotomous scoring referencing true (Triangular) answer. (see 1.2)\nSub-scores, for each alternative graph interpretation\n2. Triangular Score : using partial scoring [-1/q, +1/p] referencing true (Triangular) answer key.\n3. Orthogonal Score : using partial scoring [-1/q, +1/p] referencing (incorrect Orthogonal) answer key.\n4. Tversky Score : using partial scoring [-1/q, +1/p] referencing (incorrect connecting-lines strategy) answer key.\n5. Satisficing Score : using partial scoring [-1/q, +1/p] referencing (incorrect satisficing stategy) answer key.\n\n2.3.1 Prepare Answer Keys\nWe start by importing the answer keys for each stimulus set. For each stimulus set (defined by condition+task phase) an answer key file exist that defines the set of response options that indicate each graph interpretation.\n\n\nCODE\nkey_111_raw <- read_csv('keys/SGC3A_scaffold_111_key.csv') %>% mutate(condition = 111, phase = \"scaffold\")\nkey_121_raw <- read_csv('keys/SGC3A_scaffold_121_key.csv')%>% mutate(condition = 121, phase = \"scaffold\")\nkey_test_raw <- read_csv('keys/SGC3A_test_key.csv')%>% mutate(condition = \"\", phase = \"test\")\n\n#TODO decompose tversky responses for key_121_raw and key_test_raw\n\nkeys_raw <- rbind(key_111_raw) #, key_121_raw, key_test_raw)\nrm(key_111_raw, key_121_raw, key_test_raw)\n\n\nIn order to calculate scores using the \\([-1/q, +1/p]\\) algorithm, we need to define the subset of all response options (set N) that should be selected (set P) and should not be selected (set Q). In order to calculate subscores for each graph interpretation (triangular, orthogonal) we must define these sets independently for each interpretation. The answer key files the ‘correct’ answer (i.e. set P) for each interpretation, for each question. We must derive the contents of set Q based on set\n\nSET N = all response options (superset) \\(N\\)\nSET P = all options that should be selected (rewarded as +1/p) \\(P \\subset N\\)\nSET A = items that should not be selected, but if they are, don’t penalize (ignored). These include any options referenced in the question (i.e. select shifts that start at the same time as X; don’t penalize if they also select ‘X’), as well as options within 0.5hr offset from the data point to accommodate reasonable visual errors.\\(A \\subset N\\)\nSET Q = all options that should NOT be selected (penalized as -1/q). These are options that weren’t referenced in the question and aren’t within 0.5hr of the correct option. \\(Q = N - (P \\cup A)\\)\n\n\n2.3.1.1 Triangular Key\nFirst we construct the key set based on the ‘Triangular’ interpretation (ie. the actually correct answers). TODO EXAMPLE IMAGE\n\n\nCODE\nverify = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TRIANGULAR KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tri <- keys_raw %>% \n  select(Q, condition, OPTIONS, TRIANGULAR, TRIve, ALSO) %>% \n  mutate(\n    \n    #replace NAs \n    TRIve = str_replace_na(TRIve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TRIANGULAR,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TRIve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DEFINE SETS N, P, A\nfor (x in 1:nrow(keys_tri)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tri[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tri[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tri[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tri[x,'set_q'] = Q\n  keys_tri[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tri <- keys_tri %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n#cleanup \nrm(N,A,P,Q,n_q,s,x,tempunion)\n\n\nThis leaves us a dataframe keys_tri that define the sets of response options consistent with the triangular graph interpretation.\nTo verify we have generated the correct sets, we verify that for each row (question), each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE TODO TROUBLESHOOT FALSE; THINK THIS IS BECAUSE KEY FILE IS INCOMPLETE FOR ALL BUT RAW 111\n\n\n2.3.1.2 Orthogonal Key\nTODO EXAMPLE IMAGE Next we construct the key set based on the ‘Orthogonal’ interpretation. ::: {.cell}\n\nCODE\nverify = c() #sanity check\n\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT ORTHOGONAL KEY SET\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_orth <- keys_raw %>% \n  select(Q, condition, OPTIONS, ORTHOGONAL, ORTHve, ALSO) %>% \n  mutate(\n    \n    #replace NAs \n    ORTHve = str_replace_na(ORTHve,\"\"),\n    ALSO = str_replace_na(ALSO,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = ORTHOGONAL,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(ORTHve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_orth)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_orth[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_orth[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_orth[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_orth[x,'set_q'] = Q\n  keys_orth[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_orth <- keys_orth %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n:::\nThis leaves us a dataframe keys_orth that define the sets of response options consistent with the orthogonal graph interpretation.\nTo verify we have generated the correct sets, we verify that for each row (question), each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE TODO TROUBLESHOOT FALSE; THINK THIS IS BECAUSE KEY FILE IS INCOMPLETE FOR ALL BUT RAW 111\n\n\n2.3.1.3 Tversky Keys\nTODO EXAMPLE IMAGE Next we construct the key set based on the ‘Tversky’ interpretation. The term Tversky is shorthand for a partial interpretation of the coordinate system where subjects select a set of responses that lay along a connecting line from the referenced data point or referenced time for that item. The term is named for Barbara Tversky based on her work on graphical primitives (e.g. “lines connect”).\n\n\nCODE\nverify_max = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-MAX\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_max <- keys_raw %>% \n  select(Q, condition, OPTIONS, ALSO, TV_max, TV_max_ve) %>% \n  mutate(\n  \n    #replace NAs \n    ALSO = str_replace_na(ALSO,\"\"),\n    TV_max = str_replace_na(TV_max,\"\"),\n    TV_max_ve = str_replace_na(TV_max_ve,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_max,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_max_ve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_max)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_max[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_max[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_max[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_max[x,'set_q'] = Q\n  keys_tversky_max[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_max[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_max <- keys_tversky_max %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\nverify_tversky_start = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-START\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_start <- keys_raw %>% \n  select(Q, condition, OPTIONS, ALSO, TV_start, TV_start_ve) %>% \n  mutate(\n  \n    #replace NAs \n    ALSO = str_replace_na(ALSO,\"\"),\n    TV_start = str_replace_na(TV_start,\"\"),\n    TV_start_ve = str_replace_na(TV_start_ve,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_start,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_start_ve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_start)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_start[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_start[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_start[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_start[x,'set_q'] = Q\n  keys_tversky_start[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_start[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_start <- keys_tversky_start %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\nverify_tversky_end = c() #sanity check\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-END\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_end <- keys_raw %>% \n  select(Q, condition, OPTIONS, ALSO, TV_end, TV_end_ve) %>% \n  mutate(\n  \n    #replace NAs \n    ALSO = str_replace_na(ALSO,\"\"),\n    TV_end = str_replace_na(TV_end,\"\"),\n    TV_end_ve = str_replace_na(TV_end_ve,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_end,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_end_ve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_end)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_end[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_end[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_end[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_end[x,'set_q'] = Q\n  keys_tversky_end[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_end[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_end <- keys_tversky_end %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\nverify_tversky_duration = c()\n##——————————————————————————————————————————————————————————————————————\n##CONSTRUCT TVERSKY KEY SET for TVERSKY-DURATION\n##——————————————————————————————————————————————————————————————————————\n#1. DEFINE SETS N, P, A\nkeys_tversky_duration <- keys_raw %>% \n  select(Q, condition, OPTIONS, ALSO, TV_dur, TV_dur_ve) %>% \n  mutate(\n  \n    #replace NAs \n    ALSO = str_replace_na(ALSO,\"\"),\n    TV_dur = str_replace_na(TV_dur,\"\"),\n    TV_dur_ve = str_replace_na(TV_dur_ve,\"\"),\n    \n    #P options that SHOULD be selected (rewarded)\n    set_p = TV_dur,\n    n_p = nchar(set_p), #number of true-select options\n    \n    #A options that are ignored if selected \n    set_a = str_c(TV_dur_ve,ALSO, sep=\"\"),\n    n_a = nchar(set_a),\n    \n    #N store all answr options (superset)\n    set_n = OPTIONS,  \n    n_n = nchar(set_n)\n  \n) %>% select(Q, condition, set_n, set_p, set_a, n_n, n_p, n_a)\n\n#2. DO THE STUFF THAT'S EASIER IN A LOOP\nfor (x in 1:nrow(keys_tversky_duration)) {\n  \n  #UNWIND STRINGS FOR SETDIFF\n  #n all answer options\n  N = keys_tversky_duration[x,'set_n'] %>% pull(set_n) %>% strsplit(\"\") %>% unlist()\n  #p correct-select answer options\n  P = keys_tversky_duration[x,'set_p'] %>% pull(set_p) %>% strsplit(\"\") %>% unlist()\n  #a ignore-select answer options (should not be selected, but if they are, don't penalize)\n  A = keys_tversky_duration[x,'set_a'] %>% pull(set_a) %>% strsplit(\"\") %>% unlist()\n  \n  #Q = N - (P+A)\n  #answers that are penalized (at -1/q) if selected \n  s = union(P,A) #rewarded plus ignored \n  # s = union(s,X) # + trapdoor \n  Q = setdiff(N,s) # = penalized at -1/q when selected \n  \n  #save set to dataframe\n  Q = str_c(Q, collapse=\"\")\n  n_q = nchar(Q)\n  keys_tversky_duration[x,'set_q'] = Q\n  keys_tversky_duration[x,'n_q'] = n_q\n  \n  #verify each element in N is included in one and only one of P,A,Q\n  tempunion = union(s,Q) %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  N = N %>% str_c(collapse=\"\") %>% strsplit(\"\") %>% unlist()\n  verify_tversky_duration[x] = setequal(tempunion,N)\n}\n\n#3. reorder cols for ease of use\nkeys_tversky_duration <- keys_tversky_duration %>% select(Q, condition, set_n, set_p, set_a, set_q, n_n, n_p, n_a, n_q) %>% mutate(verify = n_p + n_a + n_q)\n\n\nThis leaves us four dataframes, each corresponding to a different variant of a ‘lines connecting to reference point’ strategy.\n- keys_tversky_max : the superset of lines connecting options - keys_tversky_start : lines connecting to the rightward diagonal (start time) of the reference point - keys_tversky_end: lines connecting to the leftward diagonal (end time) of the reference point - keys_tversky_duration: lines connecting to the horizontal y-intercept (duration) of the reference point\nTo verify we have generated the correct sets, we verify that for each row (question), each response in N is included in either set P, A or Q (once and only once).\nTRUE, TRUE, TRUE, TRUE, TRUE TODO TROUBLESHOOT FALSE; THINK THIS IS BECAUSE KEY FILE IS INCOMPLETE FOR ALL BUT RAW 111 TRUE, TRUE, TRUE, TRUE, TRUE TRUE, TRUE, TRUE, TRUE, TRUE TRUE, TRUE, TRUE, TRUE, TRUE\n\n\n\n2.3.2 Score Items\nNext, we import the item-level response data. For each row in the item level dataset (indicating the response to a single question-item for a single subject), we compare the raw response df_items$response with the answer keys in each interpretation (keys_orth, keys_tri), then using those sets, determine the number of correctly selected items(p) and incorrectly selected items (q), which in turn are used to calculate partial[-1/q, +1/p] scores for each interpretation. The resulting scores are then stored on each item, and can be used to determine which graph interpretation the subject held.\nscore_TRI (how triangular was the subject’s response?) score_ORTH(how orthogonal was the subject’s response)\n\n\nCODE\ndf_test <- read_rds('data/sgc3a_items.rds')\ndf_items <- read_rds('data/sgc3a_items.rds')\ndf_items <- df_items %>% filter(q < 6) %>% filter(condition == 111)\n\n\nnote: this cell takes several minutes to run and is not optimized\n\n\nCODE\n#CALCULATE THE TRIANGULAR, ORTHOGONAL OR TVERSKIAN SUBSCORES FROM KEYFRAME\ncalc_sub_score <- function(keyframe, question, condition, response){\n  \n  #TODO verify type is in df_keymap$score\n  #type must be one of \"tri\", \"orth\", \"tv_max\", \"tv_start\", \"tv_end\", \"tv_duration\", \"both\", \"ref\"\n  #keyframe must be one of keys_raw, keys_tri, \"keys_orth\", \"keys_tversky_max\", \"keys_tversky_start\", \"keys_tversky_end\", \"keys_tversky_duration\", \n  \n  #STEP 1 GET KEY \n  if (question < 6) #for q1 - q5 find key for question by condition\n  {\n    # print(keyframe)\n    #GET KEY FOR THIS SCORE TYPE, QUESTION AND CONDITION\n    p =  keyframe %>% filter(Q == question) %>% filter(condition == condition) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    q =  keyframe %>% filter(Q == question) %>% filter(condition == condition) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    pn = keyframe %>% filter(Q == question) %>% filter(condition == condition) %>% select(n_p)\n    qn = keyframe %>% filter(Q == question) %>% filter(condition == condition) %>% select(n_q) \n\n  } else {\n    #GET KEY FOR THIS SCORE TYPE, QUESTION \n    p =  keyframe %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n    q =  keyframe %>% filter(Q == question) %>% select(set_q) %>% pull(set_q) %>% str_split(\"\") %>% unlist()\n    pn = keyframe %>% filter(Q == question) %>% select(n_p)\n    qn = keyframe %>% filter(Q == question) %>% select(n_q) \n  }\n  \n  #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n  ps = length(intersect(r,p))\n  qs = length(intersect(r,q))\n  # df_items[x,'tri_ps'] = tri_ps\n  # df_items[x,'tri_qs'] = tri_qs\n  \n  #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n  x = f_partialP(ps,pn,qs,qn)\n  \n  #cleanup\n  rm(p,q,pn,qn,ps,qs)\n  \n  return(x) #true correct, trues, false correct, falses\n  \n}\n\n#CALCULATE THE REFERENCE SCORES\ncalc_ref_score <- function(question, condition, response){\n  \n  #STEP 1 GET KEY for this question and condition\n  if (question < 6) #for q1 - q5 find key for question by condition\n  {\n     #1. GET reference point from ALSO column in raw keys\n     ref_p = keys_raw %>% filter(Q == question) %>% filter(condition == condition) %>% select(ALSO) %>% pull(ALSO) %>% str_split(\"\") %>% unlist()\n     #2. get all possible options [doesn't matter which key, they're all the same]\n     ref_n =keys_raw %>% filter(Q == question) %>% filter(condition == condition) %>% select(OPTIONS) %>% pull(OPTIONS) %>% str_split(\"\") %>% unlist() \n     #3. calc answers that aren't the reference point\n     ref_q = setdiff(ref_n,ref_p)\n     #4. cal number of ps and qs \n     ref_pn = length(ref_p)\n     ref_qn = length(ref_q)\n  } else {\n    #get REFERENCE POINT keys for this question\n     #1. GET reference point from ALSO column in raw keys\n     ref_p = keys_raw %>% filter(Q == question) %>% select(ALSO) %>% pull(ALSO) %>% str_split(\"\") %>% unlist()\n     #2. get all possible options [doesn't matter which key, they're all the same]\n     ref_n =keys_raw %>% filter(Q == question) %>% select(OPTIONS) %>% pull(OPTIONS) %>% str_split(\"\") %>% unlist() \n     #3. calc answers that aren't the reference point\n     ref_q = setdiff(ref_n,ref_p)\n     #4. cal number of ps and qs \n     ref_pn = length(ref_p)\n     ref_qn = length(ref_q)\n  }\n    \n  #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n  ref_ps = length(intersect(response,ref_p))\n  ref_qs = length(intersect(response,ref_q))\n  # df_items[x,'both_ps'] = ref_ps\n  # df_items[x,'both_qs'] = ref_qs     \n \n  #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n  x = f_partialP(ref_ps,ref_pn,ref_qs,ref_qn)\n  \n  #cleanup\n  rm(ref_p,ref_q,ref_pn,ref_qn,ref_ps,ref_qs)   \n  \n  return(x) #true correct, trues, false correct, falses\n\n}\n\n\n#CALCULATE SCORE BASED ON UNION OF ORTH & TRI (SUBJECT SELECTS BOTH ANSWERS )\ncalc_both_score <- function(question, condition, response){\n  \n  #STEP 1 GET KEY for this question and condition\n  if (question < 6) #for q1 - q5 find key for question by condition\n  {\n     #grab the tri and orth keys for this question as well as N option set\n     tri_p =  keys_tri %>%  filter(Q == question) %>% filter(condition == condition) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_p = keys_orth %>% filter(Q == question) %>% filter(condition == condition) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     set_n =  keys_tri %>%  filter(Q == question) %>% filter(condition == condition) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n     #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n     both_p = union(tri_p, orth_p) #the selection of tri and p\n     #2. calc answers that should't be selected as diffrence between N [same for all keys] and both_p\n     both_q = setdiff(set_n,both_p)\n     both_pn = length(both_p)\n     both_qn = length(both_q)\n  } else{\n    \n     #grab the tri and orth keys for this question as well as N option set\n     tri_p =  keys_tri %>%  filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     orth_p = keys_orth %>% filter(Q == question) %>% select(set_p) %>% pull(set_p) %>% str_split(\"\") %>% unlist()\n     set_n =  keys_tri %>%  filter(Q == question) %>% select(set_n) %>% pull(set_n) %>% str_split(\"\") %>% unlist() \n     #1. calc answer that is both tri and orth and only these --> union of tri_p and orth_p\n     both_p = union(tri_p, orth_p) #the selection of tri and p\n     #2. calc answers that shouldn't be selected as difference between N [same for all keys] and both_p\n     both_q = setdiff(set_n,both_p)\n     both_pn = length(both_p)\n     both_qn = length(both_q)\n  }\n    \n  #STEP 2 CALC INTERSECTIONS BETWEEN RESPONSE AND KEY\n  both_ps = length(intersect(response,both_p))\n  both_qs = length(intersect(response,both_q))\n  # df_items[x,'both_ps'] = both_ps\n  # df_items[x,'both_qs'] = both_qs\n \n  #STEP 3 CALC f_partialP schema SCORE FOR THIS INTERSECTION \n  x = f_partialP(both_ps,both_pn,both_qs,both_qn)\n  \n  #cleanup\n  rm(both_p,both_q,both_pn,both_qn,both_ps,both_qs)   \n  \n  return(x) #true correct, trues, false correct, falses\n  \n}\n\n\n\n\nCODE\n#CALCULATE SUBSCORES (in loop)\nfor (x in 1:nrow(df_items)) {\n  \n  #get properties of the RESPONSE ITEM\n  qu = df_items[x,'q']\n  cond = df_items[x,'condition']\n  r = df_items[x,'response'] %>% str_split(\"\") %>% unlist()\n\n  #calculate the main subscores\n  df_items[x,'score_TRI'] = calc_sub_score(keys_tri, qu, cond, r)\n  df_items[x,'score_ORTH'] = calc_sub_score(keys_orth, qu, cond, r)\n  df_items[x,'score_TV_max'] = calc_sub_score(keys_tversky_max, qu, cond, r)\n  df_items[x,'score_TV_start'] = calc_sub_score(keys_tversky_start, qu, cond, r)\n  df_items[x,'score_TV_end'] = calc_sub_score(keys_tversky_end, qu, cond, r)\n  df_items[x,'score_TV_duration'] = calc_sub_score(keys_tversky_duration, qu, cond, r)\n\n  # #calculate special subscores\n  df_items[x,'score_REF'] = calc_ref_score(qu, cond, r)\n  df_items[x,'score_BOTH'] = calc_both_score(qu, cond, r)\n\n}\n\n  #CALCULATE ABSOLUTE SCORES\n  #calculate absolute scores dichotomous\n  df_items$score_ABS = as.integer(df_items$correct) \n  \n  #niceABS indicates if the response is correct without penalizing the allowable triangular options(ie. the ref point)\n  df_items$score_niceABS  <- as.integer((df_items$score_TRI == 1))\n \n  #niceABS indicates if the response is correct without penalizing the allowable triangular options(ie. the ref point)\n  # df_items[x,'score_niceABS'] = (df_items[x,'score_TRI'] == 1)\n  # df_items[x,'score_niceABS'] = as.integer(df_items[x,'score_niceABS']) \n\n\n\n\n2.3.3 Derive Interpretation\nFinally, we compare the interpretation subscores and decide which is highest. This indicates the interpretation that the individual’s response most closely approximates. TODO HANDLE EQUAL COLUMNS TODO HANDLE BLANKS TODO HANDLE CONFUSION\n\nis it blank –> blank\nis it triangular?\nis it orthogonal?\nis it tversky?\nis it satisfice? ::: {.cell}\n\n\nCODE\ndf_items$best <- \"?\" #set to null\nthreshold_range = 0.5 #set required variance in subscores to be discriminant\nthreshold_frenzy = 7\n\n\n\n# df_items <- backup\nfor (x in 1:nrow(df_items)) {\n  \n  #CALCULATE MAX TVERSKY SUBSCORE\n  #first reshape subscores \n  t = df_items[x,] %>% select(score_TV_max, score_TV_start, score_TV_end, score_TV_duration)\n  t.long = gather(t,score, value, 1:4)\n  \n  #replace empty scores with NA so we can ignore them\n  #sometimes TVERSKY subscores are blank if they don't apply for that question \n  t.long[t.long == \"\"] = NA\n\n  df_items[x,'score_TVERSKY'] = as.numeric(max(t.long$value,na.rm = TRUE))\n  df_items[x,'tv_type'] = t.long[which.max(t.long$value),'score']\n  \n  \n  #NOW CALCULATE VARIANCE IN SUBSCORES\n  s = df_items[x,] %>% select(score_TRI, score_ORTH, score_TVERSKY)\n  s.long = gather(s,score, value, 1:3)\n  \n  #calculate the range between highest and lowest scores \n  r = as.numeric(range(s.long$value,na.rm = TRUE))\n  r = diff(r)\n  df_items[x,'range'] = r\n  # print(s.long)\n  \n  #DISCRIMINANT BETWEEN SUBSCORES TO PREDICT BEST FIT INTERPRETATION\n  \n  #is the response BLANK?\n  if( df_items[x,'num_o'] == 0) {df_items[x,'best'] = \"blank\"}\n  \n  #is the response a 'frenzy'? ie. they selected more than half of the datapoints?\n  else if( df_items[x,'num_o'] > threshold_frenzy) {df_items[x,'best'] = \"frenzy\"}\n  \n  #otherwise does the response perfectly match both TRI AND ORTH?\n  else if( df_items[x,'score_BOTH'] == 1) {df_items[x,'best'] = \"TRI + ORTH\"}\n  \n  #otherwise does the response perfectly match the reference point\n  else if( df_items[x,'score_REF'] == 1) {df_items[x,'best'] = \"reference\"}\n\n  #otherwise try to derive from subscores\n  else {\n   \n   #is there enough variance between scores to be able to differentiate?\n   \n    if (r < threshold_range) {\n      #then we can't predict the interpretation\n    }\n    else {\n      #if there IS enough variance to be predictive, take the highest subscore\n      df_items[x,'best'] = s.long[which.max(s.long$value),'score']\n    }\n  }\n  \n  \n  #REFERENCE CODE FOR FINDING MAX COLUMNS [to avoid reshaping dataframe to long]\n  # max = max.col(df_items[x,] %>% select(score_TRI,score_ORTH, score_TV_max, score_TV_start, score_TV_end), ties.method = \"first\")\n  # df_items[x,'best'] = names[max]\n  \n}\n\n#cleanup \nrm(t, t.long, s, s.long)\n\ndf_items %>% filter(q==2) %>% filter(response ==\"D\") %>% select(q, response, score_TRI, score_ORTH, score_TVERSKY, score_REF, range, best)\n\n\n  q response score_TRI score_ORTH score_TVERSKY score_REF range      best\n1 2        D         0          0             0         1     0 reference\n\n:::\n\n\nCODE\n# test <- df_items %>% filter(q<6) %>% filter(condition == 111) %>% select(q, response, score_TRI, score_ORTH, score_TVERSKY, score_BOTH, score_REF, range, best)\n\n# gf_histogram(~score_TRI, data = test)\n# gf_histogram(~score_ORTH, data = test)\n# gf_histogram(~score_ABS, data = test)\n# gf_histogram(~score_niceABS, data = test)"
  }
]